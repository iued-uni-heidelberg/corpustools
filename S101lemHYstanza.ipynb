{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8kESyrmIuaPuWIkP5vrwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S101lemHYstanza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armenian lemmatization with Stanza"
      ],
      "metadata": {
        "id": "skix7t6sFaZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading evaluation sets\n",
        "- 420 words: test with about 420 words of Armenian text\n",
        "- Armenian \"Brown-type\" corpus b"
      ],
      "metadata": {
        "id": "fFBRX6lTFfcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "!wget https://heibox.uni-heidelberg.de/f/ce6096da570f47b99500/?dl=1"
      ],
      "metadata": {
        "id": "m549clSLFHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "!mv index.html?dl=1 evaluation-set-v01.txt"
      ],
      "metadata": {
        "id": "eI_j8KDdFRCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/a847a12bffd4491f9070/?dl=1\n"
      ],
      "metadata": {
        "id": "IWwqNLkxPMfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 TED2020-dehy-hy-aa"
      ],
      "metadata": {
        "id": "0QkNxyeRPb7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### downloading Armenian Wikipedia\n",
        "!wget https://heibox.uni-heidelberg.de/f/d1f866a61bd545318213/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles.txt.gz\n",
        "!gunzip hywiki-20221101-pages-articles.txt.gz"
      ],
      "metadata": {
        "id": "j_-b-YYGq8bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-20221101-pages-articles.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQMJimofsTMd",
        "outputId": "b72457fb-481d-43e0-ce2e-e316e72ec3b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2446411  56341167 803098410 hywiki-20221101-pages-articles.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing stanza"
      ],
      "metadata": {
        "id": "i__aUXulFkw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdzVArLUF3cb"
      },
      "outputs": [],
      "source": [
        "!pip install spacy-stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import spacy_stanza\n"
      ],
      "metadata": {
        "id": "-VN9g4N4GAR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing English stanza (optional)"
      ],
      "metadata": {
        "id": "w6Kfwj63FzYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional\n",
        "# Download the stanza model if necessary\n",
        "stanza.download(\"en\")\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = spacy_stanza.load_pipeline(\"en\")\n",
        "\n",
        "doc = nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
        "print(doc.ents)"
      ],
      "metadata": {
        "id": "dEA7KJdZPrWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### downloading and testing Armenian stanza"
      ],
      "metadata": {
        "id": "HGyKxEJNGG8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"hy\")\n"
      ],
      "metadata": {
        "id": "xq53mDsUGumV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_hy = spacy_stanza.load_pipeline(\"hy\")"
      ],
      "metadata": {
        "id": "KZKOs0aVG8Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "doc = nlp_hy(\"ՄԱՐԴՈՒ ԻՐԱՎՈՒՆՔՆԵՐԻ ՀԱՄԸՆԴՀԱՆՈՒՐ ՀՌՉԱԿԱԳԻՐ. ՆԵՐԱԾԱԿԱՆ. Քանզի մարդկային ընտանիքի բոլոր անդամներին ներհատուկ արժանապատվությունըև հավասար ու անօտարելի իրավունքները աշխարհի ազատության, արդարության ու խաղաղության հիմքն են.\")"
      ],
      "metadata": {
        "id": "m022wp2JHvOO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n"
      ],
      "metadata": {
        "id": "LPhSOX15ICmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### full analysis of the file (optional)\n",
        "- includes dependency parsing"
      ],
      "metadata": {
        "id": "NVyvpuMDQXYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "with open('/content/TED2020-dehy-hy-aa', 'r', encoding='utf-8') as infile, open('/content/TED2020-dehy-hy-aa-ANALYSIS-full-v01.txt', 'w') as outfile:\n",
        "    # read sample.txt an and write its content into sample2.txt\n",
        "    outfile.write(\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{LAncestors}\\n\")\n",
        "    for line in infile:\n",
        "        line = line.strip()\n",
        "        doc = nlp_hy(line)\n",
        "        # outfile.write(line + '\\n')\n",
        "        for token in doc:\n",
        "            LAncestors = list(token.ancestors)\n",
        "            print(str(LAncestors))\n",
        "            try:\n",
        "                SLAncestors = str(list(token.ancestors))\n",
        "                parent = LAncestors[0]\n",
        "                parentLem = parent.lemma_\n",
        "            except:\n",
        "                parentLem = \"NONE\"\n",
        "            outfile.write(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{SLAncestors}\\n\")\n",
        " "
      ],
      "metadata": {
        "id": "HJdW66EmJI2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### function for lemmatization"
      ],
      "metadata": {
        "id": "_w7MrFvNQqxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parseFile(iFileName, oFileName, nlp_model = nlp_hy):\n",
        "    with open(iFileName, 'r', encoding='utf-8') as infile, open(oFileName, 'w') as outfile:\n",
        "        # read sample.txt an and write its content into sample2.txt\n",
        "        outfile.write(\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        "        c = 0\n",
        "        for line in infile:\n",
        "            c+=1\n",
        "            if c%10 == 0: print(str(c))\n",
        "            line = line.strip()\n",
        "            doc = nlp_model(line)\n",
        "            # outfile.write(line + '\\n')\n",
        "            for token in doc:\n",
        "                LAncestors = list(token.ancestors)\n",
        "                # print(str(LAncestors))\n",
        "                try:\n",
        "                    SLAncestors = str(list(token.ancestors))\n",
        "                    parent = LAncestors[0]\n",
        "                    parentLem = parent.lemma_\n",
        "                except:\n",
        "                    parentLem = \"NONE\"\n",
        "                outfile.write(f\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        " \n",
        "    return\n"
      ],
      "metadata": {
        "id": "QT0tpHwjY4O5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### command to lemmatize the file"
      ],
      "metadata": {
        "id": "FJoxNaZ7vfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('/content/TED2020-dehy-hy-aa', '/content/TED2020-dehy-hy-aa--lemmatization-v01.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "rgdb1fl3a6F4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf97ebf0-cf21-47d7-a370-efd54489e93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('hywiki-20221101-pages-articles.txt', 'hywiki-20221101-pages-articles.vert', nlp_hy)"
      ],
      "metadata": {
        "id": "lrSvU_NbsZ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking OCR errors\n",
        "### wikipedia lemmatized --> frequency dictionary "
      ],
      "metadata": {
        "id": "Disi8bxMhOD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/5b3213f991f84ca496ba/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles-v03.vert"
      ],
      "metadata": {
        "id": "lhs5GwRihMxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-20221101-pages-articles-v03.vert"
      ],
      "metadata": {
        "id": "xJlX-J5ij72h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/350790e66ca24efdab1a/?dl=1\n",
        "!mv index.html?dl=1 hy-texts-vert.tgz \n",
        "!tar xvzf hy-texts-vert.tgz"
      ],
      "metadata": {
        "id": "dtxtpTo_mTSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Arm_ABBY.txt"
      ],
      "metadata": {
        "id": "2LPlwmpYsSt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('Parfum_Arm_ABBY.txt', 'Parfum_Arm_ABBY.vert.txt', nlp_hy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnrYlLB_uRsH",
        "outputId": "88bf3621-464d-4feb-db1d-6449890d91ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "20\n",
            "30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հարցնում', 'են', '՝', 'ինչ', '՞', 'է', 'եդելնրա', 'հետ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ինչ', '՞', 'էնա', 'անում', 'դանակով', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Սա', 'ինչ', '՞', 'է', '–', 'ասաց', 'Տերյեն', 'և', ',', 'կռանալով', 'զամբյուղի', 'վրա', ',', 'հոտոտեց', 'այն', ',', 'քանի', 'որ', 'ենթադրում', 'էր', 'դրա', 'մեջ', 'ինչ', '-', 'որ', 'ուտելիք', 'հայտնաբերել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Նրա', 'համար', 'վնասակար', 'չի', 'լինի', ',', '–', 'շշպռեց', 'ժան', '–', 'նան', ',', '–', 'իսկ', 'ինձ', 'համար', 'կլինի', '։', 'Ես', 'նիհարել', 'եմ', 'տասը', 'ֆունտ', ',', 'չնայած', 'կերել', 'եմ', 'երեք', 'հոգու', 'փոխարեն', '։', 'Իսկ', 'հանուն', 'ինչի', '՞', '։', 'Հանուն', 'շաբաթական', 'երեք', '<UNK>րանկի', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'մյուս', 'կողմից', ',', 'լավ', 'չէ', 'երեխային', 'դես', 'ու', 'դեն', 'նետել', '։', 'Ով', '՞', 'գիտի', ',', 'օգտակար', 'կլինի', '\"', 'նրան', 'արդյոք', 'այդ', 'կաթը', '։', 'Աանկիկը', ',', 'հասկանում', 'ես', ',', 'սովորել', 'է', 'քո', 'կրծքի', 'հոտին', 'ու', 'քո', 'սրտի', 'բաբախյունին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ապա', 'որքան', '՞', 'ես', 'պահանջում', ',', '–', 'գոռաց', 'Տերյեն', '։', '–', 'Հինգ', 'ֆրանկը', 'Նման', 'չնչին', 'գործի', 'դիմաց', ',', 'ինչպիսին', 'Նորածնին', 'կերակրելն', 'է', ',', 'մի', 'կույտ', 'փող', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'ինչու', '՞', ',', 'սիրելիս', ',', '–', 'ասաց', 'Տերյեն', 'և', 'կրկին', 'մատով', 'շուռումուռ', 'տվեց', 'զամբյուղի', 'պարունակությունը', '։', '–', 'չէ', '՞', 'որ', 'սա', 'հիասքանչ', 'մանկիկ', 'է', '։', 'Այնքան', 'վարդագույն', 'է', ',', 'լաց', 'չի', 'լինում', ',', 'հանգիստ', 'է', 'քնում', ',', 'և', 'կնքված', 'էլ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Անհնար', 'է', '։', 'Բացարձակապես', 'անհնար', 'է', ',', 'որ', 'կրծքի', 'երեխան', 'դիվահար', 'լինի', '։', 'Երեխան', 'մարդ', 'չէ', ',', 'այլ', 'նախամարդ', ',', 'և', 'դեռևս', 'չի', 'տնօրինում', 'ամբողջապես', 'ձևավորված', 'հոգուն', '։', 'Հետևաբար', ',', 'սատանայի', 'համար', 'այն', 'հետաքրքրություն', 'չի', 'ներկայացնում', '։', 'Միգուցե', 'նա', 'արդեն', 'խոսում', '՛', 'է', '։', 'Միգուցե', 'նրա', 'մոտ', 'ջղաձձութթու', '՛', 'է', '։', 'Միգուցե', 'նա', 'տեղաշարու', '՛', 'է', 'սենյակի', 'իրերը', '։', 'Միգուցե', 'Նրանից', 'գարշահոտ', '՛', 'է', 'գալիս', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դե', 'տեսնում', '՛', 'ես', '։', 'Ահա', 'այն', '՝', 'նախանշանը', '։', 'Եթե', 'նա', 'դիվահար', 'լիներ', ',', 'ապա', 'նրանից', 'գարշահոտ', 'կփչեր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Որովհետև', 'նա', 'առողջ', 'է', '–', 'գոռաց', 'Տերյեն', ',', '–', 'նա', 'առողջ', 'է', ',', 'այդ', 'պատճառով', 'էլ', 'հոտ', 'չունի', '։', 'Հոտ', 'ունեն', 'միայն', 'հիվանդ', 'երեխաները', ',', 'դա', 'բոլորին', 'է', 'հայտնի', '։', 'Օրինակ', ',', 'եթե', 'երեխան', 'ջրծաղիկ', 'ունի', ',', 'նրանից', 'ձիու', 'թրիքի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'եթե', 'քութեշ', ',', 'ապա', 'հին', 'խնձորի', ',', 'իսկ', 'թոքախտավոր', 'երեխայից', 'սոխի', 'հոտ', 'է', 'գափս', '։', 'Սա', 'առողջ', 'է', '.', 'ահա', 'և', 'բոլորը', '։', 'Այդ', 'դեպքում', 'ինչու', '՛', 'պետք', 'է']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['նրանից', 'գարշահոտ', 'գա', '։', 'Միթե', '՛', 'քո', 'Աեփական', 'երեխաներից', 'գարշահոտ', 'է', 'գալիս', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ահա', ',', '֊', 'ասաց', 'բավարարված', 'Տերյեն', 'ու', 'ձեռքերը', 'կրկին', 'ծալեց', 'թիկունքում', '։', '–', 'Կնշանակի', '՝', 'սատանայի', 'հետ', 'կապված', 'խոսքը', 'մենք', 'ետ', 'ենք', 'վերցնում', '։', 'Լավ', '։', 'Իսկ', 'հիմա', 'բարի', 'եղիր', 'ինձ', 'բացատրել', 'ինչ', '՞', 'հոտ', 'է', 'գալիս', 'կրծքի', 'նորածիններից', ',', 'եթե', 'նրանցից', 'գալիս', 'է', 'այնպիսի', 'հոտ', ',', 'որպիսին', ',', 'քո', 'կարծիքով', ',', 'պետք', 'է', 'գա', '։', 'Դե', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ինչ', '՞', 'է', 'նշանակում', '«', 'լավ', '»', ',', '–', 'ողջ', 'ուժով', 'գոռաց', 'նրա', 'վրա', 'Տերյեն', '։', '–', 'Աիթե', '՞', 'քիչ', 'են', 'այնպիսի', 'բաները', ',', 'որոնք', 'լավ', 'հոտ', 'ունեն', '։', 'Փնջովնարդոսը', 'լավ', 'հոտ', 'ունի', '։', 'Ապուրի', 'միսը', 'լավ', 'հոտ', 'ունի', '։', 'Արաբական', 'այգիները', 'լավ', 'հոտ', 'ունեն', '։', 'Ես', 'ցանկանում', 'եմ', 'իմանալ', 'ինչ', '՞', 'հոտ', 'ունեն', 'նորածինները', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ինչպես', 'կարւսմեեը', '՞', ',', '–', 'հւսրցրեց', 'նա', '՝', 'ձգտելով', 'կրկին', 'վերադառնալ', 'խիստ', 'խոսելւսոճին', '։', '–', 'Կարւսմել', '։', 'Ինչ', '՞', 'ես', 'հւսսկւսնում', 'կարամելից', '։', 'Դոնե', 'մի', 'անգամ', 'կերել', '՞', 'ես', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['մինչդեռ', 'սեփական', 'բանականությունից', 'օգտվելու', 'համար', 'մարդուն', 'անհրաժեշտ', 'է', 'ինքնավստահություն', 'ու', 'հանգիստ', '։', 'Սակայն', 'նա', 'ամենավճռական', 'ձևով', 'պայքարում', 'էր', 'հասարակ', 'ժողովրդի', 'սնահավատության', 'դեմ', '։', 'Կախարդանքն', 'ու', 'խաղաթղթով', 'գուշակությունը', ',', 'հմայիլների', 'կրումը', ',', 'չար', 'աչքից', 'ազատվելը', ',', 'ոգիների', 'կախարդանքները', ',', 'լիալոանի', 'պահին', 'աճպարարությունները', '...', 'Ինչով', '՜', 'ասես', 'չէին', 'զբաղվում', 'այդ', 'մարդիկ', '։', 'Նրան', 'խորապես', 'հուսահատեցնում', 'էր', ',', 'որ', 'նմանատիպ', 'հեթանոսական', 'ավանդույթները', 'քրիստոնեական', 'կրոնի', 'առավել', 'քան', 'հազարամյա', 'գոյությունից', 'հետո', 'դեռևս', 'արմատախիլ', 'չէին', 'արվել', '։', 'Միաժամանակ', ',', 'այսպես', 'կոչված', ',', 'դիվահարության', 'ու', 'սատանայի', 'հետ', 'կապերի', 'դեպքերի', 'մեծ', 'մասը', 'էլ', 'ավելի', 'մոտիկից', 'ուսումնասիրման', 'ժամանակ', 'ներկայանում', 'էին', 'որպես', 'սնոտիապաշտական', 'ներկայացումներ', '։', 'ճիշտ', 'է', ',', 'մերժել', 'բուն', 'սատանայի', 'գոյությունը', ',', 'կասկածել', 'նրա', 'իշխանության', 'մեջ', 'այդքան', 'հեռու', 'հայր', 'Տերյեն', 'չէր', 'գնա', '.', 'նմանատիպ', 'խնդիրների', 'լուծումը', ',', 'որոնք', 'առնչվում', 'էին', 'աստվածաբանության', 'հիմքերին', ',', 'համեստ', 'ու', 'հասարակ', 'վանականի', 'գործը', 'չէր', ',', 'դրա', 'համար', 'գոյություն', 'ունեն', 'այլ', 'ատյաններ', '։', 'Մյուս', 'կողմից', '՝', 'օրվա', 'պես', 'պարզ', 'էր', ',', 'որ', ',', 'եթե', 'նման', 'կարճամիտ', 'անձնավորությունը', ',', 'ինչպիսին', 'այդ', 'ծծմայրն', 'էր', ',', 'պնդում', 'է', ',', 'որ', 'ինքն', 'ինչ', '-', 'որ', 'դիվայնություն', 'է', 'հայտնաբերել', ',', 'նշանակում', 'է', '՝', 'սատանան', 'ոչ', 'մի', 'դեպքում', 'չէր', 'կարող', 'կապված', 'լինել', 'այդ', 'գործի', 'հետ', '։', 'Հատկապես', 'այն', 'պատճառով', ',', 'որ', 'Նրան', 'թվում', 'է', ',', 'թե', 'իբր', 'ինքը', 'դա', 'հայտնաբերել', 'է', '։', 'չէ', '՞', 'որ', 'դա', 'ճշմարիտ', 'ապացույցն', 'է', 'նրա', ',', 'որ', 'ոչ', 'մի', 'դիվայնություն', 'էլ', 'իրականում', 'չկար', ',', 'սատանան', 'այն', 'աստիճան', 'հիմար', 'չէ', ',', 'որ', 'թույլ', 'տա', 'ծծմայր', 'ժ', '՝', 'ան', '–', 'Նա', 'Ռյուսիին', 'իրեն', 'բացահայտել', '։', 'Եվ', 'այն', 'էլ', 'հոտառությամբ', '։', 'Զգացմունքներից', 'ամենապարզունակի', ',', 'ամենանվաստի', 'օգնությամբ', '։', 'Կարծես', 'թե', 'դժոխքից', 'ծծմբի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'դրախտից', 'խունկի', 'ու', 'զմուռսի', '։', 'Դա', ',', 'իրոք', ',', 'ամենամութ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Ախ', '՜', ',', 'և', 'այս', 'դժբախտ', 'փոքրիկ', 'մանկիկը', '։', 'Այս', 'անմեղ', 'արարածը', '։', 'Պառկած', 'է', 'իր', 'զամբյուղում', 'ու', 'քաղցր', 'քնել', 'է', '՝', 'անտեղյակ', 'այն', 'ստոր', 'կասկածանքներին', ',', 'որոնք', 'առաջ', 'են', 'քաշվել', 'նրա', 'դեմ', '։', 'Իսկ', 'այդ', 'անպատկառ', 'անձը', 'համարձակվում', 'է', 'պնդել', ',', 'որ', 'դու', ',', 'իբր', ',', 'հոտ', 'չունես', ',', 'ինչպի', '–', 'սին', 'պետք', 'է', 'ունենան', 'մարդկային', 'մանուկները', '։', 'Եվ', 'խնչ', 'ասենք', 'մենք', 'դրա', 'վերաբերյալ', '։', '<UNK>ու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'նա', 'զգուշորեն', 'օրորում', 'էր', 'ծնկների', 'վրա', 'դրված', 'զամբյուղը', ',', 'մատով', 'շոյում', 'նորածնի', 'գլուխն', 'ու', 'մի', 'քանի', 'աեգամ', 'կրկնում', 'ղու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', ',', 'քանզի', 'կարծում', 'էր', ',', 'որ', 'այդ', 'բացականչությունը', 'հանգստացուցիչ', 'ու', 'բարերար', 'ազդեցություն', 'է', 'թողնում', 'փոքրիկների', 'վրա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Կարամելի', 'հոտ', 'պետք', 'է', 'ունենաս', ',', 'այ', 'քեզ', 'հիմարություն', ',', 'ղու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խցկեց', 'շատ', 'խոր', ',', 'այնպես', 'որ', ',', 'Նորածնի', 'բարակ', 'շիկահեր', 'մազիկները', 'խուտուտ', 'տվեցին', 'նրա', 'ռունգերը', ',', 'հոտոտեց', 'երեխայի', 'գլուխը', 'հուսալով', 'ինչ', '-', 'որ', 'հոտ', 'ներշնչել', '։', 'Նա', 'այնքան', 'էլ', 'լավ', 'չէր', 'պատկերացնում', ',', 'թե', 'ինչպիսի', 'հոտ', 'պետք', 'է', 'ունենան', 'նորածինների', 'գլուխները', '։', 'Բնականաբար', ',', 'ոչ', 'կարամելի', 'հոտ', ',', 'այդ', 'մեկը', 'պարզից', 'պարզ', 'էր', '.', 'չէ', '՞', 'որ', 'կարամելն', 'այրված', 'շաքար', 'է', ',', 'և', 'ինչպես', 'կարող', 'է', 'նորածինը', ',', 'որը', 'մինչ', 'այժմ', 'միայն', 'կաթ', 'էր', 'խմում', ',', 'այրված', 'շաքարի', 'հոտ', 'ունենալ', '։', 'Նրանից', 'կարող', 'էր', 'կաթի', 'հոտ', 'գալ', 'ծծմոր', 'կաթի', '։', 'Բայց', 'նրանից', 'կաթի', 'հոտ', 'չէր', 'գալիս', '։', 'Նրանից', 'կարող', 'էր', 'մազերի', 'հոտ', 'գալ', ',', 'մաշկի', 'ու', 'մազերի', ',', 'և', ',', 'միգուցե', ',', 'մի', 'քիչ', 'մւսնկան', 'քրտնքի', 'հոտ', '։', 'Տերյեն', 'հոտոտեց', 'և', 'այնուհետև', 'համոզեց', 'իրեն', ',', 'որ', 'զգում', 'է', 'մաշկի', ',', 'մազերի', 'ու', ',', 'միգուցե', ',', 'մանկան', 'քրտնքի', 'թույլ', 'հոտը', '։', 'Բայց', 'նա', 'ոչինչ', 'չէր', 'զգում', '։', 'Որքան', 'էլ', 'ճգնում', 'էր', '։', '«', 'Հւսվանաբար', ',', 'մանուկները', 'հոտ', 'չունեն', '»', ',', '–', 'մտածում', 'էր', 'Նւս', '։', 'Հավանաբար', ',', 'դա', 'է', 'հարցը', '։', 'Հարցն', 'այն', 'է', ',', 'որ', 'նորւսծինը', ',', 'եթե', 'նրան', 'ւցահեն', 'մաքրության', 'մեջ', ',', 'ընդհանրապես', 'չի', 'կարող', 'հոտ', 'ունենալ', ',', 'ինչպես', 'չի', 'կարող', 'խոսել', ',', 'վազել', 'կամ', 'գրել', '։', 'Այս', 'հատկանիշները', 'գալիս', 'են', 'միայն', 'տարիքի', 'հետ', '։', 'ճշգրիտ', 'ւսսած', '՝', 'մարդը', 'միայն', 'սեռական', 'հասունացման', 'շրջւսնում', 'է', 'սկսում', 'սուր', 'հոտ', 'արձակել', '։', 'Այո', ',', 'հենց', 'ւսյդպես', 'էլ', 'կա', '։', 'Այդպես', ',', 'այլ', 'ոչ', 'ւսյլ', 'կերպ', '։', 'միթե', '՞', 'իր', 'ժամանակին', 'Հորացիոսը', 'չէր', 'գրում', '.', '«', 'Պատանուց', 'այծիկի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'աղջիկը', 'բուրում', 'է', ',', 'ինչպես', 'ծաղիկը', 'սպիտակ', 'նարգիզի', '»', '։', 'Ով-ով', ',', 'բայց', 'հռոմեացիները', 'դրա', 'մասին', 'պատկերացում', 'ունեին', '։', 'Մարդկային', 'հոտը', 'մշտապես', 'մարմնի', 'հոտն', 'է', ',', 'հետևաբար', 'մեղքի', 'հոտը', '։', 'Այդ', 'դեպքում', 'ինչ', '՞', 'հոտ', 'պետք', 'է', 'ունենա', 'նորածինը', ',', 'որը', 'դեռևս', 'ոչ', 'երազով', ',', 'ոչ', 'հոգով', 'մեղավոր', 'չէ', 'մարմնական', 'մեղքի', 'մեջ', '։', 'Ինչ', '՞', 'հոտ', 'պետք', 'է', 'նւս', 'ունենա', '։', '<UNK>ու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', '։', 'Ոչ', 'մի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ձեռքը', 'փոքրիկ', 'և', 'գեղեցիկ', ',', 'դուրս', 'էր', 'ցցվել', 'կափարիչի', 'տակից', 'ու', 'ցնցվում', 'էր', 'այտի', 'ուղղությամբ', '։', 'Տերյեն', 'գորովալից', 'ժպտաց', 'ու', 'հանկարծ', 'իրեն', 'շատ', 'հարմարավետ', 'զգաց', '։', 'Ինչ', '-', 'որ', 'մի', 'պահ', 'Նա', 'նույնիսկ', 'իրեն', 'թույլ', 'տվեց', 'մի', 'ֆանտաստիկ', 'միտք', ',', 'որ', 'կարծես', 'թե', 'ինքը', 'այդ', 'երեխայի', 'հայրն', 'էր', '։', 'Կարծես', 'թե', 'ինքը', 'դարձել', 'է', 'ոչ', 'թե', 'վանական', ',', 'այլ', 'նորմալ', 'քաղքենի', ',', 'միգուցե', 'ազնիվ', 'արհեստավոր', ',', 'իրեն', 'կին', 'է', 'գտել', 'մի', 'այնպիսի', 'տաքուկ', 'կին', ',', 'որից', 'բրդի', 'ու', 'կաթի', 'հոտ', 'է', 'գալիս', ',', 'և', 'նրանք', 'ծնել', 'են', 'որդի', ',', 'և', 'ահա', 'ինքը', 'նրան', 'օրորում', 'է', 'իր', 'սեփական', 'ծնկների', 'վրա', 'իր', 'սեփական', 'երեխային', '՝', 'ղու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', 'այդ', 'միտքը', 'հաճույք', 'էր', 'պատճառում', '։', 'Նրանում', 'ինչ', '-', 'որ', 'սփոփիչներշնչանք', 'կար', '։', 'Հայրը', 'ծնկների', 'վրա', 'օրորում', 'է', 'իր', 'սեփական', 'որդուն', '՝', 'ղու', '՜', '-', 'ղու', '՜', '-', 'ղու', '՜', ',', 'պատկերը', 'հին', 'էր', '՝', 'ինչպես', 'աշխարհը', ',', 'և', 'հավերժ', 'նոր', 'ու', 'ճիշտ', 'այն', 'ժամանակից', ',', 'ինչ', 'աշխարհը', 'լուսավոր', 'է', ',', 'հենց', 'այդպես', '։', 'Տերյեի', 'սիրտը', 'ջերմացավ', ',', 'նա', 'հուզվեց', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'այդ', 'պահին', 'նորածինը', 'սկսեց', 'ժչալ', '։', 'Նա', 'կկոցեց', 'աչքերը', ',', 'լայն', 'բացեց', 'իր', 'կարմիր', 'բուկը', 'և', 'այնքան', 'զզվելի', 'ու', 'ականջ', 'ծակող', 'ձայնով', 'ծղրտաց', ',', 'որ', 'Տերյեի', 'արյունը', 'երակներում', 'սառեց', '։', 'Նա', 'առաջ', 'պարզած', 'ձեռքով', 'ցնցում', 'էր', 'զամբյուղն', 'ու', 'գոռում', '՝', 'ղու', '՜', '–', 'ղու', '՜', '–', 'ղու', '՜', ',', 'որպեսզի', 'երեխային', 'ստիպի', 'լռել', ',', 'բայց', 'վերջինս', 'ավելի', 'բարձր', 'էր', 'ոռնում', '.նրա', 'դեմքը', 'կապտել', 'էր', ',', 'ևնա', 'կարծես', 'պատրաստ', 'էր', 'ոռնոցից', 'պայթել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n",
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ուժեղ', 'խելքն', 'ու', 'փորձը', ',', 'որպեսզի', 'ընտրություն', 'կատարի', 'երկու', 'տարբերակների', 'միջև', '։', 'Բայց', ',', 'այնուամենայնիվ', ',', 'նա', 'ընտրություն', 'կատարեց', 'հօգուտ', 'աճեցողական', 'տարբերակի', ',', 'ինչպես', 'ընտրություն', 'է', 'կատարում', 'սերմնահատիկը', ',', 'պետք', '՛', 'է', 'արդյոք', 'իրեն', 'ծիլեր', 'տալ', 'թե', 'ավելի', 'լավ', 'է', 'մնալ', 'չհասունացած', '։', 'Կամ', 'ինչպես', 'տիզը', 'ծառի', 'վրա', ',', 'որին', 'նույնպես', 'կյւսնքը', 'չի', 'ւսռաջարկում', 'որևէ', 'այլ', 'տարբերւսկ', ',', 'հւսրա', '–', 'տև', 'ձմեռներից', 'բացի', '։', 'Փոքրիկ', 'այլանդակ', 'տիզն', 'իր', 'ւսրճճա', '–', 'մոխրագույն', 'մարմինը', 'փաթաթում', 'է', 'գնդի', 'պես', ',', 'որպեսզի', 'դեպի', 'արտաքին', 'աշխարհը', 'դարձնի', 'յուր', 'նվազագույն', 'մակերեսը', ',', 'նա', 'իր', 'մաշկը', 'դարձնում', 'է', 'հւսրթ', 'ու', 'խիտ', ',', 'որպեսզի', 'ոչինչ', 'չարձակի', 'դուրս', 'ոչնվազագույն', 'ճառագայթում', ',', 'ոչ', 'թեթևագույն', 'գոլորշացում', '։', 'Տիզը', 'դիտավորյալ', 'իրեն', 'փոքր', 'ու', 'աննկատ', 'է', 'դարձնում', ',', 'որւցեսզի', 'ոչ', 'ոք', 'չնկատի', 'ու', 'չտրորի', '։', 'Միայն', 'տիզը', ',', 'կենտրոնանալով', 'ինքն', 'իր', 'մեջ', ',', 'Նստում', 'է', 'իր', 'ծառի', 'վրա', '՝', 'կույր', ',', 'խուլ', 'ու', 'համր', ',', 'ու', 'միայն', 'հոտոտում', 'է', ',', 'տարիներ', 'շւսրունակ', 'մի', 'քանի', 'միլիմետր', 'հեռավորությունից', 'հոտոտում', 'է', 'մոտակայքով', 'ւսնցնող', 'ողջերի', 'արյունը', ',', 'որոնց', 'նա', 'երբեք', 'չի', 'հասնի', '։', 'Տիզը', 'թերևս', 'կարող', 'էր', 'թույլ', 'տւսլ', 'իրեն', 'ընկնել', '։', 'Նա', 'թերևս', 'կւսրող', 'էր', 'թույլ', 'տալ', 'իրեն', 'ընկնել', 'անտառի', 'հողին', ',', 'իր', 'փոքրազույն', 'ոտիկներով', 'սողալ', '-', 'անցնել', 'մի', 'քանի', 'միլիմետր', 'այս', 'կւսմ', 'այն', 'կողմ', 'ու', 'թւսղվելչոր', 'տերևների', 'մեջ', 'մեռնելու', ',', 'և', 'ոչ', 'ոք', 'նրա', 'համար', 'չէր', 'ափսոսա', '։', 'Ասւո', '–', 'ծան', 'է', 'հւսյտնի', ',', 'որ', 'ոչ', 'ոք', '։', 'Բայց', 'տիզը', 'հւսմւսռ', 'է', ',', 'տոկուն', 'ու', 'գւսրշելի', ',', 'ծւցտվել', 'է', ',', 'աւցրում', 'է', 'ու', 'սւցասում', '։', 'Սպւսսում', 'է', ',', 'մինչև', 'որ', 'բւսրձրագույն', 'աստիճանի', 'անհավւսնւսկւսն', 'դիւց', '–', 'կածն', 'ուղիղ', 'իր', 'մոտ', '՝', 'ծառի', 'ւոակ', 'բերի', 'որևիցե', 'կենդւսնու', 'տեսքուէ', 'արյուն', '։', 'Եվ', 'միայն', 'այդ', 'ժւսմանւսկ', 'է', 'նա', 'հրւսժար', '–', 'վում', 'իր', 'զարտնիությունից', ',', 'պոկվում', 'է', 'տեղից', 'ու', 'կառչում', ',', 'ներպտուտակվում', ',', 'խրվում', 'օտար', 'մւսրմնի', 'մեջ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n",
            "170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', 'Աստել', 'էր', 'ոտքերը', 'մեկնած', 'փայտերի', 'վրա', '.', 'թիկունքով', 'հենվելով', 'ցախանոցի', 'պատին', '՝', 'նա', 'փակել', 'էր', 'աչքերն', 'ու', 'չէր', 'շարժվում', '։', 'Նա', 'ոչինչ', 'չէր', 'տեսնում', ',', 'ոչինչ', 'չէր', 'լսում', 'ու', 'չէր', 'զգում', '։', 'Նա', 'ուղղակի', 'ներշնչում', 'էր', 'կւայ', '՞', '–', 'տի', 'հոտը', ',', 'որը', 'քուլայվում', 'էր', 'նրա', 'շուրջն', 'ու', 'կուտակվում', 'տանիքի', 'ներքևում', ',', 'ինչպես', 'թասակի', 'տակ', '։', 'Նա', 'խմում', 'էր']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n",
            "190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գետից', 'ոչ', 'հեռու', 'Աորտելյերի', 'փողոցի', 'վրա', ',', 'ապրում', 'էր', 'Նրա', 'ծանոթը', 'Գրիմալ', 'ազգանունով', 'կաշեգործը', ',', 'որին', 'աշխատանքի', 'համար', 'մշտապես', 'պետք', 'էին', 'լինում', 'տղաներ', 'ոչ', 'թե', 'որպես', 'աշակերտներ', 'կամ', 'ենթավարպետներ', ',', 'այլ', 'որպես', 'էժան', 'աշխատուժ', '։', 'չէ', '՞', 'որ', 'այղ', 'արհեստի', 'մեջ', 'հարկ', 'էր', 'լինում', 'կատարել', 'կյանքի', 'համար', 'այն', 'աստիճան', 'վտանգավոր', 'գործողություններ', 'մորթափառից', 'մաքրել', 'նեխող', 'գազանների', 'մորթիները', ',', 'միմյանց', 'խառնել', 'դաբաղման', 'թունավոր', 'ու', 'ներկանյութերի', 'լուծույթները', ',', 'թափել', 'կսկծոր', 'օգտագործված', 'քիմիական', 'նյութերը', ',', 'որ', 'կարգին', 'վարպետը', ',', 'սովորաբար', 'խնայելով', 'իր', 'ուսուցառած', 'օգնականներին', ',', 'վարձում', 'էր', 'գործազուրկ', 'ու', 'անտուն', 'խառնամբոխին', 'կամ', 'խնամազուրկ', 'երեխաներին', ',', 'որոնց', 'ճակատագրով', 'դժբախտության', 'դեպքում', 'ոչ', 'ոք', 'չի', 'հետաքրքրվի', '։', 'Հասկանալի', 'է', ',', 'որ', 'տիկին', 'Գայարը', 'գիտեր', ',', 'որ', 'Գրիմալի', 'դաբաղանոցում', 'Գրենույը', 'մարդկային', 'չափանիշներով', 'կենդանի', 'մնալու', 'շանս', 'չուներ', '։', 'Բայց', 'Նա', 'այնպիսի', 'կին', 'չէր', ',', 'որ', 'մտահոգվեր', 'նման', 'հարցերի', 'շուրջ', '։', 'Չէ', '\"', 'որ', 'նա', 'կատարել', 'էր', 'իր', 'պարտքը', '։', 'Խնամակալությունն', 'ավարտվել', 'է', '։', 'Ինչ', 'էլ', 'որ', 'տեղի', 'ունենար', 'խնամառուի', 'հետ', 'ապագայում', ',', 'դա', 'նրան', 'չէր', 'վերաբերում', '։', 'Ողջ', 'կմնա', '՝', 'լավ', 'է', ',', 'կմեռնի', '՝', 'Նույնպես', 'լավ', 'է', ',', 'կարևորն', 'այն', 'է', ',', 'որ', 'ամեն', 'ինչ', 'լինի', 'օրենքով', '։', 'Այդ', 'իսկ', 'պատ', '–', 'ճառովնա', 'պարոն', 'Գրիմալին', 'խնդրեց', 'գրությամբ', 'հաստատել', 'երեխայի', 'փոխանցումը', ',', 'իր', 'հերթին', 'ստացական', 'տվեց', 'տասնհինգ', 'ֆրանկ', 'միջնորդադրամ', 'ստանալու', 'վերաբերյալ', 'և', 'ուղղվեց', 'տուն', '՝', 'Շարոն', 'փողոց', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այն', 'հանգամւսնքը', ',', 'որ', 'այս', 'հոյւսկապության', 'սկզբում', 'կանգնած', 'էր', 'սպանությունը', ',', 'նա', ',', 'եթե', 'ընդհւսնրաւցես', 'գիտակցում', 'էր', 'դւս', ',', 'ընդունում', 'էր', 'խոր', 'անտւսրբերու', '–', 'թյամբ', '։', 'Աարե', 'փորոցի', 'աղջկւս', 'արտւսքինը', '՝', 'նրւս', 'դեմքը', ',', 'Նրա', 'մարմինը', ',', 'Գրենույն', 'արդեն', 'չէր', 'կւսրողւսնում', 'վերհիշել', '։', 'չէ', '՞', 'որ', 'ւցւսհւցւսնել', 'էր', 'լավագույնը', ',', 'ինչը', 'նա', 'խլեց', 'ու', 'սեփւսկանացրեց', '.', 'նրա', 'բուրմունքի', 'էությունը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ալքիմիկոս', 'է', ',', 'ասում', 'են', 'մարդիկ', ',', 'լավ', 'է', ',', 'թող', 'այդպես', 'էլ', 'մտածեն', '։', 'Այն', 'մասին', ',', 'որ', 'իր', 'արվեստն', 'արհեստ', 'է', ',', 'ինչպես', 'և', 'ցանկացած', 'ուրիշը', ',', 'գիտեր', 'միայն', 'ինքը', ',', 'և', 'դրանում', 'էր', 'նրա', 'հպարտությունը', '։', 'Նա', 'չէր', 'էլ', 'ցանկանում', 'գյուտարար', 'լինել', '։', 'Գյուտարարությունը', 'բավական', 'կասկածելի', 'է', ',', 'գտնում', 'էր', 'Ռալդինին', ',', 'քանի', 'որ', 'այն', 'մշտապես', 'նշանակում', 'է', 'կանոնների', 'խախտում', '։', 'Նա', 'ամենևին', 'էլ', 'չէր', 'պատրաստվում', 'կոմս', 'Վերամոնի', 'համար', 'նոր', 'օծանելիք', 'հնա', '–', 'րել', '։', 'Համենայնդեպս', ',', 'Շենյեն', 'հարկադրված', 'չի', 'լինի', 'իրեն', 'հւսմոզել', 'Պելիսյեից', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', 'ձեռք', 'բերել', '։', 'Նա', 'արդեն', 'ձեռք', 'էր', 'բերել', 'այդ', 'օծանելիքները', '։', 'Ահա', 'դրանք', ',', 'պաւոուհւսնի', 'մոտի', 'գրասեղանի', 'վրա', '՝', 'հղկած', 'խցանով', 'փոքրիկ', 'ապակե', 'սրվակների', 'մեջ', '։', 'Նա', 'դրւսնք', 'գնել', 'էր', 'մի', 'քանի', 'օր', 'ւսռաջ', '։', 'Բնականաբար', ',', 'անձամբ', 'չէր', 'գնել', '։', 'չէ', '՞', 'որ', 'նւս', 'չէր', 'կարող', 'օծանելիքի', 'համար', 'անձամբ', 'մտնել', 'Պելիսյեի', 'մոտ', '։', 'Նա', 'գործել', 'էր', 'միջնորդի', 'միջոցով', ',', 'իսկ', 'վերջինս', 'էլ', 'իր', 'հերթին', 'մեկ', 'այլ', 'միջնորդի', 'օգնությւսմբ', '։', 'Զգուշությունը', 'երբեք', 'չի', 'խանգւսրի', '։', 'Քանզի', 'Ռալդինին', 'պատրաստվում', 'էր', 'այդ', 'օծանելիքն', 'օգտւսգործել', 'ոչ', 'միայն', 'իսպանակւսն', 'կաշին', 'բուրումնավետ', 'դարձնելու', 'հւսմար', '.', 'դրա', 'համար', 'մեկ', 'սրվակը', 'չէր', 'բւսվականւսցնի', '։', 'Նա', 'էլ', 'ավելի', 'վատ', 'մտադրություն', 'ուներ', ',', 'ւցւստճենել', 'այն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ախ', '՜', ',', 'որքան', 'կատ', 'է', ',', 'որ', 'ազնիվ', 'մարդը', 'ստիււ|ւ|ած', 'է', 'հնւսրամտություն', 'գործածել', '։', 'Որքան', 'ծանր', 'է', 'զոհւսբե–', 'րել', 'այն', 'ամենւսթանկարժեքը', ',', 'որ', 'ունես', '՝', 'նման', 'խղճուկ', 'ձևով', 'վարկւսբեկելով', 'սեփական', 'ւցւստիվը', '։', 'Ռւսյց', 'ինչ', '՞']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'խոնջանքով', '»', ',', 'մշկային', 'գերհագեցած', 'բուրմունքով', '։', 'Բոլորին', 'հանկարծ', 'տիրում', 'էր', 'մուշկի', 'հոտով', 'բուրելու', 'գազա', '–', 'նւսյին', 'ցանկությունը', ',', 'և', 'Բալդինիին', 'ոչինչ', 'չէր', 'մնում', ',', 'քան', 'իր', 'հազրեվարդը', 'վերամշակել', 'գլուխը', 'լվանալու', 'համար', 'ջրի', 'ունարդոսը', 'կարել', 'բույրաբարձիկի', 'մեջ', '։', 'Դրա', 'փոխարեն', ',', 'երբ', 'հաջորդ', 'տարի', 'նա', 'պատվիրեց', 'համապատասխան', 'քանակությամբ', 'մուշկ', ',', 'մշկահոտ', 'ցիբետին', 'ու', 'կող', '–', 'բենու', 'շիթ', ',', 'Պելիսյեի', 'խելքին', 'փչեց', 'հորինել', '«', 'Անտառային', 'ծաղիկ', '»', 'անվանումով', 'օծանելիք', ',', 'և', 'այն', 'անմիջապես', 'հաջողություն', 'նվաճեց', '։', 'Գիշերային', 'երկարատև', 'փորձերի', 'գնով', 'կամ', 'խելագար', 'գումարներով', 'լրտեսներին', 'կա', '–', 'շառելով', 'Բալդինին', 'ի', 'վերջո', 'պարզեց', ',', 'թե', 'ինչից', 'է', 'բաղկացած', '«', 'Անտառային', 'ծաղիկները', '»', ',', 'իսկ', 'Պելիսյեն', 'արդեն', 'կրկին', 'աչքի', 'ընկավ', 'այս', 'անգամ', '«', 'Թուրքական', 'գիշերներով', '»', 'կամ', '«', 'էիսաբոնյան', 'բուրմունքով', '»', ',', '«', 'Թագավորակւսն', 'պալատի', 'ծաղկեփնջով', '»', 'կւսմ', ',', 'սատանան', 'գիտի', ',', 'թե', 'էլ', 'ինչով', '։', 'Համենայնդեպս', ',', 'այդ', 'մարդն', 'իր', 'անսանձելի', 'նորարարական', 'կրքով', 'վտանգ', 'էր', 'ներկայացնում', 'ողջ', 'արհեստի', 'համար', '։', 'Ինչ', 'լավ', 'կլիներ', ',', 'եթե', 'դաժան', 'ժամանակների', 'արտադրամասային', 'իրավունքը', 'նորից', 'ետ', 'գւսր', '։', 'Նմւսն', 'լկտի', 'դուրսպրծուկի', ',', 'նման', 'գռփողի', 'հանդեպ', ',', 'որը', 'հւսրս', '–', 'ւոանում', 'էր', 'հոտերի', 'արժեզրկման', 'հաշվին', ',', 'կարելի', 'էր', 'կիրառել', 'ամենահրեշային', 'միջոցները', '։', 'Նրւսնից', 'խլել', 'ւսրւոո', '–', 'նագիրը', ',', 'արգելելօծանագործային', 'գործի', 'մեջ', 'խցկվել', '...', 'և', 'ընդհանրապես', ',', 'խարդախը', 'նւսխևառաջ', 'թող', 'ինչ', '-', 'որ', 'բան', 'սովորի', '։', 'չէ', '՞', 'որ', 'նա', '՝', 'այդ', 'Պելիսյեն', ',', 'ուսուցւսռւսծ', 'օծանագործ', 'ու', 'ձեռնոցագործ', 'չէր', '։', 'Նրա', 'հայրն', 'ընդամենը', 'քացախ', 'քամող', 'էր', ',', 'և', 'Պելիսյեն', 'ևս', 'քւսցւսխ', 'քամող', 'էր', ',', 'ոչ', 'այլ', 'ինչ', '։', 'Եվ', 'միայն', 'այն', 'պատճւսռով', ',', 'որ', 'նւս', '՝', 'որպես', 'քացախ', 'քւս', '–', 'մող', ',', 'սպիրտային', 'ւսրտադրության', 'մեջ', 'մուտքի', 'իրւսվունք', 'ուներ', ',', 'նրան', 'հաջողվեց', 'ներթափանցել', 'իրւսկւսն', 'օծւսնա', '–', 'գործների', 'շրջան', ',', 'և', 'այժմ', 'նւս', 'անօրինւսկւսնություններ', 'է']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350\n",
            "360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'կամ', 'վերցնենք', 'խանգարվածությունը', 'արագության', 'վրա', '։', 'Ինչու', '՞', 'անհրաժեշտ', 'եղավ', 'այդքան', 'շատ', 'նոր', 'ճանապարհներ', 'անցկացնել', '։', 'Ինչի', '՞', 'համար', 'են', 'այդ', 'նոր', 'կամուրջները', '։', 'Ինչի', '՞', 'համար', '։', 'Որպեսզի', 'մեկ', 'շաբաթում', 'էիոն', '՞', 'հասնեն', '։', 'Իսկ', 'ինչ', '՞', 'օգուտ', 'կա', 'դրանից', '։', 'Ում', '՞', 'համար', 'է', 'դա', 'օգտավետ', '։', 'Ում', '՞', 'է', 'պետք', 'գլուխը', 'կոտրելով', 'սլանալ', 'Ատլան', '–', 'տյան', 'օվկիանոսով', '։', 'Մեկ', 'ամիս', 'անց', 'Ամերիկայում', 'հայտնվելու', 'համար', '՞', '։', 'Բայց', 'չէ', '՞', 'որ', 'մարդիկ', 'հազարամյակներ', 'շարունակ', 'հրաշալիորեն', 'բավարարվում', 'էին', 'առանց', 'այդ', 'աշխարհամասի', '։', 'Ինչ', '՞', 'է', 'կորցրել', 'նախնադարյան', 'անտառում', 'հնդկացիների', 'կամ', 'սևամորթների', 'մոտ', 'քաղաքակիրթ', 'մարդը', '։', 'Անգամ', 'Հյուսիս', 'Նրանք', 'հասան', '՝', 'էւսւցլան', '–', 'դիա', ',', 'որտեղ', 'հավերժական', 'սառույց', 'է', ',', 'և', 'որտեղ', 'ւսպրում', 'են', 'վայրի', 'մւսրդիկ', ',', 'ովքեր', 'հում', 'ձուկ', 'են', 'խժռում', '։', 'Դա', 'դեռ', 'քիչ', 'էր', ',', 'ցանկւսցան', 'ևս', 'մի', 'աշխարհամաս', 'հայտնաբերել', ',', 'ասում', 'են', ',', 'ինչ', '-', 'որ', 'տեղ', 'հարավային', 'ծովերում', '։', 'Իսկ', 'մեր', 'ինչին', '՞', 'է', 'պետք', 'այդ', 'խելագարությունը', '։', 'Միայն', 'այն', 'պատճառով', ',', 'որ', 'ուրիշներն', 'էլ', 'են', 'այդպես', 'անում', '՝', 'իսպանացիները', ',', 'անիծյալ', 'անգլիացիները', ',', 'անպատկառ', 'հոլւսնդացիները', ',', 'որոնց', 'հետ', 'հետագայում', 'ստիպված', 'էինք', 'մարտ', 'մղել', ',', 'ինչն', 'ընդհանրաւցես', 'մեզ', 'չէինք', 'կարող', 'թույլ', 'տւսլ', '։', 'Երեք', 'հարյուր', 'հազար', 'լիկր', 'կանխիկ', 'գումար', 'ահւս', 'թե', 'որքան', 'արժի', 'մեկ', 'ռազմանավը', ',', 'իսկ', 'հետո', 'նա', 'մեկ', 'թնդւսնոթային', 'կրակոցից', 'հինգ', 'րոպեի', 'ընթացքում', 'խորտակվում', 'է', ',', 'և', 'մնւսք', 'բւս', '–', 'րով', 'հավերժ', ',', 'հարկատուների', 'փողեր', '։', 'Այժմ', 'ֆինւսնսների', 'պարոն', 'Նւսխարարը', 'պւսհանջում', 'է', 'իրեն', 'փոխւսնցել', 'բոլոր', 'եկամուտների', 'տւսսներորդ', 'մւսսը', ',', 'և', 'դա', 'կործւսնարար', 'է', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Քանզի', 'եթե', 'արդեն', 'թույլատրելի', 'է', 'Աստծու', 'եկեղեցու', 'հեղինակությունն', 'ամենաանամոթ', 'ու', 'անպատկառ', 'ձևով', 'կասկածի', 'տակ', 'դնելը', ',', 'եթե', 'ոչ', 'պակաս', 'աստվածատուր', 'միապետության', 'ու', 'թագավորների', 'սրբազան', 'անձերի', 'մասին', 'է', 'խոսվում', 'ուղղակի', 'որպես', 'կառավարման', 'այլ', 'ձևերի', 'ընդհանուր', 'կատալոգում', 'տեղ', 'գտած', 'հնարավոր', 'տարբերակների', ',', 'նրանց', 'կարելի', 'է', 'ընտրել', 'սեփական', 'ճաշակով', '։', 'Ի', 'վերջո', ',', 'հասել', 'ենք', 'նրան', ',', 'որ', 'անգամ', 'անձամբ', 'Աստծուն', '՝', 'ամենազոր', 'Տիրոջը', ',', 'համարում', 'են', 'ավելորդություն', 'ու', 'բացարձակ', 'լրջությամբ', 'պնդում', ',', 'որ', 'երկրի', 'վրա', 'կարգ', 'ու', 'կանոնը', ',', 'բարոյականությունն', 'ու', 'երջանկությունը', 'կարող', 'են', 'լինել', 'առանց', 'նրա', 'ուղղակի', 'բուն', 'մարդկանց', 'բնածին', 'բարոյականության', 'ու', 'բանականության', 'շնորհիվ', '...', '<UNK>', '՜', 'Աստված', ',', 'Աստված', ',', 'այդ', 'դեպքում', 'համենայնդեպս', 'պետք', 'չէ', 'զարմանալ', ',', 'եթե', 'ամեն', 'ինչ', 'ընթանում', 'է', 'գլխիվայր', ',', 'և', 'բարքերը', 'վերջնականապես', 'այլասերվել', 'են', ',', 'ու', 'մարդկությունը', 'իր', 'վրա', 'բերեց', 'պատիժը', 'նրա', ',', 'ում', 'մերժում', 'է', '։', 'Դա', 'վատ', 'կվերջանա', '։', '1681', 'թվին', 'մեծ', 'գիսաստղը', ',', 'որի', 'վրանրանք', 'զվարճանում', 'էին', ',', 'որընրանք', 'համարում', 'են', 'ընդամենը', 'աստղերի', 'կույտ', ',', 'Տիրոջ', 'նախազգու–', 'շացնողնախանշանն', 'էր', ',', 'քանզի', 'այն', ',', 'այժմ', 'արդեն', 'մենք', 'դա', 'գիտենք', ',', 'կանխագուշակեց', 'սանձարձակության', 'հոգևոր']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Օծանելիքը', 'գարշելիության', 'աստիճան', 'լավն', 'էր', '։', 'Ցավոք', 'սրտի', ',', 'այդ', 'ողորմելի', 'Պելիսյեն', 'լավ', 'գիտեր', 'իր', 'գործը', '։', 'Վարւցետ', 'էր', ',', 'Աստված', 'վկա', ',', 'թող', 'որ', 'նա', 'հազար', 'անգամ', 'ոնչ', 'փ', 'չէր', 'սովորել', '։', 'Ռալդինին', 'կցւսնկանար', ',', 'որպեսզի', 'դւս', 'լիներ', 'իր', 'օծանելիքը', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '։', 'Նրանում', 'չկար', 'գռեհկության', 'ստվեր', 'անգամ', '։', 'Ռացարձւսկապես', 'դասական', 'հոտ', 'էր', 'ավարտուն', 'ուներդւսշնակ', '։', 'Եվ', 'միևնույն', 'ժւս', '–', 'մանակ', 'սքանչելիորեն', 'նոր', '։', 'Թարմ', 'էր', ',', 'բայց', 'ոչ', 'ձանձրալի', '։', 'Ծաղկային', 'էր', ',', 'բայց', 'ոչ', 'քաղցրւսվուն', '։', 'Ուներ', 'խորություն', '՝', 'հրաշալի', ',', 'գրավիչ', ',', 'շքեղ', ',', 'մուգ', 'շւսգւսնակագույն', 'խորություն', ',', 'և', 'ընդ', 'որում', '՝', 'նրւսնում', 'չկար', 'ոչ', 'գերծանրւսբեռնվւս', '–', 'ծություն', ',', 'ոչ', 'վերամբարձություն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Հրաշալի', 'է', ',', 'հրաշալի..', '-', 'մրթմրթաց', 'նւս', '՝', 'ւսգւււ', '–', 'հաբւսր', 'հոտուոելով', '։', '–', 'Նրւսնում', 'ուրւսխություն', 'կւս', ',', 'նա', 'չքնաղ', 'է', '՝', 'ինչպես', 'մեղեդին', ',', 'նւս', 'ուղղւսկի', 'ստեղծոււՏ', 'է', 'լւսվ', 'ւորւսմւսդրություն', '...', 'Ինչ', '՜', 'ւսնհեթեթություն', 'է', '՝', 'լւսվ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['<UNK>իծաղեի', '՜', 'է', 'նման', 'ճարտասանությունը', '.', '«', 'Մեղեդի', 'է', '։', 'Ուրախություն', 'է', '։', 'Չքնաղ', 'է', '։', 'Բարձրացնում', 'է', 'տրամադրությունը', '»', '։', 'Հիմարություն', '։', 'Մանկական', 'հիմարություն', '.', 'Րոպեական', 'տպավորություն', '։', 'Հին', 'սխալ', '։', 'Խառնվածքի', 'հարց', '։', 'Ամենայն', 'հավանականությամբ', 'իտալական', 'ժառանգականություն', '։', 'Երբեք', 'մի', 'դատիր', 'առաջին', 'տպավորությամբ', '։', 'չէ', '՞', 'որ', 'դա', 'ոսկե', 'կանոն', 'է', ',', 'Բւսլդինի', ',', 'այ', 'դու', 'ծեր', 'ոչխարի', 'գլուխ', '։', 'Երբ', 'հոտ', 'ես', 'քաշում', '՝', 'հոտ', 'քաշիր', ',', 'իսկ', 'դատիր', 'հետո', '։', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '–', 'ը', 'շարքային', 'օծանելիք', 'չէ', '։', 'Բավական', 'հաջող', 'արտադրանք', 'է', '։', 'ճարպկորեն', 'թխված', 'անշնորհք', 'ապրանք', '։', 'Եթե', 'չասենք', 'կեղծիք', '։', 'Իսկ', 'կեղծիքից', 'բացի', ',', 'ուրիշ', 'էլ', 'ինչ', '՞', 'կարելի', 'է', 'սպասել', 'Պելիսյեի', 'նման', 'մարդուց', '։', 'Բնականաբար', ',', 'այնպիսի', 'տիպը', ',', 'որպիսին', 'Պելիսյեն', 'է', ',', 'հասարակ', 'օծանելիք', 'չի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'դու', ',', 'Բալդինի', ',', 'թույլչես', 'տա', 'քեզհիմարւսցնեն', '։', 'Դու', 'միայն', 'առաջին', 'րոպեին', 'փոքր', '-', 'ինչ', 'կորցրիր', 'գլուխդ', 'կեղծ', 'տպավորությամբ', '։', 'Բայց', 'միթե', '՞', 'հայտնի', 'է', ',', 'թե', 'ինչ', 'տեղի', 'կունենա', 'այդ', 'հոտի', 'հետ', 'մեկ', 'ժամ', 'անց', ',', 'երբ', 'եթերային', 'փոխւս', '–', 'րինումները', 'գոլորշանան', ',', 'ու', 'բացահայտվի', 'նրա', 'միջուկը', '։', 'Կամ', 'այսօր', 'երեկոյան', ',', 'երբ', 'բուրմունք', 'կւսրձակեն', 'միւսյն', 'այս', 'ծանր', ',', 'մութ', 'բաղադրիչները', ',', 'որոնք', 'այժմ', 'թաքնվում']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n",
            "410\n",
            "420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Քեզ', 'ինչ', '՞', 'է', 'պետք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "430\n",
            "440\n",
            "450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'հնչում', '՞', 'է', 'բանը', ',', '–', 'հարցրեց', 'նա', '։', '–', 'Դու', 'էլի', '՞', 'ինչ', '-', 'որ', 'բան', 'պետք', 'է', 'ինձ', 'փոխանցես', '։', 'Դե', '՞', '։', 'Խոսիր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'ուզում', 'եք', 'ւսյծի', 'մորթիները', 'բուրումնեա', '՛', 'դարձնել', ',', 'վարւցետ', 'Ռալդինի', '։', 'Այս', 'մորթիները', ',', 'որոնք', 'ես', 'եմ', 'ձեզ', 'բերել', ',', 'դուք', 'դրանց', '՞', 'եք', 'ցանկանում', 'բուրմունք', 'հւս', '–', 'ղորդել', ',', '–', 'շշնջաց', 'Գրենույը', 'կւսրծես', 'ի', 'գիտություն', 'չընդունելով', 'Ռալդինիի', 'պատասխանը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այդպես', ',', '–', 'ասւսց', 'Ռալդինին', ',', 'որը', 'բւսցարձւսկապես', 'ցնցված', 'էր', 'խոսակցության', '՝', 'դեւցի', 'ճշգրիտի', 'ոլորտ', 'նմւսն', 'շրջադարձով', '–', 'էլ', '՞', 'ինչ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ռուրավետ', 'բալասանի', 'յուղը', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470\n",
            "480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բուրավետ', 'բալասանից', ',', 'վարդի', 'յուղից', 'ու', 'մեխակից', ',', 'ինչ֊', 'ւցես', 'նաև', 'բերգամոտից', 'ու', 'հազրեվարդի', 'լուծամզված', '–', 'քից', 'և', 'ւսյլն', '։', 'Դա', 'պարզելու', 'համար', 'պետք', 'է', ',', 'ինչպես', 'ասում', 'են', ',', 'ունենալ', 'բավակւսնին', 'նուրբ', 'հոտառություն', ',', 'ու', 'լիովին', 'հնարավոր', 'է', ',', 'որ', 'Աստված', 'քեզ', 'բավականին', 'նուրբ', 'հոտառություն', 'է', 'տվել', ',', 'ինչպես', 'և', 'շատ', 'ուրիշ', 'մարդկանց', '՝', 'հատկապես', 'քո', 'տարիքում', '։', 'Սակայն', 'օծանագործի', 'համար', '–', 'և', 'այստեղ', 'նա', 'վեր', 'պարզեց', 'մատն', 'ու', 'դուրս', 'ցցեց', 'կուրծքը', ',', '-', 'սակայն', 'օծանագործի', 'համար', 'քիչ', 'է', 'ուղղակի', 'Նուրբ', 'հոտւսռություն', 'ունենալը', '։', 'Նրան', 'անհրաժեշտ', 'է', 'տասնամյակների', 'ընթացքում', 'վարժեցված', ',', 'անկաշառ', 'ւսշխատող', 'հոտառական', 'օրգան', ',', 'որը', 'թույլ', 'կտա', 'վստահորեն', 'կռահել', 'նույնիսկ', 'ամենաբարդ', 'հոտերը', ',', 'դրանց', 'բաղադրությունն', 'ու', 'համաչափությունները', ',', 'ինչւղես', 'նաև', 'ստեղծել', 'նոր', 'բուրմունքների', 'անհայտ', 'խառնուրդներ', '։', 'Նման', 'քիթը', ',', '-', 'և', 'Նա', 'մատով', 'թխկթխկացրեց', 'իրենը', ',', '–', 'այդքան', 'հեշտ', 'չի', 'տրվում', ',', 'երիտասարդ', '։', 'Նման', 'քիթը', 'վաստւսկում', 'են', 'ջւսնւս', '–', 'սիրությւսմբ', 'ու', 'համբերությամբ', '։', 'թե', '՞', 'դու', 'կկւսրողանայիր', 'ուղղակի', 'այնւցես', '՝', 'ձեռքի', 'հետ', 'անվանել', '«', 'Ամուրն', 'ու', 'Պսի', '–', 'քեն', '»', '–', 'ի', 'ճշգրիտ', 'բանաձևը', '։', 'Դե', '՞', '։', 'Կկարոաղնյյի', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Աիգուցե', 'դու', 'ինձ', 'գոնե', 'մոտավոարպես', '՞', 'կասես', ',', '-', 'ասաց', 'Ռալդինին', 'ու', 'թեթևակի', 'թեքվեց', 'առաջ', ',', 'որպեսզի', 'ավելի', 'լավ', 'ուսումնասիրի', 'դուսն', 'մեջ', 'թաքնված', 'դոդոշին', '։', '–', 'Դոնե', 'մոտավորապես', ',', 'ընդհանուր', 'տեսքով', '։', 'Դե', '՞', '։', 'Խոսիր', ',', 'չէ', '\"', 'որ', 'դու', 'Փւսրիզի', 'լւսվւսգույն', 'քիթն', 'ես', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Դե', ',', 'տեսնում', '՞', 'ես', ',', '–', 'փնթփնթաց', 'Ռալդինին', '՝', 'միւսժա', '–', 'մանւսկ', 'բավւսրարված', 'ու', 'հիւսսթւսփվւսծ', '։', '–', 'Չես', 'կւսրող', '։', 'Իհարկե', 'ոչ', '։', 'Ոնց', 'կարող', 'ես', 'իմւսնւսլ', '։', 'Դու', 'Նրանցից', 'ես', ',', 'ով', 'ճւսշ', 'ուտեփս', 'որոշում', 'է', '՝', 'ւսրդյոք', 'աւցուրի', 'մեջ', 'մաղւսդւս֊', 'նոս', '՞', 'է', ',', 'թե', '\"', 'կերբելուկ', '։', 'Դե', 'ինչ', ',', 'դւս', 'էլ', 'ւսրդեն', 'քիչ', 'չէ', '։', 'Ռայց']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Բանաձև', ',', 'բանաձև', ',', '–', 'խռպոտ', 'ձայնով', 'խոսեց', 'Գրե–', 'նույը', ',', 'և', 'Նրա', 'կերպարը', 'դռան', 'շրջանակի', 'մեջ', 'առավել', 'հստակ', 'ուրվագծվեց', '։', '–', 'Ինձ', 'ոչ', 'մի', 'բանաձև', 'պետք', 'չէ', '։', 'Դեղատոմսն', 'իմ', 'քթի', 'մեջ', 'է', '։', '<UNK>առնեմ', '՞', 'դրանք', 'ձեզ', 'համար', ',', 'մետր', ',', 'խառնեմ', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այսինքն', '՝', 'ինչպես', '՞', ',', '–', 'բացականչեց', 'Բալդինին', 'ավելի', 'բարձր', ',', 'քան', 'պատշաճ', 'էր', 'նրան', ',', 'և', 'մոմը', 'մոտեցրեց', 'թզուկի', 'դեմքին', '։', '–', 'Այսինքն', '՝', 'ինչպես', '՞', 'խառնել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Դու', 'կարծում', 'ես', ',', 'որ', 'ես', 'քեզ', 'թույլ', 'կտամ', 'տնօրինել', 'իմ', 'արհեստւսնոցը', '։', 'Բնւսհյութերը', ',', 'որոնք', 'մի', 'ողջ', 'ունեցւխսծք', 'ար<UNK>են', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Պան', '։', '–', 'Ռալդինին', 'կտրուկ', 'դուրս', 'փչեց', 'իր', 'մեջ', 'եղած', 'շունչը', '։', 'Այնուհետև', 'թոքերը', 'լցրեց', 'օդով', ',', 'երկար', 'նայեց', 'սարդանման', 'Գրենույին', 'և', 'մտորեց', '։', '«', 'Ըստ', 'էության', '՝', 'միթե', 'միևնույն', 'չէ', ',', '–', 'մտածեց', 'նաայսպես', 'թե', 'այնպես', 'վաղն', 'ամեն', 'ինչ', 'ավարտվելու', 'է', '։', 'Ես', ',', 'իհարկե', ',', 'գիտեմ', ',', 'որ', 'նա', 'չի', 'կարող', 'անել', 'այն', ',', 'ինչը', 'խոստանում', 'է', ',', 'դա', 'բացառվում', 'է', ',', 'այլապես', 'նւս', 'ավելի', 'մեծ', 'համբավ', 'կունենար', ',', 'քան', 'մեծն', 'Ֆրանժիպանին', '։', 'Ռայց', 'ինչու', '՞', 'սեւիւսկան', 'աչքերով', 'չհամոզվեմ', 'նրանում', ',', 'ինչը', 'գիտեմ', '։', 'Աիգուցե', 'հւսնկարծ', 'մի', 'գեղեցիկ', 'օր', 'Աեսինայում', 'իմ', 'գլուխը', 'մի', 'միտք', 'գա', ',', 'ծեր', 'մարդկանց', 'մոտ', 'երբեմն', 'լինում', 'են', 'տարօրինակություններ', 'ու', 'խենթ', 'մտքեր', ',', 'որ', 'ես', 'չճանաչեցի', 'մի', 'հանճարի', ',', 'հրաշամա', '–', 'նուկի', ',', 'արարածի', ',', 'ով', 'Աստծու', 'ողորմությամբ', 'շռայլորեն', 'օժտված', 'էր', '...', 'Դա', 'ամբողջապես', 'բացառվում', 'է', '։', 'Ելնելով', 'այն', 'ամենից', ',', 'ինչ', 'ինձ', 'հուշում', 'է', 'բանականությունս', ',', 'դա', 'բացառվում', 'է', '...', 'Ռայց', 'չէ', '՞', 'որ', 'լինում', 'են', 'հրաշքներ', '։', 'Անկասկած', '։', 'Եվ', 'ահա', ',', 'երբ', 'Աեսինայում', 'մոտենա', 'իմ', 'մեռնելու', 'ժամը', ',', 'մահվան', 'մահճում', 'ինձ', 'կայցելի', 'մի', 'միտք', ',', 'այն', 'երեկո', 'Փարիզում', 'քեզներկայացավ', 'հրաշքը', ',', 'իսկ', 'դու', 'փակեցիր', 'աչքերդ', '...', 'Դա', ',', 'բնականաբար', ',', 'այնքան', 'էլ', 'հաճելի', 'չէր', 'լինի', ',', 'Ռալդինի', '։', 'Ավելի', 'լավ', 'է', 'այս', 'հիմարը', 'սեղանի', 'վրա', 'մի', 'երկու', 'կաթիլ', 'վարդի', 'յուղ', 'ու', 'մուշկի', 'թուրմ', 'թափի', ',', 'դու', 'ևս', 'դրանք', 'կթափեիր', ',', 'եթե', 'քեզ', 'դեռևս', 'իրոք', 'շարունակեր', 'հե–', 'տաքրքրել', 'Պելիսյեի', 'օծանելիքը', '։', 'Եվ', 'ինչ', '՞', 'Նշանակություն', 'ունի', 'մի', 'քանի', 'կաթիլը', ',', 'այո', ',', 'թանկարժեք', ',', 'բավականին', ',', 'բավականին', 'թանկարժեք', ',', 'եթե', 'համեմատես', 'դա', 'գիտելիքների', 'հուսալիության', 'ու', 'հանգիստ', 'ծերության', 'հետ', '»', '։', '–', 'Էսիր', ',', '–', 'ասաց', 'նա', 'միտումնավոր', 'խիստ', 'տոնով', '–', 'Ասիր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', '...', 'Ի', 'դեպ', ',', 'ինչպես', '՞', 'է', 'քո', 'անունը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['հնարավորություն', 'կստանաս', 'հենց', 'այժմ', ',', 'անմիջապես', 'գործով', 'ապացուցել', 'քո', 'հիմնավորումը', '։', 'Դրանով', 'իսկ', 'դու', 'հնարավորություն', 'կստանաս', 'խայտառակ', 'ձախողման', 'միջոցով', 'սովորել', 'համեստության', '՝', 'որպես', 'առաքինության', '։', 'Քո', 'պատանի', 'տարիքում', 'դա', 'դեռևս', 'ներելի', 'է', 'և', 'դժվար', 'թե', 'անուղղելի', 'աստիճանի', 'հասած', 'լինի', ',', 'սակայն', 'այդ', 'դասը', 'Նախադրյալ', 'է', 'քո', 'հետագա', 'հաջողության', 'համար', '՝', 'որպես', 'արտադրամասի', 'անդամի', ',', 'որպես', 'մարդու', 'ու', 'բարի', 'քրիստոնյայի', '։', 'Ես', 'պատրաստ', 'եմ', 'իմ', 'հաշվին', 'քեզ', 'տալ', 'այդ', 'դասը', ',', 'քանզի', 'որոշակի', 'հանգամանքների', 'բերումով', 'այսօր', 'տրամադրված', 'եմ', 'շռայլություն', 'ցուցաբերել', ',', 'և', ',', 'ով', 'գիտի', ',', 'ինչ', '-', 'որ', 'ժամանակ', 'այս', 'տեսարանի', 'մասին', 'հիշողությունը', ',', 'հնարավոր', 'է', ',', 'ուրախություն', 'պատճառի', 'ինձ', '։', 'Ռայց', 'չկարծես', ',', 'թե', 'քեզ', 'կհաջողվի', 'ինձ', 'խաբել', '։', 'Ջուզեպպե', 'Ռալդինիի', 'քիթը', 'հին', 'է', ',', 'բայց', 'հոտառությունը', 'սուր', ',', 'բավականաչափ', 'սուր', ',', 'որպեսզի', 'անմիջապես', 'հայտնաբերի', 'նվազագույն', 'տարբերությունը', 'քո', 'լուծույթի', 'ու', 'այս', 'արտադրանքի', 'միջև', '։', '–', '–', 'Եվնա', 'գրպանից', 'դուրս', 'հանեց', '«', 'Ամուրն', 'և', 'Պսիքեն', '»', '–', 'ով', 'Ներծծված', 'թաշկինակն', 'ու', 'թւսփ', 'տվեց', 'Գրենույի', 'քթի', 'առաջ', '։', '–', 'Հապա', 'մի', 'այստեղ', 'արի', ',', 'դու', ',', 'Փւսրիզի', 'լավագույն', 'քիթ', '։', 'Հապա', 'այստեղ', 'արի', '՝', 'սեղանի', 'մոտ', ',', 'ու', 'ցույց', 'տուր', ',', 'թե', 'ինչի', 'ես', 'ունակ', '։', 'Ռայց', 'տես', ',', 'այստեղ', 'ոչինչ', 'չկոտրես', 'ու', 'շուռ', 'չտաս', '։', 'Չհւս', '–', 'մարձակվես', 'ոչ', 'մի', 'բանի', 'ձեռք', 'տալ', '։', 'Նախևւսռաջ', 'ես', 'շւստ', 'լույս', 'կվառեմ', '։', 'Մենք', ',', 'ի', 'պատիվ', 'այս', 'փոքրիկ', 'փորձարարության', ',', 'հրավառություն', 'կկազմակերպենք', ',', 'այդդւեսէէէէէ', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ձեզ', 'համար', 'որքան', '՞', 'պատրաստեմ', ',', 'մետր', ',', '–', 'հարցրեց', 'Գրենույը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որքան', '՞', ',', 'ինչը', '՞', ',', '–', 'հարցրեց', 'Ռալդինին', ',', 'ով', 'դեռ', 'չէր', 'ավարտել', 'իր', 'խոսքը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այս', 'օծանելիքից', '՝', 'որքան', '՞', ',', '–', 'խռպոտ', 'հարցրեց', 'Գրե–', 'նույը', '։', '–', 'որքան', '՞', 'է', 'ձեզ', 'պետք', 'ղրանից', '։', 'Կուզեք', '՞', 'մինչև', 'եզրը', 'լցնեմ', 'այ', 'այն', 'մեծ', 'ամանը', '։', '–', 'Եվ', 'նա', 'մատնացույց', 'արեց', 'երեք', 'լիտրից', 'ոչ', 'պակաս', 'տարողությամբ', 'խառնամանը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Ոչ', ',', 'պետք', 'չի', ',', '–', 'սարսափած', 'բացականչեց', 'Ռալդինին', '.', 'նրա', 'այդ', 'գոռոցի', 'մեջ', 'կար', 'վախ', '՝', 'որչափ', 'խոր', 'արմատացած', ',', 'նույնչափ', 'էլ', 'տարերային', 'վախ', 'շռայլության', 'հանդեպ', ',', 'վախ', 'իր', 'սեփականության', 'համար', '։', 'Ռայց', ',', 'կարծես', 'ամաչելով', 'այդ', 'ինքն', 'ա', 'մերկացնող', 'գոռոցից', ',', 'նա', 'անմիջապես', 'էլ', 'մռնչաց', ',', '–', 'չհամարձակվես', 'ինձ', 'ընդհատել', '։', '–', 'Այնուհետև', 'մի', 'քիչ', 'հանգստացավ', 'և', 'շարունակեց', 'թեթևակի', 'հեգնական', 'ձայնով', '–', 'Աեր', 'ինչին', '՞', 'է', 'պետք', 'երեք', 'լիտր', 'օծանելիքը', ',', 'որը', 'երկուսս', 'էլ', 'չենք', 'գնահատում', '։', 'Ըստ', 'էության', 'սրվակի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "530\n",
            "540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['քո', 'պարզունակ', 'բթամտությունը', 'ցույց', 'են', 'տալիս', ',', 'որ', 'դու', 'ոչինչ', 'չես', 'հասկանում', ',', 'դու', 'բարբարոս', 'ես', 'ու', 'անտաշ', ',', 'դրա', 'հետ', 'էլ', 'գոնջոտ', ',', 'լկտի', ',', 'փսլնքոտ', '։', 'Դու', 'ի', 'վիճակի', 'չես', 'լիմոնադ', 'խառնել', ',', 'քեզ', 'չի', 'կարելի', 'սովորական', 'մատուտակի', 'ջրի', 'վաճառք', 'վստահել', ',', 'իսկ', 'դու', 'խցկվում', 'ես', 'օծանագործի', 'գործի', 'մեջ', '։', 'Գոհ', 'եղիր', ',', 'ուրախացիր', 'ու', 'շնորհակալ', 'եղիր', ',', 'որ', 'քո', 'տերը', 'քեզ', 'դեռ', 'մոտ', 'է', 'թողնում', 'դաբաղման', 'լուծույթին', '։', 'Եվ', 'չհամարձակվես', ',', 'լսում', '՞', 'ես', ',', 'երբեք', 'չհամարձակվես', 'օծանագործի', 'դռան', 'շեմն', 'անցնել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "550\n",
            "560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'չեք', 'ցանկանում', 'փորձանմուշ', 'վերցնել', ',', '–', 'կրկին', 'կարկաչող', 'ձայնով', 'ասաց', 'Գրենույը', ',', '֊', 'միթե', '՞', 'չեք', 'ուզում', ',', 'վարւցետ', '։', 'միթե', '՞', 'չեք', 'փորձի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['դեպքում', 'ժամանակ', 'առ', 'ժամանակ', 'նա', 'սխալներ', 'էր', 'գործում', ',', 'որոնք', 'այնպես', 'էին', 'հաշվարկված', ',', 'որ', 'Ռալդինին', 'դրանք', 'նկատի', ',', 'մոռանում', 'էր', 'ինչ', '-', 'որ', 'նյութ', 'զտիչի', 'միջով', 'անցկացնել', ',', 'ճիշտ', 'չէր', 'տեղադրում', 'կշեռքը', ',', 'բանաձևի', 'մեջ', 'հավելագրում', 'էր', 'ամպարի', 'անհեթեթ', 'բարձր', 'տոկոս', 'և', 'առիթ', 'էր', 'ստեղծում', ',', 'որ', 'իրեն', 'ցույց', 'տան', 'իր', 'սխալները', ',', 'որպեսզի', 'հետո', 'ինքը', 'մանրակրկիտ', 'ուղղի', '։', 'Այդ', 'կերպ', 'նրան', 'հաջողվում', 'էր', 'Ռալդինիին', 'ներշնչել', 'այն', 'պատրանքը', ',', 'որ', 'վերջիվերջո', 'ամեն', 'ինչ', 'ընթանում', 'է', 'կանոնավոր', 'և', 'պատշաճ', 'հունով', '։', 'չէ', '՞', 'որ', 'նա', 'չէր', 'ուզում', 'վախեցնել', 'ծերուկին', '։', 'չէ', '՞', 'որ', 'իրոք', 'ուզում', 'էր', 'նրանից', 'սովորել', '։', 'Ոչ', 'թե', 'օծանելիքի', 'բաղադրությունը', ',', 'ոչ', 'թե', 'այս', 'կամ', 'այն', 'բուրմունքի', 'կառուցվածքը', ',', 'ամենևին', 'ոչ', '։', 'Այդ', 'բնագավառում', 'աշխարհում', 'չկար', 'մեկը', ',', 'ով', 'կարող', 'էր', 'նրան', 'ինչ', '-', 'որ', 'բան', 'սովորեցնել', '։', 'Ռալդինիի', 'կրպակում', 'առկա', 'բաղադրամասերը', 'ամենևին', 'էլ', 'բավարար', 'չէին', 'իսկական', 'մեծ', 'օծանելիքի', 'մասին', 'նրա', 'պատկերացումներն', 'իրականացնելու', 'համար', '։', 'Այն', 'անուշահոտերը', ',', 'որ', 'կարողանում', 'էր', 'ստեղծել', 'Ռալդինիի', 'մոտ', ',', 'մանկական', 'զվարճանք', 'էր', 'այն', 'անու–', 'շաբույրերի', 'համեմատ', ',', 'որոնք', 'կրում', 'էր', 'իր', 'մեջ', 'ու', 'պատրաստվում', 'էր', 'մի', 'հրաշալի', 'օր', 'դրանք', 'իրականացնել', '։', 'Ռայց', 'դրա', 'համար', ',', 'նա', 'գիտեր', ',', 'պահանջվում', 'էին', 'երկու']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "620\n",
            "630\n",
            "640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['փոշու', 'տեսքով', 'առանց', 'Նվազագույն', 'հաջողության', '։', 'Նա', 'թորեց', 'արույրը', ',', 'ճենապակին', ',', 'կաշին', ',', 'ցորենն', 'ու', 'մանրախիճը', '։', 'Ուղղակի', 'հողը', '։', 'ԼԼրյունը', ',', 'և', 'ծառը', ',', 'և', 'թարմ', 'ձուկը', '։', 'Իր', 'սեփական', 'մազերը', '։', 'Ի', 'վերջո', ',', 'նա', 'թորեց', 'նույնիսկ', 'ջուրը', 'Սենայի', 'ջուրը', ',', 'որովհետև', 'նրան', 'թվում', 'էր', ',', 'որ', 'պետք', 'է', 'պահպանել', 'նրա', 'ինքնատիպ', 'հոտը', '։', 'Նա', 'մտածում', 'էր', ',', 'որ', 'թորման', 'կաթսայի', 'օգնությամբ', 'ինքը', 'կարող', 'էր', 'այղ', 'նյութերից', 'դուրս', 'բերել', 'նրանց', 'առանձնահատուկ', 'բուրմունքը', ',', 'ինչպես', 'այն', 'դուրս', 'էր', 'բերում', 'ուրցից', ',', 'նարդոսի', 'ու', 'չամանի', 'սերմերից', '։', 'չէ', '՞', 'որ', 'չգիտեր', ',', 'որ', 'թորումը', 'ոչ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "650\n",
            "660\n",
            "670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['սիֆիլիսային', 'ծաղկաչեչով', 'ու', 'թարախային', 'կարմրուկով', 'ւո', 'տէՁմԽ', 'ս1էւրոօ', '։', 'Ինչու', '՞', 'ոչ', 'երկու', 'տարի', 'անց', '։', 'Ինչու', '՞', 'ոչ', 'մեկ', 'տարի', 'անց', '։', 'Այդ', 'ընթացքում', 'նրան', 'կարելի', 'էր', 'ամբողջապես', 'քամել', 'ինչպես', 'արծաթի', 'հանքը', ',', 'ինչպես', 'ոսկե', 'ավանակին', '։', 'Եվ', 'թող', 'մի', 'տարուց', 'իր', 'համար', 'հանգիստ', 'մեռներ', '։', 'Ռայց', 'ոչ', '։', 'Նա', 'հիմա', 'է', 'մահանում', ',', 'անիծված', 'լինի', 'նա', ',', 'կմեռնի', 'քառասունութ', 'ժամվա', 'մեջ', '։', 'Ինչ', '-', 'որ', 'մի', 'կարճ', 'պահ', 'Բալդինին', 'մտածեց', 'այն', 'մասին', ',', 'որ', 'ուխտագնացության', 'մեկնի', 'գետից', 'այն', 'կողմ', '՝', 'Նոտր', '-', 'Գամ', '՝', 'մոմ', 'վառելու', ',', 'ու', 'Գրենույի', 'առողջության', 'համար', 'աղերսի', 'Սուրբ', 'Աստվածամորը', '։', 'Ռայց', 'հետո', 'նա', 'հրաժարվեց', 'այդ', 'մտքից', ',', 'քանի', 'որ', 'ժամանակը', 'սուղ', 'էր', '։', 'Նա', 'վազեց', 'գրչի', 'ու', 'թղթի', 'ետևից', 'և', 'կնոջը', 'վռնդեց', 'հիվանդի', 'սենյակից', '։', 'Նա', 'ասաց', ',', 'որ', 'անձամբ', 'կհերթապահի', '։', 'Այնուհետև', 'նստեց', 'մահճակալի', 'կողքի', 'աթոռի', 'վրա', '՝', 'գրառումների', 'համար', 'թղթերը', 'ծնկներին', 'դրած', ',', 'թանաքի', 'մեջ', 'թաթախված', 'գրիչը', 'ձեռքին', ',', 'և', 'փորձեց', 'Գրենույին', 'ղրդել', 'օծանագործային', 'խոստովանանքի', '։', 'Աստծու', 'սիրուն', ',', 'նա', 'չպետք', 'է', 'հենց', 'այնպես', 'իր', 'հետ', 'գերեզման', 'տանի', 'այն', 'գանձերը', ',', 'որոնք', 'կրում', 'է', 'իր', 'մեջ', '։', 'Այժմ', '՝', 'վերջին', 'ժամերին', ',', 'Նա', 'պարտավոր', 'է', 'հուսալի', 'ձեռքերի', 'փոխանցել', 'իր', 'կտակը', ',', 'որպեսզի', 'ժառանգներին', 'չզրկի', 'բոլոր', 'ժամանակների', 'լավագույն', 'բուրմունքներից', '։', 'Ինքը', '՝', 'Ռալդինին', ',', 'հոաալիորեն', 'կտնօրինի', 'այդ', 'կտակը', 'այն', 'բոլոր', 'ամենավեհ', 'անուշահոտությունների', 'բանաձևերի', 'կանոններին', ',', 'որոնք', 'երբևիցե', 'գոյություն', 'են', 'ունեցել', 'աշխարհի', 'վրա', ',', 'նա', 'կհասնի', 'դրանց', 'ճանաչմանը', '։', 'Նա', 'Գրենույի', 'անվանն', 'անմահ', 'փառք', 'կհաղոր', '–', 'ղի', ',', 'երդվում', 'է', 'բոլոր', 'սրբերով', ',', 'որ', 'այդ', 'բուրմունքներից', 'լավագույնը', 'կդնի', 'անձամբ', 'թագավորի', 'ոտքերի', 'առաջ', 'ագարե', 'սրվակով', 'ու', 'ոսկե', 'քանդակադրոշմով', 'և', 'փորագրված', 'ընծայումով', '.', '«', 'Ժան', '-', 'Ռատիստ', 'Գրենույից', '՝', 'Փարիզի', 'օծանագործից', '»', '։', 'Այդպես', 'էր', 'խոսում', 'կամ', ',', 'ավելի', 'շուտ', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ասացեք', ',', 'մետր', ',', 'կան', '՞', 'արդյոք', 'այլ', 'միջոցներ', ',', 'քամումից', 'ու', 'թորումից', 'բացի', ',', 'ինչ', '-', 'որ', 'մարմնից', 'բուրմունք', 'ստանալու', 'համար', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որոնք', '՞', 'ենկրկին', 'հնչեց', 'հարցը', ',', 'և', 'այս', 'անգամ', 'Բալ', '–', 'դինին', 'նկատեց', 'Գրենույի', 'շուրթերի', 'շարժումը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'որոնք', '՞', 'են', ',', '–', 'հարցրեց', 'Նա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Որտեղ', '՞', ',', '–', 'հարցրեց', 'Գրենույը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690\n",
            "700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', ',', 'որը', 'ոչ', 'մի', 'պատիվ', 'չուներ', ',', 'չէր', 'հավատում', 'սրբերին', 'և', 'առւսվել', 'ևս', '՝', 'իր', 'մոր', 'դժբախտ', 'հոգուն', ',', 'երդվեց', '։', 'Նա', 'կարող', 'էր', 'երդվել', 'ամեն', 'ինչով', '։', 'Նա', 'կընդուներ', 'Ռալդի', '–', 'նիի', 'բոլոր', 'ւցայմանները', ',', 'քանի', 'որ', 'նրան', 'ւսնհրաժեշտ', 'էր', 'ենթավարպետի', 'կարգավիճակը', 'հաստատող', 'թուղթը', ',', 'որը', 'հնարավորություն', 'էր', 'տալիս', 'նրան', 'առանց', 'աչքի', 'ընկնելու', 'ապրել', ',', 'առանց', 'խոչընդոտների', 'ճանապւսրհորդել', 'և', 'գտնել', 'աշխատանք', '։', 'Մնացածի', 'հւսնդեպ', 'նա', 'անտարբեր', 'էր', '։', 'Եվ', 'իՂւչ', 'պայմաններ', 'էին', 'դրանք', 'որ', '։', 'Չվերադառնալ', 'Փարիզ', '։', 'Իսկ', 'նրա', 'ինչիՆ', 'էր', 'պետք', 'Փւսրիզը', '։', 'Նա', 'անգիր', 'գիտեր', 'մինչև', 'վերջին', 'գարշահոտ', 'անկյունը', ',', 'այն', 'ամենուր', 'կրում', 'էր', 'իր', 'հետ', ',', 'արդեն', 'մի', 'քանի', 'տարի', 'շարունակ', 'տիրում', 'էր', 'Փարիզին', '։', 'Չպատրաստել', 'բւսլդինյան', 'մոդայիկ', 'օծանեիքներ', '՞', '։', 'Չփոխւսնցել', 'բանաձձեր', '՞', '։', 'Կարծես', 'թե', 'նա', 'չի', 'կարող', 'հայտնագործել', 'հազարավոր', 'ուրիշները', ',', 'նույնչափ', 'լավը', ',', 'ավելի', 'լավը', ',', 'հարկավոր', 'է', 'միայն', 'ցանկանալ', '։', 'չէ', '՞', 'որ', 'նա', 'չէր', 'պատրաստվում', 'մրցակցել', 'Ռալդինիի', 'կամ', 'բուրժուա', 'օծանագործներից', 'ցանկւսցածի', 'հետ', '։', 'Նւս', 'չէր', 'էլ', 'մտւսծում', 'իր', 'արվեստով', 'մեծ', 'գումարներ', 'վաստակելու', 'մւսսին', ',', 'նա', 'չէր', 'ուզում', 'նույնիսկ', 'վաստակել', 'դրանով', 'ապրելու', 'գումւսր', ',', 'եթե', 'հՆարաւխր', 'լիներ', 'այլ', 'կերւց', 'ապրել', '։', 'Նա', 'ցւսնկանում', 'էր', 'իրենից', 'դուրս', 'բերել', 'իր', 'ներքին', 'եսը', ',', 'ոչ', 'այլ', 'ինչ', ',', 'քան', 'իր', 'ներքին', 'եսը', ',', 'որը', 'համւսրում', 'էր', 'ավելի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['հրաշալի', 'տաղանդը', 'և', 'Ներկայացրել', 'նրա', 'ընդունակությունները', 'որպես', 'իմ', 'սեփականը', '։', 'Ամենաշատը', 'այն', ',', 'որ', 'թեթևակի', 'շեղվել', 'եմ', 'ավանդակւսն', 'արհեստավորական', 'առաքինության', 'ուղուց', '։', 'Ամենաշատը', 'նրանում', ',', 'որ', 'այսօր', 'անում', 'եմ', 'այն', ',', 'ինչը', 'դեռ', 'երեկ', 'անիծում', 'էի', '։', 'Միթե', '՛', 'դւս', 'հանցագործություն', 'է', '։', 'Ուրիշները', 'խաբում', 'են', 'ողջ', 'կյանքում', '։', 'Իսկ', 'ես', 'ընդամենը', 'մի', 'քանի', 'տարի', 'մի', 'քիչ', 'խւսրդախու', '–', 'թյուն', 'արեցի', '։', 'Եվ', 'այն', 'էլ', 'այն', 'պատճառով', ',', 'որ', 'նման', 'անսովոր', 'հնարավորություն', 'ընձեռվեց', '։', 'Միգուցե', 'հնարավորություն', 'էլ', 'չի', 'ընձեռվել', ',', 'միգուցե', 'անձամբ', 'Տերն', 'է', 'իմ', 'տուն', 'ուղարկել', 'այդ', 'կախարդին', ',', 'որպեսզի', 'ինձ', 'պարգևատրի', 'նվաստացումների', 'համար', ',', 'որոնք', 'կրել', 'եմ', 'Պելիսյեից', 'ու', 'նրա', 'հանցակից', 'ընկերներից', '։', 'Միգուցե', 'Աստծու', 'պւստիժը', 'սպասում', 'է', 'ամենևին', 'էլ', 'ոչ', 'ինձ', ',', 'այլ', 'Պելիսյեին', '։', 'Դա', 'շատ', 'ու', 'շատ', 'հնարավոր', 'է', '։', 'Իսկ', 'էլ', '՛', 'ինչով', 'Տերը', 'կկարողւսնար', 'պատժել', 'Պելիսյեին', ',', 'եթե', 'ոչ', 'իմ', 'վերելքով', '։', 'Հետևաբար', ',', 'իմ', 'երջանկությունը', 'Աստծու', 'ձեռքի', 'գործն', 'էր', ',', 'և', 'ես', 'ոչ', 'միայն', 'իրավունք', 'ունեի', ',', 'այլև', 'պարտավոր', 'էի', 'այն', 'ընդունել', 'որպես', 'այդպիսին', '՝', 'առանց', 'ամոթի', 'ու', 'զղջումի', '...', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'այղ', 'ժամանակ', 'հանկարծ', ',', 'հենց', 'դրանում', 'էր', 'վարժության', 'իմաստը', ',', 'կուտակված', 'ատելությունը', 'գինարբու', '–', 'քային', 'հզորությամբ', 'մղում', 'էր', 'դուրս', '։', 'Ինչպես', 'ամպրոպը', 'այն', 'հավաքվում', 'էր', 'այղ', 'հոտերի', 'վերևում', ',', 'որոնք', 'համարձակվել', 'էին', 'անպատվել', 'իր', 'պայծառափայլ', 'քիթը', '։', 'Ինչպես', 'կարկուտը', 'ցորենի', 'դաշտի', 'վրա', '՝', 'նա', 'հարձակվում', 'էր', 'այդ', 'գարշելիության', 'վրա', ',', 'ինչպես', 'մրրիկը', 'այն', 'վեր', 'էր', 'ածում', 'դիմափոշու', 'և', 'խեղդում', 'հորդառատ', 'ջրի', 'կողմից', 'մաքրված', 'ահռելի', 'թորած', 'ջրի', 'մեջ', '։', 'Այդ', 'աստիճան', 'արդար', 'էր', 'նրա', 'ցասումը', '։', 'Այդ', 'աստիճան', 'արդար', 'էրնրա', 'կրեժը', '։', '<UNK>', '՜', '։', 'Ինչպիսի', '՜', 'վեհ', 'ակնթարթ', '։', 'Գրենույը', 'այդ', 'փոքրիկ', 'մարդը', ',', 'գրգռվածությունից', 'դողում', 'էր', ',', 'նրա', 'մարմինը', 'ջղաձգորեն', 'սեղմվում', 'էր', 'քաղցրավուն', 'հաճույքի', 'մեջ', 'ու', 'գալարվում', 'այնպես', ',', 'որ', 'ինչ', '-', 'որ', 'մի', 'պահ', 'նա', 'բախվում', 'էր', 'հանքարանի', 'բովանցքի', 'առաստաղին', ',', 'հետո', 'դանդաղ', 'թուլանում', 'էր', 'ու', 'մնում', 'պառկած', ',', 'դատարկված', 'ու', 'խորապես', 'բավարարված', '։', 'Բոլոր', 'գարշեփ', 'հոտերի', 'ժայթքման', 'այս', 'գործողությունը', 'իրոք', 'չափից', 'դուրս', 'հաճելի', 'էր', ',', 'չափից', 'դուրս', '...', 'Նրա', 'երևակայական', 'համաշխարհային', 'թատրոնի', 'սցենարում', 'այդ', 'համարը', 'կարծես', 'ամենասիրվածն', 'էր', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "780\n",
            "790\n",
            "800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'երբ', 'մեր', 'թանկագին', 'Ժան', '-', 'Բատիստը', ',', 'որն', 'ի', 'վերջո', 'վերադարձել', 'էր', 'իր', 'մոտ', ',', 'պառկեց', 'ծիրանագույն', 'սրահում', '՝', 'իր', 'հարմարավետ', 'բազմոցի', 'վրա', ',', 'եթե', 'կուզեք', ',', 'ի', 'վերջո', 'հանեց', 'ճտքակոշիկները', ',', 'ծափ', 'տվեց', 'ու', 'իր', 'մոտ', 'կանչեց', 'ծառա', '–', 'ներին', ',', 'որոնք', 'անտեսանելի', 'էին', ',', 'անշոշափելի', ',', 'անլսելի', 'ու', 'հոտառությամբ', 'անորսալի', ',', 'այսինքն', '՝', 'ամբողջապես', 'երևակայական', 'ծառասերին', ',', 'ևնրանց', 'ուղարկեց', 'պահեստանոց', ',', 'որպեսզի', 'հոտերի', 'մեծ', 'գրադարանից', 'իրեն', 'բերեն', 'այս', 'կամ', 'այն', 'հատորը', ',', 'ու', 'հրամայեց', 'նրանց', 'իջնել', 'նկուղ', ',', 'որպեսզի', 'իրեն', 'խմիչք', 'բերեն', '։', 'Երևակայական', 'ծառաները', 'շտապում', 'էին', 'կատարել', 'կարգադրությունը', ',', 'և', 'Գրենույի', 'ստամոքսը', 'սեղմվում', 'էր', 'տանջալի', 'սպասման', 'ջղաձգությունից', '։', 'Նա', 'անսպասելիորեն', 'ունենում', 'էր', 'վաճառասեղանի', 'առջև', 'կանգնած', 'հարբեցողի', 'զգացում', ',', 'որին', 'տիրում', 'էր', 'սարսափը', ',', 'որ', 'ինչ', '-', 'որ', 'անհայտ', 'պատճառներով', 'Նրան', 'կհրաժարվեն', 'մատուցել', 'պատվիրած', 'օղին', '։', 'Իսկ', 'միգուցե', 'նկուղներն', 'ու', 'պահեստները', 'միանգամից', 'դատարկվել', '՞', 'էին', '։', 'Միգուցե', 'տակառների', 'գինին', 'ցնդել', '՞', 'էր', '։', 'Ինչու', '՞', 'իրեն', 'ստիպեցին', 'սպասել', '։', 'Ինչու', '՞', 'չեն', 'գալիս', '։', 'Գեղանյութընրան', 'հիմա', 'էր', 'պահանջվում', ',', 'անմիջապես', ',', 'նա', 'ծարավից', 'մահանում', 'է', ',', 'նա', 'կմեռնի', 'տեղում', ',', 'եթե', 'այն', 'չստանա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n",
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n",
            "1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['դրա', 'հետ', 'ոչինչ', 'չէր', 'կարող', 'անել', '։', 'Չափից', 'դուրս', 'անսպասելի', 'էր', 'բուրմունքի', 'այդ', 'հարձակումը', '։', 'Մ՝ի', 'ակնթարթ', 'մի', 'ներշնչումի', 'ակնթարթ', ',', 'որը', 'հավերժություն', 'տևեց', ',', 'նրան', 'թվաց', ',', 'որ', 'ժամանակը', 'կրկնակի', 'արագացել', 'է', 'կամ', ',', 'հակառակը', ',', 'անհետացել', ',', 'քանի', 'որ', 'դադարեց', 'հասկանալ', 'արդյոք', 'հիման', 'հիմա', '՞', 'է', ',', 'այստեղը', 'այստեղ', ',', 'ու', 'արդյոք', 'այժմը', 'անցյյա', '՞', 'չէ', ',', 'իսկ', 'այստեղը', 'այնտեղ', ',', 'այսինքն', '՝', '1753', 'թվականի', 'սեպտեմբերին', 'Փարիզում', '՝', 'Աարե', 'փողո', '–', 'ցում', ',', 'բուրմունքը', ',', 'որը', 'շիթով', 'բխում', 'էր', 'այգուց', ',', 'շիկահեր', 'աղջկա', '՞', 'բուրմունքն', 'էր', ',', 'որին', 'այն', 'ժամանակ', 'սպանեց', '։', 'Լկն', ',', 'որ', 'նա', 'այդ', 'բուրմունքը', 'կրկին', 'գտավ', 'աշխարհում', ',', 'նրա', 'աչքերը', 'լցրին', 'երանելի', 'երջանկության', 'արտասուքներով', ',', 'իսկ', 'այն', ',', 'որ', 'դա', 'կարող', 'էր', 'իրական', 'չլինել', ',', 'մահվան', 'աստիճան', 'սարսափեցրեց', 'նրան', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Լէխ', '՜', '։', 'Նա', 'ուզում', 'էր', 'տիրւսնալ', 'ւսյդ', 'բուրմունքին', '։', 'Տիրանւսլ', 'ոչ', 'այնքան', 'խենթորեն', ',', 'ինչպես', 'այն', 'ժւսմւսնակ', 'Մարե', 'փողոցի', 'վրւս', '։', 'Նա', 'ուղղակի', 'խմեց', 'այն', 'ւսղջկւս', 'հոտը', ',', 'լցրեց', 'իր', 'մեջ', 'ու', 'դրանով', 'էլ', 'կործանեց', '։', 'Ոչ', ',', 'պւստից', 'ւսյն', 'կողմ', 'գտնվող', 'աղջկւս', 'բուրմունքը', 'ցանկանում', 'էր', 'իրաւցես', 'յուրացնել', ',', 'հանել', 'նրւս', 'վրւսյից', ',', 'ինչւցես', 'մաշկը', ',', 'և', 'դւսրձնել', 'իր', 'սեւիակւս', '–', 'նությունը', '։', 'Նա', 'չգիտեր', ',', 'թե', 'դւս', 'ինչւցես', 'պետք', 'է', 'տեղի', 'ունե', '–', 'նւս', '։', 'Բայց', 'առջեում', 'ուներ', 'երկու', 'տարի', ',', 'որւցեսզի', 'սու|որեր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1020\n",
            "1030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['կսողան', 'վեր', '։', 'Եվ', 'պետք', 'է', 'մտածել', 'ար<UNK>ե', '՞', 'արդյոք', 'ապրանքը', 'վաճառել', 'այդ', 'խաբեբաներին', ',', 'թե', '՞', ',', 'ինչպես', 'անում', 'են', 'մնացած', 'մանր', 'արդյունաբերողները', ',', 'շրթներկի', 'բեռը', 'նավով', 'ուղարկել', 'Ջենովա', 'կամ', ',', 'օրինակ', ',', 'մասնակցել', 'Բոկերի', 'աշնանային', 'տոնավաճառին', ',', 'վտանգավոր', 'ձեռնարկում', 'է', ',', 'իհարկե', ',', 'բայց', 'հաջողության', 'դեւցքում', '՝', 'վերին', 'աստիճանի', 'եկամտաբեր', '։', 'Տիկինը', 'մանրակրկիտ', 'ձևով', 'ծանրութեթև', 'էր', 'անում', 'ւսյդ', 'տարբեր', 'հնւսրավորությունները', ',', 'համադրում', 'էր', 'դրանք', ',', 'իսկ', 'երբեմն', 'զուգակցում', 'մեկը', 'մյուսի', 'հետ', 'կամ', 'օգտագործում', 'դրանք', 'բոլորը', ',', 'իր', 'գանձերի', 'մի', 'մասը', 'վաճառում', 'էր', ',', 'մյուս', 'մասը', 'թաքցնում', ',', 'իսկ', 'երրորդով', 'ռիսկային', 'առուծախ', 'էր', 'անում', '։', 'Եվ', 'եթե', 'տեղեկություններ', 'հավաքելիս', 'նրա', 'մոտ', 'տպավորություն', 'էր', 'ստեղծվում', ',', 'որ', 'շուկան', 'գերհագեցած', 'է', 'շրթներկերով', ',', 'ու', 'տեսանելի', 'ժամանակահատվածում', 'իր', 'ապրանքի', 'պահանջարկը', 'չի', 'մեծանա', ',', 'նա', 'իր', 'ծածանվող', 'գլխաշորով', 'շտապում', 'էր', 'տուն', 'և', 'Դրյուոյին', 'հրամայում', 'արտւսդրանքը', 'վերւսմշակել', 'մւսքուր', 'բնահյութի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n",
            "1080\n",
            "1090\n",
            "1100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', 'սարսափեց', '։', '«', 'Իսկ', 'եթե', ',', '–', 'մտածեց', 'Նա', ',', '–', 'իսկ', 'եթե', 'այդ', 'բուրմունքը', ',', 'որին', 'տիրում', 'եմ', ',', 'վերջանա', '՞', '։', 'չէ', '՞', 'որ', 'դա', 'այնպես', 'չէ', ',', 'ինչպես', 'հիշողություններում', ',', 'որտեղ', 'բոլոր', 'հոտերն', 'անանցողիկ', 'են', '։', 'Իրականում', 'հոտը', ',', 'շփվելով', 'աշխարհի', 'հետ', ',', 'մաշվում', 'է', '։', 'Այն', 'եթերային', 'է', '։', 'Եվ', 'երբ', 'մաշվի', ',', 'այլևս', 'չի', 'լինի', 'ակունքը', ',', 'որտեղից', 'կերցրել', 'եմ', 'այն', '։', 'Եվ', 'ես', 'կմնամ', 'մերկ', ',', 'ինչպես', 'նախկինում', ',', 'և', 'ստիպված', 'կլինեմ', 'կրկին', 'ինձ', 'օգնել', 'փոխարինողնյութերով', '։', 'Ոչ', ',', 'կլինի', 'ավելի', 'վատ', ',', 'քան', 'Նախկինում', '։', 'չէ', '՞', 'որ', 'արդեն', 'ճանաչում', 'ու', 'տիրում', 'եմ', 'նրան', '՝', 'իմ', 'սեփական', 'արքայական', 'բուրմունքին', ',', 'և']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['չեմ', 'կարողնրան', 'մոռանալ', ',', 'քանի', 'որ', 'երբեք', 'չեմ', 'մոռանում', 'հոտերը', '։', 'Եվ', 'նշանակում', 'է', ',', 'որ', 'ողջ', 'կյանքումս', 'պետք', 'է', 'ւոառապեմ', 'նրա', 'մասին', 'հիշողությամբ', ',', 'ինչպես', 'արղեն', 'հիմա', 'եմ', 'տառապում', '՝', 'կանխավայելման', 'պահին', '...', 'Սյդ', 'դեպքում', 'ինչու', '՞', 'եմ', 'ընդհանրապես', 'ցանկանում', 'տիրել', 'դրան', ',', 'իմ', 'ինչին', '՞', 'է', 'պետք', '...', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ԼԼյդ', 'միտքը', 'չափազանց', 'տհաճ', 'էր', '։', 'Գրենույն', 'անչափ', 'վախեցավ', ',', 'որ', 'տիրելով', 'բուրմունքին', ',', 'որին', 'դեռչէր', 'տիրացել', ',', 'անխուսափելիորեն', 'այն', 'կրկին', 'կկորցնի', '։', 'որքան', '՞', 'երկար', 'կկարողանա', 'այն', 'պահել', '։', 'Սի', 'քանի', 'օր', '՞', '։', 'Սի', 'քանի', 'շաբաթ', '՞', '։', 'Սիգուցե', 'ողջ', 'ամիս', ',', 'եթե', 'շատ', 'խնայողաբար', 'օծվի', '։', 'Իսկ', 'հետո', '՞', '։', 'Նա', 'արդեն', 'տեսնում', 'էր', ',', 'թե', 'ինչպես', 'է', 'սրվակի', 'միջից', 'թափ', 'տալիս', 'վերջին', 'կաթիլը', ',', 'սրվակը', 'ողողում', 'գինու', 'սւղիրտով', ',', 'որւցեսզի', 'նույնիսկ', 'նվազագույն', 'մնացորդ', 'անգամ', 'չմնւս', ',', 'ու', 'տեսնում', ',', 'հոտառությամբ', 'զգում', 'է', ',', 'թե', 'ինչպես', 'է', 'իր', 'սիրելի', 'բուրմունքը', 'մեկընդմիշտ', 'ու', 'անվերադարձ', 'ցնդում', '։', 'Դա', 'կլինի', 'դանդաղ', 'մահ', ',', 'նա', 'կխեղդվի', ',', 'աստիճանաբար', ',', 'տւսնջալի', 'ցավերով', 'իրեն', 'կգոլորշացնի', 'դուրս', '՝', 'դեպի', 'գարշելի', 'աշխարհ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կան', 'հոտեր', ',', 'որոնք', 'պահպանվում', 'են', 'տասնամյակներ', 'շարունակ', '։', 'Մուշկով', 'շփված', 'սնդուկը', ',', 'դարչինի', 'յուղով', 'ներծծված', 'կաշվի', 'կտորը', ',', 'համպարի', 'գնդիկը', ',', 'մայրու', 'ծառից', 'զարդատուփը', 'հոտառական', 'իմաստով', 'գրեթե', 'հավերժ', 'են', 'ապրում', '։', 'Իսկ', 'մյուսները', '՝', 'սինե', '–', 'մեքի', 'յուղը', ',', 'բերգամոտը', ',', 'նարգիզի', 'լուծամզվածքն', 'ու', 'բրաբիոնը', 'և', 'ծաղկային', 'բույրերից', 'շատերը', ',', 'արդեն', 'մի', 'քանի', 'ժամ', 'անց', ',', 'եթե', 'դրանք', 'մաքուր', 'տեսքով', 'բացօթյա', 'դրվեն', ',', 'կորցնում', 'են', 'համն', 'ու', 'հոտը', '։', 'Օծանագործը', 'պայքարում', 'է', 'այդ', 'ճակատագրական', 'հանգամանքի', 'դեմ', '՝', 'չափից', 'դուրս', 'ցնդող', 'բուրմունքը', 'կաւցելով', 'կւսյունների', 'հետ', ',', 'նրանց', 'վրա', 'դնելով', 'կապանքներ', ',', 'որոնք', 'սանձում', 'են', 'նրանց', 'ազաւոության', 'ձգտումը', ',', 'իսկ', 'արվեստն', 'այն', 'է', ',', 'որ', 'կապանքները', 'չդրվեն', 'կոշտորեն', ',', 'այլ', 'ւսզատություն', 'տրամադրեն', 'կապված', 'հոտին', ',', 'բայց', ',', 'այսուհանդերձ', ',', 'նրան', 'պահելով', 'բավականաչափ', 'մոտ', ',', 'որպեսզի', 'չկարողանա', 'փախչել', '։', 'Այս', 'ճարւցիկ', 'հնարքը', 'Գրենույին', 'երկու', 'անգամ', 'հրաշալի', 'հաջողվեց', 'կատարել', 'բրաբիոնի', 'յուղի', 'հետ', ',', 'որի', 'վաղանցիկ', 'բուրմունքը', 'շղթայեց', 'չափւսզւսնց', 'փոքր', 'քանակությամբ', 'մուշկի', ',', 'վանիլի', ',', 'խունկի', 'ունոճու', 'հետ', 'և', 'հատկապես', 'դրւսնով', 'բացւսհայտեց', 'նրւս', 'հմւսյ', '–', 'քը', '։', 'չի', '՞', 'կարելի', 'արդյոք', 'նմւսնատիպ', 'մի', 'գործողություն', 'կատարել', 'աղջկա', 'բուրմունքի', 'հետ', '։', 'միթե', '՞', 'ւսնւցայմանո', '–', 'րեն', 'պետք', 'է', 'վատնել', 'բուրմունքներից', 'ամենասւսրսւս', '–', 'փեցնորը', ',', 'ամենաթանկարժեքն', 'ու', 'ւսմենւսփխրունը', '՝', 'այն', 'օգտագործելով', 'մաքուր', 'տեսքով', '։', 'Որքքսնն', '՜', 'ւսնհեթեթ', 'է', '։', 'Ինչպիսի', '՜', 'ւսպաշնորհություն', '։', 'միթե', '՞', 'ալմաստը', 'թողնում', 'են', 'չհղկված', '։', 'միթե', '՞', 'ոսկին', 'պարւսնոցին', 'են', 'կրում', 'բնակտորներով', '։', 'միթե', '՞', 'ինքը', 'Գրենույը', ',', 'ընդւսմենը', 'հոտերի', 'պրիմիտիվ', 'գող', 'է', '՝', 'նման', 'Դրյուոյին', 'ու', 'մնւսցած']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ծաղիկներ', 'կակղեցնողներին', ',', 'թորողներին', 'ու', 'քամողներին', '։', 'միթե', '՞', 'ինքը', 'չէ', 'աշխարհի', 'մեծագույն', 'օծանագործը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['երկրորդ', 'խորհրդականի', 'համար', ',', 'որը', ',', 'նրա', 'կարծիքով', ',', 'քաղաքացիների', 'համար', 'պարտավոր', 'է', 'զսպվածության', ',', 'քաջարիության', 'ու', 'անկոտրումության', 'օրինակ', 'դառնալ', '։', 'Դրանից', 'զատ', ',', 'նա', 'մեկն', 'էր', ',', 'որի', 'վզին', 'ոչ', 'մեկը', 'չէր', 'համարձակվի', 'փաթաթել', 'իր', 'որոշումները', 'ոչ', 'խուճապով', 'բռնկված', 'ամբոխը', ',', 'ոչ', 'առավել', 'ևս', 'մեն', '-', 'միակ', 'անւսնուն', 'տականք', '-', 'հանցագործը', '։', 'Եվ', 'այդ', 'ողջ', 'սարսափելի', 'ժամանակաընթացքում', 'Նա', 'քաղաքում', 'քչերից', 'մեկն', 'էր', ',', 'ով', 'չտրվեց', 'սարսավի', 'տենդին', 'ու', 'պահպանեց', 'սթափ', 'մտածողությունը', '։', 'Բայց', 'այդ', 'ամենը', 'տարօրինակ', 'ձևով', 'այժմ', 'փոխվել', 'էր', '։', 'Այն', 'ժամանւսկ', ',', 'երբ', 'մարդիկ', 'փողոցներում', '(', 'կարծես', 'թե', 'նրանք', 'արդեն', 'կախաղւսն', 'էին', 'բարձրացրել', 'մարդասպանին', ')', 'տոնում', 'էին', 'նրա', 'չւսրագործություննե', '–', 'րի', 'ավարտն', 'ու', 'գրեթե', 'մոռացել', 'էին', 'այն', 'չարւսբաստիկ', 'ժամանակը', ',', 'Անտուան', 'Ռիշիի', 'սրտի', 'մեջ', ',', 'ինչպես', 'մի', 'անխուսափելի', 'դժոխք', ',', 'վախ', 'էր', 'մտել', '։', 'Սկզբում', 'չէր', 'ցանկւս', '–', 'նում', 'ընդունել', ',', 'որ', 'հատկապես', 'վախն', 'էր', 'ստիպում', 'իրեն', 'հետաձգել', 'վաղուց', 'հասունացած', 'ուղևորությունները', ',', 'ավելի', 'հազվադեպ', 'քաղաք', 'դուրս', 'գալը', ',', 'այցերի', 'ու', 'խորհրդակցությունների', 'կրճատումը', ',', 'միայն', 'այն', 'ւցատճւսռով', 'որպեսզի', 'շուտ', 'տուն', 'վերադառնա', '։', 'Նա', 'երկւսր', 'ժւսմանւսկ', 'ւսրդւսրանում', 'էր', 'ինքն', 'իր', 'ւսռջև', 'զբւսղվւսծությամբ', 'ուգեր', '–', 'հոգնւսծությամբ', ',', 'բայց', ',', 'վերջիվերջո', 'խոււտու|անեց', ',', 'որ', 'որոշակիորեն', 'մտւսհոգված', 'է', ',', 'ինչւցես', 'մտահոգված', 'կլիներ', 'նրա', 'տեղում', 'գտնվող', 'յուրաքւսնչյուր', 'հւսյր', ',', 'որն', 'ուներ', 'հարսնւսցու', '-', 'դուստր', '.', 'չէ', '՞', 'որ', 'նմւսն', 'մւուսհոգությռւնը', 'սովո', '–', 'րւսկան', 'երևույթ', 'է', '...', 'Աիթե', '՞', 'ողջ', 'ւսշխւււրհով', 'մեկ', 'ւսրդեն', 'չի', 'տարածվել', 'Նրւս', 'գեղեցկության', 'մւսսին', 'փւսռքը', '։', 'Աիթե', 'չեն', 'ձգվում', 'բոլոր', 'ւցարւսնոցները', ',', 'երբ', 'կիրակի', 'օրերին', 'նրւս', 'հետ', 'եկեղեցի', 'է', 'մտնում', '։', 'Աիթե', 'Խորհրդի', 'որոշ', 'պարոններ', 'իրենց', 'կւսմ', 'իրենց', 'որդիների', 'անունից', 'արդեն', 'չեն', 'ւսկնար', '–', 'կել', 'հնարավոր', 'հավւսկնությունների', 'մւսսին', '...']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['նրբաճաշակ', 'գեղեցկությամբ', '։', 'Երբևիցե', 'նա', 'չէր', 'էլ', 'կարծել', ',', 'որ', 'Գրասում', 'Նման', 'քանակությամբ', 'չգնահատված', 'գեղեցկություն', 'կար', '։', 'Մարդասպանը', 'բացել', 'էր', 'նրա', 'աչքերը', '։', 'Մարդասպանն', 'աչքի', 'էր', 'ընկնում', 'գերազանց', 'ճաշակով', '։', 'Եվ', 'գործում', 'էր', 'համակարգված', 'ձևով', '։', 'Բավական', 'չէ', ',', 'որ', 'նրա', 'բոլոր', 'սպանություններն', 'իրականացված', 'էին', 'միատեսակ', 'ճշտակատարությամբ', ',', 'զոհերի', 'բուն', 'ընտրությունն', 'իսկ', 'մատնում', 'էր', 'գրեթե', 'մաթեմատիկական', 'հաշվարկը', '։', 'ճիշտ', 'է', ',', 'Ռիշին', 'չգիտեր', ',', 'թե', ',', 'անկեղծ', 'ասած', ',', 'ինչ', 'էր', 'մարդասպանն', 'ուզում', 'իր', 'զոհերից', ',', 'քանզի', 'չէ', '՞', 'որ', 'նա', 'չէր', 'գողացել', 'նրանց', 'գլխավոր', 'հարստությունը', '՝', 'պատանեկության', 'գեղեցկությունն', 'ու', 'հմայքը', '...', 'թե', '՞', 'գողացել', 'էր', '։', 'Համենայնդեպս', ',', 'որքան', 'էլ', 'դա', 'անհեթեթ', 'է', 'հնչում', ',', 'թվում', 'էր', ',', 'թե', 'սպանությունների', 'նպատակը', 'ոչ', 'թե', 'կործա', '–', 'նելն', 'էր', ',', 'այլ', 'խնամքով', 'հավաքածու', 'կազմելը', '։', 'Եթե', ',', 'օրինակ', ',', 'տրամաբանում', 'էր', 'Ռիշին', ',', 'բոլոր', 'զոհերին', 'ւցատկե', '–', 'րացնենք', 'ոչ', 'թե', 'որպես', 'առանձին', 'անհատներ', ',', 'այլ', 'որւցես', 'ինչ', '-', 'որ', 'բարձրագույն', 'սկզբունքի', 'մաս', ',', 'և', 'իդեալիստորեն', 'պատկերացնենք', 'նրանց', 'այդչւսփ', 'տւսրբեր', 'հատկանիշները', 'մեկ', 'միասնության', 'մեջ', 'միաձուլված', ',', 'աւցւս', 'պւստկե', '–', 'ԸԸ', ',', 'ՈՐԸ', 'բաղկացւսծ', 'էնմանատիպ', 'բազմերւսնգությունից', ',', 'ընդհանուր', 'առմամբ', ',', 'կլիներ', 'գեղեցկության', 'պատկեր', ',', 'ու', 'կախարդանքը', ',', 'որը', 'դուրս', 'էր', 'գալիս', 'նրւսնից', ',', 'կունենար', 'ոչ', 'թե', 'մարդկային', ',', 'այլ', 'աստվւսծային', 'իշխանություն', '։', '(', 'Ինչպես', 'տեսնում', 'ենք', ',', 'Ռիշին', 'լուսավորյւսլ', 'ու', 'տրւսմաբանող', 'մարդ', 'էր', ',', 'որը', 'չէր', 'վախենում', 'նույնիսկ', 'նման', 'սրբւսպիղծ', 'հետևություններ', 'անելուց', ',', 'և', 'չնւսյւսծ', 'նւս', 'մւոածում', 'էր', 'ոչ', 'թե', 'հոտւսռական', ',', 'այլ', 'օպտիկւսկան', 'կատեգորիւսներով', ',', 'այնուամենայնիվ', ',', 'շատ', 'մոտ', 'էր', 'ճշմւսրտությւււնը', ')', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գալով', 'նման', 'սարսափեցնող', 'եզրահանգման', '՝', 'Ռիշին', ',', 'իր', 'անկողնու', 'վրա', 'գիշերային', 'վերնաշապիկով', 'նստած', ',', 'ապշում', 'էր', 'Աեփական', 'հանգստության', 'վրա', '։', 'Նա', 'այլևս', 'դողից', 'չէր', 'ցնցվում', '։', 'Անորոշ', 'վախը', ',', 'որը', 'մի', 'քանի', 'շաբաթ', 'շարունակ', 'կեղեքում', 'էրնրան', ',', 'անհետացել', 'էր', '՝', 'տեղը', 'զիջելով', 'կոնկրետ', 'վտանգի', 'գիտակցմանը', '։', 'Մնյրդասպանի', 'մտադրությունն', 'ակնհայտորեն', 'ուղղված', 'էր', 'էաուրայի', 'վրա', 'ամենասկզբից', '։', 'Իսկ', 'մնացած', 'բոլոր', 'սպանությունները', 'շրջապատն', 'էին', 'այդ', 'վերջինի', '՝', 'ավարտական', 'սպանության', '։', 'ճիշտ', 'է', ',', 'անհասկանալի', 'էր', 'մնում', ',', 'թե', 'ինչպիսի', 'նյութական', 'նպատակներ', 'են', 'հետապնդում', 'այդ', 'սպանությունները', 'և', ',', 'ընդհանրապես', ',', 'ունեն', '՞', 'դրանք', 'որևէ', 'նպատակ', '։', 'Ռայց', 'հիմնականը', ',', 'հատկապես', '՝', 'մարդասպանի', 'դասակարգված', 'գործելաոճն', 'ու', 'նրա', 'ձգտումը', 'դեպի', 'կատարյալը', ',', 'Ռիշին', 'ճիշտ', 'կռահեց', '։', 'Եվ', 'որքան', 'երկար', 'էր', 'դրա', 'վրա', 'խորհում', ',', 'այնքան', 'ավելի', 'էր', 'դուր', 'գալիս', 'նրան', 'թե*', 'մեկը', ',', 'թև', 'մյուսը', ',', 'և', 'այնքան', 'մեծ', 'հարգանք', 'էր', 'տածում', 'մարդասպանի', 'հանդեպ', ',', 'նման', 'հարգանքը', ',', 'ինչպես', 'հարթ', 'հայելու', 'մեջ', ',', 'արտացոլում', 'էրնրա', 'վերաբերմունքն', 'իր', 'հանդեպ', ',', 'չէ', '՞', 'որ', 'ոչ', 'այլ', 'ոք', ',', 'այլ', 'հենց', 'ինքը', '՝', 'Ռիշին', ',', 'իր', 'նուրբ', ',', 'վերլուծական', 'խելքով', 'ներթափանցեց', 'հակառակորդի', 'մտահղացման', 'մեջ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1180\n",
            "1190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դստեր', 'հետ', 'Սնտուան', 'Ռիշիի', 'մեկնումը', 'մարդկանց', 'վրա', 'թողեց', 'տարօրինակ', 'խոր', 'տպավորություն', '։', 'Նրանց', 'թվում', 'էր', ',', 'թե', 'իրենք', 'ներկա', 'են', 'գտնվում', 'զոհւսբերությւսն', 'մի', 'ինչ', '-', 'որ', 'հնադարյան', 'ծիսակատարությւսն', '։', 'Չորսբոլորը', 'խոսում', 'էին', 'միայն', 'այն', 'մասին', ',', 'որ', 'Ռիշին', 'մեկնում', 'է', 'Գրենոբլ', ',', 'այսինքն', '՝', 'մի', 'քաղաք', ',', 'որտեղ', 'վերջին', 'ժամանակներս', 'գործում', 'է', 'աղջիկներին', 'սպանող', 'հրեշը', '։', 'Մարդիկ', 'չգիտեին', 'էլ', ',', 'թե', 'ինչ', 'մտածեն', 'դրա', 'վերաբերյալ', '։', 'Ինչով', '՞', 'բացատրել', 'Ռիշիի', 'արարքը', 'դատապարտե|ի', 'թեթևատութթ', '՞', ',', 'թե', '՞', 'հիացմունքի', 'արժանի', 'խիզախությամբ', '։', 'Մարտահարեր', '՞', 'էր', 'դա', ',', 'թե', '՞', 'աստվածների', 'ողորմածությունը', 'շարժելու', 'փորձ', '։', 'Ռայց', 'Նրանց', 'տանջում', 'էր', 'աղոտ', 'կանխազգացումը', ',', 'որ', 'շիկահեր', 'ծամերով']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ռիշին', 'հասկանում', 'էր', ',', 'որ', 'նման', 'շտապողականությունը', 'որոշակիորեն', 'բարձրացնում', 'է', 'բարոնի', 'ընտանիքի', 'հետ', 'իր', 'ընտանիքի', 'միացման', 'վճարի', 'չափը', '։', 'Նա', 'շատ', 'ավելի', 'քիչ', 'կվճարեր', ',', 'եթե', 'սպասելու', 'ժամանակ', 'ունենար', '։', 'Այդ', 'դեպքում', 'բարոնը', 'ստիպված', 'կլիներ', ',', 'ինչպես', 'աղքատը', ',', 'հարուստ', 'վաճառականի', 'համաձայնությունը', 'խնդրել', 'այդ', 'գործարքի', 'համար', ',', 'չէ', '՞', 'որ', 'էաուրայի', 'գեղեցկության', 'մասին', 'փառքը', 'պիտի', 'աճի', ',', 'ինչպես', 'որ', 'Ռիշիի', 'հարստությունը', 'և', 'ինչպես', 'Ռույոնների', 'ֆինանսական', 'սնանկացումը', '։', 'Ռայց', 'լավ', ',', 'թող', 'լինի', 'այդպես', '։', 'չէ', '՞', 'որ', 'Նրա', 'հակառակորդը', 'ոչ', 'թե', 'բարոնն', 'էր', ',', 'այլ', 'անհայտ', 'մարդասպանը', '։', 'Ահա', 'թե', 'ում', 'գործին', 'պետք', 'է', 'խանգարեբ', 'Ամուսնացած', 'կինը', ',', 'ով', 'կորցրել', 'է', 'կուսությունը', 'և', 'միգուցե', 'հղի', 'է', ',', 'արդեն', 'չի', 'կարոդ', 'ներգրավվել', 'նրա', 'բացառիկ', 'հավաքածուի', 'մեջ', '։', 'Այդնախշապատկերի', 'վերջին', 'վանդակը', 'կմնա']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200\n",
            "1210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', 'պահակախմբին', 'հարցրեց', ',', 'թե', 'որ', 'ճանապարհով', 'է', 'գնացել', 'երկրորդ', 'խորհրդականը', '։', 'Պահակներից', 'մեկը', 'ցույց', 'տվեց', 'դեպի', 'հյուսիս', '։', 'Իսկ', 'գուցե', 'Կաբ', '–', 'րիի', '՞', 'ուղղությամբ', '։', 'Կամ', 'գուցե', 'ուղղվել', 'է', 'դեպի', 'հարավ', '՞', 'Օրիբոյի', 'կամ', 'էա', '-', 'Նապուլի', 'ուղղությամբ', '։', 'Իհարկե', 'ոչ', ',', 'ասաց', 'պահակը', ',', 'նա', 'Աեփական', 'աչքերով', 'է', 'տեսել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երկու', 'ժամ', 'հետո', ',', 'երբ', 'արդեն', 'շատ', 'էր', 'մթնել', ',', 'նրանք', 'մոտեցան', '։', 'Իրենց', 'ծպտվածությունը', 'պահպանելու', 'համար', 'երեքն', 'էլ', 'փոխել', 'էին', 'հագուստները', '։', 'Երկու', 'կանայք', 'էլ', 'մուգ', 'գույնի', 'շրջազգեստներով', 'ու', 'շղարշներով', 'էին', ',', 'Ռիշին', '՝', 'սև', 'բաճկոնով', '։', 'Նա', 'իրեն', 'ներկայացնում', 'էր', 'որպես', 'Կաստեղանայից', 'եկած', 'ազնվական', ',', 'վաղը', 'ցանկանում', 'էր', 'ծովանցով', 'հասնել', 'էերինյան', 'կղզիներ', ',', 'թող', 'տերը', 'լուսաբացին', 'մոտ', 'նախաճաշ', 'պատրաստի', '։', 'Կան', '՞', 'արդյոք', 'տանն', 'այլ', 'կենվորներ', '։', 'Ոչ', ',', 'ասաց', 'տերը', ',', 'միայն', 'Նիցցայից', 'մի', 'կաշեգործի', 'ենթավարպետ', ',', 'ով', 'ախոռում', 'է', 'գիշերում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1230\n",
            "1240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'մի', 'կողմ', 'դրեց', 'մահակն', 'ու', 'ողջ', 'ջանասիրությամբ', 'անցավ', 'գործի', '։', 'Սկզբում', 'բացեց', 'իր', 'հետ', 'բերած', 'քաթւսնը', 'և', 'այն', 'մաքուր', 'կողմով', 'փռեց', 'սեղանի', 'ու', 'աթոռների', 'կրա', '՝', 'հետևելով', ',', 'որպեսզի', 'ճարպոտ', 'կողմին', 'չդիպչի', '–', 'Մղջ', '–', 'կա', 'շքեղ', 'բուրմունքը', ',', 'որը', 'հանկարծ', 'տաք', 'ու', 'խիտ', 'ալիքով', 'հորդեց', 'նրանից', ',', 'այս', 'անգամ', 'Գրենային', 'չհուզեց', '։', 'չէ', '՞', 'որ', 'դա', 'նրան', 'ծանոթ', 'էր', ',', 'իսկ', 'արբածության', 'աստիճան', 'վայելքն', 'ավելի', 'ուշ', 'կստանա', 'այն', 'բանից', 'հետո', ',', 'երբ', 'իրոք', 'կտիրի', 'նրան', '։', 'Այժմ', 'այն', 'որքան', 'հնարավոր', 'է', 'շատ', 'պետք', 'է', 'հավաքել', ',', 'որքան', 'հնարավոր', 'է', 'քիչ', 'արտահոսք', 'տալ', ',', 'այժմ', 'նրանից', 'պահանջվում', 'էր', 'կենտրոնացվածու', '–', 'թյուն', 'ու', 'արագաշարժություն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['և', 'որ', 'ճակատագիրն', 'իրեն', 'տանում', 'էր', 'խճճված', ',', 'բայց', 'վերջին', 'հաշվով', 'ճիշտ', 'ուղով', ',', 'այլապես', 'միթե', '՞', 'ինքը', 'կարող', 'էր', 'հայտնվել', 'այստեղ', 'այս', 'մութ', 'սենյակում', '՝', 'իր', 'ձգտումների', 'նպատակակետի', 'մոտ', '։', 'Ինքը', ',', 'եթե', 'լավ', 'խորհրդածենք', ',', 'հիրավի', 'օրհնյալ', 'անհատ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'հետո', '՞', '։', 'Ինչ', '՞', 'կանի', 'դրանից', 'հեւոո', '։', 'Չգիտեր', '։', 'Միգուցե', 'կվերադւսռնա', 'սովորակւսն', 'կյանքին', ',', 'միգուցե', 'կամուսնանա', ',', 'միգուցե', 'որդի', 'կսաղմնավորի', ',', 'միգուցե', 'ոչինչ', 'չի', 'անի', ',', 'միգուցե', 'կմեռնի', '։', 'Նա', 'բացւսրձւսկւսպես', 'անտւսրբեր', 'էր', 'դրա', 'հւսնդեպ', '։', 'Դրա', 'մասին', 'մւուսծելը', 'նրւսն', 'նույնչափ', 'անիմաստ', 'էր', 'թվում', ',', 'ինչւցես', 'ւևռածելը', 'ւսյն', 'մասին', ',', 'թե', 'ինչ', 'ւսնի', 'մահւսնալուց', 'հետո', ',', 'բնւսկանւսբւսր', ',', 'ոչինչ', '։', 'Ոչինչ', ',', 'ինչի', 'մասին', 'նա', 'կարող', 'էր', 'իմանալ', 'ւսրդեն', 'հիմւս', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['հանցագործի', 'նկատմամբ', 'պահանջվում', 'էր', 'բացառիկ', 'վերաբերմունք', '։', 'չէ', '՞', 'որ', 'չի', 'կարելի', 'նրան', '՝', 'ինչպես', 'հասարակ', 'ավազակին', ',', 'շղթայակապ', 'քարշ', 'տալ', 'հրապարակ', 'ու', 'գավազաններով', 'խփել', '։', 'Դրանում', 'ոչ', 'մի', 'սենսացիոն', 'բան', 'չէր', 'լինի', '։', 'Բոլորովին', 'այլ', 'բան', 'է', 'նրան', 'հանել', 'շքեղ', 'կառքի', 'փափուկ', 'նստատեղից', 'ու', 'մոտեցնել', 'խաչին', '.', 'դրանում', 'անհամեմատ', 'ավելի', 'շատ', 'ահագնացող', 'դաժանություն', 'կար', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'Պապոնը', 'դա', 'գիտեր', '։', 'Նրա', 'բռունցքները', ',', 'որոնք', 'սեղմել', 'էին', 'երկաթյա', 'ձողը', ',', 'դողացին', '։', 'Նրա', 'ուժեղ', 'ձեռքերը', 'հանկարծ', 'դարձան', 'այնքան', 'թույլ', ',', 'ծնկներն', 'այնքան', 'փափուկ', ',', 'սիրտն', 'այնքան', 'երկչոտ', ',', 'ինչպես', 'երեխայինը', '։', 'Նա', 'չէր', 'կարողանա', 'բարձրացնել', 'այդ', 'ձողը', ',', 'կյանքում', 'երբեքնրա', 'մոտ', 'ուժ', 'չէր', 'գտնվի', 'բարձրացնել', 'այն', 'ընդդեմ', 'փոքրիկ', 'անմեղ', 'մարդու', ',', 'ախ', '՜', ',', 'նա', 'վախենում', 'էր', 'այն', 'պահից', ',', 'երբ', 'նրան', 'կբերեն', 'այստեղ', 'վերև', '.', 'Նա', 'արտասվեց', ',', 'ստիպված', 'եղավ', 'հենվել', 'իր', 'մահաբեր', 'ձողի', 'վրա', ',', 'որպեսզի', 'ծնկների', 'թուլությունից', 'վայր', 'չընկնի', 'հսկայամարմին', ',', 'ուժեղ', 'Պապոնը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1370\n",
            "1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ռայց', 'դրանից', 'ոչինչ', 'չստացվեց', '։', 'Դրանից', 'ոչինչ', 'չէր', 'էլ', 'կարող', 'ստացվել', '։', 'չէ', '՞', 'որ', 'դիմակավորված', 'էր', 'աշխարհի', 'լւսվւսգույն', 'օծանելիքով', ',', 'իսկ', 'այդ', 'դիմակի', 'տակ', 'դեմք', 'չկար', ',', 'ոչինչ', 'չկար', ',', 'բացի', 'հոտի', 'համատարած', 'բացակայությունից', '։', 'Եվ', 'այդ', 'պահին', 'նա', 'անսպասելիորեն', 'վատ', 'զգաց', ',', 'որովհետև', 'տեսավ', ',', 'թե', 'ինչպես', 'են', 'կրկին', 'մառախուղները', 'վեր', 'բարձրանում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1390\n",
            "1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Այժմ', 'ամեն', 'ինչ', 'լավ', 'կլինի', '։', 'Քաղաքային', 'խորհուրդը', 'չեղյալ', 'համարեց', 'դատավճիռը', '։', 'Բոլոր', 'վկաները', 'հրաժարվեցին', 'ցուցմունքներից', '։', 'Դու', 'ազատ', 'ես', '։', 'Դու', 'կարող', 'ես', 'անել', 'ինչ', 'ուզում', 'ես', '։', 'Ռայց', 'ես', 'ուզում', 'եմ', ',', 'որ', 'դու', 'մնաս', 'ինձ', 'մոտ', '։', 'Ես', 'կորցրել', 'եմ', 'դստերս', ',', 'ես', 'ուզում', 'եմ', 'քեզ', 'որ', '–', 'դեգրել', '։', 'Դու', 'նման', 'ես', 'նրան', '։', 'Դունույնչափ', 'գեղեցիկ', 'ես', ',', 'ինչպես', 'նա', ',', 'քո', 'մազերը', ',', 'քո', 'շուրթերը', ',', 'քո', 'ձեռքը', '...', 'Ես', 'ողջ', 'ժամանակ', 'բռնել', 'էի', 'քո', 'ձեռքից', ',', 'դու', 'այնպիսի', 'ձեռք', 'ունես', ',', 'ինչպիսին', 'նրանն', 'էր', '։', 'Իսկ', 'երբ', 'նայում', 'եմ', 'քո', 'աչքերին', ',', 'թվում', 'է', ',', 'որնա', 'է', 'ինձ', 'նայում', '։', 'Դու', 'նրա', 'եղբայրն', 'ես', ',', 'և', 'ես', 'ուզում', 'եմ', ',', 'որ', 'դառնաս', 'իմ', 'որդին', ',', 'իմ', 'ուրախությունը', ',', 'իմ', 'հպարտությունը', ',', 'իմ', 'ժառանգորդը', '։', 'Քո', 'ծնողները', 'դեռ', 'ողղ', '՞', 'են', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['֊', 'Նշանակում', 'է', '՝', 'դու', 'համաձայն', 'ես', 'դառնալ', 'իմ', 'որդին', ',', '-', 'մի', 'շեչով', 'ասաց', 'նա', 'ու', 'վեր', 'թռավնստարանի', 'վրայից', ',', 'որպեսզի', 'նստի', 'մահճակալի', 'եզրին', 'և', 'Դրենույի', 'մյուս', 'ձեռքը', 'սեղմի', '։', '–', 'Համաձձան', '՞', 'ես', '։', 'Համաձձան', '՞', 'ես', '։', 'Դու', 'ցանկանու', '՞', 'ես', ',', 'որ', 'ես', 'քո', 'հայրը', 'դառնամ', '։', 'Ոչինչ', 'մի', 'ասա', '։', 'Մի', 'խոսիր', '։', 'Դու', 'դեռ', 'շատ', 'թույլ', 'ես', ',', 'որպեսզի', 'խոսես', '։', 'Միայն', 'գլխով', 'արա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1410\n",
            "1420\n",
            "1430\n",
            "1440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'մեկ', 'այլ', 'անգամ', ',', 'երբ', 'արդեն', 'Բուրգունդիայում', 'էր', ',', 'նրա', 'մտքով', 'անցավ', '.', '«', 'Երբ', 'ես', 'կանգնած', 'էի', 'այգու', 'քարե', 'պատից', 'այս', 'կողմ', ',', 'որտեղ', 'խաղում', 'էր', 'շիկահեր', 'աղջիկը', ',', 'և', 'ինձ', 'էր', 'հասնում', 'նրա', 'բուրմունքը', '...', 'կամ', 'ավելի', 'շուտ', 'բուրմունքի', 'խոստումը', ',', 'քանի', 'որ', 'Նրա', 'ավելի', 'ուշ', 'բուրմունքը', 'դեռ', 'ընդհանրապես', 'գոյություն', 'չուներ', ',', '֊', 'միգուցե', 'այն', ',', 'ինչը', 'զգացի', 'այն', 'ժամանակ', ',', 'նման', 'էր', 'ւսյն', 'բանին', ',', 'ինչը', 'մարդիկ', 'զգում', 'էին', 'հրաւցարակում', ',', 'երբ', 'ես', 'նրանց', 'հեղեղեցի', 'իմ', 'օծանելիքով', '...', '–', 'Բայց', 'նա', 'անմիջապես', 'դեն', 'նետեց', 'այդ', 'միտքը', '։', '–', 'Ոչ', ',', 'դա', 'մի', 'այլ', 'բան', 'էր', '։', 'չէ', '՞', 'որ', 'գիտեի', ',', 'որ', 'ուզում', 'եմ', 'բուրմունքին', 'տիրանալ', ',', 'այլ', 'ոչ', 'աղջկան', '։', 'Իսկ', 'այդ', 'մարդիկ', 'մտածում', 'էին', ',', 'որ', 'իրենք', 'հրապուրված', 'են', 'ինձնով', ',', 'մինչդեռ', 'այն', ',', 'ինչով', 'նրանք', 'իրոք', 'հրապուրված', 'էին', ',', 'նրանց', 'համար', 'մնաց', 'գաղտնիք', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian_uncorrected.txt\n"
      ],
      "metadata": {
        "id": "D-Qu1FP8mbO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dealing with Armenian OCR output with line breaks (is it correct?)\n",
        "\n",
        "FName = 'Parfum_Armenian_uncorrected.txt'\n",
        "FNameOut = 'Parfum_Armenian.txt'\n",
        "\n",
        "FIn = open(FName, 'r')\n",
        "FOut = open(FNameOut, 'w')\n",
        "\n",
        "for SLine in FIn:\n",
        "    SLine = SLine.strip()\n",
        "    if SLine == '': \n",
        "        FOut.write('\\n\\n')\n",
        "        continue\n",
        "    if SLine[-1] == '-':\n",
        "        SLine2write = SLine[:-1]\n",
        "        FOut.write(SLine2write)\n",
        "        continue\n",
        "\n",
        "    FOut.write(SLine + ' ')\n",
        "FOut.flush()\n",
        "\n"
      ],
      "metadata": {
        "id": "tstyqM_cph11"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('Parfum_Armenian.txt', 'Parfum_Armenian.vert.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "Gf-OW1n_rbue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0715b5e5-c398-4ecd-d8e6-0b7e1481a320"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: [\"'\", 'Շարցնում', 'են', \"'\", 'ինչ', '՞', 'է', 'եղել', 'նրա', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'ինչ', '՛', 'էնա', 'անում', 'դանակով', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Նրա', 'համար', 'վնասակար', 'չի', 'լինի', ',', '-', 'շշպռեց', 'Ժաննան', ',', '-', 'իսկ', 'ինձ', 'համար', 'կլինի', ':', 'Ես', 'նիհարել', 'եմ', 'տասը', 'ֆունտ', ',', 'չնայած', 'կերել', 'եմ', 'երեք', 'հոգու', 'փոխարեն', ':', 'Իսկ', 'հանուն', 'ինչի', ':', 'Հանուն', 'շաբաթական', 'երեք', '<UNK>րանկի', '՛']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'մյուս', 'կողմից', ',', 'լավ', 'չէ', 'երեխային', 'դես', 'ու', 'դեն', 'նետել', ':', 'Ով', '՛', 'գիտի', ',', 'օգտակար', 'կլինի', '՝', 'նրան', 'արդյոք', 'այդ', 'կաթը', ':', 'Մանկիկը', ',', 'հասկանում', 'ես', ',', 'սովորել', 'է', 'քո', 'կրծքի', 'հոտին', 'ու', 'քո', 'սրտի', 'բաբախյունին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n",
            "140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ապա', 'որքան', '՞', 'ես', 'պահանջում', ',', '-', '-', 'գոռաց', 'Տերյեն', ':', '-', 'Հինգ', 'ֆրանկը', 'նման', 'չնչին', 'գործի', 'դիմաց', ',', 'ինչպիսին', 'նորածնին', 'կերակրելն', 'է', ',', 'մի', 'կույտ', 'փող', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'ինչու', '՛', ',', 'սիրելիս', ',', '-', 'ասաց', 'Տերյեն', 'ն', 'կրկին', 'մատով', 'շուռումուռ', 'տվեց', 'զամբյուղի', 'պարունակությունը', ':', 'չէ', '՞', 'որ', 'սա', 'հիասքանչ', 'մանկիկ', 'է', ':', 'Այնքան', 'վարդագույն', 'է', ',', 'լաց', 'չի', 'լինում', ',', 'հանգիստ', 'է', 'քնում', ',', 'ն', 'կնքված', 'էլ', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խամարդ', ',', 'ն', 'դեռնս', 'չի', 'տնօրինում', 'ամբողջապես', 'ճնավորված', 'հոգուն', ':', 'Հետնաբար', ',', 'սատանայի', 'համար', 'այն', '`', 'հետաքրքրություն', 'չի', 'ներկայացնում', ':', 'Միգուցենա', 'արդեն', 'խոսում', '՛', 'է', ':', 'Միգուցե', 'նրա', 'մոտ', 'ջղաճգութու', '՞', 'է', ':', 'Միգուցե']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '-', 'Դետեսնում', 'ես', ':', 'Ահա', 'այն', 'նախանշանը', ':', 'Եթենա', '՞', 'դիվահար', 'լիներ', ',', 'ապա', 'նրանից', 'գարշահոտ', 'կփչեր', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170\n",
            "180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Որովհետն', 'նա', 'առողջ', 'է', ',', '-', 'գոռաց', 'Տերյեն', ',', '-', 'նա', 'առողջ', 'է', ',', 'այդ', 'պատճառով', 'էլ', 'հոտ', 'չունի', ':', 'Հոտ', 'ունեն', '`', 'միայն', 'հիվանդ', 'երեխաները', ',', 'դա', 'բոլորին', 'է', 'հայտնի', ':', 'Օրինակ', ',', 'եթե', 'երեխան', 'ջրծաղիկ', 'ունի', ',', 'նրանից', 'ձիու', 'թրիքի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'եթե', 'քութեշ', ',', 'ապա', 'հին', 'խնձորի', ',', 'իսկ', 'թոքախտավոր', 'երեխայից', 'սոխի', 'հոտ', 'է', 'գալիս', ':', 'Սա', 'առողջ', 'է', '.', 'ահա', 'ն', 'բոլորը', ':', 'Այդ', 'դեպքում', 'ինչու', '՛', 'պետք', 'է']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['նրանից', 'գարշահոտ', 'գա', ':', 'Միթե', '՛', 'քո', 'սեփական', 'երեխաներից', 'գարշահոտ', 'է', 'գալիս', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ն', '-', 'Ահա', ',', '-', 'ասաց', 'բավարարված', 'Տերյեն', 'ու', 'ձեռքերը', 'կրկին', 'ծալեց', 'թիկունքում', ':', 'Կնշանակի', '՝', 'սատանայի', 'հետ', 'կապված', 'խոսքը', 'մենք', 'ետ', 'ենք', 'վերցնում', ':', 'Լավ', ':', 'Իսկ', 'հիմա', 'բարի', 'եղիր', 'ինձ', 'բացատրել', 'ինչ', '՞', 'հոտ', 'է', 'գալիս', 'կրծքի', 'նորածիններից', ',', 'եթե', 'նրանցից', 'գալիս', 'է', 'այնպիսի', 'հոտ', ',', 'որ', '`', 'պիսին', ',', 'քո', 'կարծիքով', ',', 'պետք', 'է', 'գա', ':', 'Դե', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՍՏ', '-', 'Ինչ', 'է', 'նշանակում', '«', 'լավ', '»', ',', '-', 'ողջ', 'ուժով', 'գոռաց', 'նրա', '`', 'վրա', 'Տերյեն', '-', '-', 'Միթե', '՛', 'քիչ', 'են', 'այնպիսի', 'բաները', ',', 'որոնք', 'լավ', '`', 'հոտ', 'ունեն', ':', 'Փնջով', 'նարդո', 'լավ', 'հոտ', 'ունի', ':', 'Ապուրի', 'միսը', 'լավ', 'հոտ', 'ունի', ':', 'Արաբական', 'այգիները', 'լավ', 'հոտ', 'ունեն', ':', 'Ես']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ցանկանում', 'եմ', 'իմանալ', 'ինչ', '՞', 'հոտ', 'ունեն', 'նորածինները', ':', 'Ծծմայրը', 'դանդաղում', 'էր', 'պատասխանել', ':', 'Նա', ',', 'իհարկե', ',', 'գիտեր', ',', 'թե', 'ինչ', 'հոտ', 'է', 'գալիս', 'կրծքի', 'նորածիններից', ',', 'գիտեր', 'բացարձակ', 'ճշտությամբ', ',', 'նրա', 'ձեռքի', 'սկով', 'տասնյակ', 'մանկիկներ', 'էին', 'անցել', ',', 'նա', 'նրանց', 'կերակրել', 'էր', ',', 'խնամել', ',', 'օրորել', ',', 'համբուրել', '...', 'Նա', 'կարող', 'էր', 'գիշերը', 'նրանց', 'ճանաչել', 'հոտով', ',', 'նույնիսկ', 'այսօր', 'նա', 'քթով', 'պարզորոշ', 'հիշում', 'էր', 'այդ', 'մանկական', 'հոտը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220\n",
            "230\n",
            "240\n",
            "250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ինչպես', 'կարամել', '՛', ',', '-', 'հարցրեց', 'նա', '՝', 'ձգտելով', 'կրկին', 'վերադառնալ', 'խիստ', 'խոսելաոճին', ':', '-', 'Կարամել', ':', 'Ինչ', '՞', 'ես', 'հասկանում', 'կարամելից', ':', 'Գոնե', 'մի', 'անգամ', 'կերել', '՛', 'ես', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['մինչդեռ', 'սեփական', 'բանականությունից', 'օգտվելու', 'համար', 'մարդուն', 'անհրաժեշտ', 'է', 'ինքնավստահություն', 'ու', 'հանգիստ', ':', 'Սակայն', 'նա', 'ամենավճռական', 'ձնով', 'պայքարում', 'էր', 'հասարակ', 'ժողովրդի', 'սնահավատության', 'դեմ', ':', 'Կախարդանքն', 'ու', 'խաղաթղթով', 'գուշակությունը', ',', 'հմայիխերի', 'կրումը', ',', 'չար', 'աչքից', 'ազատվելը', ',', 'ոգիների', 'կախարդանթները', ',', 'լիալուսնի', 'պահին', 'աճպարարությունները', '...', 'Ինչով', '՛', 'ասես', 'չէին', 'զբաղվում', 'այդ', 'մարդիկ', ':', 'Նրան', 'խորապես', 'հուսահատեգնում', 'էր', ',', 'որ', 'նմանատիպ', 'հեթանոսական', 'ավանդույթները', 'քրիստոնեական', 'կրոնի', 'առավել', 'քան', 'հազարամյա', 'գոյությունից', 'հետո', 'դեռնս', 'արմատախիլ', 'չէին', 'արվել', ':', 'Միաժամանակ', ',', 'այսպես', 'կոչված', ',', 'դիվահարության', 'ու', 'սատանայի', 'հետ', 'կապերի', 'դեպքերի', 'մեծ', 'մասը', 'էլ', 'ավելի', 'մոտիկից', 'ուսումնասիրման', 'ժամանակ', 'ներկայանում', 'էին', 'որպես', 'սնոտիապաշտական', 'ներկայացումներ', ':', 'Ճիշտ', 'է', ',', 'մերժել', 'բուն', 'սատանայի', 'գոյությունը', ',', 'կասկածել', 'նրա', 'իշխանության', 'մեջ', 'այդքան', 'հեռու', 'հայր', 'Տերյեն', 'չէր', 'գնա', '.', 'նմանատիպ', 'խնդիրների', 'լուծումը', ',', 'որոնք', 'առնչվում', 'էին', 'աստվածաբանության', 'հիմքերին', ',', 'համեստ', 'ու', 'հասարակ', 'վանականի', 'գործը', 'չէր', ',', 'դրա', 'համար', 'գոյություն', 'ունեն', 'այլ', 'ատյաններ', ':', 'Մյուս', 'կողմից', 'օրվա', 'պես', 'պարզ', 'էր', ',', 'որ', ',', 'եթե', 'նման', 'կարճամիտ', 'անձնավորությունը', ',', 'ինչպիսին', 'այդ', 'ծծմայրն', 'էր', ',', 'պնդում', 'է', ',', 'որ', 'ինքն', 'ինչ', '-', 'որ', 'դիվայնություն', 'Է', 'հայտնաբերել', ',', 'նշանակում', 'է', '՝', 'սատանան', 'ոչ', 'մի', 'դեպքում', 'չէր', 'կարող', 'կապված', 'լինել', 'այդ', 'գործի', 'հետ', ':', 'Հատկապես', 'այն', 'պատճառով', ',', 'որնրան', 'թվում', 'է', ',', 'թե', 'իբր', 'ինքը', 'դա', 'հայտնաբերել', 'է', ':', 'չէ', '՞', 'որ', 'դա', 'ճշմարիտ', 'ապացույցն', 'է', 'նրա', ',', 'որ', 'ոչ', 'մի', 'դիվայնություն', 'էլ', 'իրականում', 'չկար', '.', 'սատանան', 'այն', 'աստիճան', 'հիմար', 'չէ', ',', 'որ', 'թույլ', 'տա', 'ծծմայր', 'Ժաննա', 'Բյուսիին', 'իրեն', 'բացահայտել', ':', 'Եվ', 'այն', 'էլ', 'հոտառությամբ', ':', 'Ջգազմունքներից', 'ամենապարզունակի', ',', 'ամենանվաստի', 'օգնությամբ', ':', 'Կարծես', 'թե', 'դժոխքից', 'ծծմբի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'դրախտից', 'խունկի', 'ու', 'զմուռսի', ':', 'Դա', ',', 'իրոք', ',', 'ամենամութ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'մնահավատությոն', 'է', ',', 'որն', 'արժանի', 'է', 'վայրի', 'հեթանոսա', '`', 'կան', 'ժամանակներին', ',', 'երբ', 'մարդիկ', 'ապրում', 'էին', 'կենդանիների', 'պես', ',', 'երբ', 'նրանց', 'տեսողությունն', 'այնքան', 'թույլ', 'էր', ',', \"'\", 'որ', 'չէին', 'տարբերում', 'գույները', ',', 'բայց', 'գտնում', 'էին', ',', 'որ', 'լսում', 'են', 'արյան', 'հոտը', ',', 'որ', 'կարող', 'են', 'հոտի', 'օգնությամբ', 'տարբերել', 'սուն', 'բարեկամից', ',', 'որ', 'իրենց', 'հոտն', 'առնում', 'են', 'հսկա', '՛մարդակերներն', 'ու', 'դարճորյակ', 'գայլերը', ',', 'որ', 'իրենց', 'որսով', 'են', 'զբաղված', 'վրիժառության', 'աստվածուհիները', ',', 'ն', '.', 'այդ', '`', 'խսկպատճառով', 'իրենց', 'նողկալի', 'աստվածներին', 'խարույկՄ', 'ների', 'վրա', 'այրված', 'գարշահոտ', 'մարդկային', 'զոհեր', 'էին', 'մա', '\"', '`', 'տուցում', ':', 'Սարսափելի', 'է', ':', '«', 'Հիմարը', 'քթով', 'է', 'տեսնում', 'ավելի', 'սն', 'աչքերով', '»', ',', 'ն', 'հավանաբար', ',', 'աստվածատուր', 'բաՄ', '.', 'նականռթյան', 'լույսը', 'հազար', 'տարի', 'նս', 'պետք', 'է', 'լուսավորի', ',', '|', 'նչն', 'որ', 'նախնադարյան', 'հավատալիքների', 'վերջին', 'մնացորդներն', 'անհետանան', ',', 'ինչպես', 'ուրվականները', ':', '-', 'Ախ', 'ն', 'այս', 'դժբախտ', 'փոքրիկ', 'մանկիկը', ':', 'Այս', 'անմեղ', 'արարածը', ':', 'Պառկած', 'է', 'իր', 'զամբյուղում', 'ու', 'քաղցր', 'քնել', 'է', '՝', 'անտեղյակ', 'այն', 'ստոր', 'կասկածանքներին', ',', 'որոնք', 'առաջ', 'են', 'քաշվել', 'նրա', 'դեմ', ':', 'Իսկ', 'այդ', 'անպատկառ', 'անձր', 'համարճակվում', 'է', 'պնդել', ',', 'որ', 'դու', ',', 'իբր', ',', 'հու', 'չունես', ',', 'ինչպիսին', 'պետք', 'է', 'ունենան', 'մարդկային', 'մանուկները', ':', 'Եվ', 'ինչ', '՞', '|', 'ասենք', 'մենք', 'դրա', 'վերաբերյալ', ':', '<UNK>ո', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ':', 'Եվ', 'նա', 'զգուշորեն', 'օրորում', 'էր', 'ծնկների', 'վրա', 'դրված', 'զամբյուղը', ',', 'մատով', 'շոյում', 'նորածնի', 'գլուխն', 'ու', 'մի', 'քանի', 'անգամ', 'կրկնում', 'ղու', '՛', '-', 'ղող<UNK>ղո', '՛', ',', 'քանզի', 'կարծում', 'էր', ',', 'որ', 'այդ', 'Ի', '\"', 'Ցո', 'վանչությունը', 'հանգստացուցիչ', 'ու', 'բարերար', 'ազդեցություն', 'է', 'թողնում', 'փոքրիկների', 'վրա', \"'\", 'Մ', 'Շ', 'Կարամելի', 'հոտ', 'պետք', 'է', 'ունենաս', ',', 'այ', 'քեզ', 'հիմարություն', ',', 'ղո', '՛', '-', 'ղու', '՛', '-', 'ղո', '՛', ':', '2', 'Որոշ', 'ժամանակ', 'նա', 'տատանվում', 'էր', ',', 'այնուհետն', 'ետ', 'ՐՊ', 'արդյոք', 'որնէ', 'մեկը', 'չի', '՞', 'հետնում', 'իրեն', ',', 'զամբյուղը', 'Գետնից', 'բարձրացրեց', 'ու', 'դրա', 'մեջ', 'խցկեց', 'իր', 'հաստ', 'քիթր', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280\n",
            "290\n",
            "300\n",
            "310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խցկեց', 'շատ', 'խոր', ',', 'այնպես', 'որ', ',', 'նորածնի', 'բարակ', 'շիկահեր', 'մազիկները', 'խուտուտ', 'տվեցին', 'նրա', 'ռունգերը', ',', 'հոտոտեց', 'երեխայի', 'գլուխը', 'հուսալով', 'ինչ', '-', 'որ', 'հոտ', 'ներշնչել', ':', 'Նա', 'այնքան', 'էլ', 'լավ', 'չէր', 'պատկերացնում', ',', 'թե', 'ինչպիսի', 'հոտ', 'պետք', 'է', 'ունենան', 'նորածինների', 'գլուխները', ':', 'Բնականաբար', ',', 'ոչ', 'կարամելի', 'հոտ', ',', 'այդ', 'մեկը', 'պարզից', 'պարզ', 'էր', '.', 'չէ', \"'\", 'որ', 'կարամեխ', 'այրված', 'շաքար', 'է', ',', 'ն', 'ինչպես', 'կարող', 'է', 'նորածինը', ',', 'որը', 'մինչ', 'այժմ', 'միայն', 'կաթ', 'էր', 'խմում', ',', 'այրված', 'շաքարի', 'հոտ', 'ունենալ', ':', 'Նրանից', 'կարող', 'էր', 'կաթի', 'հոտ', 'գալ', 'ծծմոր', 'կաթի', ':', 'Բայց', 'նրանից', 'կաթի', 'հոտ', 'չէր', 'գալիս', ':', 'Նրանից', 'կարող', 'էր', 'մազերի', 'հոտ', 'գալ', ',', 'մաշկի', 'ու', 'մազերի', ',', 'ն', ',', 'միգուցե', ',', 'մի', 'քիչ', 'մանկան', 'քրտնքի', 'հոտ', ':', 'Տերյեն', 'հոտոտեց', 'ն', 'այնուհետն', 'համոզեց', 'իրեն', ',', 'որ', 'զգում', 'Է', 'մաշկի', ',', 'մազերի', 'ու', ',', 'միգուցե', ',', 'մանկան', 'քրտնքի', 'թույլ', 'հոտը', ':', 'Բայց', 'նա', 'ոչինչ', 'չէր', 'զգում', ':', 'Որքան', 'էլ', 'ճգնում', 'էր', ':', '«', 'Հավանաբար', ',', 'մանուկները', 'հոտ', 'չունեն', '»', ',', '-', 'մտածում', 'էր', 'նա', ':', 'Հավանաբար', ',', 'դա', 'է', 'հարցը', ':', 'Հարցն', 'այն', 'է', ',', 'որ', 'նորածինը', ',', 'եթե', 'նրան', 'պահեն', 'մաքրության', 'մեջ', ',', 'ընդհանրապես', 'չի', 'կարող', 'հոտ', 'ունենալ', ',', 'ինչպես', 'չի', 'կարող', 'խոսել', ',', 'վազել', 'կամ', 'գրել', ':', 'Այս', 'հատկանիշները', 'գալիս', 'են', 'միայն', 'տարիքի', 'հետ', ':', 'Ճշգրիտ', 'ասած', '՝', 'մարդը', 'միայն', 'սեռական', 'հասունացման', 'շրջանում', 'է', 'սկսում', 'սուր', 'հոտ', 'արձակել', ':', 'Այո', ',', 'հենց', 'այդպես', 'էլ', 'կա', ':', 'Այդպես', ',', 'այլ', 'ոչ', 'այլ', 'կերպ', ':', 'Միթե', '՛', 'իր', 'Ժամանակին', 'Հորացիոսը', 'չէր', 'գրում', '.', '«', 'Պատանուց', 'այծիկի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'աղջիկը', 'բուրում', 'է', ',', 'ինչպես', 'ծաղիկը', 'սպիտակ', 'նարգիզի', '»', ':', 'Ով-ով', ',', 'բայց', 'հռոմեացիները', 'դրա', 'մասին', 'պատկերացում', 'ունեին', ':', 'Մարդկային', 'հոտը', 'մշտապես', 'մարմնի', 'հոտն', 'է', ',', 'հետնաբար', 'մեղքի', 'հոտը', ':', 'Այդ', 'դեպքում', 'ինչ', '՞', 'հոտ', 'պետք', 'է', 'ունենա', 'նորածինը', ',', 'որը', 'դեռնս', 'ոչ', 'երազով', ',', 'ոչ', 'հոգով', 'մեղավոր', 'չէ', 'մարմնական', 'մեղքի', 'մեջ', ':', 'Ինչ', '՞', 'հոտ', 'պետք', 'է', 'նա', 'ունենա', ':', 'Ղո՛.', '-', 'ղու', '՛', '-', 'ղու', '՛', ':', 'Ոչ', 'մի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ճեռքը', 'փոքրիկ', 'ն', 'գեղեցիկ', ',', 'դուրս', 'էր', 'ցցվել', 'կափարիչի', 'տակից', 'ու', 'ցնցվում', 'էր', 'այտի', 'ուղղությամբ', ':', 'Տերյեն', 'գորովալից', 'ժպտաց', 'ու', 'հանկարծ', 'իրեն', 'շատ', 'հարմարավետ', 'զգաց', ':', 'Ինչ', '-', 'որ', 'մի', 'պահ', 'նա', 'նույնիսկ', 'իրեն', 'թույլ', 'տվեց', 'մի', 'ֆանտաստիկ', 'միտք', ',', 'որ', 'կարծես', 'թե', 'ինքը', 'այդ', 'երեխայի', 'հայրն', 'էր', ':', 'Կարծես', 'թե', 'ինքը', 'դարձել', 'է', 'ոչ', 'թե', 'վանական', ',', 'այլ', 'նորմալ', 'քաղքենի', ',', 'միգուցե', 'ազնիվ', 'արհեստավոր', ',', 'իրեն', 'կին', 'է', 'գտել', 'մի', 'այնպիսի', 'տաքուկ', 'կին', ',', 'որից', 'բրդի', 'ու', 'կաթի', 'հոտ', 'է', 'գալիս', ',', 'ն', 'նրանք', 'ծնել', 'են', 'որդի', ',', 'ն', 'ահա', 'ինքը', 'նրան', '`', 'օրորում', 'է', 'իր', 'սեփական', 'ծնկների', 'վրա', 'իր', 'սեփական', 'երեխային', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', '.', 'այդ', 'միտքը', 'հաճույք', 'էր', 'պատճառում', ':', 'Նրանում', 'ինչ', '-', 'որ', 'սփոփիչ', 'ներշնչանք', 'կար', ':', 'Հայրը', 'ծնկների', '`', 'վրա', 'օրորում', 'է', 'իր', 'սեփական', 'որդուն', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ',', 'պատկերը', 'հին', 'էր', 'ինչպես', 'աշխարհը', ',', 'ն', 'հավերժ', 'նոր', 'ու', 'ճիշտ', 'այն', 'ժամանակից', ',', 'ինչ', 'աշխարհր', 'լուսավոր', 'է', ',', 'հենց', 'այդպես', ':', 'Տերյեի', 'սիրտը', 'ջերմացավ', ',', 'նա', 'հուզվեց', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'այդ', 'պահին', 'նորածինը', 'սկսեց', 'ճչալ', ':', 'Նա', 'կկոցեց', 'աչքերը', ',', 'լայն', 'բացեց', 'իր', 'կարմիր', 'բուկը', 'ն', 'այնքան', 'զզվելի', 'ու', 'ականջ', 'ծակող', 'ձայնով', 'ծղրտաց', ',', 'որ', 'Տերյեի', 'արյունը', 'երակներում', 'սառեց', ':', 'Նա', 'առաջ', 'պարզած', 'ձեռքով', 'ցնցում', 'էր', 'զամբյուղն', 'ու', 'գոռում', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ',', 'որպեսզի', 'երեխային', 'ստիպի', 'լռել', ',', 'բայց', 'վերջինս', 'ավելի', 'բարճր', 'էր', 'ոռնում', '.', 'նրա', 'դեմքը', 'կապտել', 'էր', ',', 'ն', 'նա', 'կարծես', 'պատրաստ', 'էր', 'ոռնոցից', 'պայթել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340\n",
            "350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Տիկին', 'Գայարը', ',', 'չնայած', 'դեռ', 'երեսուն', 'տարեկան', 'էլ', 'չկար', ',', 'արդեն', 'ապրել', 'էր', 'իր', 'կյանքը', ':', 'Նրա', 'արտաքինը', 'համապատասխանում', 'էր', 'տարիքին', ',', 'բայց', 'միաժամանակ', 'նա', 'իր', 'տարիքից', 'երկու', ',', 'երեք', ',', 'հարյուրապատիկ', 'անգամ', 'ավելի', 'մեծ', 'տեսք', 'ուներ', ',', 'նման', 'էր', 'աղջկա', 'մումիայի', ',', 'բայց', 'ներքուստ', 'արդեն', 'վաղուց', 'մեռած', 'էր', '.', 'փոքր', 'հասակում', 'հայրը', 'վառարանի', 'կրակխառնիչով', 'հարվածել', 'էր', 'նրա', 'ճակատին', '՝', 'ուղիղ', 'քթարմատից', 'վերն', ',', 'ն', 'այդ', 'Ժամանակվանից', 'նա', 'կորցրել', 'էր', 'հոտառությունը', ',', 'ինչպես', 'նան', 'մարդկային', 'ջերմության', 'ու', 'սառնության', 'ցանկացած', 'զգացում', 'ն', ',', 'ընդհանրապես', ',', 'ցանկացած', 'ուժեղ', 'զգացում', ':', 'Այդ', 'մեկ', 'հարվածով', 'նրա', 'մեջ', 'սպանվել', 'էին', 'ն', 'քնքշությունը', ',', 'ն', 'զզվանքը', ',', 'ն', 'ուրախությունը', ',', 'ն', '.', 'հուսահատությունը', ':', 'Ավելի', 'ուշ', ',', 'համատեղ', 'ապրելով', 'ամուսնու', 'հետ', 'ու', 'ծնելով', 'իր']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n",
            "500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'հիշեցնել', 'իր', 'պարտքի', 'մասին', ':', '«', 'Քաղաքավարության', 'համար', 'նա', 'մեկ', 'շաբաթ', 'սպասեց', ',', 'ու', 'երբ', 'պակասող', 'փո', '`', 'ղերը', 'այդպես', 'էլ', 'չփոխանցվեցին', ',', 'նա', 'բռնեց', 'տղայի', 'ձեռ|', '2', 'ունրա', 'հետ', 'գնաց', 'քաղաք', ':', 'Տ', ':', '`', 'Գետից', 'ոչ', 'հեռու', 'Մորտելյերի', 'փողոցի', 'վրա', ',', 'ապրում', 'էր', 'րա', 'ծանոթը', 'Գրիմալ', 'ազգանունով', 'կաշեգործը', ',', 'որին', 'աշՆ', '1', 'խատանքի', 'համար', 'մշտապես', 'պետք', 'էին', 'լինում', 'տղաներ', '2', 'Հ', 'ոչ', 'թե', 'որպես', 'աշ', 'սկերտներ', 'կամ', 'ենթավարպետներ', ',', 'այլ', 'որՏՅ', ':', 'պես', 'իխե', 'աշխատուժ', ':', 'չէ', '՞', 'որ', 'այդ', 'արհեստի', 'մեջ', 'հարկ', 'էր', '`', 'լինում', 'կատարել', 'կյանքի', 'համար', 'այն', 'աստիճան', 'վտանգավոր', 'գործողություններ', 'մորթափառից', 'մաքրել', 'նեխող', 'գազանների', 'մորթիները', ',', 'միմյանց', 'խառնել', 'դաբաղման', 'թուն', '.', 'ՐԵ', ':', 'ներկանյութերի', 'լուծույթները', ',', 'թափել', 'կսկծոր', 'գործված', 'քիմիական', 'Նյութերը', ',', 'որ', 'կարգին', 'վարպետը', ',', 'Աաաա', 'խնայելով', 'իր', 'ուսուցառած', 'օգնականներին', ',', 'վարձում', 'էր', 'գործազուրկ', 'ու', 'անտուն', 'խառնամբոխին', 'կամ', 'խնամազուրկ', 'երեխաներին', ',', 'որոնց', 'ճակատագրով', 'դժբախտության', 'դեպքում', 'ոչ', 'ոք', 'չի', 'հետաքրքրվի', ':', 'Հասկանալի', 'է', ',', 'որ', 'տիկին', 'Գայարը', 'գիտեր', ',', 'որ', 'Փրիմալի', 'դաբաղանոցում', 'Գրենույը', 'մարդկային', 'չափանիշներով', 'կենդանի', 'մնալու', 'շանս', 'չուներ', ':', 'Բայց', 'նա', 'այնպիսի', 'կին', 'չէր', ',', 'որ', 'մտահոգվեր', 'նման', 'հարցերի', 'շուրջ', ':', 'Չէ', '\"', 'որ', 'խնա', 'կատարել', 'էր', 'իր', 'պարտքը', ':', 'Խնամակալությունն', 'ավարտվել', 'է', ':', 'Ինչ', 'էլ', 'որ', 'տեղի', 'ունենար', 'խնամառուի', 'հետ', 'ապագայում', ',', 'դա', 'նրան', 'չէր', 'վերաբերում', ':', 'Ողջ', 'կմնա', '՝', 'լավ', 'է', ',', 'կմեռնի', 'նույնպես', 'լավ', 'է', ',', 'կարնորն', 'այն', 'է', ',', 'որ', 'ամեն', 'ինչ', 'լինի', 'օրենքով', ':', 'Այդ', 'իսկ', 'պատճառով', 'նա', 'պարոն', 'Գրիմալին', 'խնդրեց', 'գրությամբ', 'հաստատել', 'երեխայի', 'փոխանցումը', ',', 'իր', 'հերթին', 'ստացական', 'տվեց', 'տասնհինգ', 'ֆրանկ', 'միջնորդադրամ', 'ստանալու', 'վերաբերյալ', 'ն', 'ուղղվեց', 'տուն', '՝', 'Շարոն', 'փողոց', ':', 'Նա', 'նույնիսկ', 'փոքրագույն', 'խղճի', 'խայթ', 'չէր', 'զգում', ':', 'Շակառակը', ',', 'գտնում', 'էր', ',', 'որ', 'ոչ', 'միայն', 'օրենքով', 'է', 'գործել', ',', 'այլն']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրգռվածությունից', 'նա', 'քիչ', 'էր', 'մնում', 'վատանար', ':', 'Նա', 'դեռնս', 'նույնիսկ', 'չէր', 'էլ', 'պարզել', 'որտեղից', 'է', 'ընդհանրապես', 'գալիս', 'այդ', 'բուրմունքը', ':', 'Երբեմն', 'թեթն', 'քամիների', 'միջն', 'ընդմիջումները', 'տնում', 'էին', 'րոպեներ', ',', 'ն', 'ամեն', 'անգամմնա', '՛', 'վրա', 'հարձակվում', 'էր', 'սահմռկեցուցիչ', 'սարսափը', ',', 'որ', 'ինքը', 'հավերժորեն', 'կորցրեց', 'այն', ':', 'Ի', 'վերջո', ',', 'նա', 'հանգեց', 'այն', 'փրկարար', 'հետնությանը', ',', 'որ', 'քամին', 'իրեն', 'է', 'հասնում', 'գետի', 'մյուս', 'ափից', '՝', 'հարավարնելյան', 'ուղղությամբ', 'ինչ', '-', 'որ', 'տեղից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այն', 'հանգամանքը', ',', 'որ', 'այս', 'հոյակապության', 'սկզբում', 'կանգնած', 'էր', 'սպանությունը', ',', 'նա', ',', 'եթե', 'ընդհանրապես', 'գիտակցում', 'էր', 'դա', ',', 'ընդունում', 'էր', 'խոր', 'անտարբերությամբ', ':', 'Մարե', 'փողոցի', 'աղջկա', 'արտաքինը', 'նրա', 'դեմքը', ',', 'նրա', 'մարմինը', ',', 'Գրենույն', 'արդեն', 'չէր', 'կարողանում', 'վերհիշել', ':', 'չէ', '՞', 'որ', 'պահպանել', 'էր', 'լավագույնը', ',', 'ինչը', 'նա', 'խլեց', 'ու', 'սեփականացրեց', '.', 'նրա', 'բուրմունքի', 'էությունը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1010\n",
            "1020\n",
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['10', '-', 'Շենյե', ',', '-', 'կանչեց', 'Բալդինին', 'իր', 'փոքրիկ', 'գրասենյակից', ',', 'որտեղ', 'նա', ',', 'աչքերը', 'փակ', 'դռանը', 'հառած', ',', 'մի', 'քանի', 'ժամ', 'քարացած', 'կանգնած', 'էր', ',', '-', 'հագեք', 'ճեր', 'կեղծամը', ':', 'Ուճիթապտղի', 'յուղի', 'տակառիկների', 'ն', 'կախված', 'բայոնյան', 'ապխտած', 'ազդրերի', 'միջն', 'հայտնվեց', 'Շենյեն', '՝', 'Բալդինիի', 'ենթավարպետը', 'նույնպես', 'արդեն', 'մի', 'ծեր', 'մարդ', ',', 'չնայած', 'տիրոջից', 'ավելի', 'երիտասարդ', ',', 'ու', 'քայլեց', 'առաջ', 'դեպի', 'առավել', 'նրբաճաշակ', 'կահավորված', 'կրպակի', 'շինությունը', ':', 'Նա', 'սերթուկի', 'գրպանից', 'դուրս', 'բերեց', 'իր', 'կեղծամը', 'ն', 'քաշեց', 'գլուխը', ':', \"'\", '-', 'Պարոն', 'Բալդինի', ',', 'դուք', 'դոււս', '՛', 'եք', 'գնում', ':', '`', 'ԾՈջ', '-', 'ասաց', 'Բալդինին', ',', '-', 'ես', 'մի', 'երկու', 'ժամով', 'առանձնանում', 'եմ', 'իմ', 'աշխատասենյակում', 'ու', 'ցանկանում', 'եմ', ',', 'որ', 'ինճ', 'բացարճակապես', 'ոչ', 'ոք', 'չանհանգստացնի', ':', 'ա', 'ՄԶ', 'հասկանում', 'եմ', ':', 'Դուք', 'նոր', 'օծանելիքներ', 'եք', 'հայտնագործում', ':', '`', '`', 'Բալդինի', 'Հենց', 'այդպես', ':', 'Կոմս', 'Վերամոնի', 'պատվե|', 'րով', 'ուզում', 'եմ', 'բուրումնավետ', 'դարձնել', 'իսպանական', 'կաշվի', 'մի', 'կտոր', ':', 'Նա', 'պահանջում', 'է', 'բացարճակապես', 'ինչ', '-', 'որ', 'նոր', 'հոտ', ':', 'Պահանջում', 'է', 'ինչ', '-', 'որ', 'մի', '...', 'մի', '...', 'կարծեմ', 'դա', 'կոչվում', 'էր', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '՝']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['այն', ',', 'ինչը', 'նա', 'պահանջում', 'է', ',', 'իսկ', 'պատրաստված', 'է', 'Սեն', '-', 'Անդրե', '-', 'դեզ', '-', 'Ար', 'փողոցի', 'այն', 'բթամիտի', 'կողմից', '...', 'ինչպես', '՛', 'էր', 'անունը', '...']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Այո', ',', 'Պելիսյե', ':', 'Ճիշտ', 'է', ':', 'Այդպես', 'են', 'նրան', '՝', 'այդ', 'բթամիտին', 'անվանում', ':', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', 'Պելիսյեից', '։', 'Դուք', 'գիտեք', '՛', 'այդ', 'օծանելիքը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Գռեհիկկ', '՞', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Իրոք', '՛', ':', 'Իսկ', 'էլ', 'ինչ', '՞', 'կա', 'այնտեղ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ալքիմիկոս', 'է', ',', 'ասում', 'են', 'մարդիկ', '.', 'լավ', 'է', ',', 'թող', 'այդպես', 'էլ', 'մտածեն', ':', 'Այն', 'մասին', ',', 'որ', 'իր', 'արվեստն', 'արհեստ', 'է', ',', 'ինչպես', 'ն', 'ցանկացած', 'ուրիշը', ',', 'գիտեր', 'միայն', 'ինքը', ',', 'Ա', 'դրանում', 'էր', 'նրա', 'հպարտությունը', ':', 'Նա', 'չէր', 'էլ', 'ցանկանում', 'գյուտարար', 'լինել', ':', 'Գյուտարարությունը', 'բավական', 'կասկածելի', 'է', ',', 'գտնում', 'էր', 'Բալդինին', ',', 'քանի', 'որ', 'այն', 'մշտապես', 'նշանակում', 'է', 'կանոնների', 'խախտում', ':', 'Նա', 'ամեննին', 'էլ', 'չէր', 'պատրաստվում', 'կոմս', 'Վերամոնի', 'համար', 'նոր', 'օծանելիք', 'հնարել', ':', 'Համենայնդեպս', ',', 'Շենյեն', 'հարկադրված', 'չի', 'լինի', 'իրեն', 'համոզել', 'Պելիսյեից', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', 'ձեռք', 'բերել', ':', 'Նա', 'արդեն', 'ձեռք', 'էր', 'բերել', 'այդ', 'օծանելիքները', ':', 'Ահա', 'դրանք', ',', 'պատուհանի', 'մոտի', 'գրասեղանի', 'վրա', '՝', 'հղկած', 'խցանով', 'փոքրիկ', 'ապակե', 'սրվակների', 'մեջ', ':', 'Նա', 'դրանք', 'գնել', 'էր', 'մի', 'քանի', 'օր', 'առաջ', ':', 'Բնականաբար', ',', 'անձամբ', 'չէր', 'գնել', ':', 'Չէ', '՝', 'որ', 'նա', 'չէր', 'կարող', 'օծանելիքի', 'համար', 'անձամբ', 'մտնել', 'Պելիսյեի', 'մոտ', ':', 'Նա', 'գործել', 'էր', 'միջնորդի', 'միջոցով', ',', 'իսկ', 'վերջինս', 'էլ', 'իր', 'հերթին', 'մեկ', 'այլ', 'միջնորդի', 'օգնությամբ', ':', 'Ջգուշությունը', 'երբեք', 'չի', 'խանգարի', ':', 'Քանզի', 'Բալդինին', 'պատրաստվում', 'էր', 'այդ', 'օծանելիքն', 'օգտագործել', 'ոչ', 'միայն', 'իսպանական', 'կաշին', 'բուրումնավետ', 'դարճնելու', 'համար', '.', 'դրա', 'համար', 'մեկ', 'սրվակը', 'չէր', 'բավականացնի', ':', 'Նա', 'էլ', '՛', 'ավելի', 'վատ', 'մտադրություն', 'ուներ', '.', 'պատճենել', 'այն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ախ', '՛', ',', 'որքան', 'վատ', 'է', ',', 'որ', 'ազնիվ', 'մարդը', 'ստիպված', 'Է', 'հնարամտություն', 'գործածել', ':', 'Որքան', 'ծանր', 'է', 'զոհաբերել', 'այ', 'ամենաթանկարժեքը', ',', 'որ', 'ունես', '՝', 'նման', 'խղճուկ', 'ձնով', 'վարկաբեկելով', 'սեփական', 'պատիվը', ':', 'Բայց', 'ինչ', '՞']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Խոնջանքով', '»', ',', 'մշկային', 'գերհագեցած', 'բուրմունքով', ':', 'Բոլորին', 'հանկարծ', 'տիրում', 'էր', 'մուշկի', 'հոտով', 'բուրելու', 'գազանային', 'ցանկությունը', ',', 'ն', 'Բալդինիին', 'ոչինչ', 'չէր', 'մնում', ',', 'քան', 'իր', 'հազրեվարդը', 'վերամշակել', 'գլուխը', 'լվանալու', 'համար', 'ջրի', 'ու', 'նարդոսը', 'կարել', 'բույրաբարձիկի', 'մեջ', ':', 'Դրա', 'փոխարեն', ',', 'երբ', 'հաջորդ', 'տարի', 'նա', 'պատվիրեց', 'համապատասխան', 'քանակությամբ', 'մուշկ', ',', 'մշկահոտ', 'ցիբետին', 'ու', 'կողբենու', 'շիթ', ',', 'Պելիսյեի', 'խելքին', 'փչեց', 'հորինել', '«', 'Անտառային', 'ծաղիկ', '»', 'անվանումով', 'օծանելիք', ',', 'ն', 'այն', 'անմիջապես', 'հաջողություն', 'նվաճեց', ':', 'Գիշերային', 'երկարատն', 'փորձերի', 'գնով', 'կամ', 'խելագար', 'գումարներով', 'լրտեսներին', 'կաշառելով', '՝', 'Բալդինին', 'ի', 'վերջո', 'պարզեց', ',', 'թե', 'ինչից', 'է', 'բաղկացած', '«', 'Անտառային', 'ծաղիկները', '»', ',', 'իսկ', 'Պելիսյեն', 'արդեն', 'կրկին', 'աչքի', 'ընկավ', 'այս', 'անգամ', '«', 'Թուրքական', 'գիշերներով', '»', 'կամ', '«', 'Լիսաբոնյան', 'բուրմունքով', '»', ',', '«', 'Թագավորական', 'պալատի', 'ծաղկեփնջով', '»', 'կամ', ',', 'սատանան', 'գիտի', ',', 'թե', 'էլ', 'ինչով', ':', 'Համենայնդեպս', ',', 'այդ', 'մարդն', 'իր', 'անսանձելի', 'նորարարական', 'կրքով', 'վտանգ', 'էր', 'ներկայացնում', 'ողջ', 'արհեստի', 'համար', ':', 'Ինչ', 'լավ', 'կլիներ', ',', 'եթե', 'դաժան', 'ժամանակների', 'արտադրամասային', 'իրավունքը', 'նորից', 'ետ', 'գար', ':', 'Նման', 'լկտի', 'դուրսպրծուկի', ',', 'նման', 'գռփողի', 'հանդեպ', ',', 'որը', 'հարստանում', 'էր', 'հոտերի', 'արժեզրկման', 'հաշվին', ',', 'կարելի', 'էր', 'կիրառել', 'ամենահրեշային', 'միջոցները', ':', '`', '՝', 'Նրանից', 'խլել', 'արտոնագիրը', ',', 'արգելել', 'օծանագործային', 'գործի', 'մեջ', 'խցկվել', '...', 'ն', 'ընդհանրապես', ',', 'խարդախը', 'նախնառաջ', 'թող', 'ինչ', '-', 'որ', 'բան', 'սովորի', ':', 'չէ', '՞', 'որ', 'նա', '՝', 'այդ', 'Պելիսյեն', ',', 'ուսուցառած', 'օծանագործ', 'ու', 'ճեռնոցագործ', 'չէր', ':', '`', 'Նրա', 'հայրն', 'ընդամենը', 'քացախ', 'քամող', 'էր', ',', 'Ա', 'Պելիսյեն', 'նս', 'քացախ', 'քամող', 'էր', ',', 'ոչ', 'այլ', 'ինչ', ':', 'Եվ', 'միայն', 'այն', 'պատճառով', ',', 'որ', 'նա', '՝', 'որպես', 'քացախ', 'քամող', ',', 'սպիրտային', 'արտադրության', 'մեջ', 'մուտքի', 'իրավունք', 'ուներ', ',', 'նրան', 'հաջողվեց', 'ներթափանցել', 'իրական', 'օծանագործների', 'շրջան', ',', 'ն', 'այժմ', 'նա', 'անօրինականություններ', 'է']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'կատարում', 'այնտեղ', ',', 'ինչպես', 'գարշահոտ', 'Ժանտաքիսը', ':', '`', 'Ինչի', '՛', 'համար', 'էր', 'պետք', 'ամեն', 'սեզոն', 'մոդայի', 'մեջ', 'ներմու', '`', 'ծել', 'նոր', 'օծանելիք', ':', 'Ինչ', '՞', 'անհրաժեշտություն', 'կար', 'դա', 'անել', ':', 'Նախկինում', 'հանրությունը', 'լիովին', 'բավարարվում', 'էր', 'մանուշակի', 'ջրով', 'ու', 'պարզունակ', 'ծաղկային', 'խառնուրդներով', ',', 'որոնք', 'տասը', 'տարին', 'մեկ', 'ընդամենը', 'թեթնակի', 'փոփոխության', 'էին', 'ենթարկվում', ':', 'Հազարամյակներով', 'մարդիկ', 'բավարարվում', 'էին', 'խունկով', 'ու', 'զմուռսով', ',', 'մի', 'քանի', 'բալզամներով', ',', 'յուղերով', 'ու', 'չորացրած', 'խոտերով', ':', 'Եվ', 'նույնիսկ', 'այն', 'բանից', 'հետո', ',', 'երբ', 'նրանք', 'սովորեցին', 'փորձանոթների', '`', 'ու', 'թորման', 'կաթսաների', 'օգնությամբ', 'թորած', 'ջուր', 'ստանալ', ',', 'ջրային', 'գոլորշու', 'օգնությամբ', 'խոտերից', ',', 'ծաղիկնե', '`', 'րից', 'ու', 'տարբեր', 'տեսակի', 'փայտանյութերից', 'եթերային', 'յուղերի', 'տեսքով', 'խլել', 'նրանց', 'բուրումնավետությունը', ',', '`', 'կաղնուց', 'պատրաստված', 'ճզմիչների', 'օգնությամբ', 'քամել', 'այն', 'սերմերից', 'ու', 'կորիզներից', 'ն', 'մրգերի', 'կեղններից', 'կամ', 'խնամքով', 'ֆիլտրված', 'ճարպերի', 'օգնությամբ', 'այն', 'դուրս', 'բերել', 'ծաղկաթերթիկներից', ',', 'հոտերի', 'քանակը', ',', 'այնուամենայնիվ', ',', 'դեռնս', 'սահմանափակ', 'էր', ':', 'Այն', 'ժամանակներում', '`', 'այնպիսի', 'կերպար', ',', 'որպիսին', 'Պելիսյեն', 'է', ',', 'ընդհանրապես', 'չէր', 'կարող', 'լինել', '.', 'չէ', '՞', 'որ', 'այն', 'ժամանակներում', 'նույնիսկ', 'հասարակ', 'շրթներկի', 'պատրաստման', 'համար', 'պահանջվում', 'էին', 'ունակություններ', ',', 'որոնց', 'մասին', 'այդ', 'քացախագործը', 'չէր', 'էլ', 'կարող', 'երազել', ':', 'Պետք', 'էր', 'ոչ', 'միայն', 'կարողանալ', 'թորել', ',', 'պետք', 'էր', 'լինել', 'քսուքներ', 'պատրաստող', 'ու', 'դեղագործ', ',', 'ալքիմիկոս', 'ու', 'արհեստավոր', ',', 'միաժամանակ', 'առնտրական', ',', 'հումանիստ', 'ու', 'այգեպան', ':', 'Պետք', 'էր', 'կարողանալ', 'ոչխարի', 'երիկամների', 'ճարպը', 'տարբերել', 'հորթի', 'ճարպից', ',', 'իսկ', '«', 'Վիկտորիա', '»', 'տեսակի', 'մանուշակը', 'Պարմի', 'մանուշակից', ':', 'Անհրաժեշտ', 'էր', 'տիրապետել', 'լատիներենին', ':', 'Պետք', 'էր', 'գիտենալ', ',', 'թե', 'երբ', 'ես', 'տերւապատվում', \"խամ'\", 'բարները', ',', 'ն', 'երբ', 'է', 'ծաղկում', 'խորդենին', ',', 'ն', 'որ', 'արնածագի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'կամ', 'վերցնենք', 'խանգարվածությունը', 'արագության', 'վրա', ':', 'Ինչու', '՛', 'անհրաժեշտ', 'եղավ', 'այդքան', 'շատ', 'նոր', 'ճանապարհներ', 'անցկացնել', ':', 'Ինչի', '՞', 'համար', 'են', 'այդ', 'նոր', 'կամուրջները', ':', 'Ինչի', 'համար', ':', 'Որպեսզի', 'մեկ', 'շաբաթում', 'Լիոն', '՞', 'հասնեն', ':', 'Իսկ', 'ինչ', '՞', 'օգուտ', 'կա', 'դրանից', ':', 'Ում', 'համար', 'Է', 'դա', 'օգտավետ', ':', 'Ում', '՞', 'է', 'պետք', 'գլուխը', 'կոտրելով', 'սլանալ', 'Ատլանտյան', 'օվկիանոսով', ':', 'Մեկ', 'ամիս', 'անց', 'Ամերիկայում', 'հայտնվելու', 'համար', '՛', ':', 'Բայց', 'չէ', '՞', 'որ', 'մարդիկ', 'հազարամյակներ', 'շարունակ', 'հրաշալիորեն', 'բավարարվում', 'էին', 'առանց', 'այդ', 'աշխարհամասի', ':', 'Ինչ', '՞', 'է', 'կորցրել', 'նախնադարյան', 'անտառում', 'հնդկացիների', 'կամ', 'սնամորթների', 'մոտ', 'քաղաքակիրթ', 'մարդը', ':', 'Անգամ', 'Հյուսիս', 'նրանք', 'հասան', '՝', 'Լապլանդիա', ',', 'որտեղ', 'հավերժական', 'սառույց', 'է', ',', 'Ա', 'որտեղ', 'ապրում', 'են', 'վայրի', 'մարդիկ', ',', 'ովքեր', 'հում', 'ձուկ', 'են', 'խժռում', ':', 'Դա', 'դեռ', 'քիչ', 'էր', ',', 'ցանկացան', 'նս', 'մի', 'աշխարհամաս', 'հայտնաբերել', ',', 'ասում', 'են', ',', 'ինչ', '-', 'որ', 'տեղ', 'հարավային', 'ծովերում', ':', 'Իսկ', 'մեր', 'ինչին', '՞', 'է', 'պետք', 'այդ', 'խելագարությունը', ':', 'Միայն', 'այն', 'պատճառով', ',', 'որ', 'ուրիշներն', 'էլ', 'են', 'այդպես', 'անում', '՝', 'իսպանացիները', ',', 'անիծյալ', 'անգլիացիները', ',', 'անպատկառ', 'հոլանդացիները', ',', '.', 'որոնց', 'հետ', 'հետագայում', 'ստիպված', 'էինք', 'մարտ', 'մղել', ',', 'ինչն', 'ընդհանրապես', 'մեզ', 'չէինք', 'կարող', 'թույլ', 'տալ', ':', 'Երեք', 'հարյուր', 'հազար', 'լիվր', 'կանխիկ', 'գումար', '՝', 'ահա', 'թե', 'որքան', 'արժի', 'մեկ', 'ռազմանավը', ',', 'իսկ', 'հետո', 'նա', 'մեկ', 'թնդանոթային', 'կրակոցից', 'հինգ', 'րոպեի', 'ընթացքում', 'խորտակվում', 'է', ',', 'ն', 'մնաք', 'բարով', 'հավերժ', ',', 'հարկատուների', 'փողեր', ':', 'Այժմ', 'ֆինանսների', 'պարոն', 'նախարարը', 'պահանջում', 'է', 'իրեն', 'փոխանցել', 'բոլոր', 'եկամուտների', 'տասներորդ', 'մասը', ',', 'ն', 'դա', 'կործանարար', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1220\n",
            "1230\n",
            "1240\n",
            "1250\n",
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n",
            "1350\n",
            "1360\n",
            "1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Հրաշալի', 'է', ',', 'հրաշալի', '...', '-', 'մրթմրթաց', 'նա', '՝', 'ագահաբար', 'հոտոտելով', ':', '-', '\"', 'Նրանում', '.', 'ուրախություն', 'կա', ',', 'նա', 'չքնաղ', 'է', '՝', 'ինչպես', 'մեղեդին', ',', 'նա', 'ուղղակի', 'ստեղծում', 'է', 'լավ', 'տրամադրություն', '...', 'Ինչ', '՞', 'անհեթեթություն', 'է', '՝', 'լավ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['<UNK>իծաղեի', '՛', 'է', 'նման', 'ճարտասանությունը', '.', '«', 'Մեղեդի', 'է', ':', 'Ուրախություն', 'է', ':', 'Չքնաղ', 'է', ':', 'Բարձրացնում', 'է', 'տրամադրությունը', '»', ':', 'Հիմարություն', ':', 'Մանկական', 'հիմարություն', ':', 'Րոպեական', 'տպավորություն', ':', 'Շին', 'սխալ', ':', 'Խառնվածքի', 'հարց', ':', 'Ամենայն', 'հավանականությամբ', '՝', 'իտալական', 'ժա']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '`', 'վորությամբ', ':', 'չէ', '՞', 'որ', 'դա', 'ոսկե', 'կանոն', 'է', ',', 'Բալդինի', ',', 'այ', 'դու', '՝', 'ծեր', 'ոչխարի', 'գլուխ', ':', 'Երբ', 'հոտ', 'ես', 'քաշում', '՝', 'հոտ', 'քաշիր', ',', 'իսկ', 'դատիր', 'հետո', ':', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ը', 'շարքային', 'օծաելիք', 'չէ', ':', 'Բավական', 'հաջող', 'արտադրանք', 'է', ':', 'Ճարպկորեն', 'թխված', 'անշնորհք', 'ապրանք', ':', 'Եթե', 'չասենք', 'կեղծիք', ':', 'Իսկ', 'կեղծիքից', 'բացի', ',', 'ուրիշ', 'էլ', 'ինչ', '՞', 'կարելի', 'Է', 'սպասել', 'Պելիսյեի', 'նման', 'մարդուց', ':', 'Բնականաբար', ',', 'այնպիսի', 'տիպը', ',', 'որպիսին', 'Պելիսյեն', 'է', ',', 'հասարակ', 'օծանելիք', 'չի', 'արտադրի', ':', 'Կեղծարարը', 'կարողանում', 'է', 'թոզ', 'փչել', 'մարդկանց', 'աչքերին', ',', 'հոտառությունը', 'շարքից', 'հանել', 'հոտի', 'կատարյալ', 'ներդաշնակությամբ', ':', 'Այդ', 'մարդը', 'հոտառական', 'արվեստի', 'գայլ', 'էր', 'գառան', 'մորթիով', ',', 'ահա', 'թե', 'ով', 'է', 'այդ', 'ճարպիկ', 'խաբեբան', '.', 'մի', 'խոսքով', '՝', 'տաղանդավոր', 'հրեշ', ':', 'Իսկ', 'դա', 'ավելի', 'վատ', 'է', ',', 'քան', 'ինչ', '-', 'որ', 'մի', 'անտաղանդ', 'ապաշնորհ', ',', 'որը', 'չի', 'գիտակցում', 'իր', 'տգիտությունը', ':', '52', 'Բայց', 'դու', ',', 'Բալդինի', ',', 'թույլ', 'չես', 'տա', 'քեզ', 'հիմարացնեն', ':', 'հու', '`', 'միայն', 'առաջին', 'րոպեին', 'փոքր', '-', 'ինչ', 'կորցրիր', 'գլուխդ', 'կեղծ', '`', 'տպավորությամբ', ':', 'Բայց', 'միթե', '՛', 'հայտնի', 'է', ',', 'թե', 'ինչ', 'տեղի', 'կու|', 'նենա', 'այդ', 'հոտի', 'հետ', 'մեկ', 'ժամ', 'անց', ',', 'երբ', 'եթերային', \"փոխա'րինումնե\", 'ը', 'գոլորշանան', ',', 'ու', 'բացահայտվի', 'նրա', 'միջուկը', ':', '222', 'ՅՆԱ', 'այսօր', 'երեկոյան', ',', 'երբ', 'բուրմունք', 'կարձակեն', 'միա', 'ա', '.', '`', 'ան', 'ծանր', ',', 'մութ', 'բաղադրիչները', ',', 'որոնք', 'այժմ', 'թաքնվում']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1390\n",
            "1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երկրորդ', 'կանոնն', 'ասում', 'է', '.', 'օծանելիքն', 'ապրում', 'է', 'Ժամանակի', 'մեջ', ',', 'նա', 'ունի', 'իր', 'երիտասարդությունը', ',', 'իր', 'հասունությունն', 'ու', 'ծերությունը', ':', 'Եվ', 'եթե', 'միայն', 'այդ', 'բոլոր', 'երեք', 'տարիքներում', 'միատեսակ', 'հաճելի', 'բուրմունք', 'Է', 'արճակում', ',', 'այն', 'կարելի', 'է', 'համարել', 'հաջողված', ':', 'չէ', '՞', 'որ', 'արդեն', 'քանիցս', 'եղել', 'է', 'այնպես', ',', 'որ', 'մեր', 'կողմից', 'պատրաստված', 'խառնուրդն', 'առաջին', 'փորձի', 'Ժամանակ', 'բուրում', 'էր', 'հրաշալի', 'թարմությամբ', ',', 'կարճ', 'ժամանակ', 'անց', 'նեխած', 'մրգահոտերով', ',', 'ն', 'ի', 'վերջո', '՝', 'արդեն', 'չափից', 'դուրս', 'զզվելի', 'մաքուր', 'մուշկի', 'հոտով', ',', 'քանի', 'որ', 'մենք', 'անցել', 'էինք', 'նրա', 'չափաբաժնի', 'նորմից', ':', 'Ընդհանուր', 'առմամբ', 'մուշկի', 'հետ', 'պետք', 'Է', 'զգուշությամբ', 'վարվել', ':', 'Մեն', '-', 'միակ', 'կաթիլը', 'կարող', 'է', 'հասցնել', 'աղետալի', 'հետնանքների', ':', 'Հնուց', 'եկող', 'սխալ', ':', 'Ով', 'գիտի', ',', 'միգուցե', 'Պելիսյեն', 'չափից', 'դոււս', '՛', 'է', 'մուշկ', 'խառնել', ':', 'Միգուցե', 'երեկոյան', 'կողմ', 'նրա', 'գոռոզամիտ', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ից', 'միմիայն', 'կատվի', 'մեզի', 'հոտ', '՛', 'մնա', ':', 'Կապրենք', 'կտեսնենք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1410\n",
            "1420\n",
            "1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'նրա', 'ճեռքը', 'մեխանիկորեն', 'շարունակում', 'էր', 'հազար', 'անգամ', 'փորձված', 'նրբագեղ', 'շարժումով', 'Ժանյակավոր', 'թաշկինակը', 'թրջել', 'օծանելիքով', ',', 'այն', 'թափ', 'տալ', 'ու', 'արագ', 'անցկացնել', 'դեմքի', 'կողքով', ',', 'ն', 'ամեն', 'անգամ', 'մեխանիկորեն', 'իր', 'մեջ', 'էր', 'ներշնչում', 'բուրմունքով', 'ներթափանցված', 'օդի', 'չափաբաժինը', ',', 'որպեսզի', 'արվեստի', 'բոլոր', 'կանոններով', 'շունչը', 'պահելով', 'կատարի', 'երկարատն', 'արտաշնչում', ':', 'Ի', 'վերջո', ',', 'քիթն', 'ազատեց', 'նրան', 'այդ', 'տանջանքից', '.', 'ալերգիկ', 'ձնով', 'ներսից', 'ուռչելով', '՝', 'կարծես', 'խցանվեց', 'մեղրամոմե', 'խցանով', ':', 'Այժմ', 'արդեն', 'ընդհանրապես', 'չէր', 'կարող', 'որնէ', 'հոտ', 'զգալ', 'ու', 'հազիվ', 'էր', 'կարողանում', 'շնչել', ':', 'Քիթը', 'լցված', 'էր', ',', 'ինչպես', 'ծանր', 'հարբուխի', 'Ժամանակ', ',', 'իսկ', 'աչքերի', 'անկյուններում', 'արտասուքի', 'կաթիլներ', 'էին', 'հայտնվել', ':', 'Փառք', 'Աստծու', ':', 'Այժմ', 'կարելի', 'է', 'հանգիստ', 'խղճով', 'աշխատանքը', 'դադարեցնել', ':', 'Այժմ', 'նա', 'կատարեց', 'իր', 'պարտքը', ',', 'արեց', 'այն', 'ամենը', ',', 'ինչ', 'կարող', 'էր', 'արվեստի', 'բոլոր', 'կանոնների', 'համաձան', ',', 'ու', 'ինչպես', 'մեկ', 'անգամ', 'չէ', ',', 'որ', 'տեղի', 'էր', 'ունենում', ',', 'պարտվեց', ':', 'Սիռ', '՛', 'քօտտ6', 'ոօ', 'օԵկցճեսր', ':', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n",
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'ետ', 'քաշեց', 'սողնակը', ',', 'բացեց', 'ծանր', 'դուռը', 'ու', 'ոչինչ', 'չտեսավ', ':', 'Մթությունն', 'ամբողջությամբ', 'կլանեց', 'մոմի', 'լույսը', ':', 'Հետոնա', '՞', 'աստիճանաբար', 'նշմարեց', 'երեխայի', 'կամ', 'տղայի', 'փոքրիկ', 'կերպար', 'ձեռքին', 'ինչ', '-', 'որ', 'առարկա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Քեզ', 'ինչ', '՞', 'է', 'պետք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n",
            "1590\n",
            "1600\n",
            "1610\n",
            "1620\n",
            "1630\n",
            "1640\n",
            "1650\n",
            "1660\n",
            "1670\n",
            "1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'ուզում', 'եք', 'այծի', 'մորթիները', 'բուրումնեա', '՛', 'դարձնել', ',', 'վարպետ', 'Բալդինի', ':', 'Այս', 'մորթիները', ',', 'որոնք', 'ես', 'եմ', 'ճեզ', 'բերել', ',', 'դուք', 'դրանց', '՞', 'եք', 'ցանկանում', 'բուրմունք', 'հաղորդել', ',', '-', 'շշնջաց', 'Գրենույը', 'կարծես', 'ի', 'գիտություն', 'չընդունելով', 'Բալդինիի', 'պատասխանը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Պելիսյեի', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ով', '՛', ',', '-', 'հարցրեց', 'Գրենույն', 'ու', 'ավելի', 'շատ', 'խոնարհվեց', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այդ', 'պահին', 'Բալդինիի', 'մարմնով', 'սարսափի', 'թեթն', 'ջղաձգություն', 'անցավ', ':', 'Ոչ', 'այն', 'պատճառով', ',', 'որ', 'ինքը', 'հարգրեց', 'իրեն', '՝', 'որտեղից', '՛', 'է', 'այս', 'տղային', 'ամեն', 'ինչ', 'այդպիսի', 'ճշտությամբ', 'հայտնի', ',', 'այլ', 'ուղղակի', 'այն', 'պատճառով', ',', 'որ', 'ատելի', 'օծանելիքի', 'անունը', ',', 'որի', 'բաղադրությունը', 'այսօր', 'նա', ',', 'ի', 'խայտառակություն', 'իրեն', ',', 'չկարողացավ', 'պարզել', ',', 'բարձրաձայն', 'հնչեցվեց', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'ինչպես', '՛', 'քո', 'գլխում', 'նման', 'աբսուրդային', 'գաղափար', 'ծագեց', ',', 'որ', 'ես', 'ուրիշների', 'օծանելիքն', 'եմ', 'օգտագործում', ',', 'որպեսզի', '...']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այդպես', ',', '-', 'ասաց', 'Բալդինին', ',', 'որը', 'բացարձակապես', 'գնցված', 'էր', 'խոսակցության', '՝', 'դեպի', 'ճշգրիտի', 'ոլորտ', 'նման', 'շրջադարձով', ':', '-', 'էլ', '՛', 'ինչ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բուրավետ', 'բալասանի', 'յուղը', '՛', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['աներ', 'սարսափելի', 'աշխատանք', ',', 'թերնս', 'ավելի', 'վատ', ',', 'քան', 'մասերի', 'պարզունակ', 'նույնականացումը', '.', 'չէ', '՞', 'որ', 'պետք', 'էր', 'չափել', ',', 'ու', 'կշռել', ',', 'ու', 'գրառել', ',', 'ն', 'ընդ', 'որում', '՝', 'լինել', 'չափազանց', 'ուշադիր', ',', 'քանզի', 'նվազագույն', 'անզգուշությունը', 'կաթոցիչի', 'դողդողոցը', ',', 'սխալը', 'կաթիխերը', 'հաշվելիս', ',', 'կարող', 'էր', 'ամեն', 'ինչ', 'կործանել', ':', 'Իսկ', 'յուրաքանչյուր', 'չհաջողված', 'փորճ', 'սարսափելի', 'թանկ', 'էր', 'նստում', ':', 'Յուրաքանչյուր', 'փչացված', 'խառնուրդ', 'արժեր', 'մի', 'փոքրիկ', 'ունեցվածք', '...', 'Նրա', 'մոտ', 'ցանկություն', 'առաջացավ', 'փորձել', 'այս', 'փոքրիկ', 'մարդուն', ',', 'ցանկություն', 'առաջացավ', 'նրան', 'հարցնել', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', 'ճշգրիտ', 'բանաճնի', 'մասին', ':', 'Եթե', 'նա', 'գիտի', 'այն', 'մեկ', 'գրամի', 'ու', 'մեկ', 'կաթիլի', 'ճշգրտությամբ', ',', 'կնշանակի', 'ակնհայտորեն', 'խաբեբա', 'է', ',', 'որն', 'ինչ', '-', 'որ', 'ձնով', 'կարողացել', 'է', 'հայթայթել', 'Պելիսյեի', 'բանաձնը', ',', 'որպեսզի', 'վստահություն', 'ներշնչի', 'ու', 'Բալդինիի', 'մոտ', 'տեղ', 'ստանա', ':', 'Բայց', 'եթենա', '՞', 'բացահայտի', 'մոտավորապես', ',', 'նշանակում', 'է', '՝', 'նա', 'հոտառության', 'հանճար', 'է', 'ն', ',', 'որպես', 'այդպիսին', ',', 'արժանի', 'Է', 'Բալդինիի', 'պրոֆեսիոնալ', 'հետաքրքրությանը', ':', 'Չի', 'կարելի', 'ասել', ',', 'որ', 'Բալդինին', 'կասկածի', 'տակ', 'դրեց', 'գործերից', 'հեռանալու', '՝', 'իր', 'կողմից', 'ընդունված', 'որոշումը', ':', 'Նույնիսկ', 'եթե', 'այս', 'պատանին', 'լիտրերով', 'այդ', 'օծանելիքից', 'հայթայթի', ',', 'Բալդինին', 'չի', 'ցանկանա', 'դրանով', 'բուրումնավետ', 'դարձնել', 'կոմս', 'Վերամոնի', 'կաշին', ',', 'բայց', '...', 'Բայց', 'չէ', '՞', 'որ', 'մարդը', 'նրա', 'համար', 'չի', 'ողջ', 'կյանքում', 'եղել', 'օծանագործ', 'ն', 'ողջ', 'կյանքում', 'զբաղվել', 'հոտերի', 'կազմումով', ',', 'որպեսզի', 'մի', 'ակնթարթում', 'կորցնի', 'իր', 'ողջ', 'պրոֆեսիոնալ', 'կիրքը', ':', 'Այժմ', 'նրան', 'հետաքրքրում', 'էր', 'անիծյալ', 'օծանելիքի', 'բանաձճնը', ',', 'ավելին', '՝', 'նա', 'ցանկանում', 'էր', 'ուսումնասիրել', 'տարօրինակ', 'տղայի', 'տաղանդը', ',', 'որն', 'ընթերցեց', 'իր', 'ճակատի', 'հոտը', ':', 'Նա', 'ցանկանում', 'էր', 'իմանալ', ',', 'թե', 'ինչ', 'է', 'թաքնված', 'դրա', 'ետնում', ':', 'Նրա', 'մոտ', 'առաջացավ', 'հասարակ', 'հետաքրքրասիրություն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1720\n",
            "1730\n",
            "1740\n",
            "1750\n",
            "1760\n",
            "1770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բուրավետ', 'բալասանից', ',', 'վարդի', 'յուղից', 'ու', 'մեխակից', ',', 'ինչպես', 'նան', 'բերգամոտից', 'ու', 'հազրեվարդի', 'լուծամզվածքից', 'ն', 'այխ', ':', 'Դա', 'պարզելու', 'համար', 'պետք', 'է', ',', 'ինչպես', 'ասում', 'են', ',', 'ունենալ', 'բավականին', 'նուրբ', 'հոտառություն', ',', 'ու', 'լիովին', 'հնարավոր', 'է', ',', 'որ', 'Աստված', 'քեզ', 'բավականին', 'նուրբ', 'հոտառություն', 'Է', 'տվել', ',', 'ինչպես', 'ն', 'շատ', 'ուրիշ', 'մարդկանց', '՝', 'հատկապես', 'քո', 'տարիքում', ':', 'Սակայն', 'օծանագործի', 'համար', ',', '-', 'ն', 'այստեղ', 'նա', 'վեր', 'պարզեց', 'մատն', 'ու', 'դուրս', 'ցցեց', 'կուրծքը', ',', 'սակայն', 'օծանագործի', 'համար', 'քիչ', 'է', 'ուղղակի', 'նուրբ', 'հոտառություն', 'ունենալը', ':', 'Նրան', 'անհրաժեշտ', 'Է', 'տասնամյակների', 'ընթացքում', 'վարժեցված', ',', 'անկաշառ', 'աշխատող', 'հոտառական', 'օրգան', ',', 'որը', 'թույլ', 'կտա', 'վստահորեն', 'կռահել', 'նույնիսկ', 'ամենաբարդ', 'հոտերը', ',', 'դրանց', 'բաղադրությունն', 'ու', 'համաչափությունները', ',', 'ինչպես', 'նան', 'ստեղծել', 'նոր', 'բուրմունքների', 'անհայտ', 'խառնուրդներ', ':', 'Նման', 'քիթը', ',', 'ն', 'նա', 'մատով', 'թխկթխկացրեց', 'իրենը', ',', '-', 'այդքան', 'հեշտ', 'չի', 'տրվում', ',', 'երիտասարդ', ':', 'Նման', 'քիթը', 'վաստակում', 'են', 'ջանասիրությամբ', 'ու', 'համբերությամբ', ':', 'թե', '՞', 'դու', 'կկարողանայիր', 'ուղղակի', 'այնպես', '՝', 'ձեռքի', 'հետ', 'անվանել', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', 'ճշգրիտ', 'բանաձնը', ':', 'Դե՛', '՞', 'Կկարոաանայի', '՛', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Միգուցե', 'դու', 'ինճ', 'գոնե', 'մոտավոարպս', '՛', 'կասես', ',', 'ասաց', 'Բալդինին', 'ու', 'թեթնակի', 'թեքվեց', 'առաջ', ',', 'որպեսզի', 'ավելի', 'լավ', 'ուսումնասիրի', 'դռան', 'մեջ', 'թաքնված', 'դոդոշին', 'Գոնե', 'մոտավորապես', ',', 'ընդհանուր', 'տեսքով', ':', 'Դե', 'Խոսիր', ',', 'չէ', '՞', 'որ', 'դու', 'Փարիզի', 'լավագույն', 'քիթն', 'ես', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դե', ',', 'տեսնում', '՛', 'ես', ',', '-', 'փնթփնթաց', 'Բալդինին', '՝', 'միաժամանակ', 'բավարարված', 'ու', 'հիասթափված', ':', '-', 'Չես', 'կարող', ':', 'Իհարկե', 'ոչ', ':', 'Ոնց', 'կարող', 'ես', 'իմանալ', ':', 'Դու', 'նրանցից', 'ես', ',', 'ով', 'ժաշ', 'ուտելիս', 'որոշում', 'է', '՝', 'արդյոք', 'ապուրի', 'մեջ', 'մաղադանոս', '՛', 'է', ',', 'թե', '՞', 'կերբելուկ', ':', 'Դե', 'ինչ', ',', 'դա', 'էլ', 'արդեն', 'քիչ', 'չէ', ':', 'Իայց']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1780\n",
            "1790\n",
            "1800\n",
            "1810\n",
            "1820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'ղատոմսն', 'իմ', 'քթի', 'մեջ', 'է', ':', '<UNK>առնեմ', '՞', 'դրանք', 'ձեզ', 'համար', ',', 'Հ', ':', 'մետր', ',', 'խառնեմ', ':', 'Ն', '`', '-', 'Այսինքն', '՝', 'ինչպես', '՛', ',', '-', 'բացականչեց', 'Բալդինին', 'ավելի', 'Բարեր', ',', 'քան', 'պատշաճ', 'էր', 'նրան', ',', 'ն', 'մոմը', 'մոտեցրեց', 'թզուկի', 'դեմքին', '-', '-', 'Այսինքն', '՝', 'ինչպես', '՛', 'խառնել', ':', 'Գրենույն', 'առաջին', 'անգամ', 'ետ', 'չընկրկեց', ':', 'Զ', '-', 'Ախր', 'դրանք', 'բոլորն', 'այստեղ', 'են', '՝', 'այդ', 'հոտերը', ',', 'որոնք', '18', 'պեոտլ', 'են', ',', 'դրանք', 'բոլորը', 'կան', 'այս', 'սենյակում', ',', 'ասաց', 'նա', '`', 'Ակրկին', 'մատն', 'ուղղեց', 'դեպի', 'մթությունը', ':', 'Վարդի', 'յուղն', '`', '.', 'ահա', 'անտեղ', 'է', ':', 'Իսկ', 'այնտեղ', 'նարնջի', 'գույնը', ':', 'Իսկ', 'այն', '`', 'տեղ', 'մեխակը', ':', 'Իսկ', 'այնտեղ', '՝', 'հազրեվարդը', '...']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1830\n",
            "1840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դու', 'կարծում', 'ես', ',', 'որ', 'ես', 'քեզ', 'թույլ', 'կտամ', 'տնօրինել', 'իմ', 'արհեստանոցը', ':', 'Բնահյութերը', ',', 'որոնք', 'մի', 'ողջ', 'ունեցվածք', 'ար<UNK>են', '՞', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '-', '<UNK>ահ', '՛', ':', '-', 'Բալդինին', 'կտրուկ', 'դուրս', 'փչեց', 'իր', 'մեջ', 'եղած', 'շունչը', ':', 'Այնուհետն', 'թոքերը', 'լցրեց', 'օդով', ',', 'երկար', 'նայեց', 'սարդանման', 'Գրենույին', 'ն', 'մտորեց', ':', '«', 'Ըստ', 'էության', '՝', 'միթե', '՛', '`', 'միննույն', 'չէ', ',', '-', 'մտածեց', 'նա', ',', '-', 'այսպես', 'թե', 'այնպես', 'վաղն', 'ամեն', 'ինչ', 'ավարտվելու', 'է', ':', 'Ես', ',', 'իհարկե', ',', 'գիտեմ', ',', 'որ', 'նա', 'չի', 'կարող', 'անել', 'այն', ',', 'ինչը', 'խոստանում', 'է', ',', 'դա', 'բացառվում', 'է', ',', 'այլապես', 'նա', 'ավելի', 'մեծ', 'համբավ', 'կունենար', ',', 'քան', 'մեծն', 'Ֆրանժիպանին', ':', 'Բայց', 'ինչու', 'սեփական', 'աչքերով', 'չհամոզվեմ', 'նրանում', ',', 'ինչը', 'գիտեմ', ':', 'Միգուցե', 'հանկարծ', 'մի', 'գե', '`', 'ղեցիկ', 'օր', 'Մեսինայում', 'իմ', 'գլուխը', 'մի', 'միտք', 'գա', ',', 'ծեր', 'մարդ', '`', 'կանց', 'մոտ', 'երբեմն', 'լինում', 'են', 'տարօրինակություններ', 'ու', 'խենթ', 'մտքեր', ',', 'որ', 'ես', 'չճանաչեցի', 'մի', 'հանճարի', ',', 'հրաշամանուկի', ',', 'արարածի', ',', 'ով', 'Աստծու', 'ողորմությամբ', 'շռայլորեն', 'տված', 'էր', '...', 'Դա', 'ամբողջապես', 'բացառվում', 'է', ':', 'Ելնելով', 'մենից', ',', 'ինչ', 'ինճ', 'հուշում', 'է', 'բանականությունս', ',', 'դա', 'ացառվ/', 'ճի', '.', 'Բայց', 'չէ', '՞', 'որ', 'լինում', 'են', 'հրաշքներ', ':', 'Անկաս', '`', '`', 'կած', ':', 'Եվ', 'ահա', ',', 'երբ', 'Մեսինայում', 'մոտենա', 'իմ', 'մեռնելու', 'ժա', '.', 'մահվան', 'մահճում', 'ինճ', 'կայցելի', 'մի', 'միտք', '.', 'այն', 'երեկո', 'Փա', 'Ա', 'ւմ', 'քեզ', 'ներկայացավ', 'հրաշքը', ',', 'իսկ', 'դու', 'փակեցիր', 'դ', '...', 'Դա', ',', 'բնականաբար', ',', 'այնքան', 'էլ', 'հաճելի', 'չէր', 'լինի', ',', 'Բալդինի', ':', 'Ավելի', 'լավ', 'Է', 'այս', 'հիմարը', 'սեղանի', 'վրա', 'մի', '`', 'երկու', 'կաթիլ', 'վարդի', 'յուղ', 'ու', 'մուշկի', 'թուրմ', 'թափի', ',', 'դու', 'նս', '|', 'անք', 'կթափեիր', ',', 'եթե', 'քեզ', 'դեռնս', 'իրոք', 'շարունակեր', 'հեՏ', 'սքրքրել', 'Պելիսյեի', 'օծանելիքը', ':', 'Եվ', 'ինչ', '՞', 'նշանակություն', 'Սուր', 'մի', 'քանի', 'կաթիլը', ',', 'այո', ',', 'թանկարժեք', ',', 'բավականին', ',', '`', 'բավականին', 'թանկարժեք', ',', 'եթե', 'համեմատես', 'դա', 'գիտեոուսալիության', 'ու', 'հանգիստ', 'ծերության', 'հետ', '»', ':', '-', 'ասաց', 'նա', 'միտումնավոր', 'խիստ', 'տոնով', ':', '-', 'Լսիր', ':', 'ԳԵ', 'ՅՔ', 'պ', ',', 'ինչպես', '՛', 'է', 'քո', 'անունը', ':', '2', 'ո', 'Պրենույ', ',', '-', 'ասաց', 'Գրենույը', ':', '-', 'Ժան', '-', 'Բատիստ', 'Գրենույ', ':', 'Ե', 'Ե', 'Սհա', ',', '-', 'ասաց', 'Բալդինին', '-', 'Դե', 'ուրեմն', 'լսիր', ',', '`', 'Ժան', '-', 'Իատ', 'Գրենույ', ':', 'Ես', 'միտքս', 'փոխեցի', ':', 'Դու']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1850\n",
            "1860\n",
            "1870\n",
            "1880\n",
            "1890\n",
            "1900\n",
            "1910\n",
            "1920\n",
            "1930\n",
            "1940\n",
            "1950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ձեզ', 'համար', 'որքան', '՞', 'պատրաստեմ', ',', 'մետր', ',', '-', 'հարցրեց', 'Գրենույը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որքան', '՞', ',', 'ինչը', '՞', ',', '-', 'հարցրեց', 'Բալդինին', ',', 'ով', 'դեռ', 'չէր', 'ավարտել', 'իր', 'խոսքը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այս', 'օծանելիքից', '՝', 'որքան', '՞', ',', '-', '-', 'խռպոտ', 'հարցրեց', 'Գրենույը', ':', '-', 'որքան', '՞', 'է', 'ձեզ', 'պետք', 'դրանից', ':', 'Կուզեք', '՛', 'մինչն', 'եզրը', 'լցնեմ', 'այ', 'այն', 'մեծ', 'ամանը', ':', '-', 'Եվ', 'նա', 'մատնացույց', 'արեց', 'երեք', 'լիտրից', 'ոչ', 'պակաս', 'տարողությամբ', 'խառնամանը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ոչ', ',', 'պետք', 'չի', ',', '-', 'սարսափած', 'բացականչեց', 'Բալդինին', '.', 'նրա', 'այդ', 'գոռոցի', 'մեջ', 'կար', 'վախ', '՝', 'որչափ', 'խոր', 'արմատացած', ',', 'նույնչափ', 'էլ', 'տարերային', 'վախ', 'շռայլության', 'հանդեպ', ',', 'վախ', 'իր', 'սեփականության', 'համար', ':', 'Բայց', ',', 'կարծես', 'ամաչելով', 'այդ', 'ինքնամերկացնող', 'գոռոցից', ',', 'նա', 'անմիջապես', 'էլ', 'մռնչաց', ',', '-', 'չհամարձակվես', 'ինձ', 'ընդհատել', ':', '-', 'Այնուհետն', 'մի', 'քիչ', 'հանգստացավ', 'ն', 'շարունակեց', 'թեթնակի', 'հեգնական', 'ձայնով', ':', '-', 'Մեր', 'ինչին', '՞', 'է', 'պետք', 'երեք', 'լիտր', 'օծանելիքը', ',', 'որը', 'երկուսս', 'էլ', 'չենք', 'գնահատում', ':', 'Ըստ', 'էության', '՝', 'սրվակի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1970\n",
            "1980\n",
            "1990\n",
            "2000\n",
            "2010\n",
            "2020\n",
            "2030\n",
            "2040\n",
            "2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'քո', 'պարզունակ', 'բթամտությունը', 'ցույց', 'են', 'տալիս', ',', 'որ', 'դու', '`', 'ոչինչ', 'չես', 'հասկանում', ',', 'դու', 'բարբարոս', 'ես', 'ու', 'անտաշ', ',', 'դրա', '`', 'հետ', 'էլ', 'գոնջոտ', ',', 'լկտի', ',', 'փսլնքոտ', ':', 'Դու', 'ի', 'վիճակի', 'չես', 'լիմոնադ', 'խառնել', ',', 'քեզ', 'չի', 'կարելի', 'սովորական', 'մատուտակի', '`', 'ջրի', 'վաճառք', 'վստահել', ',', 'իսկ', 'դու', 'խցկվում', 'ես', 'օծանագործի', '`', 'գործի', 'մեջ', ':', 'Գոհ', 'եղիր', ',', 'ուրախացիր', 'ու', 'շնորհակալ', 'եղիր', ',', '`', 'որ', 'քո', 'տերը', 'քեզ', 'դեռ', 'մոտ', 'է', 'թողնում', 'դաբաղման', 'լուծույլ', 'բիչեվ', 'չհամարձակվես', ',', 'լսում', '՛', 'ես', ',', 'երբեք', 'չհամարճակվես', '`', 'օծանագործի', 'դռան', 'շեմն', 'անցնել', ':', 'լ', '`', 'Այդպես', 'էր', 'խոսում', 'Բալդինին', ':', 'Եվ', 'մինչ', 'նա', 'խոսում', 'էր', ',', ':', 'ակա', 'տարածությունը', 'լցվեց', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', '`', 'բուրմունքով', ':', 'Բուրմունքի', 'մեջ', 'կա', 'համոզչություն', ',', 'որն', '5', 'արեւ', 'ուժեղ', 'է', 'բառերից', ',', 'ակնհայտությունից', ',', 'զգացմունքից', 'ու', 'կամքից', ':', 'Բուրմունքի', 'համոզչությունն', 'ան', ':', 'ժխտելի', 'է', ',', 'անհաղթահարելի', ',', 'այն', 'մեր', 'մեջ', 'Է', 'մտնում', ',', '`', 'ինչպես', 'օդն', 'է', 'մտնում', 'մեր', 'թոքերի', 'մեջ', ',', 'որը', 'շնչում', 'ենք', ',', '\"ան', 'լեփ', '-', 'լեցուն', ',', 'մինչն', 'վերջ', 'լցվում', 'է', 'մեր', 'մեջ', ':', 'Եվ', 'դրա', 'դեմ', 'դկան', 'միջոցներ', ':', 'Գրենույը', 'մի', 'կողմ', 'դրեց', 'շիշը', ',', 'օծանելիքից', 'թրջված', 'ճեռ6', '.', 'քրհեռացրեց', 'շշի', 'վզիկից', 'ն', 'չորացրեց', 'այ', 'քսելով', 'իր', 'բաճաաա', 'ԱՉ', 'Ց', 'փեշին', ':', 'Մեկ', ',', 'երկու', 'քայլ', 'ետ', ',', 'ողջ', 'մարմնով', 'անճոռնի', 'խոնարհումը', 'Բալդինիի', 'խրատների', 'կարկուտի', 'ներքո', 'բասկանաչափ', 'տատանեցին', 'օդը', ',', 'որպեսզի', 'տարածեն', 'հենց', '|', 'տեղծված', 'բուրումնահոտությունը', ':', 'Չնայած', 'Բալդինին']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2060\n",
            "2070\n",
            "2080\n",
            "2090\n",
            "2100\n",
            "2110\n",
            "2120\n",
            "2130\n",
            "2140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ակելով', 'թաշկինակը', 'սեղմել', 'քթին', ',', 'կարծես', 'ուզում', 'էր', 'ով', 'պաշտպանվել', 'իր', 'հոգու', 'վրաանո', '՛', 'հարձակումից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'չեք', '՛', 'ցանկանում', 'փորձանմուշ', 'վերցնել', ',', '-', '-', 'կրկին', 'կարկաչող', 'ճայնով', 'ասաց', 'Գրենույը', ',', '-', 'միթե', '՛', 'չեք', 'ուզում', ',', 'վարպետ', ':', 'Միթե', '՛', 'չեք', 'փորձի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2160\n",
            "2170\n",
            "2180\n",
            "2190\n",
            "2200\n",
            "2210\n",
            "2220\n",
            "2230\n",
            "2240\n",
            "2250\n",
            "2260\n",
            "2270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['գործընթացը', 'այն', 'միջոցների', 'օգնությամբ', ',', 'առանց', 'որոնց', 'այդ', 'գործընթացը', 'պարզապես', 'չէր', 'կարող', 'տեղի', 'ունենալ', ',', 'Բալդինիին', ',', 'վերջիվերջո', ',', 'հաջողվեց', 'տիրանալ', 'այդ', 'սինթետիկ', 'բաղադրատոմսին', ':', 'ինչպես', '՛', 'կարող', 'էր', 'Գրենույն', 'առանց', 'նման', 'բաղադրատոմսի', 'խառնել', 'իր', 'բուրումնավետ', 'բաղադրությունները', ',', 'Բալդինիի', 'համար', 'մնում', 'էր', 'գաղտնիք', 'ն.նույնիսկ', 'հրաշք', ',', 'բայց', 'այժմ', 'նա', 'առնվազն', 'այդ', 'հրաշքը', 'գրառեց', 'բանաձնի', 'տեսքով', 'ն', 'դրանով', 'իսկ', 'որոշ', 'չափով', 'հագեցրեց', 'իր', 'դասակարգման', 'հանդեպ', 'ունեցած', 'ծարավը', 'ու', 'իր', 'օծանագործային', 'աշխարհի', 'պատկերը', 'պաշտպանեց', 'ամբողջական', 'կործանումից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2280\n",
            "2290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['դեպքում', 'ժամանակ', 'առ', 'ժամանակ', 'նա', 'սխալներ', 'էր', 'գործում', ',', 'որոնք', 'այնպես', 'էին', 'հաշվարկված', ',', 'որ', 'Բալդինին', 'դրանք', 'նկատի', '.', 'մոռանում', 'էր', 'ինչ', '-', 'որ', 'նյութ', 'զտիչի', 'միջով', 'անցկացնել', ',', 'ճիշտ', 'չէր', 'տեղադրում', 'կշեռքը', ',', 'բանաձնի', 'մեջ', 'հավելագրում', 'էր', 'ամպարի', 'անհեթեթ', 'բարձր', 'տոկոս', 'ն', 'առիթ', 'էր', 'ստեղծում', ',', 'որ', 'իրեն', 'ցույց', 'տան', 'իր', 'սխալները', ',', 'որպեսզի', 'հետո', 'ինքը', 'մանրակրկիտ', 'ուղղի', ':', 'Այդ', 'կերպ', 'նրան', 'հաջողվում', 'էր', 'Բալդինիին', 'ներշնչել', 'այն', 'պատրանքը', ',', 'որ', 'վերջիվերջո', 'ամեն', 'ինչ', 'ընթանում', 'է', 'կանոնա', '`', 'վոր', 'ն', 'պատշաճ', 'հունով', ':', 'չէ', '՞', 'որ', 'նա', 'չէր', 'ուզում', 'վախեցնել', '`', 'ծերուկին', ':', 'չէ', '՞', 'որ', 'իրոք', 'ուզում', 'էր', 'նրանից', 'սովորել', ':', 'Ոչ', 'թե', 'օծանելիքի', 'բաղադրությունը', ',', 'ոչ', 'թե', 'այս', 'կամ', 'այն', 'բուրմունքի', 'կառուցվածքը', ',', 'ամեննին', 'ոչ', ':', 'Այդ', 'բնագավառում', 'աշխարհում', 'չկար', 'մեկը', ',', 'ով', 'կարող', 'էր', 'նրան', 'ինչ', '-', 'որ', 'բան', 'սովորեցնել', ':', 'Բալդինիի', 'կրպակում', 'առկա', 'բաղադրամասերը', 'ամեննին', 'էլ', 'բավարար', 'չէին', 'իսկական', 'մեծ', 'օծանելիքի', 'մասին', 'նրա', 'պատկերացումներն', 'իրականացնելու', 'համար', ':', 'Այն', 'անուշահոտերը', ',', 'որ', 'կարողանում', 'էր', 'ստեղծել', 'Բալդինիի', 'մուտ', ',', 'մանկական', 'զվարճանք', 'էր', 'այն', 'անուշաբույրերի', 'համեմատ', ',', 'որոնք', 'կրում', 'էր', 'իր', 'մեջ', 'ու', 'պատրաստվում', 'էր', 'մի', 'հրաշալի', 'օր', 'դրանք', 'իրականացնել', ':', 'Բայց', 'դրա', 'համար', ',', 'նա', 'գիտեր', ',', 'պահանջվում', 'էին', 'երկու', 'անպատճառ', 'պայմաններ', ':', 'Նախնառաջ', 'պարկեշտ', 'բյուրգերական', 'ապրելակերպի', 'պատրանք', 'գոնե', 'առնվազն', 'ենթավարպետի', 'դիրք', ',', 'որի', 'շղարշի', 'տակ', 'նա', 'կկարողանար', 'անզուսպ', 'տրվել', 'սեփական', 'կրքերին', 'ն', 'առանց', 'խոչընդոտների', 'հետապնդել', 'սեփական', 'նպատակները', ':', 'Եվ', 'երկրորդ', 'արհեստի', 'այն', 'հնարքների', 'իմացությունը', ',', 'որը', 'թույլ', 'կտար', 'պատրաստել', ',', 'առանձնացնել', ',', 'կենտրոնացնել', ',', 'պահածոյացնել', 'բուրումնավետ', 'նյութերը', 'ն', 'դրանով', 'իսկ', 'սկզբունքորեն', 'դրանք', 'դնել', 'իր', 'տնօրինման', 'տակ', 'ինչ', '-', 'որ', 'բարձրագույն', 'նպատակների', 'համար', ':', 'Չնայած']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2300\n",
            "2310\n",
            "2320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', 'հմայված', 'էր', 'այդ', 'գործընթացով', ':', 'Եթե', 'կյանքում', 'ինչ', '-', 'որ', 'ժամանակ', 'ինչ', '-', 'որ', 'բան', 'նրա', 'մոտ', 'հիացմունք', 'է', 'առաջացնում', ',', 'իհարկե', ',', 'արտաքնապես', 'երբեք', 'չդրսնորվող', ',', 'այլ', 'թաքնված', ',', 'սառը', 'բոցով', 'այրվող', 'հիացմունք', ',', 'ապա', 'հենց', 'այդ', 'միջոցը', 'կրակի', ',', 'ջրի', 'ու', 'գոլորշու', 'հնարամիտ', 'սարքավորման', 'օգնությամբ', 'իրարից', 'պոկել', 'նրանց', 'անուշահոտություն', 'արճակող', 'հոգին', ':', 'չէ', '՞', 'որ', 'անուշահոտություն', 'արձակող', 'հոգին', '՝', 'եթերային', 'յուղը', ',', 'դրանց', 'մեջ', 'պարունակվող', 'լավագույն', 'բանն', 'էր', 'միակը', ',', 'ինչը', 'նրան', 'հետաքրքրում', 'էր', 'դրանց', 'մեջ', ':', 'Անհամ', 'մնացորդը', ',', 'ծաղիկները', ',', 'տերնները', ',', 'կեղնները', ',', 'պտուղները', ',', 'գույները', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2330\n",
            "2340\n",
            "2350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['մեջ', 'այն', 'մասին', ',', 'թե', 'ինչպես', 'է', 'ամենը', 'եղել', 'նախկինում', ',', 'ն', 'ավելի', 'ու', 'ավելի', 'ինքնամոռաց', 'էր', 'խորասուզվում', 'մշուշոտ', 'պատրանքների', 'մեջ', ',', 'Գրենույը', ',', 'հակառակը', ',', 'շուտով', 'արգելեց', 'ինքն', 'իրեն', 'տրվել', 'անսանձ', 'ֆանտազիաներին', ':', 'Որպես', 'սկիզբ', 'նա', 'գլխից', 'դուրս', 'նետեց', 'թորման', 'մեծ', 'կաթսայի', 'պատկերը', ',', 'իսկ', 'դրա', 'փոխարեն', 'սկսեց', 'խորհել', ',', 'թե', 'իսչ', 'կերպ', 'օգտագործի', 'իրնոր', '՛', 'ձեռք', 'բերած', 'գիտելիքները', 'մոտակա', 'նպատակների', 'համար', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2360\n",
            "2370\n",
            "2380\n",
            "2390\n",
            "2400\n",
            "2410\n",
            "2420\n",
            "2430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['սիֆիլիսային', 'ծաղկաչեչով', 'ու', 'թարախային', 'կարմրուկով', 'յո', 'Տռժյօ', 'սետօ', ':', 'Ինչու', '՛', 'ոչ', 'երկու', 'տարի', 'անց', ':', 'Ինչու', '՛', 'ոչ', 'մեկ', 'տարի', 'անց', ':', 'Այդ', 'ընթացքում', 'նրան', 'կարելի', 'էր', 'ամբողջապես', 'քամել', 'ինչպես', 'արծաթի', 'հանքը', ',', 'ինչպես', 'ոսկե', 'ավանակին', ':', 'Եվ', 'թող', 'մի', 'տարուց', 'իր', 'համար', 'հանգիստ', 'մեռներ', ':', 'Բայց', 'ոչ', ':', 'Նա', 'հիմա', 'է', 'մահանում', ',', 'անիծված', 'լինի', 'նա', ',', 'կմեռնի', 'քառասունութ', 'ժամվա', 'մեջ', ':', 'Ինչ', '-', 'որ', 'մի', 'կարճ', 'պահ', 'Բալդինին', 'մտածեց', 'այն', 'մասին', ',', 'որ', 'ուխտագնացության', 'մեկնի', 'գետից', 'այն', 'կողմ', '՝', 'Նոտր', '-', 'Դամ', '՝', 'մոմ', 'վառելու', ',', 'ու', 'Գրենույի', 'առողջության', 'համար', 'աղերսի', 'Սուրբ', 'Աստվածամորը', ':', 'Բայց', 'հետո', 'նա', 'հրաժարվեց', 'այդ', 'մտքից', ',', 'քանի', 'որ', 'ժամանակը', 'սուղ', 'էր', ':', 'Նա', 'վազեց', 'գրչի', 'ու', 'թղթի', 'ետնից', 'ն', 'կնոջը', 'վռնդեց', 'հիվանդի', 'սենյակից', ':', 'Նա', 'ասաց', ',', 'որ', 'անճամբ', 'կհերթապահի', ':', 'Այնուհետն', 'նստեց', 'մահճակալի', 'կողքի', 'աթոռի', 'վրա', '՝', 'գրառումների', 'համար', 'թղթերը', 'ծնկներին', 'դրած', ',', 'թանաքի', 'մեջ', 'թաթախված', 'գրիչը', 'ձեռքին', ',', 'ն', 'փորձեց', 'Գրենույին', 'դրդել', 'օծանագործային', 'խոստովանանքի', ':', 'Աստծու', 'սիրուն', ',', 'նա', 'չպետք', 'է', 'հենց', 'այնպես', 'իր', 'հետ', 'գերեզման', 'տանի', 'այն', 'գանձերը', ',', 'որոնք', 'կրում', 'է', 'իր', 'մեջ', ':', 'Այժմ', '՝', 'վերջին', 'Ժամերին', ',', 'նա', 'պարտավոր', 'է', 'հուսալի', 'ձեռքերի', 'փոխանցել', 'իր', 'կտակը', ',', 'որպեսզի', 'Ժառանգներին', 'չզրկի', 'բոլոր', 'ժամանակների', 'լավագույն', 'բուրմունքներից', ':', 'Իսքը', 'Բալդինին', ',', 'հուսալիորեն', 'կտնօրինի', 'այդ', 'կտակը', '՝', 'այն', 'բոլոր', 'ամենավեհ', 'անուշահոտությունների', 'բանաձների', 'կանոններին', ',', 'որոնք', 'երբնիցե', 'գոյություն', 'են', 'ունեցել', 'աշխարհի', 'վրա', ',', 'նա', 'կհասնի', 'դրանց', 'ճանաչմանը', ':', 'Նա', '.', 'Գրենույի', 'անվանն', 'անմահ', 'փառք', 'կհաղորդի', ',', 'երդվում', 'է', 'բոլոր', 'սրբերով', ',', 'որ', 'այդ', 'բուրմունքներից', 'լավագույնը', 'կդնի', 'անճամբ', 'թագավորի', 'ոտքերի', 'առաջ', 'ագարե', 'սրվակով', 'ու', 'ոսկե', 'քանդակադրոշմով', 'ն', 'փորաԳրված', 'ընծայումով', '.', '«', 'Ժան', '-', 'Բատիստ', 'Գրենույից', '՝', 'Փարիզի', 'օծանագործից', '»', ':', 'Այդպես', 'էր', 'խոսում', 'կամ', ',', 'ավելի', 'շուտ', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2440\n",
            "2450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ասացեք', ',', 'մետր', ',', 'կան', '՞', 'արդյոք', 'այլ', 'միջոցներ', ',', 'քամումից', 'ու', 'թորումից', 'բացի', ',', 'ինչ', '-', 'որ', 'մարմնից', 'բուրմունք', 'ստանալու', 'համար', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որոնք', '՞', 'են', ',', '-', 'կրկին', 'հնչեց', 'հարցը', ',', 'ն', 'այս', 'անգամ', 'Բալդինին', 'նկատեց', 'Գրենույի', 'շուրթերի', 'շարժումը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որոնք', '՞', 'են', ',', '-', 'հարցրեց', 'նա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '-', 'Որտեղ', '՛', ',', '-', 'հարցրեց', 'Գրենույր', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2470\n",
            "2480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ամենից', 'առավել', 'նա', 'կցանկանար', 'մեկնել', 'հարավ', '՝', 'այնտեղ', ',', 'որտեղ', 'կարելի', 'է', 'ուսումնասիրել', 'նոր', 'տեխնիկական', 'միջոցները', ',', 'որոնց', 'մասին', 'պատմեց', 'ծերունին', ':', 'Բայց', 'այդ', 'մասին', ',', 'իհարկե', ',', 'պետք', 'չէր', 'նույնիսկ', 'երազել', ':', 'չէ', '՞', 'որ', 'նա', 'ընդամենը', 'աշակերտ', 'է', ',', 'այսինքն', '՝', 'ոչինչ', ':', 'Խիստ', 'ասած', '՝', 'բացատրեց', 'նրան', 'Բալդինին', '՝', 'հաղթահարելով', 'Գրենույի', 'համբարձման', 'առիթով', 'ուրախության', 'առաջին', 'բռնկումը', ',', 'նա', 'ավելի', 'փոքր', 'էր', ',', 'քան', 'ոչինչը', ',', 'քանզի', 'կարգին', 'աշակերտը', 'պետք', 'է', 'ունենա', 'անթերի', 'ծագում', '՝', 'օրինական', 'ամուսնության', 'մեջ', 'գտնվող', 'ծնողներ', ',', 'որոշակի', 'դասային', 'պատկանելություն', 'ունեցող', 'բարեկամներ', 'ն', 'ուսման', 'վերաբերյալ', 'վարպետի', 'հետ', 'պայմանագիր', ':', 'Իսկ', 'Գրենույը', 'դրանցից', 'ոչ', 'մեկը', 'չունի', ':', 'Եվ', 'եթե', 'ինքը', 'Բալդինին', ',', 'այնուամենայնիվ', ',', 'համաձայնում', 'է', 'օգնել', 'նրան', 'մի', 'հրաշալի', 'օր', 'դառնալու', 'ենթավարպետ', ',', 'ապա', 'դա', 'կանի', 'միայն', 'ապագայում', '՝', 'Գրենույի', 'անթերի', 'վարքագծի', 'պայմանով', 'ն', 'նրա', 'անսովոր', 'տաղանդի', 'հանդեպ', 'հարգանքից', 'դրդված', ':', 'Թեն', 'ինքը']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենույը', ',', 'որը', 'ոչ', 'մի', 'պատիվ', 'չուներ', ',', 'չէր', 'հավատում', 'սրբերին', 'ն', 'առավել', 'նս', '՝', 'իր', 'մոր', 'դժբախտ', 'հոգուն', ',', 'երդվեց', ':', 'Նա', 'կարող', 'էր', 'երդվել', 'ամեն', 'ինչով', ':', 'Նա', 'կընդուներ', 'Բալդինիի', 'բոլոր', 'պայմանները', ',', 'քանի', 'որ', 'նրան', 'անհրաժեշտ', 'էր', 'ենթավարպետի', 'կարգավիճակը', 'հաստատող', 'թուղթը', ',', 'որը', 'հնարավորություն', 'էր', 'տալիս', 'նրան', 'առանց', 'աչքի', 'ընկնելու', 'ապրել', ',', 'առանց', 'խոչընդոտների', 'ճանապարհորդել', 'ն', 'գտնել', 'աշխատանք', ':', 'Մնացածի', 'հանդեպ', 'նա', 'անտարբեր', 'էր', ':', 'Եվ', 'ինչ', '՞', 'պայմաններ', 'էին', 'դրանք', 'որ', ':', 'Չվերադառնալ', 'Փարիզ', ':', 'Իսկ', 'նրա', 'ինչին', '՞', 'էր', 'պետք', 'Փարիզը', ':', 'Նա', 'անգիր', 'գիտեր', 'մինչն', 'վերջին', 'գարշահոտ', 'անկյունը', ',', 'այն', 'ամենուր', 'կրում', 'էր', 'իր', 'հետ', ',', 'արդեն', 'մի', 'քանի', 'տարի', 'շարունակ', 'տիրում', 'էր', 'Փարիզին', ':', 'Չպատրաստել', 'բալդինյան', 'մոդայիկ', 'օծանեիքներ', '՛', ':', 'Չփոխանցել', 'բանաճներ', '՛', ':', 'Կարծես', 'թե', 'նա', 'չի', 'կարող', 'հայտնագործել', 'հազարավոր', 'ուրիշները', ',', 'նույնչափ', 'լավը', ',', 'ավելի', 'լավը', '.', 'հարկավոր', 'է', 'միայն', 'ցանկանալ', ':', 'չէ', '՞', 'որ', 'նա', 'չէր', 'պատրաստվում', 'մրցակցել', 'Բալդինիի', 'կամ', 'բուրժուա', 'օծանագործներից', 'ցանկացածի', 'հետ', ':', 'Նա', 'չէր', 'էլ', 'մտածում', 'իր', 'արվեստով', 'մեծ', 'գումարներ', 'վաստակելու', 'մասին', ',', 'նա', 'չէր', 'ուզում', 'նույիսկ', 'վաստակել', 'դրանով', 'ապրելու', 'գումար', ',', 'եթե', 'հնարավոր', 'լիներ', 'այլ', 'կերպ', 'ապրել', ':', 'Նա', 'ցանկանում', 'էր', 'իրենից', 'դուրս', 'բերել', 'իր', 'ներքին', 'եսը', ',', 'ոչ', 'այլ', 'ինչ', ',', 'քան', 'իր', 'ներքին', 'եսը', ',', 'որը', 'համարում', 'էր', 'ավելի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "2510\n",
            "2520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'փոքրիկ', ',', 'կծկված', ',', 'կուզ', 'հիշեցնող', 'ուղեպայուսակը', 'մեջ', '`', 'քին', 'գցած', ',', 'թիկունքից', 'նա', 'ծերունու', 'տեսք', 'ուներ', ':', 'Գետի', '`', 'այ', 'կողմում', '՝', 'Պառլամենտի', 'շենքի', 'մոտ', ',', 'որտեղ', 'նրբանցքը', 'շրջադարճ', 'էր', 'կատարում', ',', 'Բալդինին', 'նրան', 'կորցրեց', 'տեսադաշտից', 'ն', 'չափազանց', 'մեծ', 'թեթնություն', 'զգաց', ':', 'Նա', 'երբեք', 'տանել', 'չէր', 'կարող', 'այդ', 'տղային', ',', 'երբեք', ',', 'ն', 'այժմարդեն', ',', 'ի', 'վերջո', ',', 'ի', 'վիճակի', 'էր', 'խոստովանել', 'դա', 'ինքն', 'իրեն', ':', 'Այդ', 'ամբողջ', 'Ժամանակ', ',', 'ինչ', 'օթնան', 'էր', 'տվել', 'Գրենույին', 'իր', 'տանիքի', 'տակ', 'ն', 'ուզածի', 'պես', 'քամում', 'էր', 'նրան', ',', 'նա', 'իր', 'հոգում', 'երբեք', 'իրեն', 'լավ', 'չի', 'զգացել', ':', 'Նա', 'զգում', 'էր', 'իրեն', 'որպես', 'անթերի', 'բարոյականություն', 'ունեցող', 'մարդ', ',', 'ով', 'առաջին', 'անգամ', 'ինչ', '-', 'որ', 'արգելված', 'բան', 'է', 'անում', ',', 'խաղում', 'ինչ', '-', 'որ', 'խաղ', 'անթույլատրելի', 'միջոցներով', ':', 'Իհարկե', ',', 'մերկացման', 'վտանգը', 'չնչին', 'էր', ',', 'իսկ', 'հաջողության', 'հասնելու', 'հնարավորությունները', 'հսկայական', ',', 'բայց', 'Ննույնչափ', 'մեծ', 'էր', 'նան', 'նյարդայնությունն', 'ու', 'խղճի', 'խայթը', ':', 'Եվ', 'իրոք', ',', 'այդ', 'բոլոր', 'տարիների', 'ընթացքում', 'չէր', 'լիսում', 'մի', 'օր', ',', 'որ', 'նրան', 'չհետապնդեր', 'այն', 'տհաճ', 'միտքը', ',', 'որ', 'ինչ', '-', 'որ', 'ձնով', 'ստիպված', 'կլինի', 'վճարել', 'այն', 'բանի', 'համար', ',', 'որ', 'կապվել', 'է', 'այդ', 'մարդու', 'հետ', ':', '«', 'Միայն', 'թե', 'այս', 'ամենը', 'լավ', 'ավարտվի', ',', '-', 'մշտապես', 'վախվորած', 'աղոթում', 'էր', 'նա', ':', '-', 'Միայն', 'թե', 'ինձ', 'հաջողվեր', 'օգտվել', 'այդ', 'համարձակ', 'բախտափորձությունից', 'չվճարելով', 'դրա', 'օգուտի', 'դիմաց', 'անհավասարազոր', 'տոկոսներով', ':', 'Միայն', 'թե', 'հաջողվեր', ':', 'Ընդհանուր', 'առմամբ', 'ես', 'վատ', 'քայլ', 'եմ', 'կատարում', ',', 'բայց', 'Տերը', 'դրա', 'վրա', 'աչք', 'կփակի', ',', 'համոզված', 'եմ', ':', 'Իմ', 'ողջ', 'կյանքի', 'ընթացքում', 'Նա', 'բավականին', 'հաճախ', 'է', 'ինձ', 'խիստ', 'պատժել', 'առանց', 'որնէ', 'առիթի', ',', 'այնպես', 'որ', ',', 'միայն', 'արդարացի', 'կլինի', ',', 'եթե', 'այս', 'անգամ', 'Նա', 'ներողամտություն', 'ցուցաբերի', ':', 'Եվ', 'որն', '՛', 'է', 'իմ', 'մեղքը', ',', 'եթե', 'դա', 'ընդհանրապես', 'մեղք', 'է', ':', 'Ամենաշատը', 'այն', ',', 'որ', 'որոշ', 'չափով', 'խախտել', 'եմ', 'արտադրամասի', 'կանոնադրությունը', ',', 'շահագործել', 'եմ', 'ինչ', '-', 'որ', 'մի', 'տգետի']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բ', 'հրաշալի', 'տաղանդը', 'ն', 'ներկայացրել', 'նրա', 'ընդունակու', '`', 'թյունները', 'որպես', 'իմ', 'սեփականը', ':', 'Ամենաշատը', 'այն', ',', 'որ', 'թեթնակի', 'շեղվել', 'եմ', 'ավանդական', 'արհեստավորական', 'ա', 'սքինության', 'ուղուց', ':', 'Ամենաշատը', 'նրանում', ',', 'որ', 'այսօր', 'անումեմ', 'ար', ',', 'ինչը', 'դեռ', 'երեկ', 'անիծում', 'էի', ':', 'Միթե', '՛', 'դա', \"հան'\", 'ծություն', 'է', ':', 'Ուրիշները', 'խաբում', 'են', 'ողջ', 'կյանքում', ':', '|', 'Իսկ', 'ես', 'ընդամենը', 'մի', 'քանի', 'տարի', 'մի', 'քիչ', 'խարդախուԼԷ', 'րեցի', ':', 'Եվ', 'այն', 'էլ', 'ան', 'պատճառով', ',', 'որ', 'նման', 'անՀաա', 'հնարավորություն', 'ընճեռվեց', ':', 'Միգուցե', 'հնարավո', '`', 'րություն', 'էլ', 'չի', 'ընձեռվել', ',', 'միգուցե', 'անձամբ', 'Տերն', 'է', 'իմ', 'տուն', '`', 'ուղարկել', 'այդ', 'կախարդին', ',', 'որպեսզի', 'ինձ', 'պարգնատրի', 'աստացումների', 'համար', ',', 'որոնք', 'կրել', 'եմ', 'Պելիսյեից', 'ու', '|', 'հրա', 'հանցակից', 'ընկերներից', ':', 'Միգուցե', 'Աստծու', 'պատիժը', '`', 'սպասում', 'է', 'ամեննին', 'էլ', 'ոչ', 'ինձ', ',', 'այլ', 'Պելիսյեին', ':', 'Դա', 'շատ', 'ու', 'շատ', 'հնարավոր', 'է', ':', 'Իսկ', 'էլ', '՞', 'ինչով', 'Տերը', 'կկարողանար', 'պատժել', 'Պելիսյեին', ',', 'եթե', 'ոչ', 'իմ', 'վերելքով', ':', 'Հետնաբար', ',', 'իմ', 'երջանկությունը', 'Աստծու', 'ձեռքի', 'գործն', 'էր', ',', 'ն', 'ես', 'ոչ', 'միայն', ':', ':', 'իրավունք', 'ունեի', ',', 'այլն', 'պարտավոր', 'էի', 'այն', 'ընդունել', 'որԼ', 'պ', 'յս', 'այդպիսին', '՝', 'առանց', 'ամոթի', 'ու', 'զղջումի', '...', '»', ':', '`', 'Այդպես', 'էր', 'հաճախ', 'մտածում', 'Բալդինին', 'անցած', 'տա']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2530\n",
            "2540\n",
            "2550\n",
            "2560\n",
            "2570\n",
            "2580\n",
            "2590\n",
            "2600\n",
            "2610\n",
            "2620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրենուն', 'այդ', 'գյուղական', 'պարզությունն', 'ընկալում', 'էր', 'որպես', 'փրկություն', ':', 'Այդ', 'անխռով', 'բուրմունքները', 'շոյում', 'էին', 'նրա', 'հոտառությունը', ':', 'Առաջին', 'անգամ', 'նա', 'պարտավոր', 'չէր', 'հետնել', 'իր', 'յուրաքանչյուր', 'ներշնչմանը', ',', 'որպեսզի', 'չառնի', 'ինչ', '-', 'որ', 'նոր', ',', 'անսպասելի', ',', 'թշնամական', 'հոտ', 'կամ', 'բաց', 'չթողնի', 'ինչ', '-', 'որ', 'հաճելին', ':', 'Առաջին', 'անգամ', 'նա', 'կարող', 'էր', 'գրեթե', 'ազատ', 'շնչել', 'ն', 'ստիպված', 'չէր', 'մշտապես', 'տագնապահույզ', 'հոտոտել', ':', 'Գրեթե', '՝', 'ասացինք', 'մենք', ',', 'քանզի', 'իրականում', 'հենց', 'այնպես', 'ոչինչ', ',', 'իհարկե', ',', 'չէր', 'թափանցում', 'Գրենույի', 'քթի', 'միջով', ':', 'Նույնիսկ', 'եթենա', '՞', 'դրա', 'համար', 'չուներ', 'փոքրագույն', 'առիթ', ',', 'նրա', 'մեջ', 'մշտապես', 'արթուն', 'էր', 'պահուստային', 'բնազդային', 'զգացումն', 'այն', 'ամենի', 'հանդեպ', ',', 'ինչը', 'գալիս', 'էր', 'դրսից', ',', 'Ա', 'ինչը', 'նա', 'ստիպված', 'էր', 'լինում', 'ներս', 'թողնել', 'իր', 'մեջ', ':', 'Իր', 'ողջ', 'կյանքում', '՝', 'նույնիսկ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2630\n",
            "2640\n",
            "2650\n",
            "2660\n",
            "2670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['կողմից', 'մոռացված', 'այս', 'անապատը', 'թվում', 'էր', 'մի', 'ինչ', '-', 'որ', 'անդրշիրիմյան', 'վայր', ':', 'Նույնիսկ', 'ողջ', 'երկրով', 'մեկ', 'որոնվող', 'ավազակ', 'Լեբրունը', 'գերադասեց', 'հասնել', 'Սեվեննա', ',', 'որտեղ', 'նրան', 'բռնեցին', 'ու', 'քառատեցին', ',', 'քան', 'թաքնվել', '<UNK>լոմդյյու', '՛', 'Կանտալում', ',', 'որտեղ', 'նրան', ',', 'ճիշտ', 'է', ',', 'ոչ', 'ոք', 'չէր', 'գտնի', ',', 'բայց', 'որտեղ', 'նրան', 'սպասվում', 'էր', 'ցմահ', 'միայնակության', 'անխուսափելի', 'մահը', ',', 'իսկ', 'դա', 'նրան', 'թվում', 'էր', 'էլ', 'ավելի', 'սարսափելի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2680\n",
            "2690\n",
            "2700\n",
            "2710\n",
            "2720\n",
            "2730\n",
            "2740\n",
            "2750\n",
            "2760\n",
            "2770\n",
            "2780\n",
            "2790\n",
            "2800\n",
            "2810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'երբ', 'մեր', 'թանկագին', 'Ժան', '-', 'Բատիստը', ',', 'որն', 'ի', 'վերջո', 'վերադարձել', 'էր', 'իր', 'մոտ', ',', 'պառկեց', 'ծիրանագույն', 'սրահում', '՝', 'իր', 'հարմարավետ', 'բազմոցի', 'վրա', ',', 'եթե', 'կուզեք', ',', 'ի', 'վերջո', 'հանեց', 'ճտքակոշիկները', ',', 'ծափ', 'տվեց', 'ու', 'իր', 'մոտ', 'կանչեց', 'ծառաներին', ',', 'որոնք', 'անտեսանելի', 'էին', ',', 'անշոշափելի', ',', 'անլսելի', 'ու', 'հոտառությամբ', 'անորսալի', ',', 'այսինքն', '՝', 'ամբողջապես', 'երնակայական', 'ծառաներին', ',', 'ն', 'նրանց', 'ուղարկեց', 'պահեստանոց', ',', 'որպեսզի', 'հոտերի', 'մեծ', 'գրադարանից', 'իրեն', 'բերեն', 'այս', 'կամ', 'այն', 'հատորը', ',', 'ու', 'հրամայեց', 'նրանց', 'իջնել', 'նկուղ', ',', 'որպեսզի', 'իրեն', 'խմիչք', 'բերեն', ':', 'Երնակայական', 'ծառաները', 'շտապում', 'էին', 'կատարել', 'կարգադրությունը', ',', 'ն', 'Գրենույի', 'ստամոքսը', 'սեղմվում', 'էր', 'տանջալի', 'սպասման', 'ջղաճգությունից', ':', 'Նա', 'անսպասելիորեն', 'ունենում', 'էր', 'վաճառասեղանի', 'առջն', 'կանգնած', 'հարբեցողի', 'զգացում', ',', 'որին', 'տիրում', 'էր', 'սարսափը', ',', 'որ', 'ինչ', '-', 'որ', 'անհայտ', 'պատճառներով', 'նրան', 'կհրաժարվեն', 'մատուցել', 'պատվիրած', 'օղին', ':', 'Իսկ', 'միգուցե', 'նկուղներն', 'ու', 'պահեստները', 'միանգամից', 'դատարկվել', '՛', 'էին', ':', 'Միգուցե', 'տակառների', 'գինին', 'ցնդել', '՛', 'էր', ':', 'Ինչու', 'իրեն', 'ստիպեցին', 'սպասել', ':', 'Ինչու', 'չեն', 'գալիս', ':', 'Դեղանյութը', 'նրան', 'հիմա', 'էր', 'պահանջվում', ',', 'անմիջապես', ',', 'նա', 'ծարավից', 'մահանում', 'է', ',', 'նա', 'կմեռնի', 'տեղում', ',', 'եթե', 'այն', 'չստանա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2820\n",
            "2830\n",
            "2840\n",
            "2850\n",
            "2860\n",
            "2870\n",
            "2880\n",
            "2890\n",
            "2900\n",
            "2910\n",
            "2920\n",
            "2930\n",
            "2940\n",
            "2950\n",
            "2960\n",
            "2970\n",
            "2980\n",
            "2990\n",
            "3000\n",
            "3010\n",
            "3020\n",
            "3030\n",
            "3040\n",
            "3050\n",
            "3060\n",
            "3070\n",
            "3080\n",
            "3090\n",
            "3100\n",
            "3110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Պարոն', ',', '-', 'ի', 'վերջո', 'սկսեց', 'նա', ',', '-', 'ես', 'հիացած', 'եմ', 'ինքս', 'ինձնով', ':', 'Ես', 'ցնցված', 'եմ', 'իմ', 'հանճարեղությամբ', ',', 'բնականաբար', ',', 'երբեք', 'չեմ', 'կասկածել', 'հողի', 'գազի', 'տեսության', 'ճշմարտացիության', 'մեջ', ',', 'իհարկե', ',', 'ոչ', ',', 'բայց', 'այն', 'հանգամանքը', ',', 'որ', 'գործնական', 'թերապիայում', 'այն', 'նման', 'փայլուն', 'հաստատում', 'է', 'ստանում', ',', 'ապշեցնում', 'է', 'ինճ', ':', 'Դուք', 'կենդանի', 'էիք', ',', 'իսկ', 'ես', 'ճեզ', 'մարդ', 'դարձրի', ':', 'հա', '՛', 'ուղղակի', 'աստվածային', 'արարմունք', 'է', ':', 'Թույլ', 'տվեց', 'ինճ', 'շոյված', 'զգալ', ':', 'Մոտեցեք', 'ահա', 'այն', 'հայելուն', 'ն', 'նայեք', 'ձեզ', ':', 'Դուք', 'կյանքում', 'առաջին', 'անգամ', 'եք', 'իմանում', ',', 'որ', 'մարդ', 'եք', ',', 'չէի', 'ասի', 'առանձնահատուկ', 'կամ', 'եզակի', 'ն', 'կամ', 'ինչ', '-', 'որ', 'հատկանիշով', 'նշանավոր', ',', 'բայց', 'ն', '.', 'այնպես', ',', 'լիովին', 'նորմալ', 'մարդ', ':', 'Դե', ',', 'վերջապես', 'մոտեցեք', 'հայելուն', ',', 'պարոն', ':', 'Նայեք', 'ձեզ', 'ու', 'զմայլվեք', 'հրաշքով', ',', 'որն', 'ինքս', 'եմ', 'արարել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'Ամենից', 'առավել', 'Գրենույին', 'ապշեցրեց', 'այն', 'փաստը', ',', 'որ', 'ինքն', 'անհավանական', 'նորմալ', 'տեսք', 'ուներ', ':', 'Մարկիզը', 'ժիշտ', 'էր', '.', 'նրա', 'մեջ', 'առանձնահատուկ', 'ոչինչ', 'չկար', '.', 'լավ', 'արտաքին', 'չուներ', ',', 'բաց', 'նան', 'շատ', 'այլանդակ', 'էլ', 'չէր', ':', 'Նա', 'հասակով', 'ցածր', 'էր', ',', 'փոքր', '-', 'ինչ', 'կողը', 'ծուռ', ',', 'ոչ', 'արտահա', 'յտիչ', 'դեմքով', '.', 'կարճ', 'ասած', '՝', 'նա', 'ուներ', 'այնպիսի', 'տեսք', ',', 'ինչպես', 'հազարավոր', 'այլ', 'մարդիկ', ':', 'Եթենա', '՛', 'այժմ', 'քայլի', 'փողոցով', ',', 'նրա', 'ետնից', 'ոչ', 'մեկը', 'չի', 'շրջվի', ':', '`', 'Նա', 'ինքը', 'նս', 'ուշադրություն', 'չէր', 'դարձնի', 'նմանի', 'վրա', ',', 'որպիսին', 'դարձել', 'էր', 'այժմ', ',', 'եթե', 'վերջինս', 'հանդիպեր', 'նրա', 'ճանապարհին', ':', '(', 'Թերնս', 'միայն', 'այն', 'դեպքում', ',', 'եթե', 'հոտառությամբ', 'զգար', ',', 'որ', 'այդ', 'հանդիպածը', 'չունի', 'մանուշակներից', 'բացի', 'որնէ', 'այլ', 'հոտ', ',', 'իսչպես', 'հայելու', 'միջի', 'պարոնը', 'ն', 'ինչպես', 'ինքն', 'անձամբ', ',', 'որ', 'կանգնած', 'է', 'հայելու', 'առջն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3130\n",
            "3140\n",
            "3150\n",
            "3160\n",
            "3170\n",
            "3180\n",
            "3190\n",
            "3200\n",
            "3210\n",
            "3220\n",
            "3230\n",
            "3240\n",
            "3250\n",
            "3260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բ', 'Այդ', 'մարդկային', 'հոտի', 'նմանակման', 'համար', ',', 'թող', 'որ', '`', 'այ', 'չէր', 'բավարարում', 'նրան', ',', 'բայց', 'լիովին', 'բավարար', 'էր', ',', 'որպեսզի', 'խաբի', 'ուրիշներին', ',', 'Գրենույն', 'ընտրեց', 'Ռունելի', 'արհեստանոցի', 'ամենաաննկատ', 'բաղադրամասերը', ':', 'Մ', '`', 'Միբուռ', 'կատվի', 'կեղտ', '՝', 'դեռես', 'բավականին', 'թարմ', ',', 'նա', '`', 'գտավ', 'դեպի', 'բակ', 'տանող', 'դռան', 'շեմից', 'դուրս', ':', 'Նա', 'դրանից', 'վերցրեց', 'կես', 'գդալ', 'ու', 'դրեց', 'խառնիչի', 'մեջ', 'մի', 'քանի', 'կաթիլ', 'քացախի', 'ու', 'մանր', 'աղի', 'հետ', 'մեկտեղ', ':', 'Սեղանի', 'տակկնա', '՛', 'հայտնաբերեց', 'ձեռքի', 'բութ', 'մատի', 'չափ', 'մի', 'կտոր', 'պանիր', ',', 'որն', 'ակնհայտորեն', 'մնացել', 'էր', 'Ռունելի', 'ինչ', '-', 'որ', 'մի', 'հացկերույթից', ':', 'Պանիրն', 'արդեն', 'բավականաչափ', 'հին', 'էր', ',', 'սկսել', 'էր', 'քայքայվել', 'ու', 'ներթափանց', 'ծակող', 'սուր', 'հոտ', 'ուներ', ':', 'Սարդինաներով', 'տակառիկի', 'կափարիչի', 'վրայից', ',', 'որը', 'դրված', 'էր', 'կրպակի', 'հետնամասում', ',', 'նա', 'քերեց', 'ճկան', 'փորոտիքի', 'հոտ', 'ունեցող', 'ինչ', '-', 'որ', 'մնացուկ', ',', 'այն', 'խառնեց', 'հոտած', 'ձվի', 'ու', 'կուղբի', 'շիթի', ',', 'անուշադրի', ',', 'մշկընկույզի', ',', 'եղջյուրի', 'տաշեղների', 'ու', 'թեթն', 'այրված', 'խոզի', 'կաշվի', 'հետ', ':', 'Դրան', 'ավելացրեց', 'բավական', 'մեծ', 'քանակության', 'մուշկի', 'հոտ', ',', 'այդ', 'սարսափելի', 'համեմունքները', 'ջրիկացրեց', 'սպիրտով', ',', 'թողեց', ',', 'որ', 'թրմվի', 'ու', 'զտելով', 'քամեց', 'երկրորդ', 'շշի', 'մեջ', ':', 'Խառնուրդի', 'հոտը', 'սարսափելի', 'էր', ':', 'Այն', 'կոյուղաջրի', ',', 'տարրալուծվածքի', ',', 'նեխվածքի', 'գարշահոտ', 'էր', 'արձակում', ',', 'իսկ', 'երբ', 'հովհարի', 'թափահարումն', 'այս', 'գոլորշացմանը', 'մաքուր', 'օդ', 'էր', 'խառնում', ',', 'տպավորություն', 'էր', 'ստեղծվում', ',', 'որ', 'դութ', 'ամառային', 'տաք', 'օրին', 'կանգնած', 'եք', 'Փարիզում', ',', 'Օ', \"'Ֆեր\", 'ու', 'Լենժեր', 'փողոցների', 'խածմերուկում', ',', 'որտեղ', 'միանում', 'էին', 'ձկնաշարքերի', ',', 'Անմեղների', 'գերեզմանատան', 'ու', 'իրար', 'գլխի', 'լցված', 'տների', 'հոտերը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3270\n",
            "3280\n",
            "3290\n",
            "3300\n",
            "3310\n",
            "3320\n",
            "3330\n",
            "3340\n",
            "3350\n",
            "3360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'մարդկանց', ',', 'ձգտում', 'էր', 'որքան', 'հնարավոր', 'է', 'մոտ', 'հեռավորությամբ', 'անցնել', 'նրանց', 'կողքով', ',', 'անցնում', 'էր', 'ձեռքը', 'լայն', 'թափ', 'տալով', 'ու', 'պատահաբար', 'դիպչում', 'անցորդի', 'ձեռքին', ':', 'Մի', 'անգամ', 'նա', 'պատահաբար', 'հրեց', 'մի', 'տղամարդու', ',', 'որին', 'ցանկանում', 'էր', 'անցնել', ':', 'Նա', 'կանգ', 'առավ', ',', 'սերողություն', 'խնդրեց', ',', 'ն', 'մարդը', ',', 'որը', 'դեռնս', 'երեկ', 'Գրենույի', 'անսպասելի', 'հայտնվելու', 'դեպքում', 'ամպրոպից', 'խոցվածի', 'պես', 'կանգ', 'կառներ', ',', 'ճնացրեց', ',', 'թե', 'ոչինչ', 'տեղի', 'չի', 'ունեցել', ',', 'ընդունեց', 'ներողությունը', ',', 'նույնիսկ', 'թեթնակի', 'ժպտաց', 'ն', 'ճեռքով', 'թեթնակի', 'խփեց', 'Գրենույի', 'ուսին', ':', 'Նա', 'դուրս', 'եկավ', 'նրբանցքներից', 'ու', 'մտավ', 'Սուրբ', 'Պետրոսի', 'տաճարի', 'դիմացի', 'հրապարակը', ':', 'Զանգերը', 'ղողանջում', 'էին', ':', 'Գլխավոր', 'մուտքի', 'երկու', 'կողմերում', 'խմբվում', 'էին', 'մարդիկ', ':', 'Հենց', 'նոր', 'ավարտվել', 'էր', 'պսակադրության', 'արարողությունը', ':', 'Բոլորը', 'ցանկանում', 'էին', 'տեսնել', 'հարսնացուին', ':', 'Գրենույը', 'վազեց', 'այնտեղ', 'ու', 'խառնվեց', 'ամբոխին', ':', 'Նա', 'հրմշտելով', 'մխրճվում', 'էր', 'մարդկային', 'զանգվածի', 'մեջ', 'հավաքվածների', 'ամենախիտ', 'հատվածը', '.', 'թող', 'նրանք', 'կիպ', 'կանգնեն', 'իր', 'շուրջբոլորը', ',', 'թող', 'ներծծվեն', 'իր', 'սեփական', 'հոտով', ':', 'Եվնա', '՛', ',', 'ձեռքերով', 'հրմշտելով', ',', 'ճանապարհ', 'էր', 'բացում', 'ճնշող', 'նեղվածքի', 'միջով', ',', 'ու', 'ավելի', 'լայն', 'էր', 'դնում', 'ոտքերը', '.', 'պատռեց', 'վերնաշապիկի', 'օձիքը', ',', 'որպեսզի', 'հոտը', 'կարողանա', 'անարգել', 'դուրս', 'հոսել', 'իր', 'մարմնից', ':', 'Եվ', 'նրա', 'ուրախությունն', 'անսահման', 'էր', ',', 'երբ', 'նկատեց', ',', 'որ', 'ուրիշները', 'ոչինչ', 'չնկատեցին', ',', 'բացարճակապես', 'ոչինչ', ',', 'որ', 'բոլոր', 'այս', 'տղամարդիկ', ',', 'ու', 'կանայք', ',', 'ու', 'երեխաները', ',', 'ովքեր', 'կանգնած', 'էին', 'կիպ', 'նրա', 'շուրջը', ',', 'այդքան', 'դյուրությամբ', 'թույլ', 'տվեցին', 'իրենց', 'խաբել', 'ու', 'շնչում', 'էին', 'նրա', 'գարշահոտը', ',', 'որը', 'պատրաստված', 'էր', 'կատվի', 'կեղտից', ',', 'պանրից', 'ու', 'քացախից', ',', 'ինչպես', 'իրենց', 'նմանների', 'հոտը', ',', 'իսկ', 'նրան', '՝', 'Գրենույին', '՝', 'ընկեցիկին', 'ու', 'ապօրինի', 'վիժվածքին', ',', 'ընդունում', 'էին', 'իրենց', 'միջավայրում', 'որպես', 'հավասարի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3370\n",
            "3380\n",
            "3390\n",
            "3400\n",
            "3410\n",
            "3420\n",
            "3430\n",
            "3440\n",
            "3450\n",
            "3460\n",
            "3470\n",
            "3480\n",
            "3490\n",
            "3500\n",
            "3510\n",
            "3520\n",
            "3530\n",
            "3540\n",
            "3550\n",
            "3560\n",
            "3570\n",
            "3580\n",
            "3590\n",
            "3600\n",
            "3610\n",
            "3620\n",
            "3630\n",
            "3640\n",
            "3650\n",
            "3660\n",
            "3670\n",
            "3680\n",
            "3690\n",
            "3700\n",
            "3710\n",
            "3720\n",
            "3730\n",
            "3740\n",
            "3750\n",
            "3760\n",
            "3770\n",
            "3780\n",
            "3790\n",
            "3800\n",
            "3810\n",
            "3820\n",
            "3830\n",
            "3840\n",
            "3850\n",
            "3860\n",
            "3870\n",
            "3880\n",
            "3890\n",
            "3900\n",
            "3910\n",
            "3920\n",
            "3930\n",
            "3940\n",
            "3950\n",
            "3960\n",
            "3970\n",
            "3980\n",
            "3990\n",
            "4000\n",
            "4010\n",
            "4020\n",
            "4030\n",
            "4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ախ', '՛', ':', 'Նա', 'ուզում', 'էր', 'տիրանալ', 'այդ', 'բուրմունքին', ':', 'Տիրանալ', 'ոչ', 'այնքան', 'խենթորեն', ',', 'ինչպես', 'այն', 'ժամանակ', 'Մարե', 'փողոցի', 'վրա', ':', 'Նա', 'ուղղակի', 'խմեց', 'այն', 'աղջկա', 'հոտը', ',', 'լցրեց', 'իր', 'մեջ', 'ու', 'դրանով', 'էլ', 'կործանեց', ':', 'Ոչ', ',', 'պատից', 'այն', 'կողմ', 'գտնվող', 'աղջկա', 'բուրմունքը', 'ցանկանում', 'էր', 'իրապես', 'յուրացնել', '.', 'հանել', 'նրա', 'վրայից', ',', 'ինչպես', 'մաշկը', ',', 'ն', 'դարձնել', 'իր', 'սեփականությունը', ':', 'Նա', 'չգիտեր', ',', 'թե', 'դա', 'ինչպես', 'պետք', 'է', 'տեղի', 'ունենա', ':', 'Բայց', 'առջնում', 'ուներ', 'երկու', 'տարի', ',', 'որպեսզի', 'սովորեր', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4050\n",
            "4060\n",
            "4070\n",
            "4080\n",
            "4090\n",
            "4100\n",
            "4110\n",
            "4120\n",
            "4130\n",
            "4140\n",
            "4150\n",
            "4160\n",
            "4170\n",
            "4180\n",
            "4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ապրիլին', 'նրանք', 'փափկեցնում', 'էին', 'բեկտենու', 'հատապտուղն', 'ու', 'նարնջի', 'ծաղիկները', ',', 'մայիսին', '՝', 'ծովի', 'չափ', 'վարդ', ',', 'որի', 'բուրմունքը', 'մի', 'ողջ', 'ամիս', 'քաղաքը', 'խորասուզում', 'էր', 'անտեսանելի', ',', 'սերուցքի', 'պես', 'քաղցր', 'մշուշի', 'մեջ', ':', 'Գրենույը', 'ճիու', 'պես', 'էր', 'աշխատում', ':', 'Համեստ', ',', 'գրեթե', 'ստրուկի', 'պատրաստակամությամբ', 'նա', 'կատարում', 'էր', 'բոլոր', 'օժանդակ', 'գործառնությունները', ',', 'որոնք', 'նրան', 'հանձնարարում', 'էր', 'Դրյուոն', ':', 'Բայց', 'մինչ', 'նա', ',', 'թվում', 'էր', ',', 'մտազուրկ', 'խառնում', 'ու', 'կուտակում', 'էր', 'ծաղիկները', ',', 'լվանում', 'շշերը', ',', 'ավլում', 'արհեստանոցը', 'կամ', 'ցախ', 'կրում', ',', 'նրա', 'աչքից', 'չէր', 'վրիպում', 'արհեստի', 'Էական', 'կողմերից', 'ն', 'ոչ', 'մեկը', ',', 'բուրմունքների', 'կերպարանափոխություններից', 'ոչ', 'մեկը', ':', 'Ավելի', 'ճշտապահորեն', ',', 'քան', 'երբնիցե', 'կարող', 'էր', 'անել', 'Դրյուոն', ',', 'Գրենույը', ',', 'շնորհիվ', 'իր', 'քթի', ',', 'ուղեկցում', 'ու', 'պահպանում', 'էր', 'բուրմունքների', 'տեղաշարժը', 'սկսած', 'ծաղկային', 'ծաղկաթերթիկներից', 'Ճարպի', 'ու', 'սպիրտի', 'միջով', '.', 'անցկացնելուց', ',', 'վերջացրած', 'թանկարժեք', 'փոքրիկ', 'սրվակների', 'մեջ', 'լցնելը', ':', 'Նա', 'շատ', 'ավելի', 'վաղ', ',', 'քան', 'նկատում', 'էր', 'Դրյուոն', ',', 'հոտառությամբ', 'զգում', 'էր', 'երբ', 'է', 'ճարպը', 'սկսում', 'չափից', 'դուրս', 'տաքանալ', ',', 'երբ', 'է', 'ծաղկային', 'զանգվածը', 'կորցնում', 'իր', 'որակը', ',', 'երբ', 'է', 'եփուկը', 'հագենում', 'բուրմունքով', ',', 'թե', 'ինչ', 'էր', 'տեղի', 'ունենում', 'խառնինչեի', '՛', 'ներսում', 'ն', 'կոնկրետ', 'որ', 'պահին', 'պետք', 'է', 'դադարեր', 'թորման', 'գործընթացը', ':', 'Եվ', 'ամեն', 'անգամ', ',', 'բնականաբար', ',', 'հասկանալ', 'էր', 'տալիս', '՝', 'կարծես', 'պատահաբար', 'է', 'ստացվում', ',', 'ն', 'անում', 'էր', 'դա', '՝', 'հաճկատարության', 'դիմակը', 'չհանելով', ':', 'Իրեն', 'թվում', 'է', ',', 'ասում', 'էր', 'նա', ',', 'որ', 'այժմ', 'ճարպը', ',', 'հավանաբար', ',', 'շատ', 'Ե']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4200\n",
            "4210\n",
            "4220\n",
            "4230\n",
            "4240\n",
            "4250\n",
            "4260\n",
            "4270\n",
            "4280\n",
            "4290\n",
            "4300\n",
            "4310\n",
            "4320\n",
            "4330\n",
            "4340\n",
            "4350\n",
            "4360\n",
            "4370\n",
            "4380\n",
            "4390\n",
            "4400\n",
            "4410\n",
            "4420\n",
            "4430\n",
            "4440\n",
            "4450\n",
            "4460\n",
            "4470\n",
            "4480\n",
            "4490\n",
            "4500\n",
            "4510\n",
            "4520\n",
            "4530\n",
            "4540\n",
            "4550\n",
            "4560\n",
            "4570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'սիրում', 'էր', 'բուրմունքը', ':', 'Միայն', 'դա', ',', 'ուրիշ', 'ոչինչ', ',', 'ն', 'սիրում', 'էր', 'որպես', 'ապագայի', 'իր', 'սեփական', 'բուրմունք', ':', 'Մեկ', 'տարի', 'անց', 'կտիրանա', 'դրան', ',', 'նա', 'երդվել', 'է', 'սեփական', 'կյանքով', ':', 'Եվ', 'այդ', 'ինքնատիպ', 'երդումը', 'տալով', 'կամ', 'այդ', 'նշանադրությունը', 'կնքելով', ',', 'երդվելով', 'պահպանել', 'հավատարմությունն', 'իր', 'ապագա', 'բուրմունքի', 'հանդեպ', '/', 'նա', 'ուրախ', 'տրամադրությամբ', 'լքեց', 'երդման', 'վայրն', 'ու', 'Դյու', '-', 'Կուր', 'պահակամուտքով', 'վերադարձավ', 'քաղաք', ':', 'Գիշերն', 'իր', 'խրճիթի', 'մեջ', 'պառկած', '՝', 'նա', 'հիշողության', 'մեջ', 'Աս', 'մեկ', 'անգամ', 'դուրս', 'բերեց', 'աղջկա', 'բուրմունքը', ',', 'չկարողացավ', 'դիմակայել', 'գայթակղությանը', 'ն', '.', 'խորասուզվեց', 'դրա', 'մեջ', ',', 'նա', 'շոյում', 'էր', 'նրան', 'ու', 'թույլ', 'տալիս', ',', 'որ', 'շոյի', 'իրեն', ',', 'նրան', 'զգում', 'էր', 'չափազանց', 'մոտ', '՝', 'կողքին', ',', 'այնքան', 'մոտ', ',', 'այնքան', 'երանելի', 'մոտ', ',', 'կարծես', 'արդեն', 'տիրացել', 'էր', 'նրան', 'իր', 'բուրմունքին', ',', 'իր', 'սեփական', 'բուրմունքին', ',', 'ն', 'քանի', 'դեռ', 'ընթանում', 'էր', 'արբեցման', 'այդ', 'հրաշալի', 'ակնթարթը', ',', 'նա', 'դրան', 'սիրում', 'էր', 'իր', 'մեջ', 'ն', 'իրեն', '՝', 'շնորհիվ', 'դրա', ':', '`', 'Նա', 'ցանկանում', 'էր', 'քնել', 'սիրահարվածության', 'այդ', 'զգացումով', ':', 'Իայց', 'հենց', 'այն', 'պահին', ',', 'երբ', 'փակեց', 'աչքերը', ',', 'ն', 'նրան', 'մնում', 'էր', 'ընդամենը', 'մեկ', 'անգամ', 'ներշնչել', ',', 'որպեսզի', 'ընկղմվեր', 'երազի', 'մեջ', ',', 'բուրմունքը', 'նրան', 'լքեց', ',', 'հանկարծ', 'անհետացավ', ',', 'ննրա', 'տեղը', 'լցվեց', 'այծի', 'փարախի', 'սառը', 'հոտով', ':', 'Գրենույր', 'սարսափեց', ':', '«', 'Իսկ', 'եթե', ',', '-', 'մտածեց', 'նա', ',', '-', 'իսկ', 'եթե', 'այդ', 'բուրմունքը', ',', 'որին', 'տիրում', 'եմ', ',', 'վերջանա', '՞', ':', 'Չէ', '\"', 'որ', 'դա', 'այնպես', 'չէ', ',', 'ինչպես', 'հիշողություններում', ',', 'որտեղ', 'բոլոր', 'հոտերն', 'անանցողիկ', 'են', ':', 'Իրականում', 'հոտը', ',', 'շփվելով', 'աշխարհի', 'հետ', ',', 'մաշվում', 'է', ':', 'Այն', 'եթերային', 'է', ':', 'Եվ', 'երբ', 'մաշվի', ',', 'այլես', 'չի', 'լինի', 'ակունքը', ',', 'որտեղից', 'վերցրել', 'եմ', 'այն', ':', 'Եվ', 'ես', 'կմնամ', 'մերկ', ',', 'ինչպես', 'նախկինում', ',', 'Ա', 'ստիպված', 'կլինեմ', 'կրկին', 'ինճ', 'օգնել', 'փոխարինող', 'նյութերով', ':', 'Ոչ', ',', 'կլինի', 'ավելի', 'վատ', ',', 'քան', 'նախկինում', ':', 'չէ', '՞', 'որ', 'արդեն', 'ճանաչում', 'ու', 'տիրում', 'եմ', 'նրան', '՝', 'իմ', 'սեփական', 'արքայական', 'բուրմունքին', ',', 'ն']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այդ', 'միտքը', 'չափազանց', 'տհաճ', 'էր', ':', 'Գրենույն', 'անչափ', 'վախեցավ', ',', 'որ', 'տիրելով', 'բուրմունքին', ',', 'որին', 'դեռ', 'չէր', 'տիրագել', ',', 'անխուսափելիորեն', 'այն', 'կրկին', 'կկորցնի', ':', 'որքան', '՞', 'երկար', 'կկարողանա', 'այն', 'պահել', ':', 'Մի', 'քանի', 'օր', '՛', ':', 'Մի', 'քանի', 'շաբաթ', '՛', ':', 'Միգուցե', 'ողջ', 'ամիս', ',', 'եթե', 'շատ', 'խնայողաբար', 'օծվի', ':', 'Իսկ', 'հետո', '՞', 'Նա', 'արդեն', 'տեսնում', 'էր', ',', 'թե', 'ինչպես', 'է', 'սրվակի', 'միջից', 'թափ', 'տալիս', 'վերջին', 'կաթիլը', ',', 'սրվակը', 'ողողում', 'գինու', 'սպիրտով', ',', 'որպեսզի', 'նույնիսկ', 'նվազագույն', 'մնացորդ', 'անգամ', 'չմնա', ',', 'ու', 'տեսնում', ',', 'հոտառությամբ', 'զգում', 'է', ',', 'թե', 'ինչպես', 'է', 'իր', 'սիրելի', 'բուրմունքը', 'մեկընդմիշտ', 'ու', 'անվերադարձ', 'ցնդում', ':', 'Դա', 'կլինի', 'դանդաղ', 'մահ', ',', 'նա', 'կխեղդվի', ',', 'աստիճանաբար', ',', 'տանջալի', 'ցավերով', 'իրեն', 'կգոլորշացնի', 'դուրս', '՝', 'դեպի', 'գարշելի', 'աշխարհ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4590\n",
            "4600\n",
            "4610\n",
            "4620\n",
            "4630\n",
            "4640\n",
            "4650\n",
            "4660\n",
            "4670\n",
            "4680\n",
            "4690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['նրան', 'պահելով', 'բավականաչափ', 'մոտ', ',', 'որպեսզի', 'չկարողանա', 'փախչել', ':', 'Այս', 'ճարպիկ', 'հնարքը', 'Գրենույին', 'երկու', 'անգամ', 'հրաշալի', 'հաջողվեց', 'կատարել', 'բրաբիոնի', 'յուղի', 'հետ', ',', 'որի', 'վաղանցիկ', 'բուրմունքը', 'շղթայեց', 'չափազանց', 'փոքր', 'քանակությամբ', 'մուշկի', ',', 'վանիլի', ',', 'խունկի', 'ու', 'նոճու', 'հետ', 'ն', 'հատկապես', 'դրանով', 'բացահայտեց', 'նրա', 'հմայքը', ':', 'Չի', 'կարելի', 'արդյոք', 'նմանատիպ', 'մի', 'գործողություն', 'կատարել', 'աղջկա', 'բուրմունքի', 'հետ', ':', 'Միթե', '՛', 'անպայմանորեն', 'պետք', 'է', 'վատնել', 'բուրմունքներից', 'ամենասարսափեցնողը', ',', 'ամենաթանկարժեքն', 'ու', 'ամենափխրունը', '՝', 'այն']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['օգտագործելով', 'մաքուր', 'տեսքով', ':', 'որքան', '՞', 'անհեթեթ', 'է', ':', 'Ինչպիսի', '՛', 'ապաշնորհություն', ':', 'Միթե', 'ալմաստը', 'թողնում', 'են', 'չհղկված', ':', 'Միթե', '՛', 'ոսկին', 'պարանոցին', 'են', 'կրում']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բնակտորներով', ':', 'Միթե', '՛', 'ինքը', 'Գրենույը', ',', 'ընդամենը', 'հո']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4700\n",
            "4710\n",
            "4720\n",
            "4730\n",
            "4740\n",
            "4750\n",
            "4760\n",
            "4770\n",
            "4780\n",
            "4790\n",
            "4800\n",
            "4810\n",
            "4820\n",
            "4830\n",
            "4840\n",
            "4850\n",
            "4860\n",
            "4870\n",
            "4880\n",
            "4890\n",
            "4900\n",
            "4910\n",
            "4920\n",
            "4930\n",
            "4940\n",
            "4950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ո', ',', 'այլ', 'Գրենոբլում', ',', 'մինչն', 'որը', 'յոթ', 'օրվա', 'ճանաէր', ':', 'Նրանք', ',', 'ի', 'պատիվ', 'եպիսկոպոսի', ',', 'ջահերով', 'երթ', 'սզմակերպեցին', ',', 'իսկ', 'դեկտեմբերի', '24-ին', 'Աստծուն', 'մեծ', '`', 'շնորհս', 'սկալական', 'պատարագ', 'մատուցեցին', ':', '1766', 'թվի', 'նվարի', 'մեկից', 'ուժեղացված', 'պահակախմբերը', 'հանվեդն', ',', 'Ա', 'կանայք', 'գիշերները', 'տնից', 'դուրս', 'գալու', 'թույլտվուստազան', ':', 'Անհավանական', 'արագությամբ', 'հասաբ<UNK>', '՞', 'սկան', 'ու', 'մասնավոր', 'կյանքն', 'ընկավ', 'նորմալ', 'հունի', '`', 'մեջ', ':', 'Կարծես', 'քամին', 'փչեց', '-', 'տարավ', 'վախը', ',', 'ոչ', 'ոք', 'այլնս', '`', 'չէր', 'խոսում', 'այն', 'սարսափի', 'մասին', ',', 'որն', 'ընդամենը', 'մի', 'քանի', 'ամիս', 'առաջ', 'իշխում', 'էր', 'քաղաքում', 'ու', 'նրա', 'մերճակայքում', ':', 'Նույնիսկ', 'զոհերի', 'ընտանիքներում', 'չէին', 'խոսում', 'այդ', 'մասին', ':', 'Թվում', 'էր', ',', 'թե', 'եկեղեցուց', 'վտարումը', ',', 'որի', 'մասին', 'բարձրաձայնել', 'էր', 'եպիսկոպոսը', ',', 'արտաքսել', 'էր', 'ոչ', 'միայն', 'մարդասպանին', ',', 'այլն', 'նրա', 'մասին', 'ցանկացած', 'հիշողություն', ':', 'Իսկ', 'մարդկանց', 'հենց', 'միայն', 'դա', 'էր', 'պետք', ':', 'Միայն', 'Ննա', ',', 'ով', 'դուստր', 'ուներ', ',', 'որը', 'մտնում', 'էր', 'հրաշալի', 'պատանեկության', 'տարիք', ',', 'աշխատում', 'էր', 'նրան', 'չթողնել', 'առանց', 'հսկողության', ',', 'մթնշաղի', 'գալստյան', 'հետ', 'սարսափ', 'էր', 'զգում', ',', 'իսկ', 'առավոտյան', ',', 'նրան', 'ողջ', 'ու', 'առողջ', 'գտնելով', ',', 'իրեն', 'երջանիկ', 'էր', 'զգում', ',', 'չնայած', ',', 'իհարկե', ',', 'ինքն', 'իրեն', 'չէր', 'խոստովանում', ',', 'թե', 'ինչն', 'էր', 'պատճառը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4960\n",
            "4970\n",
            "4980\n",
            "4990\n",
            "5000\n",
            "5010\n",
            "5020\n",
            "5030\n",
            "5040\n",
            "5050\n",
            "5060\n",
            "5070\n",
            "5080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'Անցած', 'տարի', 'սպանությունների', 'ժամանակ', ',', 'նա', 'դեռ', '|', 'ոիպ', 'ճակատագրապաշտական', 'մաքառումներ', 'չէր', 'զգում', ':', 'Կախարդական', 'իշխանությունը', ',', 'որն', 'այդ', 'ժամանակ', 'նրա', 'վրա', 'ուներ', 'դուստրը', ',', 'համենայնդեպս', ',', 'նրան', 'այդպես', 'էր', 'թվում', ',', 'դեռես', 'մանկության', 'կախարդական', 'իշխանությունն', 'էր', ':', 'Եվ', 'այդ', 'իսկ', 'պատճառով', 'երբեք', 'Սֆորեն', 'չէր', 'երկյուղում', ',', 'որ', 'Լաուրան', 'կդառնա', 'մարդասպանի', 'զոհը', ',', 'որը', ',', 'ինչպես', 'հայտնի', 'էր', ',', 'չէր', 'հարճակվում', 'ոչ', 'երեխաների', ',', 'ոչ', 'կանանց', ',', 'այլ', 'բացառապես', 'հասուն', 'աղջիկների', 'վրա', ',', 'ովքեր', 'դեռ', 'չէին', 'կորցրել', 'անմեղությունը', ':', 'Այնուհանդերձ', ',', 'նա', 'ուժեղացրեց', 'իր', 'տան', 'պահպանությունը', ',', 'կարգադրեց', 'տան', 'վերին', 'հարկի', 'պատուհանների', 'վրաանո', '՛', 'ճաղավանդակներ', 'դնել', 'ն', 'աղախնիս', 'հրամայեց', 'գիշերել', 'Լաուրայի', 'ննջասենյակում', ':', 'Բայց', 'միտքն', 'այն', 'մասին', '`', 'նրան', 'հեռացնի', 'քաղաքից', ',', 'ինչպես', 'անում', 'էին', 'իր', 'խավի', 'ներկայացուցիչ', 'ընկերներն', 'իրենց', 'դուստրերի', ',', 'ն', 'նույնիսկ', 'ողջ', 'ընտանիքի', 'հետ', ',', 'անտանելի', 'էր', 'նրա', 'համար', ':', 'Նմանատիպ', 'վարքագիծը', 'նա', 'համարում', 'էր', 'ամոթալի', 'ու', 'անարժան', 'Խորհրդի', 'անդամի', 'ու']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5090\n",
            "5100\n",
            "5110\n",
            "5120\n",
            "5130\n",
            "5140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['զեցկությամբ', ':', 'Երբնիցե', 'նա', 'չէր', 'էլ', 'կարԳրասում', 'նման', 'մատա', 'թայմ', ':', 'չգնահատված', 'յկո', '»', 'յուս', 'կար', ':', 'Մարդասպանը', 'բացել', 'էր', 'նրա', 'աչքել', 'սսպանւ', 'աչքի', 'ը', 'ՆՈ', 'գերազանց', 'ճաշակով', ':', 'համակարգված', 'ձնով', ':', 'Բավական', 'չե', 'Սի', 'րա', ':', 'ԲՈԲԻ', 'ապանութոններն', 'իրականացված', 'էին', 'Ա', 'վ', 'ճշտա', 'հարությամբ', ',', 'զոհերի', 'բուն', 'ընտությունն', 'իսկ', 'աու', 'էր', 'գրեթե', 'մաթեմատիկական', 'հարփարկի', ':', ':', 'Ճիշտ', 'է', ',', 'Ռիշին', 'չգիտեր', ',', 'թե', ',', 'անկեղծ', 'ասած', ',', 'ինչ', 'էր', 'մարդասպանն', 'ուզում', 'իր', 'զոհերից', ',', 'քանզի', 'չէ', '`', 'որ', 'նա', 'չէր', 'գողացել', 'նրանց', 'գլխավոր', 'հարստությունը', 'պատանեկության', 'գեղեցկությունն', 'ու', 'հմայքը', '...', 'թե', '՛', 'գողացել', 'Էր', ':', 'Համենայնդեպս', ',', 'որքան', 'էլ', 'դա', 'անհեթեթ', 'է', 'հնչում', ',', 'թվում', 'էր', ',', 'թե', 'ՍԱ', 'նարաաենրի', 'նպատակը', 'ոչ', 'թե', 'կործաել', '1', 'քով', 'հավաքածու', 'կազմելը', ':', 'Եթե', ',', 'օրիամաբւ', 'մամ', 'էր', 'Ռիշին', ',', 'բոլոր', 'զոհերին', 'պատկերացնենք', 'ոչ', 'թե', 'որպես', 'առանձին', 'անհատներ', ',', 'այլ', 'որպես', 'ինչ', '-', 'որ', 'բարձրագույն', 'սկզբունքի', 'մաս', ',', 'ն', 'իդեալիստորեն', 'պատկերացնենք', 'նրանց', 'այդչափ', 'տարբեր', 'հատկանիշները', 'մեկ', 'միասնության', 'մեջ', 'միաձուլված', ',', 'ապա', 'պատկերը', ',', 'որը', 'բաղկացած', 'է', 'նմանատիպ', 'բազմերանգությունից', ',', 'ընդհանուր', 'առմամբ', ',', 'կլիներ', 'գեղեցկության', 'պատկեր', ',', 'ու', 'կախարդանքը', ',', 'որը', 'դուրս', 'էր', 'գալիս', 'նրանից', ',', 'կունենար', 'ոչ', 'թե', 'մարդկային', ',', 'այլ', 'աստվածային', 'իշխանություն', ':', '(', 'Ինչպես', 'տեսնում', 'ենք', ',', 'Ռիշին', 'լուսավորյալ', 'ու', 'տրամաբանող', 'մարդ', 'էր', ',', 'որը', 'չէր', 'վախենում', 'նույնիսկ', 'նման', 'սրբապիղծ', 'հետնություններ', 'անելուց', ',', 'Ա', 'չնայած', 'նա', 'մտածում', 'էր', 'ոչ', 'թե', 'հոտառական', ',', 'այլ', 'օպտիկական', 'կատեգորիաներով', ',', 'այնուամենայնիվ', ',', 'շատ', 'մոտ', 'էր', 'ճշմարտությանը', ')', ':', 'Ենթադրենք', ',', 'շարունակում', 'էր', 'մտորել', 'Ռիշին', ',', 'մարդասպանը', 'նմանատիպ', 'գեղեցկության', 'հավաքածու', 'հիմնող', 'է', 'ու', 'աշխատում', 'է', 'Կատարելության', 'դիմանկարի', 'վրա', ',', 'թող']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5150\n",
            "5160\n",
            "5170\n",
            "5180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որ', 'դա', 'նույնիսկ', 'նրա', 'հիվանդագին', 'ուղեղի', \"երնակայու'\", 'թյունն', 'ր', '.', 'շարունակենք', 'ենթադրել', ',', 'որ', 'չափազանց', 'բարձր', 'ճաշակ', 'ունեցող', 'ու', 'մանրակրկիտ', 'համակարգվածությամբ', '|', 'լործող', 'մարդ', 'է', ',', 'ինչն', 'իրականում', 'շատ', 'հավանական', 'է', ',', 'այդ', 'դեպքում', 'չի', 'կարելի', 'մտածել', ',', 'որնա', 'կհրաժարվի', 'ամե', ')', 'կարժեք', 'շինարարական', 'քարից', 'այդ', 'դիմանկարի', 'համար', ',', 'որպիսին', 'կարելի', 'Է', 'գտնել', 'աշխարհիս', 'երեսին', '`', 'Լաուրայի', 'գեղեցկությունից', ':', 'Սպանությունների', 'ողջ', 'բուր|', 'գը', 'ոչմի', 'արժեք', 'չունի', 'առանց', 'նրա', ':', 'Նա', 'այն', 'քարն', 'էր', ',', 'որը', \"'\", 'պետք', 'է', 'դառնար', 'այդ', 'կառույցի', 'լուսապսակը', ':', '`', 'Գալով', 'նման', 'սարսափեցնող', 'եզրահանգման', '՝', 'Ռիշին', ',', '`', 'իր', 'անկողնու', 'վրա', 'գիշերային', 'վերնաշապիկով', 'նստած', ',', '\"', 'ապշում', 'էր', 'սեփական', 'հանգստության', 'վրա', ':', 'Նա', 'այլես', '`', 'դողից', 'չէր', 'ցնցվում', ':', 'Անորոշ', 'վախը', ',', 'որը', 'մի', 'քանի', 'շաբաթ', '`', 'շարունակ', 'կեղեքում', 'էրնրան', ',', 'անհետացել', 'էր', 'տեղը', 'զիջե', '»', 'լով', '.', 'կոնկրետ', 'վտանգի', 'գիտակցմանը', ':', 'Մարդասպանի', 'մտադրությունն', 'ակնհայտորեն', 'ուղղված', 'էր', 'Լաուրայի', 'վրա', 'ամենասկզբից', ':', 'Իսկ', 'մնացած', 'բոլոր', 'սպանությունները', 'շրջապատն', 'էին', 'այդ', 'վերջինի', '՝', 'ավարտական', 'սպանեան', ':', 'Ճիշտ', 'է', ',', 'անհասկանալի', 'էր', 'մնում', ',', 'թե', 'ինչպիսի', 'նյութական', 'նպատակներ', 'են', 'հետապնդում', 'այդ', 'սպանությունները', 'ն', ',', 'ընդհանրապես', ',', 'ունեն', '՞', 'դրանք', 'որնէ', 'նպա', '`', 'տակ', ':', 'Բայց', 'հիմնականը', ',', 'հատկապես', '`', 'մարդասպանի', 'դասակարգված', 'գործելաոճն', 'ու', 'նրա', 'ձգտումը', 'դեպի', 'կատարյալը', ',', 'Ռիշին', 'ճիշտ', 'կռահեց', ':', 'Եվ', 'որքան', 'երկար', 'էր', 'դրա', 'վրա', 'խորհում', ',', 'այնքան', 'ավելի', 'էր', 'դուր', 'գալիս', 'նրան', 'թե', '՛', 'մեկը', ',', 'թե', '՛', 'մյուսը', ',', 'ն', 'այխքան', 'մեծ', 'հարգանք', 'էր', 'տածում', 'մարդասպանի', 'հանդեպ', '.', 'նման', 'հարգանքը', ',', 'ինչպես', 'հարթ', 'հայելու', 'մեջ', ',', 'արտացոլում', 'էր', 'նրա', 'վերաբերմունքն', \"'\", 'իր', 'հանդեպ', '.', 'չէ', '՞', 'որ', 'ոչ', 'այլ', 'ոք', ',', 'այլ', 'հենց', 'ինքը', '՝', 'Ռիշին', ',', 'իր', 'նուրբ', ',', 'վերլուծական', 'խելքով', 'ներթափանցեց', 'հակառակորդի', 'մտահղացման', 'մեջ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5190\n",
            "5200\n",
            "5210\n",
            "5220\n",
            "5230\n",
            "5240\n",
            "5250\n",
            "5260\n",
            "5270\n",
            "5280\n",
            "5290\n",
            "5300\n",
            "5310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ղոցում', 'կանգնած', 'ու', 'տների', 'պատուհաններից', 'նայող', 'մարդիկ', 'չէին', 'կարողանում', 'աչք', 'կտրել', 'նրանից', ',', 'ամբոխի', 'միջից', 'երկյուղած', 'պատկառանքով', 'լի', 'ախեր', 'ու', 'օխեր', 'էին', 'լսվում', ',', 'ն', 'տղամարդիկ', 'հանում', 'էին', 'գլխարկները', 'իբր', 'երկրորդ', 'խորհրդականի', 'առջն', ',', 'իսկ', 'իրականում', '`', 'այդ', 'թագուհու', 'հպարտ', 'կեցվածքով', 'կնոջ', 'առջն', ':', 'Նրա', 'ետնից', 'համեստորեն', 'գնում', 'էր', 'վերջինիս', 'աղախինը', ',', 'այնուհետն', \"'\", 'Ռիշիի', 'ծառան', 'երկու', 'բեռնակիր', 'ճիերի', 'հետ', '(', 'կառքի', 'սգործումը', 'բացառվում', 'էր', 'գրենոբլյան', 'մայրուղու', 'անբարեկարգ', 'վիճակի', 'պատճառով', ')', '.', 'թափորը', 'եզրափակում', 'էին', 'տասից', 'ավելի', 'ջորիները', ',', 'որոնք', 'բեռնված', 'էին', 'ամենատարբեր', 'ապրանքներով', ',', 'երկու', 'գրաստապանների', 'հսկողության', 'տակ', ':', 'Դյու', '-', 'Կուրի', 'ուղեկալի', 'մոտ', 'պահակախումբը', 'հրացաններով', 'պատվի', 'առավ', 'ն', 'հրացաններն', 'իջեցրեց', 'միայն', 'այն', 'ժամանակ', ',', 'երբ', 'վերջին', 'ջորին', 'անցավ', 'դարպասների', 'միջով', ':', 'Երեխաները', 'դեռ', 'երկար', 'ժամանակ', 'վազում', 'էին', 'թափորի', 'ետնից', ',', 'ճեռքերը', 'թափ', 'տալիս', 'քարավանների', 'ետնից', ',', 'որը', 'դանդաղ', 'հեռանում', 'էր', 'զառիթափ', 'ոլորապտույտ', 'ճանապարհով', ':', 'Դստեր', 'հետ', 'Անտուան', 'Ռիշիի', 'մեկնումը', 'մարդկանց', 'վրա', 'թողեց', 'տարօրինակ', 'խոր', 'տպավորություն', ':', 'Նրանց', 'թվում', 'էր', ',', 'թե', 'իրենք', 'ներկա', 'են', 'գտնվում', 'զոհաբերության', 'մի', 'ինչ', '-', 'որ', 'հնադարյան', 'ծիսակատարության', ':', 'Չորսբոլորը', 'խոսում', 'էին', 'միայն', 'այն', 'մասին', ',', 'որ', 'Ռիշին', 'մեկնում', 'է', 'Գրենոբլ', ',', 'այսինքն', '`', 'մի', 'քաղաք', ',', 'որտեղ', 'վերջին', 'ժամանակներս', 'գործում', 'է', 'աղջիկներին', 'սպանող', 'հրեշը', ':', 'Մարդիկ', 'չգիտեին', 'էլ', ',', 'թե', 'ինչ', 'մտածեն', 'դրա', 'վերաբերյալ', ':', 'Ինչով', 'բացատրել', 'Ռիշիի', 'արարքը', 'դատապարտելի', 'թեթնատութթմ', '՞', ',', 'թե', '՞', 'հիացմունքի', 'արժանի', 'խիզախությամբ', ':', 'Մարտահարեր', '՛', 'էր', 'դա', ',', 'թե', '՞', 'աստվածների', 'ողորմածությունը', 'շարժելու', 'փորձ', ':', 'Բայց', 'նրանց', 'տանջում', 'էր', 'աղոտ', 'կանխազգացումը', ',', 'որ', 'շիկահեր', 'ծամերով']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5320\n",
            "5330\n",
            "5340\n",
            "5350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['մեկտեղ', 'համարվում', 'էր', 'Պրովանսի', 'ամենահուսալի', 'վայ', '`', 'բը', ',', 'նա', 'պատրաստվում', 'էր', 'սկզբնական', 'շրջանում', 'թաքցնել', 'իր', 'դստերը', ':', 'Իսկ', 'անձամբ', 'ինքն', 'անմիջապես', 'կվերադառնա', 'ա', '.', 'ու', 'այս', 'անգամ', 'արնելքից', '՝', \"'\", 'Անտիբի', 'ու', 'Կաննի', ')', 'ոջանցի', 'Գրասը', ',', 'որպեսզի', 'նույն', 'օրը', 'երեկոյան', '|', 'Սոր', ':', 'համեի', 'Վանս', ':', 'Նա', 'արդեն', 'իր', 'նոտարին', 'հրավիրել', '«', 'Մ', 'ԱՆՆ', 'Հիճբազիը', 'բարոն', 'դը', 'Բույոնի', 'հետ', 'համասգրի', 'իրենց', 'երեխաների', '՝', 'Լաուրայի', 'ու', 'Ալֆոնսի', 'աորաաշոթյու', ':', 'վերաբերյալ', ':', 'Նա', 'ուզում', 'էր', 'առաջարկություն', 'անել', 'Բույոնին', ',', 'որը', 'վերջինս', 'չէր', 'կարողանա', 'մերժել', '.', 'բարոնի', 'հարկերի', 'վճարումը', '40', '000', 'լիվրով', ',', 'այդ', '`', 'նույն', 'գումարի', 'օժիտ', ',', 'մի', 'քանի', 'հողամասեր', 'ու', 'Մագանոսկին', 'մերճակա', 'կարագի', 'գործարանը', ',', 'երիտասարդ', 'զույգի', 'համար', '3000', 'լիվր', 'տարեկան', 'ռենտա', ':', 'Ռիշիի', 'միակ', 'պայմանն', 'այն', 'էր', ',', 'որպեսզի', 'համաճայնագիրն', 'ուժի', '`', 'մեջ', 'մտնի', 'տասը', 'օր', 'անց', ',', 'ն', 'որպեսզի', 'երիտասարդները', 'հարսանիքից', 'անմիջապես', 'հետո', 'տեղափոխվեն', 'Վանս', ':', 'Ռիշին', 'հասկանում', 'էր', ',', 'որ', 'նման', 'շտապողականությունը', 'որոշակիորեն', 'բարձրացնում', 'է', 'բարոնի', 'ընտանիքի', 'հետ', 'իր', 'ընտանիքի', 'միացման', 'վճարի', 'չափը', ':', 'Նա', 'շատ', 'ավելի', 'քիչ', 'կվճարեր', ',', 'եթե', 'սպասելու', 'ժամանակ', 'ունենար', ':', 'Այդ', 'դեպքում', 'բարոնը', 'ստիպված', 'կլիներ', ',', 'ինչպես', 'աղքատը', ',', 'հարուստ', 'վաճառականի', 'համաձայնությունը', 'խնդրել', 'այդ', 'գործարքի', 'համար', '.', 'չէ', '՞', 'որ', 'Լաուրայի', 'գեղեցկության', 'մասին', 'փառքը', 'պիտի', 'աճի', ',', 'ինչպես', 'որ', 'Ռիշիի', 'հարստությունը', 'ն', 'ինչպես', 'Բույոնների', 'ֆինանսական', 'սնանկացումը', ':', 'Բայց', 'լավ', ',', 'թող', 'լինի', 'այդպես', ':', 'չէ', '՞', 'որ', 'նրա', 'հակառակորդը', 'ոչ', 'թե', 'բարոնն', 'էր', ',', 'այլ', 'անհայտ', 'մարդասպանը', ':', 'Ահա', 'թե', 'ում', 'գործին', 'պետք', 'է', 'խանգարել', ':', 'Ամուսնացած', 'կիսը', ',', 'ով', 'կորցրել', 'է', 'կուսությունը', 'ն', 'միգուցե', 'հղի', 'է', ',', 'արդես', 'չի', 'կարող', 'ներգրավվել', 'նրա', 'բացառիկ', 'հավաքածուի', 'մեջ', ':', 'Այդ', 'նախշապատկերի', 'վերջին', 'վանդակը', 'կմնա']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5360\n",
            "5370\n",
            "5380\n",
            "5390\n",
            "5400\n",
            "5410\n",
            "5420\n",
            "5430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['|', 'պարակի', 'վրա', 'կանգ', 'առավ', 'ու', 'հոտ', 'քաշեց', ':', 'Եվ', 'մաա', '»', 'քուր', ',', 'քաղաքային', 'հոտերի', 'հետ', 'չխառնված', 'արնմտյան', '`', 'քամու', 'ԷՐԻՔ', 'իրոք', 'կրկին', 'հայտնաբերեց', 'իր', 'ոսկե', 'թելը', '՝', 'թող', 'ր', 'բարակ', 'ու', 'թույլ', ',', 'բայց', 'ոչ', 'մի', 'բանի', 'հետ', 'չհամեմատվող', ':', 'Ընդ', 'որում', '՝', 'սիրելի', 'բուրմունքը', 'գալիս', 'էր', 'ոչ', 'թե', 'հյուսիսարնմուտքից', ',', 'որ', 'տանում', 'էր', 'ճանապարհը', 'դեպի', 'Գրենոբլ', ',', 'այլ', 'ավելի', 'շուտ', 'հարավ', '-', 'արնմուտքից', '՝', 'Կաբրի', 'տանող', 'ուղղությունից', ':', '`', 'Գրենույը', 'պահակախմբին', 'հարցրեց', ',', 'թե', 'որ', 'ճանա5', 'պարհով', 'է', 'գնացել', 'երկրորդ', 'խորհրդականը', ':', 'Պահակ', '`', 'ներից', 'մեկը', 'ցույց', 'տվեց', 'դեպի', 'հյուսիս', ':', 'Իսկ', 'գուցե', 'Կաբրիի', '՛', 'ուղղությամբ', ':', 'Կամ', 'գուցե', 'ուղղվել', 'Է', 'դեպի', 'հարավ', '՛', '՝', 'Օրիբոյի', 'կամ', 'Լա', '-', 'Նապուլի', 'ուղղությամբ', ':', 'Իհարկե', 'ոչ', ',', 'ասաց', 'պահակը', ',', 'նա', 'սեփական', 'աչքերով', 'է', 'տեսել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5440\n",
            "5450\n",
            "5460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երկու', 'ժամ', 'հետո', ',', 'երբ', 'արդեն', 'շատ', 'էր', 'մթնել', ',', 'նրանք', 'մոտեցան', ':', 'Իրենց', 'ծպտվածությունը', 'պահպանելու', 'համար', 'երեքն', 'էլ', 'փոխել', 'էին', 'հագուստները', ':', 'Երկու', 'կանայք', 'էլ', 'մուգ', 'գույնի', 'շրջազգեստներով', 'ու', 'շղարշներով', 'էին', ',', 'Ռիշին', ':', 'սն', 'բաճկոնով', ':', 'Նա', 'իրեն', 'ներկայացնում', 'էր', 'որպես', 'Կաստելլանայից', 'եկած', 'ազնվական', ',', 'վաղը', 'ցանկանում', 'էր', 'ծովանցով', 'հասնել', 'Լերինյան', 'կղզիներ', ',', 'թող', 'տերը', 'լուսաբացին', 'մոտ', 'նախաճաշ', 'պատրաստի', ':', 'Կան', '՞', 'արդյոք', 'տանն', 'այլ', 'կենվորներ', ':', 'Ոչ', ',', 'ասաց', 'տերը', ',', 'միայն', 'Նիցցայից', 'մի', 'կաշեգործի', 'ենթավարպետ', ',', 'ով', 'ախոռում', 'է', 'գիշերում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5470\n",
            "5480\n",
            "5490\n",
            "5500\n",
            "5510\n",
            "5520\n",
            "5530\n",
            "5540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'մի', 'կողմ', 'դրեց', 'մահակն', 'ու', 'ողջ', 'ջանասիրությամբ', 'անցավ', 'գործի', ':', 'Սկզբում', 'բացեց', 'իր', 'հետ', 'բերած', 'քաթանը', 'ն', 'այ', 'մաքուր', 'կողմով', 'փռեց', 'սեղանի', 'ու', 'աթոռների', 'վրա', '՝', 'հետնելով', ',', 'որպեսզի', 'ճարպոտ', 'կողմին', 'չդիպչի', ':', 'Աղջկա', 'շքեղ', 'բուրմունքը', ',', 'որը', 'հանկարծ', 'տաք', 'ու', 'խիտ', 'ալիքով', 'հորդեց', 'նրանից', ',', 'այս', 'անգամ', 'Գրենույին', 'չհուզեց', ':', 'չէ', '՞', 'որ', 'դա', 'նրան', 'ծանոթ', 'էր', ',', 'իսկ', 'արբածության', 'աստիճան', 'վայելքն', 'ավելի', 'ուշ', 'կստանա', 'այն', 'բանից', 'հետո', ',', 'երբ', 'իրոք', 'կտիրի', 'նրան', ':', 'Այժմ', 'այն', 'որքան', 'հնարավոր', 'է', 'շատ', 'պետք', 'է', 'հավաքել', ',', 'որքան', 'հնարավոր', 'է', 'քիչ', 'արտահոսք', 'տալ', ',', 'այժմ', 'նրանից', 'պահանջվում', 'էր', 'կենտրոնացվածություն', 'ու', 'արագաշարժություն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5550\n",
            "5560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ն', 'որ', 'ճակատագիրն', 'իրեն', 'տանում', 'էր', 'խճճված', ',', 'բայց', 'վերջին', 'հաշվով', 'ճիշտ', 'ուղով', ',', 'այլապես', 'միթե', '՛', 'ինքը', 'կարող', 'էր', 'հայտնվել', 'այստեղ', '՝', 'այս', 'մութ', 'սենյակում', '՝', 'իր', 'ձգտումների', 'նպատակակետի', 'մոտ', ':', 'Ինքը', ',', 'եթե', 'լավ', 'խորհրդածենք', ',', 'հիրավի', 'օրհնյալ', 'անհատ', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5570\n",
            "5580\n",
            "5590\n",
            "5600\n",
            "5610\n",
            "5620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['անգամ', 'Սնտուան', 'Ռիշին', '՝', 'ամենակարող', 'Ռիշին', ',', 'քաղաքի', 'ամենահարուստ', 'բնակիչը', ',', 'երկրորդ', 'խորհրդականը', ',', 'ազդեցիկ', ',', 'տրամաբանող', 'մարդը', ',', 'որն', 'իր', 'տրամադրության', 'տակ', 'ունի', 'ինքնապաշտպանության', 'բոլոր', 'միջոցները', ',', 'չկարողացավ', 'պահպանել', 'իր', 'սեփական', 'երեխային', ':', 'Եթե', 'մարդասպանի', 'ձեռքը', 'չերերաց', 'Լաուրայի', 'աստվածային', 'գեղեցկությունը', 'տեսնելիս', ',', 'քանի', 'որ', 'նա', 'իրականում', 'էլ', 'սուրբ', 'էր', 'թվում', 'բոլոր', 'նրանց', ',', 'ով', 'ճանաչում', 'էր', 'նրան', ',', 'հատկապես', 'հիմա', ',', 'երբ', 'մահացած', 'էր', ':', 'Այդ', 'ամենից', 'հետո', 'ինչպես', '՞', 'կարելի', 'է', 'մարդասպանից', 'ազատվելու', 'հույս', 'փայփայել', ':', '`', '՝', 'Նա', 'ժանտախտից', 'ավելի', 'սարսափելի', 'էր', ',', 'որովհետե', 'ժանտախտից', 'կարելի', 'էր', 'փախչել', ',', 'իսկ', 'այդ', 'մարդասպանից', '՝', 'չի', 'կարելի', ',', 'ինչպես', 'ցույց', 'տվեց', 'Ռիշիի', 'օրինակը', ':', 'Նա', 'ակնհայտորեն', 'գերբնական', 'ունակությունների', 'էր', 'տնօրինում', ':', 'Նա', ',', 'իհարկե', ',', 'սատանայի', 'հետ', 'միություն', 'էր', 'կազմել', ',', 'եթե', 'անճամբ', 'սատանան', 'չէր', ':', 'Եվ', 'շատերին', 'առաջին', 'հերթին', 'պարզունակ', 'մարդկանց', ',', 'կարճ', 'խելքի', 'տեր', ',', 'մնում', 'էր', 'միայն', 'մի', 'բան', 'գնալ', 'եկեղեցի', 'ու', 'աղոթել', ',', 'յուրաքանչյուր', 'արհեստավորական', 'դաս', 'աղո', '՞', 'թում', 'էր', 'իր', 'հովանավորին', '.', 'խառատները', '՝', 'սուրբ', 'Ալոիզին', ',', 'ջուլհակները', 'սուրբ', 'Կրիսպինին', ',', 'այգեպանները', 'սուրբ', 'Անտոնիոյին', ',', 'օծանագործները', ':', 'սուրբ', 'Հովսեփին', ':', 'Եվ', 'նրանք', 'իրենց', 'հետ', 'վերցնում', 'էին', 'իրենց', 'կանանց', 'ու', 'երեխաներին', ',', 'նրանց', 'հետ', 'մեկտեղ', 'աղոթում', 'էին', ',', 'ուտում', 'ու', 'քնում', 'եկեղեցում', '՝', 'նույնիսկ', 'օրը', 'ցերեկով', 'դուրս', 'չգալով', 'այնտեղից', ',', 'վստահ', ',', 'որ', 'հրեշից', 'իրենց', 'կարող', 'են', 'վտանգազերծ', 'անել', '(', 'եթե', 'ընդհանրապես', 'դեռնս', 'կար', 'որնէ', 'անվտանգություն', ')', ',', 'միայն', 'հուսահատված', 'ծխական', 'համայնքի', 'պաշտպանության', 'ներքո', 'ու', 'Աստվածամոր', 'դիմապատկերի', 'առջն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5630\n",
            "5640\n",
            "5650\n",
            "5660\n",
            "5670\n",
            "5680\n",
            "5690\n",
            "5700\n",
            "5710\n",
            "5720\n",
            "5730\n",
            "5740\n",
            "5750\n",
            "5760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'հետո', '՞', 'Ինչ', '՞', 'կանի', 'դրանից', 'հետո', ':', 'Չգիտեր', ':', 'Միգուցե', 'կվերադառնա', 'սովորական', 'կյանքին', ',', 'միգուցե', 'կամուսնանա', ',', 'միգուցե', 'որդի', 'կսաղմնավորի', ',', 'միգուցե', 'ոչինչ', 'չի', 'անի', ',', 'միգուցե', 'կմեռնի', ':', 'Նա', 'բացարձակապես', 'անտարբեր', 'էր', 'դրա', 'հանդեպ', ':', '՛Ւրա', 'մասին', 'մտածելը', 'նրան', 'նույնչափ', 'անիմաստ', 'էր', 'թվում', ',', 'ինչպես', 'մտածելը', 'այն', 'մասին', ',', 'թե', 'ինչ', 'անի', 'մահանալուց', 'հետո', '.', 'բնականաբար', ',', 'ոչինչ', ':', 'Ոչինչ', ',', 'ինչի', 'մասին', 'նա', 'կարող', 'էր', 'իմանալ', 'արդեն', 'հիմա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5770\n",
            "5780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հետո', 'մոտ', 'տասը', 'րոպե', 'ոչինչ', 'տեղի', 'չէր', 'ունենում', ':', 'Պարոսները', 'զբաղեցրել', 'էին', 'իրենց', 'տեղերը', ',', 'ժողովուրդն', 'անշարժացել', 'էր', ',', 'այլնս', 'ոչ', 'ոք', 'չէր', 'ուտում', ',', 'բոլորը', 'սպասում', 'էին', ':', 'Պապունն', 'ոււնրա', '՛', 'օժանդակ', 'աշխատողները', 'կարծես', 'քար', 'կտրած', 'կանգնած', 'էին', 'կառափնատեղիի', 'բեմի', 'վրա', ':', 'Արնը', 'մեծ', 'ու', 'դեղին', ',', 'կախված', 'էր', 'Էսթերելի', 'վերնում', ':', 'Գրասյան', 'հարթավայրից', 'տաք', 'քամի', 'էր', 'փչում', ',', 'որը', 'բերում', 'էր']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5790\n",
            "5800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['հանցագործի', 'նկատմամբ', 'պահանջվում', 'էր', 'բացառիկ', 'վերաբերմունք', ':', 'չէ', '՞', 'որ', 'չի', 'կարելի', 'նրան', '՝', 'ինչպես', 'հասարակ', 'ավազակին', ',', 'շղթայակապ', 'քարշ', 'տալ', 'հրապարակ', 'ու', 'գավազաններով', 'խփել', ':', '՛էրանում', 'ոչ', 'մի', 'սենսացիոն', 'բան', 'չէր', 'լինի', ':', 'Բոլորովին', 'այլ', 'բան', 'է', 'նրան', 'հանել', 'շքեղ', 'կառքի', 'փափուկ', 'նստատեղից', 'ու', 'մոտեցնել', 'խաչին', '.', 'դրանում', 'անհամեմատ', 'ավելի', 'շատ', 'ահագնացող', 'դաժանություն', 'կար', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'Պապոնը', 'դա', 'գիտեր', ':', 'Նրա', 'բռունցքները', ',', 'որոնք', 'սեղմել', 'էին', 'երկաթյա', 'ձողը', ',', 'դողացին', ':', 'Նրա', 'ուժեղ', 'ձեռքերը', 'հանկարծ', 'դարձան', 'այնքան', 'թույլ', ',', 'ծնկներն', 'այնքան', 'փափուկ', ',', 'սիրտն', 'այնքան', 'երկչոտ', ',', 'ինչպես', 'երեխայինը', ':', 'Նա', 'չէր', 'կարողանա', 'բարձրացնել', 'այդ', 'ձողը', ',', 'կյանքում', 'երբեք', 'նրա', 'մոտ', 'ուժ', 'չէր', 'գտնվի', 'բարձրացնել', 'այն', 'ընդդեմ', 'փոքրիկ', 'անմեղ', 'մարդու', ',', 'ախ', '՛', ',', 'նա', 'վախենում', 'էր', 'այն', 'պահից', ',', 'երբ', 'նրան', 'կբերեն', 'այստեղ', 'վերն', '.', 'նա', 'արտասվեց', ',', 'ստիպված', 'եղավ', 'հենվել', 'իր', 'մահաբեր', 'ճողի', 'վրա', ',', 'որպեսզի', 'ծնկների', 'թուլությունից', 'վայր', 'չընկնի', 'հսկայամարմին', ',', 'ուժեղ', 'Պապոնը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5820\n",
            "5830\n",
            "5840\n",
            "5850\n",
            "5860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչպես', 'օղապարանի', 'հանգույցը', ',', 'դեպի', 'իրեն', 'է', 'ճգում', '`', 'մարդկանց', ',', 'այդ', 'րոպեին', '՛նա', '՛', 'մեջ', 'կրկին', 'գլուխ', 'բարձրացրեց', 'մարդկանց', 'հանդեպ', 'ողջ', 'զզվանքը', 'ն', 'այն', 'աստիճան', 'թունավորեց', 'նրա', 'հաղթանակը', ',', 'որ', 'նա', 'ոչ', 'միայն', 'որնէ', 'ուրախություն', ',', 'այլ', 'նույնիսկ', 'բավարարվածություն', 'չզգաց', ':', 'Այն', ',', 'ինչը', 'մշտապես', 'նման', 'կրքոտությամբ', 'ցանկանում', 'էր', ',', 'այն', 'է', ',', 'որ', 'այլ', 'մարդիկ', 'սիրեն', 'իրեն', ',', 'հաջողության', 'պահին', 'նրա', 'համար', 'դարձավ', 'անտանելի', ',', 'քանզի', 'ինքը', 'չէր', 'սիրում', 'նրանց', '.', 'նա', 'ատում', 'էր', 'նրանց', ':', 'Եվ', 'հանկարծ', 'հասկացավ', ',', 'որ', 'երբեք', 'բավարարվածություն', 'չի', 'գտնի', 'սիրո', 'մեջ', ',', 'այլ', 'միայն', 'ատելության', 'մեջ', '.', 'ատելու', 'ն', 'ատված', 'լինելու', 'մեջ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'մարդկանց', 'հանդեպ', 'իր', 'ատելությունն', 'արճագանք', 'չգտավ', ':', 'Որքան', 'շատ', 'էր', 'ատում', 'նրանց', 'այդ', 'ակնթարթին', ',', 'այնքան', 'շատ', 'նրանք', 'երկրպագում', 'էին', 'իրեն', ',', 'քանի', 'որրնա', '՛', 'մեջ', 'ոչինչ', 'չէր', 'ընկալվում', 'նրանց', 'կողմից', 'որպես', 'ճշմարտություն', ',', 'սեփականացրած', 'աուրայից', 'զատ', ',', 'բուրումնավետության', 'դիմակից', 'զատ', '՝', 'գողացված', 'բուրումնավետությունից', ',', 'իսկ', 'այն', 'իրոք', 'էլ', 'արժանի', 'էր', 'աստվածագման', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'դրանից', 'ոչինչ', 'չստացվեց', ':', 'Դրանից', 'ոչինչ', 'չէր', 'էլ', 'կարող', 'ստացվել', ':', 'չէ', '՞', 'որ', 'դիմակավորված', 'էր', 'աշխարհի', 'լավագույն', 'օծանելիքով', ',', 'իսկ', 'այդ', 'դիմակի', 'տակ', 'դեմք', 'չկար', ',', 'ոչինչ', 'չկար', ',', 'բացի', 'հոտի', 'համատարած', 'բացակայությունից', ':', 'Եվ', 'այդ', 'պահին', 'նա', 'անսպասելիորեն', 'վատ', 'զգաց', ',', 'որովհետն', 'տեսավ', ',', 'թե', 'ինչպես', 'են', 'կրկին', 'մառախուղները', 'վեր', 'բարձրանում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5880\n",
            "5890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'արդե', 'րան', 'էր', ',', 'որ', 'ինքը', 'զգում', 'է', 'սրի', 'կամ', 'դաշույնի', '`', 'հարվածը', 'այդ', 'բարեգութ', 'հարվածը', 'կրծքին', ',', 'զգում', 'է', ',', 'թե', 'ինչպես', 'է', 'սայրը', 'ճեղքում', 'անցնում', 'բոլոր', 'բուրումնավետ', 'օղազրահներն', 'ու', 'գարշահոտ', 'միգամածությունները', 'ն', 'ԲԱ', 'սառը', 'սրտի', 'կենտրոնը', '.', 'ի', 'վերջո', ',', 'ի', 'վերջոնր', '՛', 'սրտի', 'մեջ', 'կա', 'այլ', ',', 'ինչ', '-', 'որ', 'այլ', 'բան', ',', 'քան', 'ինքն', 'անձամբ', ':', 'Նա', 'իրեն', 'գրեթե', 'արդեն', 'փրկված', 'էր', 'զգում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5900\n",
            "5910\n",
            "5920\n",
            "5930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այժմ', 'ամեն', 'ինչ', 'լավ', 'կլինի', ':', 'Քաղաքային', 'խորհուրդը', 'չեղյալ', 'համարեց', 'դատավճիռը', ':', 'Բոլոր', 'վկաները', 'հրաժարվեցին', 'ցուցմունքներից', ':', '՛հու', 'ազատ', 'ես', ':', 'Դու', 'կարող', 'ես', 'անել', 'ինչ', 'ուզում', 'ես', ':', 'Բայց', 'ես', 'ուզում', 'եմ', ',', 'որ', 'դու', 'մնաս', 'ինձ', 'մոտ', ':', 'Ես', 'կորցրել', 'եմ', 'դստերս', ',', 'ես', 'ուզում', 'եմ', 'քեզ', 'որդեգրել', ':', 'Դու', 'նման', 'ես', 'նրան', ':', 'Դու', 'նույնչափ', 'գեղեցիկ', 'ես', ',', 'ինչպես', 'նա', ',', 'քո', 'մազերը', ',', 'քո', 'շուրթերը', ',', 'քո', 'ձեռքը', '...', 'Ես', 'ողջ', 'ժամանակ', 'բռնել', 'էի', 'քո', 'ձեռքից', ',', 'դու', 'այնպիսի', 'ճեռք', 'ունես', ',', 'ինչպիսին', 'նրանն', 'էր', ':', 'Իսկ', 'երբ', 'նայում', 'եմ', 'քո', 'աչքերին', ',', 'թվում', 'է', ',', 'որնա', 'է', 'ինճ', 'նայում', ':', 'Դու', 'նրա', 'եղբայրն', 'ես', ',', 'ն', 'ես', 'ուզում', 'եմ', ',', 'որ', 'դառնաս', 'իմ', 'որդին', ',', 'իմ', 'ուրախությունը', ',', 'իմ', 'հպարտությունը', ',', 'իմ', 'ժառանգորդը', ':', 'Քո', 'ծնողները', 'դեռ', 'ողղ', '՛', 'են', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Նշանակում', 'է', '՝', 'դու', 'համաձայն', 'ես', 'դառնալ', 'իմ', 'որդին', ',', 'մի', 'շնչով', 'ասաց', 'նա', 'ու', 'վեր', 'թռավ', 'նստարանի', 'վրայից', ',', 'որպեսզի', 'նստի', 'մահճակալի', 'եզրին', 'ն', 'Գրենույի', 'մյուս', 'ճեռքը', 'սեղմի', '-', '-', 'Համաձձան', '՞', 'ես', ':', '<UNK>ամաճա', '՛', 'ես', ':', '՛', 'Իու', 'ցգանկանու', '՛', 'ես', ',', 'որ', 'ես', 'քո', 'հայրը', 'դառնամ', ':', 'Ոչինչ', 'մի', 'ասա', ':', 'Մի', 'խոսիր', ':', 'Դու', 'դեռ', 'շատ', 'թույլ', 'ես', ',', 'որպեսզի', 'խոսես', ':', 'Միայն', 'գլխով', 'արա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5940\n",
            "5950\n",
            "5960\n",
            "5970\n",
            "5980\n",
            "5990\n",
            "6000\n",
            "6010\n",
            "6020\n",
            "6030\n",
            "6040\n",
            "6050\n",
            "6060\n",
            "6070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբ', 'այդ', 'մարդակերները', ',', 'ավարտելով', 'ընթրիքը', ',', 'կրկին', 'հավաքվեցին', 'կրակի', 'շուրջը', ',', 'նրանցից', 'ոչ', 'մեկը', 'ոչ', 'մի', 'խոսք', 'չասաց', ':', 'Ինչ', '-', 'որ', 'մեկը', 'փսխեց', ',', 'մյուսը', 'դուրս', 'թքեց', 'փոքրիկ', 'ոսկորը', ',', 'թեթնակի', 'չպչպացրեց', 'լեզվով', ',', 'ոտքով', 'կրակի', 'մեջ', 'նետեց', 'երկնագույն', 'բաճկոնի', 'կտորը', '.', 'նրանք', 'բոլորն', 'իրենց', 'փոքր', '-', 'ինչ', 'նրաարաաի', 'էին', 'զգում', 'ու', 'չէին', 'համարճակվում', 'միմյանց', 'նայել', ':', 'Սպանություն', 'կամ', 'մեկ', 'այլ', 'ստոր', 'հանցագործություն', 'մինչ', 'այդ', 'կատարել', 'էր', 'նրանցից', 'յուրաքանչյուրը', 'լինի', 'դա', 'տղամարդ', 'թե', 'կին', ':', 'Բայց', 'որ', 'մաար', '՛', 'խժռեն', ':', 'Նման', 'զզվելի', 'քայլի', ',', 'մտածում', 'էին', 'նրանք', ',', 'երբեք', 'ու', 'երբեք', 'ընդունակ', 'չէին', ':', 'Եվ', 'զարմանում', 'էին', ',', 'թե', 'որքան', 'հեշտությամբ', 'դա', ',', 'այնուամենայնիվ', ',', 'հաջողվեգ', ',', 'ննան՛նրան', ',', 'որ', ',', 'չնայած', 'իրենց', 'ողջ', 'շփոթվածությանը', ',', 'իրենք', 'նույնիսկ', 'խղճի', 'նվազագույն', 'խայթ', 'չէին', 'զգում', ':', 'Հակառակը', ':', 'Չնայած', 'իրենց', 'ստամոքսում', 'որոշակի', 'ծանրություն', 'կար', ',', 'նրանց', 'սրտերը', 'միանշանակորեն', 'թեթնություն', 'էին', 'զգում', ':', 'Նրանց', 'մռայլ', 'հոգիներում', 'հանկարծ', 'ինչ', '-', 'որ', 'զվարթ', 'երերում', 'զգացվեց', ':', 'Եվ', 'երեսների', 'վրա', 'հայտնվեց', 'երջանկության', 'օրիորդական', ',', 'քնքուշ', 'առկայծում', ':', 'Միգուցե', 'այդ', 'պատճառով', 'էլ', 'նրանք', 'վարանում', 'էին', 'բարճրացնել', 'հայացքներն', 'ու', '՛', 'նայել', 'միմյանց', 'աչքերին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6080\n",
            "6090\n",
            "6100\n",
            "6110\n",
            "6120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian.vert.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpr4kEppuIj_",
        "outputId": "effc8073-6f82-4e21-89b7-709e3bbf3a0f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  83828  251460 2055080 Parfum_Armenian.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DWiki = {}\n",
        "with open(\"hywiki-20221101-pages-articles-v03.vert\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DWiki[line] +=1\n",
        "        except:\n",
        "            DWiki[line] = 1\n"
      ],
      "metadata": {
        "id": "5TJS8qstj_5I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DText = {}\n",
        "with open(\"Parfum_Armenian.vert.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DText[line] +=1\n",
        "        except:\n",
        "            DText[line] = 1\n"
      ],
      "metadata": {
        "id": "exBjjf9rkMxJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking if there is a frequency difference for an entry"
      ],
      "metadata": {
        "id": "lNz9tWIKuy0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DFreqDiff = {} # dictionary of frequency differences\n",
        "lenWiki = 2735468\n",
        "lenText = 83829\n",
        "c = 0\n",
        "for key, val in sorted(DText.items(), key=lambda item: item[1], reverse=True):\n",
        "    c+=1\n",
        "    valText = val + 1\n",
        "    relText = valText / lenText\n",
        "    try:\n",
        "        valWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        valWiki = 1\n",
        "    relWiki = valWiki / lenWiki\n",
        "\n",
        "    diffValue = relText / relWiki\n",
        "    DFreqDiff[key] = diffValue\n"
      ],
      "metadata": {
        "id": "ewfn2ngSu6sK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fOut = open('Parfum_Armenian-freq-diff.txt', 'w')\n",
        "for key, val in sorted(DFreqDiff.items(), key=lambda item: item[1], reverse=True):\n",
        "    try:\n",
        "        frqText = DText[key] + 1\n",
        "    except:\n",
        "        frqText = 1\n",
        "\n",
        "    try:\n",
        "        frqWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        frqWiki = 1\n",
        "    fOut.write(f'{key}\\t{val}\\t{frqText}\\t{frqWiki}\\n')\n",
        "fOut.flush()"
      ],
      "metadata": {
        "id": "v3TNjk49xxPC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat texts-vert/* >text-vert-all.vert.txt"
      ],
      "metadata": {
        "id": "rBODLGvH0_Xe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc text-vert-all.vert.txt"
      ],
      "metadata": {
        "id": "vGRyIth63pks",
        "outputId": "e4b97198-38fc-461b-bc46-b4640b0cf825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 112723  338169 3062358 text-vert-all.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DText2 = {}\n",
        "with open(\"text-vert-all.vert.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DText2[line] +=1\n",
        "        except:\n",
        "            DText2[line] = 1"
      ],
      "metadata": {
        "id": "mxkmuk223eEr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DFreqDiff2 = {} # dictionary of frequency differences\n",
        "lenWiki = 2735468\n",
        "lenText = 112723\n",
        "c = 0\n",
        "for key, val in sorted(DText2.items(), key=lambda item: item[1], reverse=True):\n",
        "    c+=1\n",
        "    valText = val + 1\n",
        "    relText = valText / lenText\n",
        "    try:\n",
        "        valWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        valWiki = 1\n",
        "    relWiki = valWiki / lenWiki\n",
        "\n",
        "    diffValue = relText / relWiki\n",
        "    DFreqDiff2[key] = diffValue\n"
      ],
      "metadata": {
        "id": "4XnwSDmF3j-D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fOut = open('text-vert-all-freq-diff.txt', 'w')\n",
        "for key, val in sorted(DFreqDiff2.items(), key=lambda item: item[1], reverse=True):\n",
        "    try:\n",
        "        frqText = DText2[key] + 1\n",
        "    except:\n",
        "        frqText = 1\n",
        "\n",
        "    try:\n",
        "        frqWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        frqWiki = 1\n",
        "    fOut.write(f'{key}\\t{val}\\t{frqText}\\t{frqWiki}\\n')\n",
        "fOut.flush()"
      ],
      "metadata": {
        "id": "6gKv0TaC39NL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading corrected file and discovering rewrite rules\n",
        "- common prefix; common suffix\n",
        "- remaining string to rewrite\n"
      ],
      "metadata": {
        "id": "Qak75Zf9hl0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "!wget https://heibox.uni-heidelberg.de/f/82b78c77a7bd4eff955d/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "LkJFnc3yh3PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrections(SFIn, SFOut, colNumberOri, colNumberCorrect):\n",
        "    LTWrongCorrect = []\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            TWrongCorrect = (LLine[colNumberOri], LLine[colNumberCorrect])\n",
        "            LTWrongCorrect.append(TWrongCorrect)\n",
        "    for SWrong, SCorrect in LTWrongCorrect:\n",
        "        FOut.write(f'{SWrong}\\t{SCorrect}\\n')\n",
        "    \n",
        "    FOut.flush()\n",
        "    return LTWrongCorrect"
      ],
      "metadata": {
        "id": "VlBmzm25qlbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}