{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg18fqYNoljVQxHukhtRuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S101lemHYstanza.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armenian lemmatization with Stanza"
      ],
      "metadata": {
        "id": "skix7t6sFaZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading evaluation sets\n",
        "- 420 words: test with about 420 words of Armenian text\n",
        "- Armenian \"Brown-type\" corpus b"
      ],
      "metadata": {
        "id": "fFBRX6lTFfcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/ce6096da570f47b99500/?dl=1"
      ],
      "metadata": {
        "id": "m549clSLFHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 evaluation-set-v01.txt"
      ],
      "metadata": {
        "id": "eI_j8KDdFRCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/a847a12bffd4491f9070/?dl=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWwqNLkxPMfB",
        "outputId": "8766619a-b984-4329-ad05-7161703a042b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-10 15:51:58--  https://heibox.uni-heidelberg.de/f/a847a12bffd4491f9070/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/6668d193-4a83-4edf-8f0a-5d7d34dea493/TED2020-dehy-hy-aa [following]\n",
            "--2022-11-10 15:51:59--  https://heibox.uni-heidelberg.de/seafhttp/files/6668d193-4a83-4edf-8f0a-5d7d34dea493/TED2020-dehy-hy-aa\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 818736 (800K) [application/octet-stream]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 799.55K   620KB/s    in 1.3s    \n",
            "\n",
            "2022-11-10 15:52:01 (620 KB/s) - ‘index.html?dl=1’ saved [818736/818736]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 TED2020-dehy-hy-aa"
      ],
      "metadata": {
        "id": "0QkNxyeRPb7W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing stanza"
      ],
      "metadata": {
        "id": "i__aUXulFkw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdzVArLUF3cb"
      },
      "outputs": [],
      "source": [
        "!pip install spacy-stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import spacy_stanza\n"
      ],
      "metadata": {
        "id": "-VN9g4N4GAR2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing English stanza (optional)"
      ],
      "metadata": {
        "id": "w6Kfwj63FzYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the stanza model if necessary\n",
        "stanza.download(\"en\")\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = spacy_stanza.load_pipeline(\"en\")\n",
        "\n",
        "doc = nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
        "print(doc.ents)"
      ],
      "metadata": {
        "id": "dEA7KJdZPrWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### downloading and testing Armenian stanza"
      ],
      "metadata": {
        "id": "HGyKxEJNGG8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"hy\")\n"
      ],
      "metadata": {
        "id": "xq53mDsUGumV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_hy = spacy_stanza.load_pipeline(\"hy\")"
      ],
      "metadata": {
        "id": "KZKOs0aVG8Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp_hy(\"ՄԱՐԴՈՒ ԻՐԱՎՈՒՆՔՆԵՐԻ ՀԱՄԸՆԴՀԱՆՈՒՐ ՀՌՉԱԿԱԳԻՐ. ՆԵՐԱԾԱԿԱՆ. Քանզի մարդկային ընտանիքի բոլոր անդամներին ներհատուկ արժանապատվությունըև հավասար ու անօտարելի իրավունքները աշխարհի ազատության, արդարության ու խաղաղության հիմքն են.\")"
      ],
      "metadata": {
        "id": "m022wp2JHvOO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n"
      ],
      "metadata": {
        "id": "LPhSOX15ICmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### full analysis of the file (optional)\n",
        "- includes dependency parsing"
      ],
      "metadata": {
        "id": "NVyvpuMDQXYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/TED2020-dehy-hy-aa', 'r', encoding='utf-8') as infile, open('/content/TED2020-dehy-hy-aa-ANALYSIS-full-v01.txt', 'w') as outfile:\n",
        "    # read sample.txt an and write its content into sample2.txt\n",
        "    outfile.write(\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{LAncestors}\\n\")\n",
        "    for line in infile:\n",
        "        line = line.strip()\n",
        "        doc = nlp_hy(line)\n",
        "        # outfile.write(line + '\\n')\n",
        "        for token in doc:\n",
        "            LAncestors = list(token.ancestors)\n",
        "            print(str(LAncestors))\n",
        "            try:\n",
        "                SLAncestors = str(list(token.ancestors))\n",
        "                parent = LAncestors[0]\n",
        "                parentLem = parent.lemma_\n",
        "            except:\n",
        "                parentLem = \"NONE\"\n",
        "            outfile.write(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{SLAncestors}\\n\")\n",
        " "
      ],
      "metadata": {
        "id": "HJdW66EmJI2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### function for lemmatization"
      ],
      "metadata": {
        "id": "_w7MrFvNQqxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parseFile(iFileName, oFileName, nlp_model = nlp):\n",
        "    with open(iFileName, 'r', encoding='utf-8') as infile, open(oFileName, 'w') as outfile:\n",
        "        # read sample.txt an and write its content into sample2.txt\n",
        "        outfile.write(\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        "        c = 0\n",
        "        for line in infile:\n",
        "            c+=1\n",
        "            if c%10 == 0: print(str(c))\n",
        "            line = line.strip()\n",
        "            doc = nlp_model(line)\n",
        "            # outfile.write(line + '\\n')\n",
        "            for token in doc:\n",
        "                LAncestors = list(token.ancestors)\n",
        "                # print(str(LAncestors))\n",
        "                try:\n",
        "                    SLAncestors = str(list(token.ancestors))\n",
        "                    parent = LAncestors[0]\n",
        "                    parentLem = parent.lemma_\n",
        "                except:\n",
        "                    parentLem = \"NONE\"\n",
        "                outfile.write(f\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        " \n",
        "    return\n"
      ],
      "metadata": {
        "id": "QT0tpHwjY4O5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### command to lemmatize the file"
      ],
      "metadata": {
        "id": "Sv_6uErhQ0Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('/content/TED2020-dehy-hy-aa', '/content/TED2020-dehy-hy-aa--lemmatization-v01.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "rgdb1fl3a6F4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e52f8df-3b5b-437a-91e5-08df5f0e3cae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'երբևէ', 'ծանրաբեռնված', 'զգացել', '՞', 'եք', 'մի', 'որևէ', 'բարդ', 'խնդրի', 'հանդիպելիս', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n",
            "170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ակնհայտ', 'է', ',', 'որ', 'բարդ', 'առաջադրանք', 'է', ',', 'բայց', 'արդյոք', '՞', 'այն', 'խճճված', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180\n",
            "190\n",
            "200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Անշուշտ', ',', 'շատ', 'մարդիկ', 'կարծում', 'են', ',', 'թե', 'արդեն', 'գիտեն', '&lt;&lt', '<UNK>Ինչ', '՞', 'է', 'գեղեցկությունը', '&gt;&gt;', 'հարցի', 'ճշգրիտ', 'պատասխանը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կարող', 'ենք', 'բացատրել', 'այդ', 'համընդհանրությունը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220\n",
            "230\n",
            "240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'կասեք', 'գեղարվեստական', 'գեղեցկության', 'մասին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250\n",
            "260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', ',', 'ինչ', '՞', 'էին', 'իրենցից', 'ներկայացնում', 'այս', 'հնագույն', 'գործիքները', ',', 'ես', 'նկատի', 'ունեմ', 'դրանք', 'հնագույն', 'են', ',', 'որովհետև', 'անծանոթ', 'են', ',', 'բայց', 'միևնույն', 'ժամանակ', 'դրանք', 'ինչ', '-', 'որ', 'կերպ', 'ծանոթ', 'են', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', ',', 'սա', 'մի', 'քիչ', 'հին', 'կատակ', 'է', ',', 'բայց', 'պարզվում', 'է', ',', 'որ', 'այն', 'գործում', 'է', '.', '.', '&lt;&lt', ';', 'ինչու', '՞', 'չես', 'մտնում', 'իմ', 'քարանձավը', ',', 'որ', 'քեզ', 'ցույց', 'տամ', 'իմ', 'կացինները', '&gt;&gt;', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այդ', 'առարկան', 'պատրաստվել', 'էր', 'կամ', '՛', 'ուղիղ', 'քայլվածքով', ',', 'կամ', '՛', 'աշխատող', 'մարդ', 'նախահոր', 'կողմից', 'լեզվի', 'ստեղծումից', '50', '.', '000', '-', '100', '.', '000', 'տարի', 'առաջ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գեղեցկությունը', 'ականատեսի', 'աչքքրում', '՞', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ոչ', '՛', ',', 'այն', 'մեր', 'ուղեղի', 'խորքում', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "290\n",
            "300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեիք', '՞', ',', 'որ', 'գենետիկորեն', 'պատրաստված', 'հացահատիկ', 'կերած', 'առնետների', 'մոտ', 'լյարդի', 'և', 'երիկամների', 'թունավորման', 'ախտանշաններ', 'են', 'ի', 'հայտ', 'եկել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "310\n",
            "320\n",
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ոմանք', 'ասում', 'են', ',', 'որ', 'օրգանական', 'կամ', 'տեղական', 'սնունդը', 'շատ', 'ավելի', 'թանկ', 'է', ',', 'բայց', 'դա', 'իրոք', '՞', 'այդպես', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'գիտեք', '՞', ',', 'թե', 'նա', 'ինչ', 'է', 'պատասխանել', 'հորը', ':', 'Ասել', 'է', ',', 'որ', 'նախընտրում', 'է', 'օրգանական', 'կարմրացրած', 'հացի', 'կտորներ', ',', 'քանի', 'որ', 'Բարկն', 'ասել', 'էր', ',', 'որ', 'նա', 'չպետք', 'է', 'ուտի', 'եգիպտացորենի', 'փաթիլներ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "350\n",
            "360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'տղային', 'մոտ', '30', 'վայրկյան', 'ժամանակ', 'էի', 'տալիս', ',', 'ինչը', 'նշանակում', 'է', ',', 'որ', 'մինչ', 'նա', 'կմոտենար', 'ինձ', ',', 'ես', 'արդեն', 'ասում', 'էի', 'նրան', '․', '«', 'ինչու', '՞', 'ես', 'լացում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'ես', 'լացում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գնա', 'նստիր', ',', 'հավաքիր', 'քեզ', ',', 'և', 'վերադարձիր', 'և', 'խոսա', 'ինձ', 'հետ', ',', 'երբ', 'կարող', 'ես', 'խոսել', 'ինչպես', '․․․', '»', 'Ինչ', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբ', 'անցան', 'տարիներ', ',', 'ես', 'սկսեցի', 'ասել', 'ինքս', 'ինձ', '․', '«', 'Աստված', 'իմ', ',', 'ինչ', '՞', 'է', 'կատարվում', 'ինձ', 'հետ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'եմ', 'ես', 'անում', '։', 'ինչու', '՞', 'եմ', 'ես', 'այսպես', 'վարվում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'հիշում', 'եմ', ',', 'որ', 'խոսում', 'էի', '12', 'տարեկան', 'ֆուտբոլ', 'խաղացող', 'տղայի', 'հետ', ',', 'և', 'ես', 'հարցեցի', 'նրան', '․', '«', 'Ինչ', '՞', 'դու', 'կզգայիր', ',', 'եթե', 'մյուս', 'խաղացողների', 'ներկայությամբ', ',', 'քո', 'մարզիչն', 'ասեր', ',', 'որ', 'դու', 'խաղում', 'ես', 'աղջկա', 'պես', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'ասացի', 'ինքս', 'ինձ', '․', '«', 'Աստված', 'իմ', ',', 'եթե', 'աղջիկ', 'կոչվելը', 'կոչնչացներ', 'նրան', ',', 'ապա', 'ինչ', '՞', 'ենք', 'մենք', 'սովորեցնում', 'նրան', 'աղջիկների', 'մասին', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'այն', 'տղաներից', 'էր', ',', 'ում', 'մասին', 'ծնողները', 'մտածում', 'էին', '․', '«', 'Ինչ', '՞', 'է', 'այս', '16', 'տարեկանն', 'անում', 'բոլոր', 'այս', '12', 'տարեկան', 'տղաների', 'հետ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n",
            "410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'նայում', 'է', 'պատուհանից', 'և', 'ինձ', 'վերև', 'կանչում', '․', '«', 'Էյ', '՜', ',', 'Էնթոնի', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Էյ', '՜', ',', 'Էնթոնի', ',', 'վերև', 'բարձրացիր', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'բացում', 'է', 'դուռն', 'ու', 'ասում', '․', '«', 'Ուզզու', '՞', 'ես', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որովհետև', 'ինձ', 'համար', ',', 'մի', 'տղայի', 'համար', ',', 'ով', 'մեծանում', 'էր', 'այդ', 'ժամանակներում', ',', 'հաշվի', 'առնելով', 'տղամարդ', 'լինելու', 'պատկերացումները', ',', '«', 'ուզզու', '՞', 'ես', '»', 'կարող', 'էր', 'նշանակել', 'միայն', 'երկու', 'բան', '՝', 'սեքս', 'կամ', 'թմրադեղ', ',', 'իսկ', 'թմրադեղեր', 'մենք', 'չէինք', 'օգտագործում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այն', 'աշխարհում', ',', 'որ', 'ես', 'պատկերում', 'եմ', 'նրա', 'համար', ',', 'ինչպես', '՞', 'պիտի', 'տղամարդիկ', 'իրենց', 'պահեն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ուզում', 'եմ', ',', 'որ', 'դուք', 'միանաք', 'ինձ', 'և', 'ես', '՝', 'ձեզ', ',', 'և', 'մենք', 'միասին', 'դաստիարակենք', 'մեր', 'տղաներին', ',', 'և', 'սովորեցնենք', 'նրանք', 'տղամարդ', 'լինել', ',', 'սովորեցնենք', ',', 'որ', 'նորմալ', 'է', 'իշխող', 'չլինել', ',', 'նորմալ', 'է', 'ունենալ', 'զգացմունքներ', 'և', 'հույզեր', ',', 'նորմալ', 'է', 'հավասարություն', 'քարոզել', '․', 'նորմալ', 'է', 'կին', 'ընկերներ', 'ունենալ', ',', 'նորմալ', 'է', 'պատկառելի', 'լինել', ',', 'որ', 'իմ', 'ազատությունը', 'որպես', 'տղամարդ', ',', 'կապված', 'է', 'քո', 'ազատությանը', 'որպես', 'կին', '։', 'Ես', 'հիշում', 'եմ', ',', 'որ', 'հարցրեցի', 'իննը', 'տարեկան', 'մի', 'տղայի', '։', 'Ես', 'հարցրեցի', 'իննը', 'տարեկան', 'մի', 'տղայի', '․', '«', 'Ինչպիսին', '՞', 'կլիներ', 'քո', 'կյանքը', ',', 'եթե', 'դու', 'ստիպված', 'չլինեիր', 'հավատարիմ', 'մնալ', 'տղամարդ', 'լինելու', 'պատկերացումներին', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "470\n",
            "480\n",
            "490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ավելի', 'տարեց', 'ուսուցիչները', '`', 'ավելի', 'փորձառուները', ',', 'ինձ', 'էին', 'նայում', 'ու', 'ասում', '.', '«', 'Օ', '՜', ',', 'ահա', 'և', 'նա', '՜', ':', '<UNK>ատ', '՜', 'հուզիչ', 'է', '.ջանք', 'ու', 'եռանդ', 'չի', '՛', 'խնայում', 'գործն', 'ավարտին', 'հասցնելու', 'համար', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հանձնարարության', 'վեջին', 'հարցը', 'հետևյալն', 'է', '.', '«', 'Ինչպես', '՞', 'եք', 'դուք', 'նախատեսում', 'ապրել', 'ձեր', 'կյանքը', '`', 'այլ', 'մարդկանց', 'վրա', 'դրական', 'ազդեցություն', 'ունենալու', 'համար', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', ',', 'ինչ', '՞', 'եք', 'դուք', 'անում', ',', 'երբ', 'ձեր', 'շուրջ', 'բոլորը', 'տեղեկատվություն', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'եք', 'երեխաներին', 'ուղղարկում', 'դպրոց', ',', 'եթե', 'նրանք', 'այլևս', 'այդտեղից', 'տեղեկատվություն', 'ստանալու', 'կարիք', 'չունեն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['գնացեք', '՛', ',', 'ստեղծեք', '՛', ':', 'գնացեք', '՛', ',', 'գլուխ', '՛', 'բերք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Ումն', '՞', 'է', 'ամենալավը', '»', ':', 'Եվ', 'նրանք', 'անմիջապես', 'պատասխանեցին', '.«', 'Ահա', ',', 'այյն', '՜', 'մեկը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Առանց', 'որևէ', 'բան', 'կարդալու', ':', 'Ահա', ',', 'այյն', '՜', 'մեկը', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'ասացի', '.«', 'Լավ', ',', 'իսկ', 'ինչով', '՞', 'է', 'այն', 'լավը', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'ասացի', '.', '«', 'Այժմ', 'կարդաացե', '՛', 'դա', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'նրանք', '.', '«', 'Օ', '՜', ',', 'այ', 'դա', 'այդքան', '՜', 'էլ', 'լավ', 'միտք', 'չէ', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "550\n",
            "560\n",
            "570\n",
            "580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'ասացի', '․', '«', 'Դուք', 'հենց', 'նոր', '՞', 'եք', 'տեղափոխվել', 'այս', 'գրասենյակ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ասացի', '․', '«', 'Ուզում', 'եք', 'ասել', ',', 'որ', 'ես', 'միակ', 'կինն', 'եմ', ',', 'որ', 'գործարք', 'եմ', 'փորձում', 'կնքել', 'ձեր', 'գրասենյակում', 'մեկ', 'տարվա', 'ընթացքու', '՞', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Հարցը', 'հետևյալն', 'է', '․', 'ինչպես', '՞', 'ենք', 'մենք', 'պատրաստվում', 'ուղղել', 'դա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կարող', 'ենք', 'փոխել', 'ղեկավար', 'պաշտոնների', 'թվերը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'փոխել', 'իրավիճակը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսօր', 'ես', 'ուզում', 'եմ', 'կենտրոնանալ', 'նրա', 'վրա', ',', 'թե', 'ինչ', '՞', 'ենք', 'մենք', 'կարող', 'անել', ',', 'որպես', 'անհատներ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'խորհուրդ', 'մենք', 'պետք', 'է', 'տանք', 'ինքներս', 'մեզ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'խորհուրդ', 'մենք', 'պետք', 'է', 'տանք', 'կանանց', ',', 'որոնք', 'աշխատում', 'են', 'մեզ', 'հետ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'խորհուրդ', 'մենք', 'պետք', 'է', 'տանք', 'մեր', 'աղջիկներին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600\n",
            "610\n",
            "620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբ', 'դուրս', 'ենք', 'գալիս', 'քննությունից', ',', 'նայում', 'իրար', ',', 'և', 'հարցնում', '․', '«', 'Ինչպես', '՞', 'էր', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Դու', 'ամենաաաձր', '՞', 'ես', 'ստացել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դա', 'ակնհայտ', 'է', '։', 'Ինչ', '՞', 'կարիք', 'կա', 'հարցնելու', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'է', 'սա', 'նշանակում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "640\n",
            "650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'Հեյդին', '՞', '։', 'Ուսանողներն', 'այդքան', 'էլ', 'համոզված', 'չեն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'սովորեցի', ',', 'որ', 'պետք', 'է', 'ձեռքս', 'բարձրացրած', 'պահել', '»', '։', 'Ես', 'ասացի', '․', '«', 'Ինչ', '՞', 'նկատի', 'ունեք', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['եթե', 'նույնիսկ', 'ես', ',', 'ում', 'համար', 'սա', 'կարևոր', 'է', ',', 'ակնհայտ', 'է', ',', 'չէ', 'որ', 'ես', 'ելույթ', 'եմ', 'ունենում', ',', 'այդ', 'ելույթի', 'ընթացքում', ',', 'ես', 'չեմ', 'կարող', 'նույնիսկ', 'նկատել', ',', 'որ', 'տղամարդկանց', 'ձեռքերը', 'դեռ', 'բարձրացրած', 'են', ',', 'և', 'կանանց', 'ձեռքերը', 'դեռ', 'բարձրացրած', 'են', ',', 'ինչպես', '՞', 'մենք', ',', 'որպես', 'ղեկավարներ', 'մեր', 'կազմակերպություններում', 'կարող', 'ենք', 'նկատել', ',', 'որ', 'տղամարդիկ', 'ավելի', 'են', 'ձգտում', 'օգտագործել', 'հնարավորությունները', 'քան', 'կանայք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'եք', 'կարծում', ',', 'ով', 'է', 'լքում', 'աշխատավայրը', ',', 'երբ', 'անհրաժեշտ', 'է', 'տանը', 'ավելի', 'շատ', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'եթե', 'դա', 'բավարար', 'դրդապատճառ', 'չի', 'հանդիսանում', 'բոլորի', 'համար', ',', 'նրանք', 'նաև', 'ավելի', 'շատ․․', '․', 'ինչպես', '՞', 'կարող', 'եմ', 'ասել․․․', '․']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Ինչպես', '՞', 'ես', 'կարող', 'եմ', 'շարունակել', 'անել', 'այն', 'ամենն', 'ինչ', 'անում', 'եմ', 'այժմ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ասացի', '․', '«', 'Դուք', 'և', 'ձեր', 'ամուսինը', 'մտածում', 'եք', 'երեխա', 'ունենալու', 'մասինն', '՞', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'է', 'տեղի', 'ունենում', ',', 'երբ', 'դուք', 'սկսում', 'եք', 'կամաց', '-', 'կամաց', 'դիրքերը', 'զիջել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "710\n",
            "720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'էլ', 'մտածեցի', '.', '«', 'Լավ', ',', 'որն', '՞', 'է', 'խնդիրը', '»', ':', 'Իսկ', 'նա', 'պատասխանեց', '.']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'այդ', 'պահին', 'իմ', 'մեջ', 'անվստահ', 'խոսեց', 'գիտնականի', 'հպարտությունը', '.', '«', 'Ինչպես', '՞', 'եք', 'ներկայացնելու', '»', ':', 'Եվ', 'նա', 'ասաց', '.']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'մտածեցի', '.', '«', 'ինչու', '՞', 'ոչ', 'հեքիաթասաց', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ուստի', 'ասացի', '.', '«', 'Գիտեք', 'ինչ', '՞', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'ուղղակի', 'ինձ', 'հետազոտող', '-', 'պատմիչ', 'չեք', 'անվանում', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Իսկապես', '՞', '»', ',', '-', 'հարցրի', 'ես', ':', '«', 'Միանշանակ', '»', ',', '-', 'եղավ', 'պատասխանը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ուստի', 'ասեմ', ',', 'որ', 'ես', 'ունեմ', 'սոցիոլոգիայի', 'ոլորտում', 'բակալավրի', 'և', 'մագիստրոսի', 'աստիճան', ',', 'իսկ', 'հիմա', 'գիտությունների', 'թեկնածու', 'եմ', 'այնպես', 'որ', ',', 'իմ', 'ողջ', 'ակադեմիական', 'կարիերայի', 'ընթացքում', 'ես', 'շրջապատված', 'եմ', 'եղել', 'այնպիսի', 'մարդկանցով', ',', 'որոնք', 'հավատացած', 'էին', '«', 'կյանքը', 'բազմազան', 'է', ',', 'սիրիր', '՛', 'այն', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'հետյալ', 'կարծիքին', 'եմ', '.', '«', 'Կյանքը', 'խառնաշփոթ', 'է', ',', 'կանոակակարի', '՛', 'այն', ',', 'դասակարգի', '՛', 'և', 'ամեն', 'ինչ', \"դի'ր\", 'իրենց', 'դարակներում', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Եվ', 'դուք', 'սկսում', 'եք', 'մտածել', 'առաջխաղացման', 'մասին', ',', 'ճիշտ', '՞', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իրականում', 'հենց', 'այսպես', 'էլ', 'լինում', 'է', ':', 'չէ', '՞', 'որ', 'երբ', 'հարցնում', 'ես', 'մարդկանց', 'սիրո', 'մասին', ',', 'նրանք', 'պատմում', 'են', 'իրենց', 'կոտրված', 'սրտերի', 'մասին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "770\n",
            "780\n",
            "790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'ընդհանրություն', 'ունեն', 'այս', 'մարդիկ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որն', '՞', 'է', 'թեման', ',', 'որն', '՞', 'է', 'նմուշը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n",
            "820\n",
            "830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['դու', 'սկսում', 'ես', 'իրականում', 'քեզ', 'ճանաչել', ',', 'երբ', 'զանգում', 'ես', 'ընկերներիդ', 'և', 'ասում', '.', '«', 'Ինչ', '-', 'որ', 'մեկի', 'կարիքն', 'ունեմ', ':', 'Ինչ', '՞', 'կառաջարկեք', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'ասաց', '.', '«', 'Ինչպես', '՞', 'եք', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դիանան', 'հարցրեց', '.', '«', 'Ինչ', '՞', 'է', 'պատահել', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'ասաց', '.', '«', 'Որն', '՞', 'է', '»', ':', 'Ես', 'էլ', 'ասացի', '.']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Եվ', 'հետո', 'ես', 'հարցրի', '.', '«', 'Դա', 'վատ', 'է', ',', 'այնպես', '՞', 'չէ', '»']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խոցելիության', 'հետ', ':', 'ինչու', '՞', 'ենք', 'մենք', 'այդքան', 'պայքարում', 'դրա', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Միայն', 'ես', '՞', 'եմ', 'պայքարում', 'խոցելիության', 'դեմ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ոչ', '<UNK>', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Շատ', 'ծիծաղելի', 'էր', ':', 'Ես', 'ֆեյսբուքով', 'և', 'թվիթերով', 'մի', 'հարց', 'էի', 'տեղադրել', '.', '«', 'Ինչպես', '՞', 'կսահմանեիք', 'խոցելիությունը', ':', 'Ինչն', '՞', 'է', 'ձեր', 'խոցելիության', 'պատճառը', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Քիչ', 'էր', 'մնում', 'ասեի', '(', 'չնայած', 'չասեցի', ')', '..', 'ուզում', 'էի', 'ասել', '.', '«', 'գիտես', '՞', 'ինչ', ':', 'Եթե', 'գոնե', 'մի', 'հինգ', 'ժամ', 'քնեիր', ',', 'այս', 'ճաշը', 'գուցե', 'շատ', 'ավելի', 'հետաքրքիր', 'լիներ', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հատկապես', 'այստեղ', ',', 'Վաշինգտոնում', ',', 'եթե', 'որևէ', 'մեկի', 'հրավիրել', 'նախաճաշի', ',', 'և', 'ասել', '.', '«', 'Հանդիպենք', 'ժամը', '<UNK><UNK>ին', '՞', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960\n",
            "970\n",
            "980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մոտավորապես', '1852', 'թ', '.', 'նրանք', 'մտածում', 'էին', '.', '&lt;&lt', '<UNK>Գուցեե', '՞', 'ես', 'աշխարհի', 'ամենահիմար', 'մարդն', 'եմ', ',', 'որ', 'չեմ', 'շտապում', 'Կալիֆորնիա', ':', '&gt;&gt', ';Եվ', 'սկսում', 'են', 'մտածել', ',', 'որ', 'իրոք', 'այդպիսին', 'են', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "990\n",
            "1000\n",
            "1010\n",
            "1020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հաղորդավար', ':', 'Կարող', 'էր', 'լինել', 'մեծ', 'բան', 'ձեզ', 'համար', ':', 'Ամուսին', '#1', ':', 'Սա', 'ձեր', '՞', 'կինն', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n",
            "1080\n",
            "1090\n",
            "1100\n",
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n",
            "1170\n",
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n",
            "1220\n",
            "1230\n",
            "1240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'ի', 'նկատի', 'ուներ', 'սրանով', ':', 'Հիմա', 'ցույց', 'կտամ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հիմա', ',', 'տեսնում', '՞', 'եք', 'այս', 'տարօրինակ', ',', 'ստորջրյա', 'մարջան', 'հիշեցնող', 'բանը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250\n",
            "1260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ով', '՞', 'է', 'հեղինակը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1270\n",
            "1280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'մենք', 'հետևյալ', 'հարցերը', 'քննարկեցինք', '․', 'կիսիր', 'քո', 'կյանքի', 'փորձը', 'ինձ', 'հետ', '։', 'Ինչ', '՞', 'խնդիրներ', 'են', 'քեզ', 'մտահոգում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'եմ', 'միշտ', 'ցանկացել', 'հարցնել', '«', 'մյուս', 'կողմի', '»', 'ներկայացուցչին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Օրինակ', 'ինչ', '՞', '»', ',', 'հարցրեց', 'նա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Փոխարենը', ',', 'մենք', 'միասին', 'առաջին', 'քայլերն', 'արեցինք', ',', 'հաղթահարելով', 'առաջին', 'ռեակցիան', ',', 'շարժվելով', 'դեպի', 'ուբունտու', ',', 'միակ', 'վայրը', ',', 'որտեղ', 'կարող', 'են', 'գտնվել', 'ամենաանհնար', 'թվացող', 'խնդիրների', 'լուծումները', '։', 'ում', '՞', 'պիտի', 'հրավիրեք', 'ճաշի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'ինչ', '՞', 'տեղի', 'կունենա', 'ճաշից', 'հետո', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', '՞', 'կբացվեն', 'դրախտի', 'դռները', ',', 'և', 'կհնչի', '\"', 'We', 'Are', 'the', 'World', '\"', 'երգը', 'ռեստորանի', 'երաժշտության', 'փոխարեն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1310\n",
            "1320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'գիտենք', 'դրա', 'մասին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1330\n",
            "1340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', '՞', 'ինչ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'ենք', 'մենք', 'մտահոգվում', ',', 'ինչ', '՞', 'կարող', 'են', 'անել', 'այս', 'երեխաներն', 'իրենց', 'հրացանով', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Տղաս', ',', 'ինչու', '՞', 'ես', 'ատում', ':', 'Ինչ', '՞', 'խնդիր', 'ունես', 'գրավորների', 'հետ', '»', ':', '«', 'Ես', 'պարտավոր', 'եմ', 'գրել', 'այն', ',', 'ինչ', 'նա', 'ասում', 'է', ',', 'որ', 'գրեմ', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Լավ', ',', 'իսկ', 'նա', 'ինչ', '՞', 'է', 'ասում', 'գրես', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Լավ', ':', 'Իսկ', 'ինչ', '՞', 'ես', 'ցանկանում', 'գրել', ':', 'Ինչի', '՞', 'մասին', 'ես', 'ցանկանում', 'գրել', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['և', 'նա', ',', 'ամենայն', 'լրջությամբ', 'կհարցնի', '.', '«', '<UNK>ուղարկկեք', '՞', 'այս', 'երեխային', 'հոգեբանի', 'մոտ', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'խնդիր', 'կա', 'այստեղ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Ինչ', '՞', 'անենք', 'այս', 'տղաների', 'հետ', '»', ':', 'Պատասխանը', 'փոխվում', 'է', '`', 'կախված', 'նրանից', ',', 'թե', 'ովքեր', 'են', 'նստած', 'սեղանի', 'շուրջ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['թե', '՞', 'այդ', 'երեխաներին', 'դաստիարակած', 'մայրերն', 'են', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ինչ', '՞', 'է', 'ստացվում', ',', 'ուսուցիչն', 'ասում', 'է', '.', '«', 'Խնդրում', 'եմ', 'նստեք', ',', 'լուռ', 'մնացեք', ',', 'արեք', 'այն', ',', 'ինչ', 'ասում', 'եմ', ',', 'հետևեք', 'կանոններին', ',', 'կառավարեք', 'ձեր', 'ժամանակը', ',', 'կենտրոնացումը', ',', 'եղեք', 'աղջիկների', 'նման', ':', '»']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'սա', 'շատ', 'լուրջ', 'խնդիր', 'է', ':', 'որտեղից', '՞', 'է', 'այն', 'գալիս', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'տեսել', '՞', 'եք', 'այս', 'գովազդը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այն', 'միանշանակ', 'չի', 'տանում', 'զարգացման', 'և', 'հատկապես', 'վատ', 'ազդեցություն', 'ունի', 'տղաների', 'համար', ':', 'Եվ', 'այսպես', ',', 'ինչ', '՞', 'պետք', 'է', 'անենք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մենք', 'պետք', 'է', 'ուշադիր', 'հետևենք', 'զրոյական', 'համբերության', 'սկզբունքին', ':', 'Արդյոք', '՞', 'այն', 'իմաստ', 'ունի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կրթական', 'խաղերի', 'մեծ', 'մասը', '`', 'չունի', ':', 'Ինչից', '՞', 'մենք', 'սկսեցինք', '.']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նրանք', 'ասում', 'են', '.', '«', 'Օ<UNK>', '<SOS>', ',', 'այո', ':', 'Նրանք', 'միշտ', 'այդպիսի', 'հիմար', 'բաներ', 'են', 'ասում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n",
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n",
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n",
            "1590\n",
            "1600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Եթե', 'ձեզ', 'դուր', 'չեն', 'գալիս', 'այս', 'կանոնները', ',', 'և', 'դրանք', 'շատերիս', 'դուր', 'չեն', 'գալիս', ',', 'ես', 'գիտեմ', ',', 'որ', 'ինձ', 'դուր', 'չէին', 'գալիս', ',', 'և', 'մինչ', 'այժմ', 'դուր', 'չեն', 'գալիս', ',', 'չնայած', 'և', 'ես', 'հետևում', 'եմ', 'դրանց', 'որոշ', 'դեպքերում', ',', 'առանց', 'գիտակցելու', ',', 'որ', 'հետևում', 'են', 'դրանց', ',', 'ինչ', '՞', 'ավելի', 'լավ', 'միջոց', 'կա', 'դրանք', 'փոխելու', 'քան', 'հումորը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'կկատարվի', ',', 'եթե', 'միացնեք', 'հումորը', 'և', 'կանանց', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1610\n",
            "1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'այնուհետև', ',', 'իմ', '40-ականներում', ',', 'ես', 'սկսեցի', 'մտածել', ',', '«', 'Ինչու', '՞', 'չանել', 'ինչ', '-', 'որ', 'բան', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'միշտ', 'սիրել', 'եմ', 'քաղաքական', 'ծաղրանկարներ', ',', 'ինչու', '՞', 'չանել', 'մի', 'բան', 'իմ', 'ծաղրանկարների', 'օգնությամբ', ',', 'որպեսզի', 'մարդիկ', 'մտածեն', 'այն', 'հիմար', 'օրենքների', 'մասին', ',', 'որոնց', 'մենք', 'հետևում', 'ենք', ',', 'և', 'նաև', 'ծիծաղեն', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1630\n",
            "1640\n",
            "1650\n",
            "1660\n",
            "1670\n",
            "1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Սա', 'նշանակում', 'է', 'հանկարծակի', 'մենք', 'կտեսնեեք', '՞', 'ավելի', 'շատ', 'իգական', 'սեռի', 'կերպարներ', 'մուլտֆիլմերում', ',', 'խաղերում', 'և', 'հեռուստաշոուներում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['հնարավոր', '՞', 'է', ',', 'որ', 'հանկարծակի', 'մեր', 'լրատվական', 'միջավայրը', 'վերածվի', 'ֆեմինիստական', 'միջավայրի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', 'ձեզ', 'մոտ', 'կարող', 'է', 'հարց', 'առաջանալ', '`', 'դե', 'լավ', ',', 'ինչ', '՞', 'կարևոր', 'է', 'իմանամ', ',', 'թե', 'ինչն', 'է', 'զվարճացնում', 'մարդկանց?']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչիս', '՞', 'է', 'պետք?']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կարող', '՞', 'եք', 'պատկերացնել', 'ինչպեսին', 'դա', 'կլինի', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1710\n",
            "1720\n",
            "1730\n",
            "1740\n",
            "1750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծափահարություններ', ')', 'Ձեր', 'կարծիքով', 'ինչքան', '՞', 'հաճախ', 'եմ', 'այդպիսի', 'օրեր', 'ունենում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1760\n",
            "1770\n",
            "1780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբ', 'դուրս', 'էի', 'գալիս', 'ննջարանից', ',', 'նա', 'ասաց', '.', '«', '<UNK>ապ', '՞', '»', ',', 'ես', 'ասացի', '«', 'Ասա', 'տղաս', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1790\n",
            "1800\n",
            "1810\n",
            "1820\n",
            "1830\n",
            "1840\n",
            "1850\n",
            "1860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՓՄ', '.', '«', 'Այսպիսով', 'որն', '՞', 'է', 'ամենամեծ', 'դժվարությունը', ',', 'երբ', 'մայր', 'և', 'դուստր', 'աշխատում', 'են', 'նման', 'վտանգավոր', 'և', 'երբեմն', 'սարսափելի', 'պայմաններում', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՓՄ', '.', '«', 'Որրոք', '՞', 'են', 'Ձեր', 'մոր', 'հետ', 'աշխատելու', 'ամենալավ', 'և', 'ամենադժվար', 'բաները', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծափահարություններ', ')', '«', 'Սպասե´ք', ',', 'սպասեք', 'ք', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'հնարավոր', 'չէ', 'պահպանել', 'լեզուն', '`', 'խոսելով', 'մեծերի', '`', 'իմ', 'ու', 'քո', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1900\n",
            "1910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'ենք', 'մենք', 'բացահայտել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['երբ', '՞', 'են', 'աշխարհի', 'այս', 'քաղաքացիները', 'վերածվում', 'լեզվական', 'սահմաններ', 'ունեցող', 'ընկալողների', ',', 'ինչպիսին', 'մենք', 'ենք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ԱՄՆ-ի', 'փոքրիկները', 'սկսում', 'են', 'ավելի', 'լավ', 'տվյալներ', 'ցուցադրել', ',', 'իսկ', 'Ճապոնիայի', 'փոքրիկները', '`', 'ավելի', 'վատ', ',', 'բայց', 'այդ', 'փոքրիկների', 'երկու', 'խումբն', 'էլ', 'պատրաստվում', 'են', 'հենց', 'այն', 'լեզուն', 'սովորելուն', ',', 'որը', 'նրանք', 'պետք', 'է', 'ապագայում', 'սովորեն', ':', 'Եվ', 'այսպես', ',', 'հարցը', 'հետևյալն', 'է', '.', 'ինչ', '՞', 'է', 'պատահում']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Սա', 'ձայնային', 'զարգացման', 'կրիտիկական', 'զարգացման', 'փուլն', 'է', ',', 'բայց', 'ինչ', '՞', 'է', 'կատարվում', 'այդ', 'ընթացքում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1930\n",
            "1940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մենք', 'հարցրեցինք', 'ինքներս', 'մեզ', '.', 'կարող', '՞', 'են', 'երեխաները', 'վիճակագրություն', 'հավաքել', 'ամբողջովին', 'նոր', 'լեզուների', 'մասին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՊՔ', '.', 'Այսպիսով', ',', 'ինչ', '՞', 'արեցինք', 'մենք', 'նրանց', 'ուղեղի', 'հետ', ':', '(', 'Ծիծաղ', ')']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'էինք', 'անում', 'մենք', 'նրանց', 'ուղեղների', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'ենք', 'մենք', 'տեսնում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1980\n",
            "1990\n",
            "2000\n",
            "2010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որն', '՞', 'էր', 'ամենավատը', ',', 'որ', 'կարող', 'էր', 'պատահել']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նորաձևության', 'ոստիկանները', 'պատրաստվում', 'էին', 'բռնել', '՞', 'քեզ', 'այդքան', 'հնաոճ', 'լինելու', 'համար']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մեկնաբանությունները', ',', 'ատելությունը', ',', 'որ', 'նա', 'ստացավ', ',', 'սկսում', 'էին', '&lt;&lt', ';', 'Ինչքան', '՞', 'ժամանակ', 'է', 'ինչ', 'շարֆը', 'պատռած', 'է&gt;&gt;', '-ից']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2030\n",
            "2040\n",
            "2050\n",
            "2060\n",
            "2070\n",
            "2080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ապա', 'ինչպես', ',', 'մեզնից', 'շատերը', 'զենքի', 'խաչերով', 'կկարողանան', 'ընտրել', 'լինել', 'Կարար', ',', 'Մալալա', 'Էլիիա', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կարող', '՞', 'են', 'նրանք', 'սպանել', 'մեզ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Փեթ', 'Միթչել', '՝', 'Որն', '՞', 'է', 'այս', 'կրծքազարդի', 'պատմությունը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Եվ', 'երբ', 'ես', 'դուրս', 'եկա', 'հանդիպելու', 'լրատվամիջոցների', 'ներկայացուցիչների', 'հետ', ',', 'նրանք', 'հարցրեցին', '․', '«', 'ինչու', '՞', 'եք', 'կրում', 'այդ', 'օձի', 'կրծքազարդը', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՓՄ', '՝', 'Որրքա', '՞', 'մեծ', 'է', 'հավաքածուն', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'եք', 'Դուք', 'մտածում', 'այդ', 'ամենի', 'մասին', '։', 'ՄՕ', '՝', 'Դե', ',', 'իրականում', 'բավականին', 'նյարդայնացնող', 'էր', ',', 'որովհետև', 'ոչ', 'մեկ', 'երբևէ', 'չի', 'նկարագրում', ',', 'թե', 'ինչ', 'է', 'կրում', 'տղամարդը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'եք', 'Դուք', 'կարողացել', 'հավասարակշռություն', 'պահպանել', ',', 'լինելով', 'ուժեղ', 'դիվանագետ', ',', 'և', 'այս', 'երկիրը', 'մնացած', 'աշխարհին', 'ներկայացնող', 'հզոր', 'ձայն', ',', 'և', 'ինչպես', '՞', 'եք', 'զգացել', 'Ձեզ', ',', 'որպես', 'մայր', 'և', 'տատիկ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'եք', 'կարողացել', 'դա', 'անել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2130\n",
            "2140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'պիտի', 'ասեմ', 'ձեզ', ',', 'որ', 'իմ', 'ամենափոքր', 'թոռնիկը', ',', 'երբ', 'նա', 'յոթ', 'տարեկան', 'դարձավ', 'անցյալ', 'տարի', ',', 'նա', 'ասաց', 'իր', 'մայրիկին', ',', 'իմ', 'աղջկան', '․', '«', 'Եվ', 'ինչ', '՞', 'կա', 'դրանում', ',', 'որ', 'Մադդի', 'տատիկը', 'պետքարտուղար', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'ճանապահորդում', 'եք', 'ամբողջ', 'աշխարհով', ',', 'բավականին', 'հաճախ', ',', 'ինչպես', '՞', 'եք', 'Դուք', 'գնահատում', 'կանանց', 'և', 'աղջիկների', 'իրավիճակը', 'համաշխարհային', 'ենթատեքստում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որտեղ', '՞', 'ենք', 'մենք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2150\n",
            "2160\n",
            "2170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'ՓՄ', '՝', 'Յոթ', 'աղջջիկ', '՞', '։', '(', 'ՄՕ', '՝', 'Յոթ', 'աղջիկ', ')', '/անգլ', '․', 'Girl', 'seven', '-', 'G7/']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հավատում', 'եք', 'արդյոք', '՞', ',', 'և', 'կարող', 'եք', 'ասել', 'մեզ', 'թե', 'ինչու', '՞', ',', 'որ', 'մեծ', 'տեղաշարժ', 'կլինի', 'այնպիսի', 'խնդիրների', 'շուրջ', ',', 'ինչպիսիք', 'են', 'բռնությունը', ',', 'խաղաղությունը', ',', 'հակամարտությունը', 'և', 'դրանց', 'լուծումները', ',', 'մշտական', 'հիմքի', 'վրա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2180\n",
            "2190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մենք', 'հանդիպման', 'էինք', ',', 'և', 'իմ', 'պատվիրակության', 'տղամարդիկ', ',', 'երբ', 'ես', 'ասում', 'էի', '․', '«', 'Դե', ',', 'ես', 'զգում', 'եմ', ',', 'որ', 'մի', 'բան', 'պետք', 'է', 'անել', 'այդ', 'կապակցությամբ', '»', ',', 'նրանք', 'ասում', 'էին', '․', '«', 'Ինչ', '՞', 'նկատի', 'ունես', 'ասելով', ',', 'զգում', 'ես', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՓՄ', '՝', 'Իսկ', 'ինչպես', '՞', 'հասնել', 'այդ', 'հավասարակշռության', ',', 'որ', 'փնտրում', 'ենք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ավելի', 'շատ', 'կանանց', 'ձայներ', '՞', 'սեղանի', 'շուրջ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ավելի', 'շատ', 'տղամարդիկկկկ', ',', 'ովքեր', 'հավատում', 'են', ',', 'որ', 'հավասարակշռությունն', 'անհրաժեշտ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'մի', 'իմաստուն', 'խոսք', 'ունեմ', ',', 'որը', 'շատ', 'եմ', 'սիրում', ',', 'քանի', 'որ', ',', 'ես', 'այնպիսի', 'մի', 'տարիքում', 'եմ', ',', 'երբ', 'ես', 'սկսեցի', 'իմ', 'կարիերան', ',', 'չգիտեմ', 'կհավատաք', ',', 'թե', 'ոչ', ',', 'գտնվեցին', 'կանայք', ',', 'ովքեր', 'քննադատում', 'էին', 'ինձ', '․', '«', 'ինչու', '՞', 'ես', 'շեղվել', 'քո', 'հիմնական', 'պարտականություններից', '»']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['կամ', '«', 'Արդյոք', '՞', 'քո', 'երեխաները', 'չեն', 'տանջվում', ',', 'այն', 'պատճառով', ',', 'որ', 'դու', 'իրենց', 'հետ', 'չես', 'ամբողջ', 'ժամանակ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', 'ն', 'հուզիչ', 'ու', 'ոգեշնչող', 'իրադարձություն', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2220\n",
            "2230\n",
            "2240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'արվեսս', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', 'կարող', '՞', 'է', 'արվեստը', 'փոխել', 'աշխարհը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2250\n",
            "2260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'հանկարծ', 'ես', 'տեսա', 'այն', ',', 'արդյոք', '՞', 'դա', 'հնարավոր', 'էր', ',', 'իմ', 'նկարը', 'պատի', 'վրա', 'մի', 'վառվող', 'ավտոմեքենայի', 'հետևում', ',', 'նկար', ',', 'որ', 'ես', 'փակցրել', 'էի', 'մի', 'տարի', 'առաջ', ',', 'մի', 'անօրինական', 'նկար', ',', 'դեռ', 'իր', 'տեղում', 'էր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2270\n",
            "2280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', ',', 'կարող', '՞', 'է', 'արդյոք', 'արվեստը', 'փոխել', 'աշխարհը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', '՞', 'նրանք', 'այդքան', 'տարբեր', 'են', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2290\n",
            "2300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինձ', 'դուր', 'էր', 'գալիս', ',', 'երբ', 'մարդիկ', 'հարցնում', 'էին', ',', '«', 'որքան', '՞', 'մեծ', 'է', 'լինելու', 'իմ', 'նկարը', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մարդիկ', 'մոտենում', 'և', 'հարցնում', 'էին', '․', '«', 'Ինչ', '՞', 'եք', 'դուք', 'անում', 'այստեղ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Նկատի', 'ունեք', ',', 'դուք', 'փակցնում', 'եք', 'երուսաղեմցու', 'լուսանկար', ',', 'հենց', 'այստեղ', '՞', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'միշտ', 'սպասում', 'եմ', 'մի', 'պահ', ',', 'և', 'այնուհետև', 'հարցնում', '․', '«', 'Դե', ',', 'կարող', '՞', 'եք', 'ասել', 'ով', 'ով', 'է', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Դեմ', 'առ', 'դեմ', '»', '-', 'ը', 'ցույց', 'տվեց', ',', 'որ', 'այն', ',', 'ինչ', 'մենք', 'կարծում', 'էինք', ',', 'որ', 'անհնար', 'է', '`', 'իրականում', 'հնարավոր', 'է', ',', 'և', 'գիտեք', '՞', 'ինչ', '.', 'այն', 'նույնիսկ', 'հեշտ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2330\n",
            "2340\n",
            "2350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'նա', 'ասաց', '․', '«', 'Գիտեք', 'ինչ', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նարկոբարոնները', 'մի', 'քիչ', 'անհանգիստ', 'էին', ',', 'որ', 'մենք', 'նկարահանումներ', 'էինք', 'անում', ',', 'բայց', 'ես', 'ասացի', 'նրանց', '․', '«', 'Գիտեք', 'ինչ', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', ',', 'ինչպես', '՞', 'նրանք', 'կարող', 'էին', 'իմանալ', 'այդ', 'նախագծի', 'մասին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նրանք', 'շարունակաբար', 'ինձ', 'հարցնում', 'էին', '․', '«', 'Որն', '՞', 'է', 'ձեր', 'նախագծի', 'նպատակը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'ՀԿ', 'եք', '՞', 'ներկայացնում', '։', 'Դուք', 'մամուլի', 'ներկայյոացիի', '՞', 'եք', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որոշ', 'մարդիկ', 'հարցնում', 'էին', '․', '«', 'ինչու', '՞', 'է', 'այն', 'սև', 'սպիտակ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'Ֆրանսիայում', 'գույներ', 'չունեք', '՞', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Կամ', 'էլ', 'նրանք', 'հարցնում', 'էին', '․', '«', 'Այս', 'բոլոր', 'մարդիկ', 'մահացա', '՞', 'են', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2400\n",
            "2410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մարդիկ', 'մոտենում', 'էին', 'մեզ', 'և', 'հարցնում', '․', '«', 'Հեյ', ',', 'ինչ', '՞', 'եք', 'դուք', 'անում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Դե', ',', 'գիտեք', ',', 'սա', 'արվեստ', 'է', '»', '։', '«', 'Արվվետ', '՞', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2420\n",
            "2430\n",
            "2440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Պատճառն', 'այն', 'է', ',', 'իհարկե', ',', 'որ', 'երբ', 'մենք', 'մեկնում', 'էինք', ',', 'մարդիկ', ',', 'որոնց', 'տները', 'գտնվում', 'էին', 'նկարներով', 'ծածկված', 'տների', 'հարևանությամբ', 'ասացին', '․', '«', 'Իսկ', 'մեր', '՞', 'կտուրները', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'ասեք', 'ինձ', 'խնդրեմ', ',', 'ինչ', '՞', 'են', 'գովազգում', 'այդ', 'նկարները', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2460\n",
            "2470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մարդիկ', 'ասում', 'են', '․', '«', 'ինչու', '՞', 'չես', 'գնում', 'Իրաք', 'կամ', 'Աֆղանստան', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կամ', ',', '«', 'Ինչպես', '՞', 'կարող', 'ենք', 'օգնել', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2480\n",
            "2490\n",
            "2500\n",
            "2510\n",
            "2520\n",
            "2530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'որն', '՞', 'էր', 'վարչակարգի', 'պատասխանը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2540\n",
            "2550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Ինչ', '՞', 'ենք', 'մենք', 'պատրաստվում', 'անել', '»', '։', '«', 'Ես', 'չգիտեմ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'արդյոք', '՞', 'վարչակարգը', 'որևէ', 'դաս', 'քաղեց', 'դրանից', '։', 'Չէի', 'ասի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2570\n",
            "2580\n",
            "2590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ով', '՞', 'կարող', 'էր', 'պատկերացնել', 'մինչև', 'ամսի', '25-ը', ',', 'որ', 'հարյուր', 'հազարավոր', 'քրիստոնյաներ', 'կաղոթեն', ',', 'և', 'տասնյակ', 'հազարավոր', 'մահմեդականներ', 'կպաշտպանեն', 'իրենց', ',', 'և', 'ապա', 'հարյուր', 'հազարավոր', 'մահմեդականներ', 'կաղոթեն', ',', 'և', 'տասնյակ', 'հազարավոր', 'քրիստոնյաներ', 'կպաշտպանեն', 'նրանց', ',', 'դա', 'հրաշալի', 'էր', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2600\n",
            "2610\n",
            "2620\n",
            "2630\n",
            "2640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եթե', 'ոլորտը', 'այսքան', 'երկար', 'գոյություն', 'ունի', ',', 'ինչու', '՞', 'են', 'կլինիկական', 'առաջընթացները', 'քիչ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2650\n",
            "2660\n",
            "2670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Լրագրողը', 'հարցրել', 'է', '.', '«', 'ինչու', '՞', 'է', 'դա', 'այդքան', 'կարևոր', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2680\n",
            "2690\n",
            "2700\n",
            "2710\n",
            "2720\n",
            "2730\n",
            "2740\n",
            "2750\n",
            "2760\n",
            "2770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ներս', 'է', 'մտնում', ',', 'ներկայացնում', 'է', 'ինքն', 'իրեն', 'մի', 'ընտանիքի', 'և', 'հարցնում', '․', '«', 'Դուք', 'Նյու', 'Հեփշայրի', 'որ', '՞', 'գյուղից', 'եք', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դա', 'ինձ', 'մոտ', 'առաջացրեց', 'հետևյալ', 'հարցը', '.', 'ինչու', '՞', 'երկրի', 'վրա', 'սոցիալապես', 'ամենազգայուն', 'մարդիկ', 'ամբողջությամբ', 'անմարդկային', 'են', 'դառնում', ',', 'երբ', 'մտածում', 'են', 'պետական', 'քաղաքականության', 'մասին', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2790\n",
            "2800\n",
            "2810\n",
            "2820\n",
            "2830\n",
            "2840\n",
            "2850\n",
            "2860\n",
            "2870\n",
            "2880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Թայմս', 'ամսագիրը', 'հարցրել', 'է', 'ամերիկացիներին', '․', '«', 'Արդյոք', '՞', 'դուք', 'պատկանում', 'են', 'մարդկանց', 'այն', '1%-ին', ',', 'ով', 'ամենաշատ', 'գումար', 'է', 'վաստակում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2890\n",
            "2900\n",
            "2910\n",
            "2920\n",
            "2930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['<UNK>անը', '՜', '։', 'Ես', 'նախանձից', 'մեռնում', 'էի', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2940\n",
            "2950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'գիտեք', 'թե', 'ինչ', '՞', 'եմ', 'հասկացել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2960\n",
            "2970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դու', 'ուղղակի', 'ծխի', 'հոտին', 'ես', 'գնում', ',', 'որ', 'գտնես', 'այրվող', 'տունը', ',', 'որպեսզի', 'գտնես', 'հրդեհում', 'ամեն', 'ինչ', 'կորցրած', 'տղային', ',', 'և', 'տեսնես', ',', 'թե', 'արդյոք', '՞', 'կարող', 'ես', 'նրան', 'փրկել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կամ', 'էլ', 'կգտնես', 'այն', 'տղային', ',', 'ով', 'սկսել', 'է', 'հրդեհը', ',', 'որպեսզի', 'տեսնես', ',', 'թե', 'կարող', '՞', 'ես', 'արդյոք', 'նրան', 'փոխել', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'հենց', 'դրա', 'համար', 'էլ', 'կան', 'ռետինե', 'կոշիկներ', ':', 'չէ', '՞', 'որ', 'անձրևը', 'կլվանա', 'կտանի', 'ամեն', 'ինչ', ',', 'եթե', 'նրան', 'թույլ', 'տաս', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2980\n",
            "2990\n",
            "3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Լավ', ',', 'պատրաա', '՞', 'եք', ':', 'Սկսեցինք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչու', '՞', 'են', 'խրտվիլակին', 'հրավիրել', 'TED', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3020\n",
            "3030\n",
            "3040\n",
            "3050\n",
            "3060\n",
            "3070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', '«', 'Դուք', 'նրան', '«', '60', 'րոպեների', '»', 'մեջ', 'տեսել', '՞', 'եք', 'Մայքլ', 'Ֆելպսի', 'հետ', 'մրցավազքով', 'լողալիս', ',', 'սոսկ', 'լողավարտիքով', ',', 'սուզվելով', 'ջրի', 'մեջ', 'այս', 'լողի', 'չեմպիոնին', 'հաղթելու', 'պատրաստակամությամբ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3080\n",
            "3090\n",
            "3100\n",
            "3110\n",
            "3120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'ես', '՞', ':', 'Դե', 'ես', 'էլ', 'չգիտեմ', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3130\n",
            "3140\n",
            "3150\n",
            "3160\n",
            "3170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նրանք', 'ունեն', 'էլեկտրականություն', ',', 'բայց', 'հարցը', 'հետևյալն', 'է', '.', 'նրանցից', 'քանիին', '՞', 'ունեն', 'լվացքի', 'մեքենա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'մնացած', 'հինգ', 'միլիարդը', ',', 'ինչպես', '՞', 'են', 'նրանք', 'լվացք', 'անում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կամ', ',', 'այլ', 'կերպ', 'ասած', ',', 'ինչպես', '՞', 'է', 'կանանց', 'մեծամասնությունը', 'լվացք', 'անում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['չէ', '՞', 'որ', 'լվացք', 'անելը', 'կանանց', 'համար', 'ծանր', 'գործ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կարող', 'ենք', 'ասել', 'այս', 'կնոջը', ',', 'որ', 'նա', 'չի', 'ունենալու', 'լվացքի', 'մեքենա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այնուհետև', 'ես', 'հարցնում', 'եմ', 'իմ', 'ուսանողներին', ',', 'ես', 'հարցրել', 'եմ', 'նրանց', '...', 'վերջին', 'երկու', 'տարվա', 'ընթացքում', 'հարցրել', 'եմ', ',', '«', 'Ձեզանից', 'քանիիը', '՞', 'չունի', 'մեքենա', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'հետո', 'ես', 'հարցրել', 'եմ', 'հետևյալը', '․', '«', 'Ձեզանից', 'քանիին', '՞', 'է', 'ձեռքով', 'լվանում', 'ձեր', 'ջինսերը', 'և', 'անկողնու', 'սավանները', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Եվ', 'ապա', 'ինչպես', '՞', 'է', 'պատահում', ',', 'որ', 'բոլորն', 'օգտագործում', 'են', 'լվացքի', 'մեքենա', ',', 'և', 'համոզված', 'են', ',', 'որ', 'միշտ', 'օգտագործելու', 'են', '.']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչով', '՞', 'է', 'այն', 'յուրահատուկ', '։', 'Ես', 'ստիպված', 'էի', 'աշխարհում', 'օգտագործվող', 'էներգիայի', 'հետազոտություն', 'անել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "3210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որոնք', '՞', 'են', 'միտումները', '։', 'Եթե', 'մենք', 'դիտարկենք', 'ապագան', 'մինչև', '2050', 'թ․', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այսպիսով', ',', 'ինչ', '՞', 'է', 'պետք', 'անել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3230\n",
            "3240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որն', '՞', 'է', 'հրաշքը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['դու', 'բեռնում', 'ես', 'լվացքը', ',', 'և', 'ինչ', '՞', 'ես', 'ստանում', 'մեքենայից', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3250\n",
            "3260\n",
            "3270\n",
            "3280\n",
            "3290\n",
            "3300\n",
            "3310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այցիս', 'վերջին', 'օրը', 'տանը', 'հետևող', 'կինը', 'եկավ', ',', 'և', 'մենք', 'մի', 'փոքր', 'զրուցեցինք', ',', 'ապա', 'նա', 'ասաց', ',', '«', 'Ինձ', 'համար', 'մի', 'բան', 'կերգեք', '՞', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3320\n",
            "3330\n",
            "3340\n",
            "3350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Դուք', 'այստեղ', 'հանգստանում', 'եք', '՞', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որքան', '՞', 'եք', 'մնալու', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որտեղից', '՞', 'էին', 'ուսանողները', 'ստացել', 'այդ', 'գիտելիքները', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կարող', '՞', 'է', 'այստեղ', 'կապ', 'լինել', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հիմա', ',', 'ինչքանով', '՞', 'է', 'արդարացի', 'մերժել', 'ուսանողին', 'հիմնվելով', 'միայն', 'լեզվական', 'կարողությունների', 'վրա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', '՞', 'նա', 'կարիք', 'ունի', 'իմանալու', 'նույն', 'լեզուն', ',', 'ինչ', 'իրավաբանը', ',', 'օրինակ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այժմ', 'թույլ', 'տվեք', 'այլ', 'տեսանկյունից', 'նայել', '.', 'եթե', 'ես', 'հանդիպեի', 'միալեզու', 'հոլանդացու', ',', 'ով', 'գտել', 'է', 'քաղցկեղի', 'բուժումը', ',', 'արդյոք', '՞', 'ես', 'կարգելեմ', 'նրա', 'մուտքը', 'որևէ', 'բրիտանական', 'համալսարան', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', ',', 'գիտեմ', ',', 'հիմա', 'դուք', 'կասեք', ',', '«', 'Իսկ', 'ինչ', '՞', 'անենք', 'վերլուծությունների', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ձեզ', 'հարցնում', 'եմ', ',', 'ինչ', '՞', 'պատահեց', 'թարգմանությունների', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', '՞', 'մեզ', 'իրականում', 'անհրաժեշտ', 'է', 'սպանել', '600', 'լեզու', 'և', 'թողնել', 'մեկ', 'խոշոր', 'լեզու', '`', 'անգլերենը', 'կամ', 'չինարենը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մեզ', 'ավելին', 'է', 'հարկավոր', ':', 'Որտեղ', '՞', 'պետք', 'է', 'լինի', 'սահմանագիծը', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3420\n",
            "3430\n",
            "3440\n",
            "3450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բացի', 'դրանից', ',', 'երբեք', 'բավարար', 'նավթ', 'չէր', 'լինում', ',', 'քանի', 'որ', 'ինչ', '՞', 'կգնեք', 'օրական', 'մեկ', 'դոլարով', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3460\n",
            "3470\n",
            "3480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', '՞', ',', 'որ', 'ավտովթարները', 'համարվում', 'են', 'երիտասարդների', 'մահացության', 'հիմնական', 'պատճառ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'գիտակցու', '՞', 'եք', ',', 'որ', 'գրեթե', 'բոլորը', 'մարդկային', 'սխալի', 'պատճառով', 'են', ',', 'այլ', 'ոչ', 'թե', 'մեքենայի', 'սխալի', ',', 'և', 'ուստի', 'կարող', 'են', 'կանխվել', 'մեքենաների', 'կողմից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտակցու', '՞', 'եք', ',', 'որ', 'մենք', 'կարող', 'էինք', 'փոխել', 'մայրուղիների', 'թողունակությունը', 'երկու', 'կամ', 'երեք', 'գործոնների', 'միջոցով', ',', 'եթե', 'չհիմնվեինք', 'մարդկային', 'դիպուկության', 'վրա', 'նեղ', 'ճանապարհին', 'մնալիս', ',', 'մարմնի', 'դիրքն', 'ուղղելիս', ',', 'և', 'ուստի', 'վարել', 'մի', 'փոքր', 'ավելի', 'մոտ', 'իրար', 'մի', 'փոքր', 'ավելի', 'նեղ', 'նրբանցքների', 'վրա', 'և', 'հեռու', 'մնալ', 'մայրուղիների', 'բոլոր', 'ճանապարհային', 'երթևեկության', 'խցանումներից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտակցու', '՞', 'եք', ',', 'որ', 'դուք', '`', 'TED-ի', 'հանդիսատեսը', ',', 'անցկացնում', 'եք', 'միջինում', 'օրական', '52', 'րոպե', 'ճանապարհային', 'երթևեկության', 'խցանումներում', '`', 'վատնելով', 'ձեր', 'ժամանակը', 'առօրյայում', 'հեռավորութունն', 'անցնելու', 'վրա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n",
            "3510\n",
            "3520\n",
            "3530\n",
            "3540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ինչ', '՜', 'հրաշք', ',', 'մարդիկ', 'սկսեցին', 'վերբեռնել', 'տեսանյութեր', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3550\n",
            "3560\n",
            "3570\n",
            "3580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ահա', ',', 'շատ', 'երգիչներ', 'սկսեցին', 'ասել', '.', '«', 'Լավ', ',', 'իսկ', 'որտեղ', '՞', 'է', 'Վիրտուալ', 'երգչախումբ', '2.0-ն', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['միթե', '՞', 'սա', 'ամենահուզիչ', 'տեսարանը', 'չէ', ',', 'որ', 'տեսել', 'եք', 'կյանքում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3590\n",
            "3600\n",
            "3610\n",
            "3620\n",
            "3630\n",
            "3640\n",
            "3650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', '<UNK>ատրաստեե<UNK>', '<UNK>', '»', ':', 'Ապա', '`', 'ասում', 'են', '.', '«', 'Նրանք', ',', 'ովքեր', 'ցատկում', 'են', ',', 'կանգնե´ք', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Գիտեք', 'ինչ', '՞', ':', 'Հավանաբար', 'ես', 'ցատկելու', 'եմ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3660\n",
            "3670\n",
            "3680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Շարժեցի', 'գլուխս', 'և', 'ինքս', 'ինձ', 'տվեցի', 'հավերժական', 'հարցը', '.', '«', 'Ինչու', '՞', 'ես', 'բանկիր', 'չդարձա', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3690\n",
            "3700\n",
            "3710\n",
            "3720\n",
            "3730\n",
            "3740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հարցրեցի', '.', '«', 'Որտեղ', '՞', 'եք', 'եղել', 'սեպտեմբերի', '11-ին', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կարող', 'է', 'առաջնորդը', 'շարունակել', 'մնալ', 'վստահելի', 'և', 'օրինական', ',', 'երբ', 'նա', 'չի', 'արել', 'մի', 'բան', ',', 'ինչ', 'անում', 'են', 'նրան', 'ենթակաները', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այդ', 'ժամանակ', 'ես', 'հարցրեցի', '.', '«', 'Ջո´ն', ',', 'որտեղ', '՞', 'է', 'քո', 'որդին', ':', 'Ինչպես', '՞', 'է', 'նա', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ասացի', '.', '«', 'Որտեղ', '՞', 'է', 'նա', 'հիմա', '»', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3770\n",
            "3780\n",
            "3790\n",
            "3800\n",
            "3810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'եք', 'դուք', 'ցանկանում', 'անել', 'այդ', 'գումարի', 'հետ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ասացի', '․', '«', 'Մի', 'րոպե', ',', 'ես', 'տեսել', 'եմ', 'Սթիվեն', 'Հոքինգին', ',', 'բոլոր', 'կաթվածահար', 'եղած', 'մարդիկ', 'չեն', '՞', 'կարող', 'հաղորդակցվել', 'այդ', 'սարքերի', 'օգնությամբ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'հարցրեցի', '․', '«', 'Այդ', 'դեպքում', ',', 'ինչպես', '՞', 'եք', 'դուք', 'հաղորդակցվում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'բոլորդ', 'տեսել', '՞', 'եք', '«', 'Սկաֆանդր', 'և', 'թիթեռնիկ', '»', 'ֆիլմը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'ասացի', ',', '«', 'Դա', 'հնացած', 'մեթոդ', 'է', '։', 'Ինչպես', '՞', 'է', 'դա', 'հնարավոր', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3820\n",
            "3830\n",
            "3840\n",
            "3850\n",
            "3860\n",
            "3870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դա', 'այն', 'հարցն', 'է', ',', 'որ', 'ես', 'ուզում', 'եմ', ',', 'որ', 'դուք', 'բոլորդ', 'ինքներդ', 'ձեզ', 'տաք', ',', 'ամեն', 'օր', ',', 'երբ', 'զգում', 'եք', ',', 'որ', 'ինչ', '-', 'որ', 'բան', 'պետք', 'է', 'անել', '։', 'երբ', '՞', ',', 'եթե', 'ոչ', 'հիմա', '։', 'Ով', '՞', ',', 'եթե', 'ոչ', 'ես', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', '՞', 'ինչ', 'էի', 'ես', 'ուզում', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'հարցեց', '․', '«', 'Ինչպես', '՞', 'ես', 'պատրաստվում', 'նշել', 'այն', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դա', 'Ձեզ', 'ինչ', 'որ', 'բան', 'ասում', '՞', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', '՞', 'որն', 'է', 'դրա', 'լավ', 'մասը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'չեմ', 'կարող', 'տեսնել', 'այս', 'ժամացույցը', 'և', 'չեմ', 'կարող', 'տեսնել', 'ժամը', 'քանիսն', 'է', '։', 'Այնպես', 'որ', ',', 'աստված', 'իմ', ',', 'այո՜', '՜', ',', 'ես', 'կարող', 'եմ', 'մի', 'քիչ', 'ավելի', 'շատ', 'ժամանակ', 'ունենալ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հեյ', '՜', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['<UNK>եսնու', '՞', 'եք', 'իմ', 'ձեռքը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3910\n",
            "3920\n",
            "3930\n",
            "3940\n",
            "3950\n",
            "3960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբևէ', 'փորձել', '՞', 'եք', 'տեսնել', 'այն', ',', 'երբ', 'ձեր', 'աչքերի', 'առջև', 'մշուշ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'ինչու', '՞', 'ես', 'դու', 'այդքան', 'պայքարում', 'մեկ', 'ուրիշ', 'անձ', 'լինելու', 'համար', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'արդյոք', '՞', 'դու', 'սիրում', 'ես', 'քո', 'աշխատանքը', ',', 'Քերոլին', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'նա', 'ասաց', '․', '«', 'Դու', 'սիրում', '՞', 'ես', 'այն', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'միայն', 'մտածում', 'էի․', 'ինչպես', '՞', 'կարող', 'եմ', 'ասել', 'նրան', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այնուհետև', 'նա', 'հարցեց', 'ինձ', '․', '«', 'Ինչ', '՞', 'էիր', 'ուզում', 'լինել', ',', 'երբ', 'փոքր', 'էիր', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3990\n",
            "4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որոշ', 'ժամանակ', 'նստած', 'մնացի', 'այնտեղ', ',', 'մտածելով', '․', '«', 'Ինչպես', '՞', 'պիտի', 'բարձրանամ', 'և', 'տուն', 'գնամ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ով', '՞', 'եմ', 'ես', 'պատրաստվում', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ով', '՞', 'եմ', 'ես', 'պատրաստվում', 'լինել', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ես', 'շարունակաբար', 'մտածում', 'էի', ',', 'ինչ', '՞', 'պատահեց', ',', 'որն', '՞', 'էր', 'իմ', 'սխալը', ',', 'ինչ', '՞', 'ես', 'չհասկացա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այնուհետև', 'ես', 'սկսեցի', 'մտածել', 'թե', 'ինչպես', 'էր', 'աչքի', 'մասնագետը', 'հարցնում', '․', '«', 'Ինչ', '՞', 'ես', 'ուզում', 'լինել', '։', 'Ինչ', '՞', 'ես', 'ուզում', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'էիր', 'ուզում', 'լինել', ',', 'երբ', 'փոքր', 'էիր', '։', 'Դու', 'սիրում', '՞', 'ես', 'քո', 'աշխատանքը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մեկ', 'այլ', 'բան', 'արա', '։', 'Ինչ', '՞', 'ես', 'ուզում', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Մեկ', 'ուրիշ', 'բան', 'արա', '։', 'Ինչ', '՞', 'ես', 'ուզում', 'լինել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4020\n",
            "4030\n",
            "4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գիտեք', '՞', 'մեզանից', 'քանիսն', 'են', 'ձևացնում', 'լինել', 'ինչ', '-', 'որ', 'մեկը', ',', 'որ', 'մենք', 'չենք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երբ', 'ես', 'ավարտեցի', 'իմ', 'ճամփորդությունը', 'փղի', 'հետ', ',', 'գիտեք', '՞', ',', 'որն', 'էր', 'ամենահրաշալի', 'պահը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'ես', 'ելույթ', 'եմ', 'ունենում', ',', 'հրաշալի', 'հանդիսատեսի', 'առջև', ',', 'և', 'ով', '՞', 'եմ', 'ես', 'և', 'ինչ', '՞', 'եմ', 'անում', 'այստեղ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծափահարություններ', ')', 'Եվ', 'գիտեք', 'ինչ', '՞', 'եմ', 'հասկացել', ',', 'ավտոմեքենաները', ',', 'մոտոցիկլերը', 'և', 'փղերը', ',', 'դա', 'ազատություն', 'չէ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4080\n",
            "4090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որքան', '՞', 'հաճախ', 'ենք', 'մենք', 'լսում', 'այն', 'մասին', ',', 'որ', 'մարդիկ', 'անտարբեր', 'են', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['որքան', '՞', 'անգամ', 'են', 'ձեզ', 'ասել', ',', 'որ', 'իրական', 'փոփոխությունն', 'անհնար', 'է', ',', 'քանի', 'որ', 'մարդիկ', 'չափազանց', 'եսասեր', 'են', ',', 'հիմար', 'կամ', 'ծույլ', ',', 'որպեսզի', 'փորձեն', 'ինչ', '-', 'որ', 'բան', 'փոխել', 'իրենց', 'համայնքում', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եկեք', 'սկսենք', 'քաղաքապետարանից', '։', 'Երբևէ', 'տեսել', '՞', 'եք', 'սրա', 'նման', 'մի', 'բան', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4100\n",
            "4110\n",
            "4120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հերոսներ․', 'ինչպես', '՞', 'ենք', 'մենք', 'դիտում', 'առաջնորդությունը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նայեք', 'այս', 'տաս', 'ֆիլմերին', '։', 'Ինչ', '՞', 'ընդհանուր', 'բան', 'կա', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որևէ', 'մեկը', 'կարող', '՞', 'է', 'գուշակել', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4130\n",
            "4140\n",
            "4150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'մենք', 'կարող', 'ենք', 'խրախուսել', 'մարդկանց', 'քվեարկել', ',', 'երբ', 'քվեները', 'որևէ', 'բան', 'չեն', 'փոխում', 'Կանադայում', '։', 'Այս', 'ամենը', 'գումարվում', 'է', 'իրար', ',']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4160\n",
            "4170\n",
            "4180\n",
            "4190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Հետո', 'նա', 'ասաց', '․', '«', 'Բայց', 'իսկականից', 'Սարա', ',', 'դու', 'կարող', 'էիր', 'ավելի', 'ջանասիրաբար', 'աշխատել', '։', 'Ինչ', 'է', ',', 'չես', '՞', 'տեսնում', ',', 'որ', 'այն', 'չափից', 'փոքր', 'է', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իմ', 'հայրը', 'գաղտնի', 'գործակա', '՞', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4210\n",
            "4220\n",
            "4230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որպես', '«', 'ներկարար', '»', ',', 'գիտես', '՞', 'արդյոք', ',', 'թե', 'ինչպես', 'գունաթափել', 'թանաքի', 'հետքերը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4240\n",
            "4250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բացի', 'դրանից', 'կային', 'նաև', 'էմոցիոնալ', 'զոհաբերություններ', ':', 'Ինչպես', '՞', 'կարելի', 'է', 'ապրել', 'մի', 'կնոջ', 'հետ', ',', 'երբ', 'այդքան', 'շատ', 'գաղտնիք', 'ունես', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կարելի', 'է', 'բացատրել', ',', 'թե', 'ինչ', 'ես', 'անում', 'յուրաքանչյուր', 'գիշեր', 'լաբում', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4260\n",
            "4270\n",
            "4280\n",
            "4290\n",
            "4300\n",
            "4310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Ինչ', '՞', 'է', 'նշանակում', 'այդ', 'չինական', 'հիերոգլիֆը', ',', 'որ', 'անընդհատ', 'տեսնում', 'եմ', 'ճանապարհին', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4320\n",
            "4330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ինչու', '՞', 'ենք', 'մենք', 'պարփակված', 'սեփական', 'իրավացիության', 'զգացմունքի', 'մեջ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Թուլ', 'տվեք', 'մի', 'բան', 'հարցնել', 'ձեզ', ',', 'կամ', 'թույլ', 'տվեք', 'մի', 'բան', 'հարցնել', 'ձեզ', ',', 'քանի', 'որ', 'դուք', 'հենց', 'այստեղ', 'եք', '։', 'Ինչպես', '՞', 'ես', 'դուք', 'ձեզ', 'զգում', 'երբ', 'սխալվում', 'եք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դուք', 'պատասխանում', 'եք', 'հետևյալ', 'հարցին', '․', 'Ինչ', '՞', 'եք', 'զգում', ',', 'երբ', 'գիտակցում', 'եք', ',', 'որ', 'սխալ', 'եք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'Գիտակցումը', ',', 'որ', 'դուք', 'սխալ', 'եք', ',', 'կարող', 'է', 'ձեզ', 'ստիպել', 'զգալ', 'այդ', 'ամենը', 'և', 'էլի', 'ուրիշ', 'բաներ', 'էլ', ',', 'ճիշտ', '՞', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4350\n",
            "4360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ճիշտ', '՞', 'եմ', 'ասում', ',', 'պր․', 'Գլխավոր', 'տնօրեն', ',', 'աստրոֆիզիկ', ',', 'մարաթոնային', 'վազքի', 'մասնակից', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Կինն', 'արթնանում', 'է', ',', 'նայում', 'է', 'ինքն', 'իրեն', ',', 'և', 'հարցնում', '․', '«', 'ինչու', '՞', 'է', 'իմ', 'մարմնի', 'սխալ', 'կողմը', 'վիրակապերի', 'մեջ', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4380\n",
            "4390\n",
            "4400\n",
            "4410\n",
            "4420\n",
            "4430\n",
            "4440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'ուր', '՞', 'է', 'իմ', 'թռչող', 'սարքը', ',', 'Քրիս', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', '՞', 'հասկանալի', 'է', 'իմ', 'յուրահատուկ', 'անգլիական', 'ակցենտը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4460\n",
            "4470\n",
            "4480\n",
            "4490\n",
            "4500\n",
            "4510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծիծաղ', ')', 'ինչու', '՞', 'պետք', 'է', 'բացարձակ', 'ընդունելի', 'լինի', 'աջակցել', 'դեմոկրատներին', 'կամ', 'հանրապետականներին', ',', 'նախընտել', 'տնտեսական', 'կառավարման', 'այս', 'կամ', 'այն', 'մոդելը', ',', 'Մաքինթոշը', 'Վինդոուսին', ',', 'բայց', 'կարծիք', 'ունենալ', 'տիեզերքի', 'ստեղծման', 'կամ', 'տիեզերքի', 'ստեղծողի', 'մասին', 'չի', 'կարելի', ',', 'քանի', 'որ', 'սա', 'սուրբ', 'է', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4520\n",
            "4530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'ինչ', '՞', 'կասեր', 'Թոմաս', 'Ջեֆերսոնը', 'այս', 'մասին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['(', 'Ծափահարություններ', ')', 'Իսկ', 'ինչ', '՞', 'է', 'նշանակում', 'աթեիստ', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['սակայն', 'իրականում', 'ինչ', '՞', 'թիվ', 'են', 'կազմում', 'Ամերիկայի', 'աթեիստները', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'որն', '՞', 'է', 'հաջորդ', 'ամենամեծ', 'խումբը', 'համոզիչ', 'կերպով', 'գերազանցելով', 'հրեաներին', '՝', '2.8', 'մլն․', ',', 'մահմեդականներին', '՝', '1.1', 'մլն․', 'բնակչությամբ', 'և', 'հինդուներին', ',', 'բուդիստներին', 'և', 'մյուս', 'բոլոր', 'կրոնները', 'միասին', 'վերցրած', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Լավ', ',', 'սա', 'քանակի', 'մասին', ',', 'իսկ', 'ինչպես', '՞', 'են', 'գործերը', 'որակի', 'առումով', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4560\n",
            "4570\n",
            "4580\n",
            "4590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'ինչու', '՞', 'դու', 'քեզ', 'աթեիստ', 'չես', 'կոչում', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Դարվինը', 'բողոքել', 'է', ',', '«', 'ինչու', '՞', 'է', 'անհրաժեշտ', 'այդքան', 'ագրեսիվ', 'լինել', '»', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'ինչ', '՞', 'եք', 'կարծում', 'հումանիստ', 'բառի', 'մասին', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4620\n",
            "4630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', 'Կառլ', 'Սագանը', ',', 'մեկ', 'այլ', 'վերջերս', 'մահացած', 'հերոս', ',', 'ասել', 'է', '«', 'Ինչպես', '՞', 'է', ',', 'որ', 'գրեթե', 'ոչ', 'մի', 'հիմնական', 'կրոն', 'ծանոթանալով', 'գիտություն', 'հետ', ',', 'չի', 'եզրակացրել', ',', '«', 'Սա', 'շատ', 'ավելի', 'լավ', 'է', ',', 'քանի', 'մենք', 'մտածում', 'էինք', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4640\n",
            "4650\n",
            "4660\n",
            "4670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երկրորդ', 'բանը', ',', 'որ', 'սովորեցի', 'այդ', 'օրը', ',', 'և', 'սա', 'այն', 'ժամանակ', ',', 'երբ', 'անցնում', 'էինք', 'Ջորջ', 'Վաշինգտոնի', 'կամրջի', 'վրայով', ',', 'որը', 'մի', 'մեծ', 'բան', 'չէր', ',', 'Ես', 'մտածեցի', ',', 'ահ', '՜', ',', 'ես', 'իսկապես', 'զղջում', 'եմ', 'միայն', 'մի', 'բանի', 'համար', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4680\n",
            "4690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'մինչ', 'մենք', 'ջրի', 'տակ', 'ենք', 'անցնում', ',', 'Ես', 'նմանատիպ', 'բան', 'զգացի', ',', 'ահ', '՜', ',', 'մահանալը', 'սարսափելի', 'չէ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչ', '՞', 'կանեիք', ',', 'որ', 'դեռ', 'չեք', 'արել', ',', 'որովհետև', 'մտածում', 'եք', ',', 'որ', 'ապրելու', 'եք', 'հավերժ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ինչպես', '՞', 'կփոխեիք', 'ձեր', 'հարաբերությունները', 'և', 'դրանց', 'հետևանքով', 'ստեղծված', 'բացասական', 'էներգիան', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4710\n",
            "4720\n",
            "4730\n",
            "4740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Իսկ', 'դուք', 'ցանկանում', 'եք', 'հրատաակկիի', '՞', 'դառնալ', ',', 'տեխնոլոգիայի', 'արտոնագող', '՞', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Որն', '՞', 'է', 'ձեր', 'նպատակը', '։']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Արդյոք', 'սա', 'այնպիսի', 'բան', 'է', ',', 'որ', 'ուրիշներն', 'էլ', 'կարող', 'են', 'անել', '՞', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՔԱ', '.', 'Այսպիսով', 'դուք', 'ցանկանում', 'եք', 'արտոնագիր', 'տալ', 'հրատարակիչներին', ',', 'որպեսզի', 'նրաան', '՞', 'էլ', 'կարողանան', 'այդպիսի', 'գեղեցիկ', 'գրքեր', 'ստեղծել', ':', '(', 'ՄՄ', '.', 'Այո', ')', 'Շատ', 'լավ', ':', 'Մայք', ',', 'շատ', 'շնորհակալություն', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՄՄ', '.', 'Շնորհակալ', 'եմ', ':', '(', 'ՔԱ', '.', 'Հաջջոութթու', '՜', ':', ')', '(', 'Ծափահարություններ', ')']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4760\n",
            "4770\n",
            "4780\n",
            "4790\n",
            "4800\n",
            "4810\n",
            "4820\n",
            "4830\n",
            "4840\n",
            "4850\n",
            "4860\n",
            "4870\n",
            "4880\n",
            "4890\n",
            "4900\n",
            "4910\n",
            "4920\n",
            "4930\n",
            "4940\n",
            "4950\n",
            "4960\n",
            "4970\n",
            "4980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1014: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Լրատվամիջոցներով', 'տեսա', 'Աիշային', 'ելույթ', 'ունենալիս', ',', 'երբ', 'նրա', 'որդուն', 'մեղադրում', 'էին', ',', 'ու', 'մտածեցի', '.', '«', 'Ինչ', 'ն', 'քաջ', 'կին', 'է', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4990\n",
            "5000\n"
          ]
        }
      ]
    }
  ]
}