{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2aHl20fazHOTa9JepFeSN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S105ocrCorrectionV04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# correction of ocr-generated text \n",
        "- using correction dictionaries \n",
        "- using rules\n"
      ],
      "metadata": {
        "id": "pS0vQT9LRLss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, sys\n"
      ],
      "metadata": {
        "id": "2yzWvD6lW-78"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi1gKbdQQyIF"
      },
      "outputs": [],
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Arm_ABBY.txt\n",
        "\n",
        "!wget https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian_uncorrected.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dealing with Armenian OCR output with line breaks (is it correct?)\n",
        "\n",
        "FName = 'Parfum_Armenian_uncorrected.txt'\n",
        "FNameOut = 'Parfum_Armenian.txt'\n",
        "\n",
        "FIn = open(FName, 'r')\n",
        "FOut = open(FNameOut, 'w')\n",
        "\n",
        "for SLine in FIn:\n",
        "    SLine = SLine.strip()\n",
        "    if SLine == '': \n",
        "        FOut.write('\\n\\n')\n",
        "        continue\n",
        "    if SLine[-1] == '-':\n",
        "        SLine2write = SLine[:-1]\n",
        "        FOut.write(SLine2write)\n",
        "        continue\n",
        "\n",
        "    FOut.write(SLine + ' ')\n",
        "FOut.flush()\n",
        "\n"
      ],
      "metadata": {
        "id": "LvHpRxM-ncIX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Arm_ABBY.txt\n",
        "!wc Parfum_Armenian_uncorrected.txt\n",
        "!wc Parfum_Armenian.txt"
      ],
      "metadata": {
        "id": "bKaXMp2uSDZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/c977e87cf2b244e6801b/?dl=1\n",
        "!mv index.html?dl=1 KorpusARM.tgz\n"
      ],
      "metadata": {
        "id": "z-5mB-CUSTTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf KorpusARM.tgz\n",
        "!mkdir KorpusARM1\n",
        "!mkdir KorpusARM1/stage01\n",
        "# concatenating files\n",
        "!cat korpusARM/hyFiktion/* >KorpusARM1/stage01/hyFiktion.txt\n",
        "!cat korpusARM/hyNatur/* >KorpusARM1/stage01/hyNatur.txt\n",
        "!cat korpusARM/hyRecht/* >KorpusARM1/stage01/hyRecht.txt\n",
        "!mkdir KorpusARM1/stage02\n",
        "\n",
        "# function for Armenian line breaks:\n",
        "\n",
        "def correctLineBreaksHY(FName, FNameOut):\n",
        "    FIn = open(FName, 'r')\n",
        "    FOut = open(FNameOut, 'w')\n",
        "    countHyphens = 0\n",
        "    for SLine in FIn:\n",
        "        SLine = SLine.strip()\n",
        "        if SLine == '': \n",
        "            FOut.write('\\n\\n')\n",
        "            continue\n",
        "        if SLine[-1] == '-':\n",
        "            SLine2write = SLine[:-1]\n",
        "            FOut.write(SLine2write)\n",
        "            countHyphens +=1\n",
        "            continue\n",
        "        FOut.write(SLine + ' ')\n",
        "    FOut.flush()\n",
        "    print(str(countHyphens) + ' hyphens corrected')\n",
        "    return\n",
        "\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyFiktion.txt', 'KorpusARM1/stage02/hyFiktion.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyNatur.txt', 'KorpusARM1/stage02/hyNatur.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyRecht.txt', 'KorpusARM1/stage02/hyRecht.txt')\n"
      ],
      "metadata": {
        "id": "pywrhPCXSVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wc KorpusARM1/stage02/hyFiktion.txt\n",
        "!wc KorpusARM1/stage02/hyNatur.txt\n",
        "!wc KorpusARM1/stage02/hyRecht.txt"
      ],
      "metadata": {
        "id": "kUqWQMklS2oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "# !wget https://heibox.uni-heidelberg.de/f/14706c04a4024b2f937d/?dl=1\n",
        "# without ճեր\n",
        "!wget https://heibox.uni-heidelberg.de/f/4a24540473564788853d/?dl=1\n",
        "\n",
        "!mv index.html?dl=1 Pilot-Corrections-all.tsv\n",
        "!wc Pilot-Corrections-all.tsv\n",
        "\n"
      ],
      "metadata": {
        "id": "n2qCSxAKT8qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading wikipedia\n",
        "### downloading Armenian Wikipedia\n",
        "!wget https://heibox.uni-heidelberg.de/f/d1f866a61bd545318213/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles.txt.gz\n",
        "!gunzip hywiki-20221101-pages-articles.txt.gz\n"
      ],
      "metadata": {
        "id": "e-6E67OXMyaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wc hywiki-20221101-pages-articles.txt"
      ],
      "metadata": {
        "id": "EiQRfY_eM892"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrections(colNumberOri, colNumberCorrect, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n",
        "\n",
        "def readCorrectionsFrq(colNumberOri, colNumberCorrect, colNumberFrq, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    '''\n",
        "    if type(LTWrongCorrect) == list:\n",
        "        pass\n",
        "    '''\n",
        "\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.rstrip('\\n')\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            SFrq = LLine[colNumberFrq]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]', f'{SFrq}')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect, SFrq in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\t{SFrq}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n"
      ],
      "metadata": {
        "id": "cuDRPHpQUGxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LTWrongCorrectWordF, DWrongCorrectWordF = readCorrectionsFrq(1, 4, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-WordForm.tsv')\n",
        "# LTWrongCorrectLemmaF, DWrongCorrectLemmaF = readCorrectionsFrq(3, 6, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-Lemma.tsv')\n",
        "print(LTWrongCorrectWordF)\n",
        "# print(LTWrongCorrectLemmaF)\n",
        "# ինձ|ինչ\n",
        "# առջև|առջևից\n",
        "# ինչ|ինձ\n",
        "# ինչ|ես\n",
        "# գիտենալ|իմանալ\n"
      ],
      "metadata": {
        "id": "6q3Qd74vUVET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(DWrongCorrectWordF))\n",
        "# print(len(DWrongCorrectLemmaF))\n"
      ],
      "metadata": {
        "id": "-_FYBzw7U42k",
        "outputId": "8de5ed4c-4d9f-4a1c-9cc9-fc6e2d787ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in sorted(DWrongCorrectWordF.items()):\n",
        "    print(f'{key}\\t{value}')"
      ],
      "metadata": {
        "id": "pT2fX38FAVve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for i in range(5):\n",
        "    LKeys = list(DWrongCorrectLemmaF.keys())\n",
        "    SKey = LKeys[i]\n",
        "    SVal = DWrongCorrectWordF[SKey]\n",
        "    print(f'{SKey} {SVal}\\n')\n",
        "'''\n",
        " "
      ],
      "metadata": {
        "id": "T7X7uZJsWajb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenizeTextHY(SFIn):\n",
        "    LLParagraphs = []\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        for SLine in FIn:\n",
        "            SLine = SLine.strip()\n",
        "            if SLine == '': continue\n",
        "            LLine = re.split('([ ,\\.\\:։;\\'\\\"\\(\\)\\-\\–\\!\\?\\{\\}\\t\\«\\»]+)', SLine)\n",
        "            # if LLine == '': continue\n",
        "            if LLine: LLParagraphs.append(LLine)\n",
        "    return LLParagraphs\n",
        "\n",
        "def printLLParagraphs(SFIn, SFOut, DCorrections1 = None, DCorrections2 = None):\n",
        "    DErrors = {}\n",
        "    LLParagraphs = tokenizeTextHY(SFIn)\n",
        "    LCorrected = []\n",
        "    FOut = open(SFOut, 'w')\n",
        "    for LPara in LLParagraphs:\n",
        "        # if LPara == [] or LPara == ['']: continue\n",
        "        if LPara == []: continue\n",
        "        # FOut.write(str(LPara) + '\\n')\n",
        "        LParaNew = []\n",
        "        FOut.write('<p>\\n')\n",
        "        \n",
        "        i = 0 # counting words\n",
        "        for el in LPara:\n",
        "            i+=1 # index of next word\n",
        "            # print(el, i)\n",
        "            # if el == ' ': continue\n",
        "            if DCorrections1:\n",
        "                if el in DCorrections1:\n",
        "                    iStart = i-5\n",
        "                    if iStart <0: iStart = 0\n",
        "                    iFinish = i+5\n",
        "                    # if iFinish >len(LPara): iFinish = len(LPara)\n",
        "                    LContext = LPara[iStart : iFinish]\n",
        "                    elCorrect = DCorrections1[el]\n",
        "                    LCorrected.append((el, elCorrect, LContext, LPara))\n",
        "\n",
        "                else:\n",
        "                    elCorrect = el\n",
        "            '''\n",
        "            if DCorrections2:\n",
        "                if el in DCorrections2:\n",
        "                    elCorrect = DCorrections2[el]\n",
        "                    LCorrected.append((el, elCorrect, LPara))\n",
        "                else:\n",
        "                    elCorrect = el                    \n",
        "            LParaNew.append(elCorrect)\n",
        "\n",
        "            '''\n",
        "\n",
        "\n",
        "        SParaNew = ' '.join(LParaNew)\n",
        "        FOut.write(f'{SParaNew}\\n')\n",
        "\n",
        "        FOut.write('</p>\\n')\n",
        "    FOut.flush()\n",
        "    return LCorrected, DErrors"
      ],
      "metadata": {
        "id": "93xc2P0iX1rS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printCorrections(LCorrected, SFOut):\n",
        "    FOut1 = open(SFOut, 'w')\n",
        "    for (el, elCorr, LContext, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)\n",
        "        FOut1.write( f'{el} \\t {elCorr} \\n\\tcontext: {SContext} \\n\\tparagraph: {SPara}\\n\\n' )    \n",
        "    return"
      ],
      "metadata": {
        "id": "biy2TG4EX19T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1, DErrors1 = printLLParagraphs('/content/Parfum_Arm_ABBY.txt', '/content/Parfum_Arm_ABBY-corrected.txt', DWrongCorrectWordF)\n",
        "printCorrections(LCorrected1, '/content/Parfum_Arm_ABBY-changes.txt')\n",
        "print(len(LCorrected1))\n",
        "LCorrected2, DErrors2 = printLLParagraphs('/content/Parfum_Armenian.txt', '/content/Parfum_Armenian-corrected.txt', DWrongCorrectWordF)\n",
        "printCorrections(LCorrected2, '/content/Parfum_Armenian-changes.txt')\n",
        "print(len(LCorrected2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ZpAZaidUad",
        "outputId": "b155299e-9be7-4058-c353-99c1bddfdab9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/Parfum_Arm_ABBY-changes.txt', 'w')\n",
        "    for (el, elCorr, LContext, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)\n",
        "        FOut1.write( f'{el}\\t{elCorr}\\t{SContext}\\t{SPara}\\n\\n' )\n",
        "\n",
        "print(len(LCorrected2))\n",
        "if LCorrected2:\n",
        "    FOut2 = open('/content/Parfum_Armenian-changes.txt', 'w')\n",
        "    for (el, elCorr, LContext, LPara) in LCorrected2:\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)        \n",
        "        FOut2.write( f'{el}\\t{elCorr}\\t{SContext}\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyFiktion-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyNatur-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyRecht-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n"
      ],
      "metadata": {
        "id": "W9wMq0uvYkzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyFiktion.txt', '/content/KorpusARM1/stage02/hyFiktion-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyFiktion.txt', '/content/KorpusARM1/stage02/hyFiktion-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyFiktion-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NluaBoyPwwbd",
        "outputId": "5b04a422-c595-4558-ac9a-fcb10b45067d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyNatur.txt', '/content/KorpusARM1/stage02/hyNatur-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyNatur.txt', '/content/KorpusARM1/stage02/hyNatur-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyNatur-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206ue_Vvw8Rt",
        "outputId": "c6c5175c-cf26-404c-e5a4-2c9d64f26e57"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyRecht.txt', '/content/KorpusARM1/stage02/hyRecht-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyRecht.txt', '/content/KorpusARM1/stage02/hyRecht-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyRecht-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4DLKC4w85F",
        "outputId": "7c92d9be-07db-4b55-d09f-ac7d955f9b6b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wikipedia"
      ],
      "metadata": {
        "id": "lm9VfuuHQcy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLParaWiki = tokenizeTextHY('/content/hywiki-20221101-pages-articles.txt')"
      ],
      "metadata": {
        "id": "UxNe9VvuQfet"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(LLParaWiki)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1nH00HmQ1Ld",
        "outputId": "d6bc950e-6ca9-4081-84e0-0006930d87c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2153019"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llPara2dict(LLParagraphs):\n",
        "    DFreq = {}\n",
        "    p=0\n",
        "    for LPara in LLParagraphs:\n",
        "        p+=1\n",
        "        if p%200000 == 0:\n",
        "            print(p)\n",
        "        # if LPara == [] or LPara == ['']: continue\n",
        "        if LPara == []: continue\n",
        "        # FOut.write(str(LPara) + '\\n')\n",
        "        i = 0 # counting words\n",
        "        for el in LPara:\n",
        "            i+=1 # index of next word\n",
        "            try:\n",
        "                DFreq[el] += 1\n",
        "            except:\n",
        "                DFreq[el] = 1\n",
        "    return DFreq\n"
      ],
      "metadata": {
        "id": "xGYc-CldQ5_X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DWiki = llPara2dict(LLParaWiki)\n",
        "print(len(DWiki))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoTwYK30SDw-",
        "outputId": "cb7186e8-6a3d-44f0-bb99-cf0ff3cce8c4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200000\n",
            "400000\n",
            "600000\n",
            "800000\n",
            "1000000\n",
            "1200000\n",
            "1400000\n",
            "1600000\n",
            "1800000\n",
            "2000000\n",
            "2071984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOut = open('hywiki-frqDict.txt', 'w')\n",
        "for key, val in sorted(DWiki.items(), key=lambda item: item[1], reverse=True):\n",
        "    FOut.write(f'{key}\\t{val}\\n')"
      ],
      "metadata": {
        "id": "fZpCsWIZShqu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-frqDict.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvTzG-NfTNO9",
        "outputId": "330da0a9-e1f4-4ccc-d82a-048a523b249c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2071974  4150227 42482907 hywiki-frqDict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head --lines=40 hywiki-frqDict.txt"
      ],
      "metadata": {
        "id": "ZXcZTSY4TRtE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}