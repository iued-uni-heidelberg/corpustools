{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compLingProject101MorphologicalAnalysisV01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfvUYpDirlXGgitWl2zCv0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S01LemmatizationEnHyV01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1dRDzwnNTst"
      },
      "source": [
        "# Morphological analysis for English and Armenian\n",
        "\n",
        "We will create a workflow for analysing English and Armenian texts\n",
        "\n",
        "For English we will use the TreeTagger \n",
        "\n",
        "For Armenian we will use the git repository with Armenian morphological analyser: \n",
        "https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nX7LqgRytTb"
      },
      "source": [
        "# importing python libraries\n",
        "import os, re, sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HjwCMIqsztj"
      },
      "source": [
        "## English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp8FKqOANJ6A"
      },
      "source": [
        "# installing TreeTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUlWsn6UmgZb"
      },
      "source": [
        "%%bash\n",
        "mkdir treetagger\n",
        "cd treetagger\n",
        "# Download the tagger package for your system (PC-Linux, Mac OS-X, ARM64, ARMHF, ARM-Android, PPC64le-Linux).\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tree-tagger-linux-3.2.4.tar.gz\n",
        "tar -xzvf tree-tagger-linux-3.2.4.tar.gz\n",
        "# Download the tagging scripts into the same directory.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/tagger-scripts.tar.gz\n",
        "gunzip tagger-scripts.tar.gz\n",
        "# Download the installation script install-tagger.sh.\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/install-tagger.sh\n",
        "# Download the parameter files for the languages you want to process.\n",
        "# list of all files (parameter files) https://cis.lmu.de/~schmid/tools/TreeTagger/#parfiles\n",
        "wget https://cis.lmu.de/~schmid/tools/TreeTagger/data/english.par.gz\n",
        "sh install-tagger.sh\n",
        "cd ..\n",
        "sudo pip install treetaggerwrapper\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VR2d5n_mo8R"
      },
      "source": [
        "%%bash\n",
        "wget https://heibox.uni-heidelberg.de/f/95a3875771c040db959a/?dl=1\n",
        "mv index.html?dl=1 humanrights02.txt\n",
        "\n",
        "wget https://heibox.uni-heidelberg.de/f/cdf240db84ca4718b718/?dl=1\n",
        "mv index.html?dl=1 en1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMxbGb2-m58C"
      },
      "source": [
        "!head --lines=20 humanrights02.txt\n",
        "!wc humanrights02.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HYUJAY5rAte",
        "outputId": "2236c7f5-9aae-454f-ff28-7bfb5db72810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english en1984.txt >en1984_vert.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\treading parameters ...\n",
            "\ttagging ...\n",
            "121000\t finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PNvmwwVrwyn"
      },
      "source": [
        "!head --lines=20 en1984_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7stVR-G1rFat"
      },
      "source": [
        "!./treetagger/cmd/tree-tagger-english humanrights02.txt >humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf0ZClfLrZd3"
      },
      "source": [
        "!head --lines=20 humanrights02_vert.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC5cBgvas4vQ"
      },
      "source": [
        "## Armenian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW7HUG3TQzjU",
        "outputId": "e714f2fb-30cf-41ce-de66-4edff10c1179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# installing Armenian morphological analyser\n",
        "!git clone https://github.com/timarkh/uniparser-grammar-eastern-armenian"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'uniparser-grammar-eastern-armenian'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 181 (delta 12), reused 40 (delta 12), pack-reused 141\u001b[K\n",
            "Receiving objects: 100% (181/181), 52.66 MiB | 16.05 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgrVLqTTStuN",
        "outputId": "514da58f-2f5f-431f-f37b-a8cef13a9a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Python classes\n",
        "!pip3 install uniparser-eastern-armenian"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting uniparser-eastern-armenian\n",
            "  Downloading uniparser_eastern_armenian-2.1.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from uniparser-eastern-armenian) (5.9.0)\n",
            "Collecting uniparser-morph>=2.2.0\n",
            "  Downloading uniparser_morph-2.6.4-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->uniparser-eastern-armenian) (3.8.1)\n",
            "Installing collected packages: uniparser-morph, uniparser-eastern-armenian\n",
            "Successfully installed uniparser-eastern-armenian-2.1.2 uniparser-morph-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bALlnO8gY4cF"
      },
      "source": [
        "# disambiguation\n",
        "!sudo apt-get install cg3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5-Y0JQES0oT"
      },
      "source": [
        "from uniparser_eastern_armenian import EasternArmenianAnalyzer\n",
        "a = EasternArmenianAnalyzer()\n",
        "analyses = a.analyze_words('Ձևաբանություն')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1gZH7s3XfMR",
        "outputId": "54bd7eb4-9d19-47e9-b429-a34e3dc39af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for ana in analyses:\n",
        "    print(ana.wf, ana.lemma, ana.gramm, ana.gloss, ana.stem, ana.subwords, ana.wfGlossed, ana.otherData)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ձևաբանություն ձեւաբանություն N,inanim,sg,nom,nonposs morphology ձևաբանություն. [] ձևաբանություն [('trans_en', 'morphology')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqmYRwfBlbNo",
        "outputId": "b2a15a63-beac-4214-a501-17e7637e163a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dir(ana)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'add_gramm',\n",
              " 'add_lemma',\n",
              " 'add_other_data',\n",
              " 'append_subword_data',\n",
              " 'build_value',\n",
              " 'errorHandler',\n",
              " 'expand_lex_morphs',\n",
              " 'g',\n",
              " 'get_lemma',\n",
              " 'gloss',\n",
              " 'gramm',\n",
              " 'lemma',\n",
              " 'otherData',\n",
              " 'printableOtherFields',\n",
              " 'propertyFields',\n",
              " 'raise_error',\n",
              " 'rxLexTag',\n",
              " 'rxLexTagOtherField',\n",
              " 'rxMultipleCommas',\n",
              " 'stem',\n",
              " 'subwords',\n",
              " 'to_json',\n",
              " 'to_xml',\n",
              " 'verbosity',\n",
              " 'wf',\n",
              " 'wfGlossed',\n",
              " 'wfGlossedStd']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ddvunxGTXQf"
      },
      "source": [
        "analyses = a.analyze_words([['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']],\n",
        "                           format='xml')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOyUBXmTbep",
        "outputId": "db6ff95f-6035-4fc8-d7c8-692646840abc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<w><ana lex=\"եւ\" gr=\"CONJ\" parts=\"և\" gloss=\"and\" trans_en=\"and, too, either\"></ana>և</w>']\n",
            "['<w><ana lex=\"ես\" gr=\"PRON,S,hum,sg,nom\" parts=\"ես\" gloss=\"me\" trans_en=\"I\"></ana><ana lex=\"է\" gr=\"V,intr,prs,sg,2\" parts=\"ե-ս\" gloss=\"be-PRS.2SG\" trans_en=\"be\"></ana>Ես</w>', '<w><ana lex=\"սիրել\" gr=\"V,tr,cvb,ipfv\" parts=\"սիր-ում\" gloss=\"love-CVB.IPFV\" trans_en=\"love, have a passion/an affection for, like\"></ana>սիրում</w>', '<w><ana lex=\"է\" gr=\"V,intr,prs,sg,1\" parts=\"ե-մ\" gloss=\"be-PRS.1SG\" trans_en=\"be\"></ana>եմ</w>', '<w><ana lex=\"դու\" gr=\"PRON,S,hum,sg,dat\" parts=\"քեզ\" gloss=\"thou\" trans_en=\"you, thou\"></ana>քեզ</w>', '<w><ana lex=\"\" gr=\"\" parts=\"\" gloss=\"\"></ana>:</w>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWxToCMSTyL6"
      },
      "source": [
        "analyses = a.analyze_words(['Ձևաբանություն', [['և'], ['Ես', 'սիրում', 'եմ', 'քեզ', ':']]],\n",
        "                           format='json')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxEQfFZvT1KM",
        "outputId": "d710d1fd-adbc-471f-bc40-f75968527b93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for ana in analyses:\n",
        "    print(str(ana))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'wf': 'Ձևաբանություն', 'lemma': 'ձեւաբանություն', 'gramm': ['N', 'inanim', 'sg', 'nom', 'nonposs'], 'wfGlossed': 'ձևաբանություն', 'gloss': 'morphology', 'trans_en': 'morphology'}]\n",
            "[[[{'wf': 'և', 'lemma': 'եւ', 'gramm': ['CONJ'], 'wfGlossed': 'և', 'gloss': 'and', 'trans_en': 'and, too, either'}]], [[{'wf': 'Ես', 'lemma': 'ես', 'gramm': ['PRON', 'S', 'hum', 'sg', 'nom'], 'wfGlossed': 'ես', 'gloss': 'me', 'trans_en': 'I'}, {'wf': 'Ես', 'lemma': 'է', 'gramm': ['V', 'intr', 'prs', 'sg', '2'], 'wfGlossed': 'ե-ս', 'gloss': 'be-PRS.2SG', 'trans_en': 'be'}], [{'wf': 'սիրում', 'lemma': 'սիրել', 'gramm': ['V', 'tr', 'cvb', 'ipfv'], 'wfGlossed': 'սիր-ում', 'gloss': 'love-CVB.IPFV', 'trans_en': 'love, have a passion/an affection for, like'}], [{'wf': 'եմ', 'lemma': 'է', 'gramm': ['V', 'intr', 'prs', 'sg', '1'], 'wfGlossed': 'ե-մ', 'gloss': 'be-PRS.1SG', 'trans_en': 'be'}], [{'wf': 'քեզ', 'lemma': 'դու', 'gramm': ['PRON', 'S', 'hum', 'sg', 'dat'], 'wfGlossed': 'քեզ', 'gloss': 'thou', 'trans_en': 'you, thou'}], [{'wf': ':', 'lemma': '', 'gramm': [], 'wfGlossed': '', 'gloss': ''}]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWNEo_RwUcSB"
      },
      "source": [
        "# analysis with disambiguation\n",
        "analyses = a.analyze_words(['Ես', 'սիրում', 'եմ', 'քեզ'], disambiguate=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRb9dCQoUdJc",
        "outputId": "4dc1380e-c2be-457b-d5b6-7259ca356c28"
      },
      "source": [
        "for ana in analyses:\n",
        "    for wfo in ana:\n",
        "        print(wfo.wf, wfo.lemma, wfo.gramm, wfo.gloss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ես ես PRON,S,hum,sg,nom me\n",
            "Ես է V,intr,prs,sg,2 be-PRS.2SG\n",
            "սիրում սիրել V,tr,cvb,ipfv love-CVB.IPFV\n",
            "եմ է V,intr,prs,sg,1 be-PRS.1SG\n",
            "քեզ դու PRON,S,hum,sg,dat thou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vzlcQSQlw55",
        "outputId": "aea9b9a3-d5ea-4576-a2e3-24d2cf36e926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(wfo))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'uniparser_morph.wordform.Wordform'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0P_zV02ZxQ8"
      },
      "source": [
        "dir(wfo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzINXeL7s9EL"
      },
      "source": [
        "# downloading and analysing texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzA4Fg9tCaH"
      },
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/e0bfae444a5a4c76957b/?dl=1\n",
        "!mv index.html?dl=1 hy1984.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOXdvc_9uv0J"
      },
      "source": [
        "FInText = open('hy1984.txt','r')\n",
        "FOutText = open('hy1984_vert.txt','w')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdxZiI7ZyLGW"
      },
      "source": [
        "for SLine in FInText:\n",
        "    SLine = SLine.strip()\n",
        "    ListOfWords = re.split('[ ,\\.:;\\!\\(\\)\\\"\\[\\]՞՝«»\\-\\—՝։\\։]+', SLine) # tokenize: split on white spaces and punctuation\n",
        "    # if len(ListOfWords) > 0: FOutText.write(str(ListOfWords) + '\\n')\n",
        "    analyses = a.analyze_words(ListOfWords, disambiguate=False)\n",
        "    FOutText.write('<p>\\n')\n",
        "    for ana in analyses:\n",
        "        # for wfo in ana:\n",
        "        # how to type all variants + disambiguate ?\n",
        "        wfo = ana[0]\n",
        "        FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "        #    FOutText.write(wfo.wf + '\\t' + wfo.gramm + '\\t' + wfo.lemma + '\\t' + wfo.gloss + '\\n')\n",
        "    FOutText.write('</p>\\n')\n",
        "FOutText.flush()"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}