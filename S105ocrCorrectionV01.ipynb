{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORxeEWrRrAUOPbiphZyo40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S105ocrCorrectionV01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# correction of ocr-generated text \n",
        "- using correction dictionaries \n",
        "- using rules\n"
      ],
      "metadata": {
        "id": "pS0vQT9LRLss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi1gKbdQQyIF",
        "outputId": "4a7b8254-2ebc-4d68-fbbc-2dd6708add5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-20 11:48:02--  https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/b99b41c7-b368-4662-b8cd-72e45fe53a42/Parfum_Arm_ABBY.txt [following]\n",
            "--2023-03-20 11:48:03--  https://heibox.uni-heidelberg.de/seafhttp/files/b99b41c7-b368-4662-b8cd-72e45fe53a42/Parfum_Arm_ABBY.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 867013 (847K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 846.69K   786KB/s    in 1.1s    \n",
            "\n",
            "2023-03-20 11:48:04 (786 KB/s) - ‘index.html?dl=1’ saved [867013/867013]\n",
            "\n",
            "--2023-03-20 11:48:04--  https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/cea91cfd-ec25-4ccd-bff1-8f794cf8c49f/Parfum_Armenian_uncorrected.txt [following]\n",
            "--2023-03-20 11:48:05--  https://heibox.uni-heidelberg.de/seafhttp/files/cea91cfd-ec25-4ccd-bff1-8f794cf8c49f/Parfum_Armenian_uncorrected.txt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 854251 (834K) [text/plain]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 834.23K   781KB/s    in 1.1s    \n",
            "\n",
            "2023-03-20 11:48:06 (781 KB/s) - ‘index.html?dl=1’ saved [854251/854251]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Arm_ABBY.txt\n",
        "\n",
        "!wget https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian_uncorrected.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dealing with Armenian OCR output with line breaks (is it correct?)\n",
        "\n",
        "FName = 'Parfum_Armenian_uncorrected.txt'\n",
        "FNameOut = 'Parfum_Armenian.txt'\n",
        "\n",
        "FIn = open(FName, 'r')\n",
        "FOut = open(FNameOut, 'w')\n",
        "\n",
        "for SLine in FIn:\n",
        "    SLine = SLine.strip()\n",
        "    if SLine == '': \n",
        "        FOut.write('\\n\\n')\n",
        "        continue\n",
        "    if SLine[-1] == '-':\n",
        "        SLine2write = SLine[:-1]\n",
        "        FOut.write(SLine2write)\n",
        "        continue\n",
        "\n",
        "    FOut.write(SLine + ' ')\n",
        "FOut.flush()\n",
        "\n"
      ],
      "metadata": {
        "id": "LvHpRxM-ncIX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Arm_ABBY.txt\n",
        "!wc Parfum_Armenian_uncorrected.txt\n",
        "!wc Parfum_Armenian.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKaXMp2uSDZk",
        "outputId": "a70e6f9e-a976-4bf6-f94c-5c4ebda8f5b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1489  68852 867013 Parfum_Arm_ABBY.txt\n",
            " 13592  72207 854251 Parfum_Armenian_uncorrected.txt\n",
            "  6126  69006 849250 Parfum_Armenian.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/c977e87cf2b244e6801b/?dl=1\n",
        "!mv index.html?dl=1 KorpusARM.tgz\n"
      ],
      "metadata": {
        "id": "z-5mB-CUSTTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf KorpusARM.tgz\n",
        "!mkdir KorpusARM1\n",
        "!mkdir KorpusARM1/stage01\n",
        "# concatenating files\n",
        "!cat korpusARM/hyFiktion/* >KorpusARM1/stage01/hyFiktion.txt\n",
        "!cat korpusARM/hyNatur/* >KorpusARM1/stage01/hyNatur.txt\n",
        "!cat korpusARM/hyRecht/* >KorpusARM1/stage01/hyRecht.txt\n",
        "!mkdir KorpusARM1/stage02\n",
        "\n",
        "# function for Armenian line breaks:\n",
        "\n",
        "def correctLineBreaksHY(FName, FNameOut):\n",
        "    FIn = open(FName, 'r')\n",
        "    FOut = open(FNameOut, 'w')\n",
        "    countHyphens = 0\n",
        "    for SLine in FIn:\n",
        "        SLine = SLine.strip()\n",
        "        if SLine == '': \n",
        "            FOut.write('\\n\\n')\n",
        "            continue\n",
        "        if SLine[-1] == '-':\n",
        "            SLine2write = SLine[:-1]\n",
        "            FOut.write(SLine2write)\n",
        "            countHyphens +=1\n",
        "            continue\n",
        "        FOut.write(SLine + ' ')\n",
        "    FOut.flush()\n",
        "    print(str(countHyphens) + ' hyphens corrected')\n",
        "    return\n",
        "\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyFiktion.txt', 'KorpusARM1/stage02/hyFiktion.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyNatur.txt', 'KorpusARM1/stage02/hyNatur.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyRecht.txt', 'KorpusARM1/stage02/hyRecht.txt')\n"
      ],
      "metadata": {
        "id": "pywrhPCXSVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wc KorpusARM1/stage02/hyFiktion.txt\n",
        "!wc KorpusARM1/stage02/hyNatur.txt\n",
        "!wc KorpusARM1/stage02/hyRecht.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUqWQMklS2oD",
        "outputId": "0ec60569-c8d0-4cf5-c2b7-6eb183b419c2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6208   92131 1081755 KorpusARM1/stage02/hyFiktion.txt\n",
            "  3642  67142 870081 KorpusARM1/stage02/hyNatur.txt\n",
            "   8940   86621 1288655 KorpusARM1/stage02/hyRecht.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "!wget https://heibox.uni-heidelberg.de/f/14706c04a4024b2f937d/?dl=1\n",
        "!mv index.html?dl=1 Pilot-Corrections-all.tsv\n",
        "!wc Pilot-Corrections-all.tsv"
      ],
      "metadata": {
        "id": "n2qCSxAKT8qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrections(colNumberOri, colNumberCorrect, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n",
        "\n",
        "def readCorrectionsFrq(colNumberOri, colNumberCorrect, colNumberFrq, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.rstrip('\\n')\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            SFrq = LLine[colNumberFrq]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]', f'{SFrq}')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect, SFrq in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\t{SFrq}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n"
      ],
      "metadata": {
        "id": "cuDRPHpQUGxD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LTWrongCorrectWordF, DWrongCorrectWordF = readCorrectionsFrq(1, 4, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-WordForm.tsv')\n",
        "# LTWrongCorrectLemmaF, DWrongCorrectLemmaF = readCorrectionsFrq(3, 6, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-Lemma.tsv')\n",
        "print(LTWrongCorrectWordF)\n",
        "# print(LTWrongCorrectLemmaF)\n",
        "# ինձ|ինչ\n",
        "# առջև|առջևից\n",
        "# ինչ|ինձ\n",
        "# ինչ|ես\n",
        "# գիտենալ|իմանալ\n"
      ],
      "metadata": {
        "id": "6q3Qd74vUVET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(DWrongCorrectWordF))\n",
        "print(len(DWrongCorrectLemmaF))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_FYBzw7U42k",
        "outputId": "0a06fedd-364f-4739-d3a2-a4f3a0861139"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for i in range(5):\n",
        "    LKeys = list(DWrongCorrectLemmaF.keys())\n",
        "    SKey = LKeys[i]\n",
        "    SVal = DWrongCorrectWordF[SKey]\n",
        "    print(f'{SKey} {SVal}\\n')\n",
        "'''\n",
        " "
      ],
      "metadata": {
        "id": "T7X7uZJsWajb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, sys\n",
        "\n",
        "def tokenizeTextHY(SFIn):\n",
        "    LLParagraphs = []\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        for SLine in FIn:\n",
        "            SLine = SLine.strip()\n",
        "            LLine = re.split('([ ,\\.\\:։;\\'\\\"\\(\\)\\-\\–\\!\\?\\{\\}\\t\\«\\»]+)', SLine)\n",
        "            if LLine: LLParagraphs.append(LLine)\n",
        "    return LLParagraphs\n",
        "\n",
        "def printLLParagraphs(SFIn, SFOut, DCorrections1 = None, DCorrections2 = None):\n",
        "    LLParagraphs = tokenizeTextHY(SFIn)\n",
        "    LCorrected = []\n",
        "    FOut = open(SFOut, 'w')\n",
        "    for LPara in LLParagraphs:\n",
        "        LParaNew = []\n",
        "        FOut.write('<p>\\n')\n",
        "        \n",
        "        for el in LPara:\n",
        "            # if el == ' ': continue\n",
        "            if DCorrections1:\n",
        "                if el in DCorrections1:\n",
        "                    elCorrect = DCorrections1[el]\n",
        "                    LCorrected.append((el, elCorrect, LPara))\n",
        "                else:\n",
        "                    elCorrect = el\n",
        "            if DCorrections2:\n",
        "                if el in DCorrections2:\n",
        "                    elCorrect = DCorrections2[el]\n",
        "                    LCorrected.append((el, elCorrect, LPara))\n",
        "                else:\n",
        "                    elCorrect = el                    \n",
        "            LParaNew.append(elCorrect)\n",
        "\n",
        "        SParaNew = ' '.join(LParaNew)\n",
        "        FOut.write(f'{SParaNew}\\n')\n",
        "\n",
        "        FOut.write('</p>\\n')\n",
        "    FOut.flush()\n",
        "    return LCorrected"
      ],
      "metadata": {
        "id": "93xc2P0iX1rS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1 = printLLParagraphs('/content/Parfum_Arm_ABBY.txt', '/content/Parfum_Arm_ABBY-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/Parfum_Arm_ABBY-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "\n",
        "LCorrected2 = printLLParagraphs('/content/Parfum_Armenian.txt', '/content/Parfum_Armenian-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected2))\n",
        "if LCorrected2:\n",
        "    FOut2 = open('/content/Parfum_Armenian-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut2.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ZpAZaidUad",
        "outputId": "33b0aeb8-47b1-4035-9dde-8c30f340e3d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyFiktion.txt', '/content/KorpusARM1/stage02/hyFiktion-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyFiktion-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NluaBoyPwwbd",
        "outputId": "ec8901f2-2c63-4912-b4c3-b1abdc1a8064"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyNatur.txt', '/content/KorpusARM1/stage02/hyNatur-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyNatur-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206ue_Vvw8Rt",
        "outputId": "a39e3df8-82cd-49a0-c9bf-5600b910f354"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyRecht.txt', '/content/KorpusARM1/stage02/hyRecht-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyRecht-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4DLKC4w85F",
        "outputId": "8ecac753-adbd-414b-e74f-34f98edef0a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1534\n"
          ]
        }
      ]
    }
  ]
}