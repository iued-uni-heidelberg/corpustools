{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/comet_installation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snDEkpImrK0C"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unbabel-comet"
      ],
      "metadata": {
        "id": "kLwwHrB5rQu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Unbabel/COMET"
      ],
      "metadata": {
        "id": "cMqOrTXorXEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install poetry"
      ],
      "metadata": {
        "id": "sXisbFDArm6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./COMET/\n",
        "!pwd\n",
        "!poetry install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HxCAg72r_-X",
        "outputId": "9ecebca1-4bc8-4562-bdd6-cbe034c86789"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COMET\n",
            "/content/COMET\n",
            "Creating virtualenv \u001b[36munbabel-comet-uyJf9FjH-py3.8\u001b[39m in /root/.cache/pypoetry/virtualenvs\n",
            "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
            "\n",
            "\u001b[39;1mPackage operations\u001b[39;22m: \u001b[34m58\u001b[39m installs, \u001b[34m0\u001b[39m updates, \u001b[34m0\u001b[39m removals\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7MyerCOrw6n",
        "outputId": "51c13c1f-18b8-4670-d1a1-750ff832265a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod a+rwx /content/COMET/comet/cli/score.py"
      ],
      "metadata": {
        "id": "VVa96dPks6tX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFhISPuwtkLa",
        "outputId": "543ea61a-f5e4-49db-c4d3-6d36ec3da96c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python:./comet/cli/score.py\"\n",
        "# !PYTHONPATH=. ./comet/cli/score.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBSTZLrnsp9B",
        "outputId": "443fff1f-64b4-495d-fba2-b56045cd6ce0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python:./comet/cli/score.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js1u83GWt2_3",
        "outputId": "853da147-74bf-4b4c-b7e8-f2952eb8a805"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python:./comet/cli/score.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e \"Dem Feuer konnte Einhalt geboten werden\\nSchulen und Kindergärten wurden eröffnet.\" >> src.de\n",
        "!echo -e \"The fire could be stopped\\nSchools and kindergartens were open\" >> hyp1.en\n",
        "!echo -e \"The fire could have been stopped\\nSchools and pre-school were open\" >> hyp2.en\n",
        "!echo -e \"They were able to control the fire.\\nSchools and kindergartens opened\" >> ref.en"
      ],
      "metadata": {
        "id": "m8-mpjhjtMQr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp1.en -r ref.en --gpus 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT3FjFRSuP22",
        "outputId": "fa0e349d-9888-41dd-d367-c51a88fb82d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "wmt20-comet-da.tar.gz: 1.79GB [00:42, 42.5MB/s]                \n",
            "Downloading (…)tencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 121MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 616/616 [00:00<00:00, 362kB/s]\n",
            "Downloading (…)\"pytorch_model.bin\";: 100% 2.24G/2.24G [00:48<00:00, 46.4MB/s]\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Predicting DataLoader 0: 100% 1/1 [00:02<00:00,  2.37s/it]\n",
            "hyp1.en\tSegment 0\tscore: 0.1902\n",
            "hyp1.en\tSegment 1\tscore: 0.9157\n",
            "hyp1.en\tscore: 0.5529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp2.en -r ref.en --gpus 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0np0nGXuo8H",
        "outputId": "36f80c05-0204-45df-a95a-3a8fc978e995"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Predicting DataLoader 0: 100% 1/1 [00:02<00:00,  2.40s/it]\n",
            "hyp2.en\tSegment 0\tscore: 0.0877\n",
            "hyp2.en\tSegment 1\tscore: 0.5022\n",
            "hyp2.en\tscore: 0.2950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/84df50ae57cf4851b4ba/?dl=1"
      ],
      "metadata": {
        "id": "TRCKtpXr-TLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 exArticles.zip"
      ],
      "metadata": {
        "id": "J-VzSNox-Z94"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading articles..."
      ],
      "metadata": {
        "id": "X2t6JXQW_ey5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s /content/article-aerzteblatt-2023-01-101-de.txt -t /content/article-aerzteblatt-2023-01-101-en-googlemt.txt -r /content/article-aerzteblatt-2023-01-101-en.txt --gpus 0"
      ],
      "metadata": {
        "id": "s27T5PQfFCj2",
        "outputId": "ac314615-ccc4-4356-b883-c9e3caf313f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Predicting DataLoader 0:  38% 5/13 [00:51<01:22, 10.33s/it]"
          ]
        }
      ]
    }
  ]
}