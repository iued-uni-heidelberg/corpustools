{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3lBstJprS+LArYEwOSTNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S105ocrCorrectionV04a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# correction of ocr-generated text\n",
        "- using correction dictionaries\n",
        "- using rules\n"
      ],
      "metadata": {
        "id": "pS0vQT9LRLss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, os, sys\n"
      ],
      "metadata": {
        "id": "2yzWvD6lW-78"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi1gKbdQQyIF"
      },
      "outputs": [],
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Arm_ABBY.txt\n",
        "\n",
        "!wget https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian_uncorrected.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dealing with Armenian OCR output with line breaks (is it correct?)\n",
        "\n",
        "FName = 'Parfum_Armenian_uncorrected.txt'\n",
        "FNameOut = 'Parfum_Armenian.txt'\n",
        "\n",
        "FIn = open(FName, 'r')\n",
        "FOut = open(FNameOut, 'w')\n",
        "\n",
        "for SLine in FIn:\n",
        "    SLine = SLine.strip()\n",
        "    if SLine == '':\n",
        "        FOut.write('\\n\\n')\n",
        "        continue\n",
        "    if SLine[-1] == '-':\n",
        "        SLine2write = SLine[:-1]\n",
        "        FOut.write(SLine2write)\n",
        "        continue\n",
        "\n",
        "    FOut.write(SLine + ' ')\n",
        "FOut.flush()\n",
        "\n"
      ],
      "metadata": {
        "id": "LvHpRxM-ncIX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Arm_ABBY.txt\n",
        "!wc Parfum_Armenian_uncorrected.txt\n",
        "!wc Parfum_Armenian.txt"
      ],
      "metadata": {
        "id": "bKaXMp2uSDZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/c977e87cf2b244e6801b/?dl=1\n",
        "!mv index.html?dl=1 KorpusARM.tgz\n"
      ],
      "metadata": {
        "id": "z-5mB-CUSTTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf KorpusARM.tgz\n",
        "!mkdir KorpusARM1\n",
        "!mkdir KorpusARM1/stage01\n",
        "# concatenating files\n",
        "!cat korpusARM/hyFiktion/* >KorpusARM1/stage01/hyFiktion.txt\n",
        "!cat korpusARM/hyNatur/* >KorpusARM1/stage01/hyNatur.txt\n",
        "!cat korpusARM/hyRecht/* >KorpusARM1/stage01/hyRecht.txt\n",
        "!mkdir KorpusARM1/stage02\n",
        "\n",
        "# function for Armenian line breaks:\n",
        "\n",
        "def correctLineBreaksHY(FName, FNameOut):\n",
        "    FIn = open(FName, 'r')\n",
        "    FOut = open(FNameOut, 'w')\n",
        "    countHyphens = 0\n",
        "    for SLine in FIn:\n",
        "        SLine = SLine.strip()\n",
        "        if SLine == '':\n",
        "            FOut.write('\\n\\n')\n",
        "            continue\n",
        "        if SLine[-1] == '-':\n",
        "            SLine2write = SLine[:-1]\n",
        "            FOut.write(SLine2write)\n",
        "            countHyphens +=1\n",
        "            continue\n",
        "        FOut.write(SLine + ' ')\n",
        "    FOut.flush()\n",
        "    print(str(countHyphens) + ' hyphens corrected')\n",
        "    return\n",
        "\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyFiktion.txt', 'KorpusARM1/stage02/hyFiktion.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyNatur.txt', 'KorpusARM1/stage02/hyNatur.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyRecht.txt', 'KorpusARM1/stage02/hyRecht.txt')\n"
      ],
      "metadata": {
        "id": "pywrhPCXSVjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wc KorpusARM1/stage02/hyFiktion.txt\n",
        "!wc KorpusARM1/stage02/hyNatur.txt\n",
        "!wc KorpusARM1/stage02/hyRecht.txt"
      ],
      "metadata": {
        "id": "kUqWQMklS2oD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4dbf59d-6737-406b-965d-1168367513ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6208   92131 1081755 KorpusARM1/stage02/hyFiktion.txt\n",
            "  3642  67142 870081 KorpusARM1/stage02/hyNatur.txt\n",
            "   8940   86621 1288655 KorpusARM1/stage02/hyRecht.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "# !wget https://heibox.uni-heidelberg.de/f/14706c04a4024b2f937d/?dl=1\n",
        "# without ճեր\n",
        "!wget https://heibox.uni-heidelberg.de/f/4a24540473564788853d/?dl=1\n",
        "\n",
        "!mv index.html?dl=1 Pilot-Corrections-all.tsv\n",
        "!wc Pilot-Corrections-all.tsv\n",
        "\n"
      ],
      "metadata": {
        "id": "n2qCSxAKT8qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading wikipedia\n",
        "### downloading Armenian Wikipedia\n",
        "!wget https://heibox.uni-heidelberg.de/f/d1f866a61bd545318213/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles.txt.gz\n",
        "!gunzip hywiki-20221101-pages-articles.txt.gz\n"
      ],
      "metadata": {
        "id": "e-6E67OXMyaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the length of wikipedia\n",
        "!wc hywiki-20221101-pages-articles.txt"
      ],
      "metadata": {
        "id": "EiQRfY_eM892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89909297-efe8-4993-9e4f-a62c532772bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2446411  56341171 803098410 hywiki-20221101-pages-articles.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrections(colNumberOri, colNumberCorrect, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\n')\n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n",
        "\n",
        "def readCorrectionsFrq(colNumberOri, colNumberCorrect, colNumberFrq, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    '''\n",
        "    if type(LTWrongCorrect) == list:\n",
        "        pass\n",
        "    '''\n",
        "\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.rstrip('\\n')\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            SFrq = LLine[colNumberFrq]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]', f'{SFrq}')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect, SFrq in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\t{SFrq}\\n')\n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect\n"
      ],
      "metadata": {
        "id": "cuDRPHpQUGxD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading corrections for word forms, with the purpose of generalizing them\n",
        "# goal: to display candidates for correction -- based on existing corrections (?)\n",
        "LTWrongCorrectWordF, DWrongCorrectWordF = readCorrectionsFrq(1, 4, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-WordForm.tsv')\n",
        "# LTWrongCorrectLemmaF, DWrongCorrectLemmaF = readCorrectionsFrq(3, 6, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-Lemma.tsv')\n",
        "print(LTWrongCorrectWordF)\n",
        "# print(LTWrongCorrectLemmaF)\n",
        "# ինձ|ինչ\n",
        "# առջև|առջևից\n",
        "# ինչ|ինձ\n",
        "# ինչ|ես\n",
        "# գիտենալ|իմանալ\n"
      ],
      "metadata": {
        "id": "6q3Qd74vUVET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1085cd8-0a27-4eb4-ade8-1ce4e6a58aaa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ինճ\tինձ\tինչ\n",
            "առջնից\tառջև\tառջևից\n",
            "ինճ\tինչ\tինձ\n",
            "171\n",
            "[('[մերճակա]', '[մերձակա]', '4'), ('[առջն]', '[առջև]', '4'), ('[թեթնություն]', '[թեթևություն]', '4'), ('[Եթենա]', '[եթե նա]', '4'), ('[ննա]', '[նա]', '4'), ('[ճեռքերն]', '[ձեռքից]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճեռքով]', '[ձեռքով]', '4'), ('[այլնս]', '[այլևս]', '4'), ('[ետնի]', '[ետևի]', '4'), ('[կեղնները]', '[կեղևները]', '4'), ('[ճկան]', '[ձկան]', '4'), ('[ննա]', '[նա]', '4'), ('[բանաձնի]', '[բանաձևի]', '4'), ('[առնտրական]', '[առևտրական]', '4'), ('[արնելյան]', '[արևելյան]', '4'), ('[կուղնորվի]', '[կուղևորվի]', '4'), ('[նս]', '[ևս]', '4'), ('[հետնեց]', '[հետևել]', '4'), ('[նուխիսկ]', '[նույնիսկ]', '4'), ('[երնույթ]', '[երևույթ]', '4'), ('[քրտնքով]', '[քրտինքով]', '4'), ('[արվարճանում]', '[արվարձանում]', '4'), ('[անճամբ]', '[անձամբ]', '4'), ('[ճայնը]', '[ձայնը]', '4'), ('[ճգվում]', '[ձգվում]', '4'), ('[ճիու]', '[ձիու]', '4'), ('[դարճնում]', '[դարձնում]', '4'), ('[ուղնորվում]', '[ուղևորվում ]', '4'), ('[իջնանատան]', '[իջևանատան]', '4'), ('[ճգտում]', '[ձգտում]', '4'), ('[դրսնորում]', '[դրսևորում]', '3'), ('[արվարճանի]', '[արվարձանի]', '3'), ('[ետնում]', '[ետևում]', '3'), ('[ճնավորված]', '[ձևավորված]', '3'), ('[Հետնաբար]', '[հետևաբար]', '3'), ('[այլնս]', '[այլևս]', '3'), ('[Շավանաբար]', '[հավանաբար]', '3'), ('[սկզբիցնեթ]', '[սկզբիցևեթ]', '3'), ('[միջն]', '[միջև]', '3'), ('[համաճայնության]', '[համաձայնություն]', '3'), ('[Թերնս]', '[թերևս]', '3'), ('[տերնի]', '[տերև]', '3'), ('[թնատակերի]', '[թևատակ]', '3'), ('[դոււս]', '[դուրս]', '3'), ('[բարճրացավ]', '[բարձրանալ]', '3'), ('[երկարատն]', '[երկարատև]', '3'), ('[նախնառաջ]', '[նախևառաջ]', '3'), ('[ներքնից]', '[ներքև]', '3'), ('[առջնից]', '[առջև]', '3'), ('[ճեռնոցագործական]', '[ձեռնոցագործական]', '3'), ('[հարնան]', '[գարնան]', '3'), ('[ճգտումը]', '[ձգտումը]', '3'), ('[առջնում]', '[առջևում]', '3'), ('[ճմռանը]', '[ձմռանը]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[ծանրութեթն]', '[ծանրութեթև]', '3'), ('[ճագի]', '[ձագի]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[ճեռքն]', '[ձեռքն]', '3'), ('[արճագանք]', '[արձագանք]', '3'), ('[ճմեռ]', '[ձմեռ]', '2'), ('[պառկածէրգերեզմանատանվրա]', '[պառկած էր գերեզմանատան վրա]', '2'), ('[ճմերուկների]', '[ձմերուկների]', '2'), ('[ունողկալի]', '[ու նողկալի]', '2'), ('[գլխապտույտնե]', '[գլխապտույտներ]', '2'), ('[ճայնի]', '[ձայնի]', '2'), ('[ճկների]', '[ձկների]', '2'), ('[այլնայլ]', '[այլևայլ]', '2'), ('[ճնականություններից]', '[ձևականություններից]', '2'), ('[չուննորներին]', '[չունևորներին]', '2'), ('[արճակվող]', '[արձակվել]', '2'), ('[խամարդ]', '[տղամարդ]', '2'), ('[Միգուցենա]', '[միգուցե նա]', '2'), ('[ջղաճգութու]', '[Ջղաձգություն]', '2'), ('[Դետեսնում]', '[դե տեսնում ]', '2'), ('[բարճրաց]', '[բարձրացնել]', '2'), ('[ինճ]', '[ինձ]', '2'), ('[Որովհետն]', '[որովհետև]', '2'), ('[ննույնիսկ]', '[նույնիսկ]', '2'), ('[հուսահատեգնում]', '[հեւսահատեցնել]', '2'), ('[որնրան]', '[որ նրան]', '2'), ('[Ջգազմունքներից]', '[Զգացմունք]', '2'), ('[մնահավատությոն]', '[սնահավատություն]', '2'), ('[հեթանոսա]', '[հեթանոսացում]', '2'), ('[խարույկՄ]', '[խարույկ]', '2'), ('[տուցում]', '[մատուցում]', '2'), ('[նականռթյան]', '[բանականություն]', '2'), ('[անձր]', '[անձ, անձրև]', '2'), ('[տարօրի]', '[տարօրինակ]', '2'), ('[թնիկները]', '[թևիկ]', '2'), ('[աստվածավախու]', '[աստվածավախություն]', '2'), ('[բարճր]', '[բարձր]', '2'), ('[լավէ]', '[լավ է]', '2'), ('[Թռենել]', '[թռնել]', '2'), ('[հանճնեց]', '[հանձնել]', '2'), ('[Դհյոյում]', '[Դյո]', '2'), ('[տակիզ]', '[տակից]', '2'), ('[առջն]', '[առջև]', '36'), ('[ետնից]', '[ետևից]', '30'), ('[միջն]', '[միջև]', '22'), ('[այնուհետն]', '[այնուհետև]', '22'), ('[բացարճակապես]', '[բացարձակապես]', '21'), ('[որնէ]', '[որևէ]', '20'), ('[այլնս]', '[այլևս]', '19'), ('[թեթն]', '[թեթև]', '18'), ('[թեթնակի]', '[թեթևակի]', '17'), ('[որնէ]', '[որևէ]', '16'), ('[ետնում]', '[ետևում]', '16'), ('[արնի]', '[արևի]', '14'), ('[միննույն]', '[միևնույն]', '13'), ('[վերնում]', '[վերևում]', '13'), ('[ինճ]', '[ինչ]', '13'), ('[արճակում]', '[արձակում]', '12'), ('[թերնս]', '[թերևս]', '12'), ('[երբնիցե]', '[երբևիցե]', '11'), ('[ճեռքը]', '[ձեռքը]', '10'), ('[երնակայության]', '[երևակայության]', '10'), ('[արնմուտք]', '[արևմուտք]', '10'), ('[ճեռք]', '[ձեռք]', '10'), ('[ճեռքի]', '[ձեռքի]', '9'), ('[ճայնով]', '[ձայնով]', '9'), ('[նան]', '[նաև]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[ճեռքերը]', '[ձեռքերը]', '8'), ('[հետնում]', '[հետևում]', '8'), ('[արճակող]', '[արձակող]', '8'), ('[որնիցե]', '[որևիցե]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[այլնս]', '[այլևս]', '8'), ('[ճեռքին]', '[ձեռքին]', '7'), ('[արնմտյան]', '[արևմտյան]', '7'), ('[այլես]', '[այլևս]', '7'), ('[Նախնառաջ]', '[նախևառաջ]', '7'), ('[հոգնոր]', '[հոգևոր]', '6'), ('[ճեռքերով]', '[ձեռքերով]', '6'), ('[ներքնում]', '[ներքևում]', '6'), ('[համարճակվում]', '[համարձակվում]', '5'), ('[արնելք]', '[արևելք]', '5'), ('[առանճին]', '[առանձին]', '5'), ('[արնմուտքից]', '[արևմուտքից]', '5'), ('[երնակայական]', '[երևակայական]', '5'), ('[թնածում]', '[թևածում]', '5'), ('[բանաճնի]', '[բանաձևի]', '5'), ('[դարճավ]', '[դարձավ]', '5'), ('[բանաճնը]', '[բանաձևը]', '5'), ('[թեթնացած]', '[թեթևացած]', '5'), ('[հետնելով]', '[հետևելով]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[կարնոր]', '[կարևոր]', '5'), ('[ճիու]', '[ձիու]', '5'), ('[հեղճուցիչ]', '[հեղձուցիչ]', '5'), ('[անճնական]', '[անձնական]', '5'), ('[առջնից]', '[առջևից]', '3'), ('[երնում]', '[երևում]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[բանաձնը]', '[բանաձևը]', '3'), ('[եթենա]', '[եթե]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճն]', '[փորձն]', '3'), ('[բանաձն]', '[բանաձևն]', '3'), ('[բանաճն]', '[բանաձևն]', '3'), ('[բարճրացնել]', '[բարձրացնել]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[բացարճակ]', '[բացարձակ]', '3'), ('[ճգտելով]', '[ձգտելով]', '3'), ('[բանաճներ]', '[բանաձևեր]', '3'), ('[թեն]', '[թեև]', '3'), ('[տերնները]', '[տերևերը]', '3'), ('[բարճունքներում]', '[բարձունքներում]', '3'), ('[առնտուրը]', '[առևտուրը]', '3'), ('[անճամբ]', '[անձամբ]', '3'), ('[օթնան]', '[օթևան]', '3'), ('[բանաճներով]', '[բանաձներով]', '3'), ('[արճակել]', '[արձակել]', '3'), ('[բնեռը]', '[բևեռը]', '3'), ('[օճեր]', '[օձեր]', '3'), ('[ոջ]', '[ոչ]', '3'), ('[անձրնը]', '[անձրևը]', '3'), ('[թեթն]', '[թեթև]', '3'), ('[ճգում]', '[ձգում]', '3'), ('[տաքագնում]', '[տաքացնում]', '3'), ('[Հնայած]', '[Չնայած]', '3'), ('[ճեռքերի]', '[Ձեռքերի]', '3'), ('[այխքան]', '[այդքան]', '3'), ('[ճնացրեց]', '[ձևացրեց]', '3'), ('[երնակայությունների]', '[երևակայությունների]', '3'), ('[առջն]', '[առջև]', '3'), ('[բարճր]', '[բարձր]', '3')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(DWrongCorrectWordF))\n",
        "# print(len(DWrongCorrectLemmaF))\n"
      ],
      "metadata": {
        "id": "-_FYBzw7U42k",
        "outputId": "74872458-5e3a-427a-bbe7-a93922183ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in sorted(DWrongCorrectWordF.items()):\n",
        "    print(f'{key}\\t{value}')"
      ],
      "metadata": {
        "id": "pT2fX38FAVve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "for i in range(5):\n",
        "    LKeys = list(DWrongCorrectLemmaF.keys())\n",
        "    SKey = LKeys[i]\n",
        "    SVal = DWrongCorrectWordF[SKey]\n",
        "    print(f'{SKey} {SVal}\\n')\n",
        "'''\n",
        ""
      ],
      "metadata": {
        "id": "T7X7uZJsWajb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section applies corrections to an Armenian texts and records which words have been corrected"
      ],
      "metadata": {
        "id": "tV6irX9rkiE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Armenian tokenization\n",
        "def tokenizeTextHY(SFIn):\n",
        "    LLParagraphs = []\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        countpara = 0\n",
        "        for SLine in FIn:\n",
        "            countpara += 1\n",
        "            if countpara % 100000 == 0: print(countpara)\n",
        "            SLine = SLine.strip()\n",
        "            if SLine == '': continue\n",
        "            LLine = re.split('([ ,\\.\\:։;\\'\\\"\\(\\)\\-\\–\\!\\?\\{\\}\\t\\«\\»]+)', SLine)\n",
        "            # if LLine == '': continue\n",
        "            if LLine: LLParagraphs.append(LLine)\n",
        "    return LLParagraphs\n",
        "\n",
        "\n",
        "# def printLLParagraphs(SFIn, SFOut, DCorrections1 = None, DCorrections2 = None):\n",
        "def printLLParagraphs(SFIn, SFOut, DCorrections1 = None):\n",
        "    DErrors = {}\n",
        "    LLParagraphs = tokenizeTextHY(SFIn)\n",
        "    LCorrected = []\n",
        "    FOut = open(SFOut, 'w')\n",
        "    for LPara in LLParagraphs:\n",
        "        # if LPara == [] or LPara == ['']: continue\n",
        "        if LPara == []: continue\n",
        "        # FOut.write(str(LPara) + '\\n')\n",
        "        LParaNew = []\n",
        "        # FOut.write('<p>\\n')\n",
        "\n",
        "        # for each word\n",
        "        i = 0 # counting words\n",
        "        for el in LPara:\n",
        "            i+=1 # index of next word\n",
        "            # print(el, i)\n",
        "            # if el == ' ': continue\n",
        "            # if there is no correction dictionary, then just copy the string -- if dictionary is not provided\n",
        "            if not DCorrections1:\n",
        "                elCorrect = el\n",
        "                continue\n",
        "\n",
        "            if el in DCorrections1:\n",
        "                iStart = i-5\n",
        "                if iStart <0: iStart = 0\n",
        "                iFinish = i+5\n",
        "                # if iFinish >len(LPara): iFinish = len(LPara)\n",
        "                LContext = LPara[iStart : iFinish]\n",
        "                elCorrect = DCorrections1[el]\n",
        "                LCorrected.append((el, elCorrect, LContext, LPara)) # word context for the corrected word\n",
        "\n",
        "            else:\n",
        "                elCorrect = el\n",
        "\n",
        "            LParaNew.append(elCorrect)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        SParaNew = ' '.join(LParaNew)\n",
        "        FOut.write(f'{SParaNew}\\n')\n",
        "\n",
        "        # FOut.write('</p>\\n')\n",
        "    FOut.flush()\n",
        "    return LCorrected, DErrors"
      ],
      "metadata": {
        "id": "93xc2P0iX1rS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printCorrections(LCorrected, SFOut):\n",
        "    FOut1 = open(SFOut, 'w')\n",
        "    for (el, elCorr, LContext, LPara) in sorted(LCorrected):\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)\n",
        "        FOut1.write( f'{el} \\t {elCorr} \\n\\tcontext: {SContext} \\n\\tparagraph: {SPara}\\n\\n' )\n",
        "    return"
      ],
      "metadata": {
        "id": "biy2TG4EX19T"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head --lines=40 /content/Parfum_Armenian.txt"
      ],
      "metadata": {
        "id": "D-rqBQ6nmn_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LCorrected1, DErrors1 = printLLParagraphs('/content/Parfum_Arm_ABBY.txt', '/content/Parfum_Arm_ABBY-corrected.txt', DWrongCorrectWordF)\n",
        "printCorrections(LCorrected1, '/content/Parfum_Arm_ABBY-changes.txt')\n",
        "print(len(LCorrected1))\n",
        "LCorrected2, DErrors2 = printLLParagraphs('/content/Parfum_Armenian.txt', '/content/Parfum_Armenian-corrected.txt', DWrongCorrectWordF)\n",
        "printCorrections(LCorrected2, '/content/Parfum_Armenian-changes.txt')\n",
        "print(len(LCorrected2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ZpAZaidUad",
        "outputId": "6f0b4059-a327-4c40-f9aa-0a667031fe69"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "print(len(LCorrected1))\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/Parfum_Arm_ABBY-changes.txt', 'w')\n",
        "    for (el, elCorr, LContext, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)\n",
        "        FOut1.write( f'{el}\\t{elCorr}\\t{SContext}\\t{SPara}\\n\\n' )\n",
        "\n",
        "print(len(LCorrected2))\n",
        "if LCorrected2:\n",
        "    FOut2 = open('/content/Parfum_Armenian-changes.txt', 'w')\n",
        "    for (el, elCorr, LContext, LPara) in LCorrected2:\n",
        "        SPara = ''.join(LPara)\n",
        "        SContext = ''.join(LContext)\n",
        "        FOut2.write( f'{el}\\t{elCorr}\\t{SContext}\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyFiktion-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyNatur-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "if LCorrected1:\n",
        "    FOut1 = open('/content/KorpusARM1/stage02/hyRecht-changes.txt', 'w')\n",
        "    for (el, elCorr, LPara) in LCorrected1:\n",
        "        SPara = ''.join(LPara)\n",
        "        FOut1.write( f'{el}  {elCorr}\\t\\t{SPara}\\n\\n' )\n",
        "'''\n"
      ],
      "metadata": {
        "id": "W9wMq0uvYkzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyFiktion.txt', '/content/KorpusARM1/stage02/hyFiktion-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyFiktion.txt', '/content/KorpusARM1/stage02/hyFiktion-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyFiktion-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NluaBoyPwwbd",
        "outputId": "02008ccf-8275-4403-d150-4be4c7617367"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyNatur.txt', '/content/KorpusARM1/stage02/hyNatur-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyNatur.txt', '/content/KorpusARM1/stage02/hyNatur-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyNatur-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206ue_Vvw8Rt",
        "outputId": "d5ce4a1a-55c5-404d-c954-00bbea26d73d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LCorrected1 = printLLParagraphs('/content/KorpusARM1/stage02/hyRecht.txt', '/content/KorpusARM1/stage02/hyRecht-corrected.txt', DWrongCorrectWordF, DWrongCorrectLemmaF)\n",
        "LCorrected1, DErrors1 = printLLParagraphs('/content/KorpusARM1/stage02/hyRecht.txt', '/content/KorpusARM1/stage02/hyRecht-corrected.txt', DWrongCorrectWordF)\n",
        "print(len(LCorrected1))\n",
        "printCorrections(LCorrected1, '/content/KorpusARM1/stage02/hyRecht-changes.txt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL4DLKC4w85F",
        "outputId": "92bc8c1d-5586-4dc4-bba3-c14c48e23d04"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wikipedia"
      ],
      "metadata": {
        "id": "lm9VfuuHQcy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    del LLParaWiki\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "iUBiwliBxnhw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LLParaWiki = tokenizeTextHY('/content/hywiki-20221101-pages-articles.txt')"
      ],
      "metadata": {
        "id": "UxNe9VvuQfet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d115e141-ebc8-403f-bbbd-ca8711b0d655"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "1600000\n",
            "1700000\n",
            "1800000\n",
            "1900000\n",
            "2000000\n",
            "2100000\n",
            "2200000\n",
            "2300000\n",
            "2400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(LLParaWiki)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1nH00HmQ1Ld",
        "outputId": "8ed2f918-a5c9-47cd-b550-b45bc30bc5b4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2153019"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llPara2dict(LLParagraphs):\n",
        "    DFreq = {}\n",
        "    p=0\n",
        "    for LPara in LLParagraphs:\n",
        "        p+=1\n",
        "        if p%200000 == 0:\n",
        "            print(p)\n",
        "        # if LPara == [] or LPara == ['']: continue\n",
        "        if LPara == []: continue\n",
        "        # FOut.write(str(LPara) + '\\n')\n",
        "        i = 0 # counting words\n",
        "        for el in LPara:\n",
        "            i+=1 # index of next word\n",
        "            try:\n",
        "                DFreq[el] += 1\n",
        "            except:\n",
        "                DFreq[el] = 1\n",
        "    return DFreq\n"
      ],
      "metadata": {
        "id": "xGYc-CldQ5_X"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DWiki = llPara2dict(LLParaWiki)\n",
        "print(len(DWiki))"
      ],
      "metadata": {
        "id": "MoTwYK30SDw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOut = open('hywiki-frqDict.txt', 'w')\n",
        "for key, val in sorted(DWiki.items(), key=lambda item: item[1], reverse=True):\n",
        "    FOut.write(f'{key}\\t{val}\\n')"
      ],
      "metadata": {
        "id": "fZpCsWIZShqu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-frqDict.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvTzG-NfTNO9",
        "outputId": "6138ac36-a359-4075-f363-ca82cd546c9f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2071974  4150227 42482907 hywiki-frqDict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head --lines=40 hywiki-frqDict.txt"
      ],
      "metadata": {
        "id": "ZXcZTSY4TRtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discover candidate rewriting rules systematically"
      ],
      "metadata": {
        "id": "6p6DaZz45mBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(LTWrongCorrectWordF))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ8K3rTm5GEb",
        "outputId": "160864da-0fec-45f3-cbd2-2c1449a0ad55"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for SWrong, SCorrect, Frq in LTWrongCorrectWordF:\n",
        "    print(SWrong, SCorrect)"
      ],
      "metadata": {
        "id": "RBhvZXOI5OlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to compare two strings\n",
        "import os\n",
        "def getCmnPrefix(S1, S2):\n",
        "    common = os.path.commonprefix([S1, S2])\n",
        "    return common\n",
        "\n",
        "\n",
        "def getCmnSuffix(S1,S2):\n",
        "    S1r = S1[::-1]\n",
        "    S2r = S2[::-1]\n",
        "    commonR = getCmnPrefix(S1r, S2r)\n",
        "    common = commonR[::-1]\n",
        "    return common\n",
        "\n",
        "def getDifInfix(S1, S2, LContext = 0, RContext = 0):\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    diffInfix1 = S1[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    # print('S1', S1, IPLen-LContext, -1*(ISLen)+RContext)\n",
        "    diffInfix2 = S2[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    # print('S2', S2, IPLen-LContext, -1*(ISLen)+RContext)\n",
        "    return(diffInfix1, diffInfix2)\n",
        "\n",
        "def getDifSuffix(S1, S2, LContext = 0):\n",
        "    # used if common suffix == ''\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    if ISLen == 0:\n",
        "        diffSuffix1 = S1[IPLen-LContext:]\n",
        "        diffSuffix2 = S2[IPLen-LContext:]\n",
        "    else:\n",
        "        diffSuffix1 = ''\n",
        "        diffSuffix2 = ''\n",
        "    return(diffSuffix1, diffSuffix2)\n",
        "\n",
        "def getDifPrefix(S1, S2, RContext = 0):\n",
        "    # used if common suffix == ''\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    if IPLen == 0:\n",
        "        diffPrefix1 = S1[:-1*(ISLen)+RContext]\n",
        "        diffPrefix2 = S2[:-1*(ISLen)+RContext]\n",
        "    else:\n",
        "        diffPrefix1 = ''\n",
        "        diffPrefix2 = ''\n",
        "\n",
        "    return(diffPrefix1, diffPrefix2)\n",
        "\n",
        "def getDiff(S1, S2, LContext = 0, RContext = 0):\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    if IPLen and ISLen:\n",
        "        diff1 = S1[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "        diff2 = S2[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    elif IPLen: # there is a common prefix, find different suffixes\n",
        "        diff1 = S1[IPLen-LContext:]\n",
        "        diff2 = S2[IPLen-LContext:]\n",
        "    elif ISLen: # there is a common suffix, find different prefixes\n",
        "        diff1 = S1[:-1*(ISLen)+RContext]\n",
        "        diff2 = S2[:-1*(ISLen)+RContext]\n",
        "    else:\n",
        "        diff1 = S1\n",
        "        diff2 = S2\n",
        "    return (diff1, diff2)\n",
        "\n",
        "\n",
        "def getPrefInfSuf(S1, S2):\n",
        "    P12 = ''\n",
        "    I1 = ''\n",
        "    I2 = ''\n",
        "    S12 = ''\n",
        "    try:\n",
        "        I1, I2 = getDifInfix(S1, S2, LContext = 0, RContext = 0)\n",
        "    except:\n",
        "        I1 = None\n",
        "        I2 = None\n",
        "    try:\n",
        "        P12 = getCmnPrefix(S1, S2)\n",
        "    except:\n",
        "        P12 = None\n",
        "    try:\n",
        "        S12 = getCmnSuffix(S1, S2)\n",
        "    except:\n",
        "        S12 = None\n",
        "\n",
        "    return P12, I1, I2, S12\n",
        "\n",
        "# testing\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[перепливи]', '[перелови]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)\n",
        "\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[розгубився]', '[розгубивсь]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)\n",
        "\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[вловив]', '[зловив]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)\n",
        "\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[переходити]', '[перешкодити]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)\n",
        "\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[переходити]', '[перешкоджати]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)\n",
        "\n",
        "P12, I1, I2, S12 = getPrefInfSuf('[ходити]', '[перешкоджати]')\n",
        "print(P12, ' | ', I1, ' > ', I2, ' | ', S12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usmxjH-f6Pad",
        "outputId": "610dbb60-5dfc-4bc3-ae5f-e0c1899d3ee4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[пере  |  пли  >  ло  |  ви]\n",
            "[розгубивс  |  я  >  ь  |  ]\n",
            "[  |  в  >  з  |  ловив]\n",
            "[пере  |  х  >  шк  |  одити]\n",
            "[пере  |  ходи  >  шкоджа  |  ти]\n",
            "[  |  ходи  >  перешкоджа  |  ти]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# testing\n",
        "P12 = getCmnPrefix('[перепливи]', '[перелови]')\n",
        "S12 = getCmnSuffix('[перепливи]', '[перелови]')\n",
        "# I1, I2 = getDifInfix('перепливи', 'перелови')\n",
        "# print(P12, S12)\n",
        "# print(I1, I2)\n",
        "\n",
        "I1, I2 = getDifInfix('[перепливи]', '[перелови]', LContext = 0, RContext = 0)\n",
        "print('rule:', I1, I2)\n",
        "print('prefix-suffix:', P12, S12)\n",
        "\n",
        "S1, S2 = getDifSuffix('розгубився', 'розгубивсь', LContext = 0)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDifSuffix('розгубився', 'розгубивс', LContext = 0)\n",
        "print(S1, S2)\n",
        "\n",
        "S1, S2 = getDifPrefix('вловив', 'зловив', RContext = 0)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDifPrefix('ловив', 'зловив', RContext = 0)\n",
        "print(S1, S2)\n",
        "\n",
        "print('new version....')\n",
        "I1, I2 = getDiff('перепливи', 'перелови', LContext = 1, RContext = 1)\n",
        "print(I1, I2)\n",
        "\n",
        "S1, S2 = getDiff('розгубився', 'розгубивсь', LContext = 1)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDiff('розгубився', 'розгубивс', LContext = 1)\n",
        "print(S1, S2)\n",
        "\n",
        "S1, S2 = getDiff('вловив', 'зловив', RContext = 1)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDiff('ловив', 'зловив', RContext = 1)\n",
        "print(S1, S2)\n",
        "\n",
        "'''\n"
      ],
      "metadata": {
        "id": "VljM6wAy-L_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createSufList(a):\n",
        "    ''' odyty] --> odyty], odyty, odyt, ody, od, o, \"\" '''\n",
        "    LSuf = []\n",
        "    for j in range(1,len(a)+1):\n",
        "        prefix = a[:j]\n",
        "        LSuf.append(prefix)\n",
        "        # print(j, len(prefix), LSuf)\n",
        "    LSuf.insert(0, '')\n",
        "    return LSuf\n",
        "\n",
        "createSufList('odyty]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwkewYUg_UVx",
        "outputId": "5788acde-a427-4c61-ecd4-c282b2826dc3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'o', 'od', 'ody', 'odyt', 'odyty', 'odyty]']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createPrefList(s):\n",
        "    LPref = [s[-i:] for i in range(1, len(s) + 1)]\n",
        "    LPref.insert(0, '')\n",
        "    # print(LPref)\n",
        "    return LPref\n",
        "\n",
        "createPrefList('[pere')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5b8Q6y1Ccwa",
        "outputId": "99a7615f-8db7-4717-9e57-97dc85dc30cb"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'e', 're', 'ere', 'pere', '[pere']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we create the list of potential rewrite rules"
      ],
      "metadata": {
        "id": "72QxAaxMEEpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function updates the given (global) dictionary with the set of rewrite rules derived from a rewriting\n",
        "'''\n",
        "def twoWords2listOfRules(W1, W2, DTRulesLen = None, DTRules = None, LTRules = None):\n",
        "    if not DTRules: DTRules = {}\n",
        "    if not DTRulesLen: DTRulesLen = {}\n",
        "    if not LTRules: LTRules = []\n",
        "\n",
        "    P12, I1, I2, S12 = getPrefInfSuf(W1, W2)\n",
        "    print(P12, I1, I2, S12)\n",
        "    LPref12 = createPrefList(P12)\n",
        "    LSuf12 = createSufList(S12)\n",
        "\n",
        "    for pref in LPref12:\n",
        "        for suf in LSuf12:\n",
        "            SlhsRule = pref + I1 + suf\n",
        "            SrhsRule = pref + I2 + suf\n",
        "            TRules = (SlhsRule, SrhsRule)\n",
        "            LTRules.append(TRules)\n",
        "            try:\n",
        "                DTRules[TRules] += 1\n",
        "            except:\n",
        "                DTRules[TRules] = 1\n",
        "\n",
        "            try:\n",
        "                DTRulesLen[TRules] = len(SlhsRule)\n",
        "            except:\n",
        "                continue\n",
        "    return LTRules, DTRules, DTRulesLen\n",
        "'''\n",
        "\n",
        "\n",
        "def twoWords2listOfRules(W1, W2):\n",
        "    DTRules = {}\n",
        "    DTRulesLen = {}\n",
        "    LTRules = []\n",
        "    P12, I1, I2, S12 = getPrefInfSuf(W1, W2)\n",
        "    print(P12, I1, I2, S12)\n",
        "    LPref12 = createPrefList(P12)\n",
        "    LSuf12 = createSufList(S12)\n",
        "\n",
        "    for pref in LPref12:\n",
        "        for suf in LSuf12:\n",
        "            SlhsRule = pref + I1 + suf\n",
        "            SrhsRule = pref + I2 + suf\n",
        "            TRules = (SlhsRule, SrhsRule)\n",
        "            LTRules.append(TRules)\n",
        "            try:\n",
        "                DTRules[TRules] += 1\n",
        "            except:\n",
        "                DTRules[TRules] = 1\n",
        "\n",
        "            try:\n",
        "                DTRulesLen[TRules] = len(SlhsRule)\n",
        "            except:\n",
        "                continue\n",
        "    return LTRules, DTRules, DTRulesLen\n",
        "\n",
        "\n",
        "def printFrqTDict(DTFrq, FOut = None):\n",
        "    for key, val in sorted(DTFrq.items(), key=lambda x:x[1], reverse=True):\n",
        "        LHS, RHS = key\n",
        "        if FOut:\n",
        "            FOut.write(f'{LHS}, {RHS}, {str(val)}\\n')\n",
        "        else:\n",
        "            print(LHS, RHS, str(val))\n",
        "    if FOut:\n",
        "        FOut.flush()\n",
        "\n",
        "def printTList(LTuples, FOut = None):\n",
        "    for el in LTuples:\n",
        "        LHS, RHS = el\n",
        "        if FOut:\n",
        "            FOut.write(f'{LHS}, {RHS}\\n')\n",
        "        else:\n",
        "            print(LHS, RHS)\n",
        "    if FOut:\n",
        "        FOut.flush()\n",
        "\n",
        "LTRules, DTRules, DTRulesLen = twoWords2listOfRules('[перепливи]', '[перелови]')\n",
        "FOut = open('printFrqTDict-test.txt', 'w')\n",
        "printFrqTDict(DTRules, FOut)\n",
        "FOut0 = open('printFrqTDictLen-test.txt', 'w')\n",
        "printFrqTDict(DTRulesLen, FOut0)\n",
        "FOut1 = open('printTList-test.txt', 'w')\n",
        "printTList(LTRules, FOut1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "yr6ic-xSEO_2",
        "outputId": "4d852356-9b65-43e7-e1a0-4dd6aba06ee5"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[пере None None ви]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-cc9476d0233c>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mFOut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mLTRules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDTRules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDTRulesLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwoWords2listOfRules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[перепливи]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[перелови]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mFOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'printFrqTDict-test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprintFrqTDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTRules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFOut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-cc9476d0233c>\u001b[0m in \u001b[0;36mtwoWords2listOfRules\u001b[0;34m(W1, W2)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mP12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPrefInfSuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mLPref12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreatePrefList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mLSuf12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateSufList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-84805066d5e7>\u001b[0m in \u001b[0;36mcreatePrefList\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreatePrefList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mLPref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mLPref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print(LPref)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLPref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findLongestMatch(SInput, DTRulesLength):\n",
        "    SOutput = None\n",
        "    for key, val in sorted(DTRulesLength.items(), key=lambda x:x[1], reverse=True):\n",
        "        LHS, RHS = key\n",
        "        if LHS in SInput:\n",
        "            SOutput = SInput.replace(LHS, RHS, 1)\n",
        "            break\n",
        "    return SOutput, SInput, key, val\n",
        "\n",
        "SOutput1, SInput, rule, len = findLongestMatch('[перепливи]', DTRulesLen)\n",
        "if SOutput1: print(SOutput1, SInput, rule, len )\n",
        "\n",
        "SOutput1, SInput, rule, len = findLongestMatch('[перепливав]', DTRulesLen)\n",
        "if SOutput1: print(SOutput1, SInput, rule, len )\n",
        "\n",
        "SOutput1, SInput, rule, len = findLongestMatch('[запливала]', DTRulesLen)\n",
        "if SOutput1: print(SOutput1, SInput, rule, len )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9o5f8XpJ6Fo",
        "outputId": "7e2cd9be-9168-4ac7-cf99-4d0e6d1bb870"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[перелови] [перепливи] ('[перепливи]', '[перелови]') 11\n",
            "[переловав] [перепливав] ('[переплив', '[перелов') 9\n",
            "[заловала] [запливала] ('плив', 'лов') 4\n"
          ]
        }
      ]
    }
  ]
}