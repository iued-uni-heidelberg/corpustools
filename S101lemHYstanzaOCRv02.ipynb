{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd4/UvcptoHPYkNAQIOTTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "293a04662db745b097d39f2d5ddbbf7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f6a00c9caa74528a6c72cdcdf3126d6",
              "IPY_MODEL_94cb3fbf256a400fb7837412ea8171a4",
              "IPY_MODEL_bf16b75b3f5d4a99a50d5bfb4460e156"
            ],
            "layout": "IPY_MODEL_f163c52abe5f4b34b3af97587c58c123"
          }
        },
        "9f6a00c9caa74528a6c72cdcdf3126d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9453ba1a0b4473aa4e2d901da7c6a55",
            "placeholder": "​",
            "style": "IPY_MODEL_60f191b4744d4e3ebd5aab6e9a7ea015",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: "
          }
        },
        "94cb3fbf256a400fb7837412ea8171a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cb62b8a8e6453f94693fd87fc4f819",
            "max": 29911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa502f52ecac447e996556ccfded5aa7",
            "value": 29911
          }
        },
        "bf16b75b3f5d4a99a50d5bfb4460e156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_746dbd670eba4b029a4fbc2737de74a8",
            "placeholder": "​",
            "style": "IPY_MODEL_74b7f034caf5439b93e12b5cb65e0bc7",
            "value": " 200k/? [00:00&lt;00:00, 9.99MB/s]"
          }
        },
        "f163c52abe5f4b34b3af97587c58c123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9453ba1a0b4473aa4e2d901da7c6a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60f191b4744d4e3ebd5aab6e9a7ea015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42cb62b8a8e6453f94693fd87fc4f819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa502f52ecac447e996556ccfded5aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "746dbd670eba4b029a4fbc2737de74a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b7f034caf5439b93e12b5cb65e0bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7605f38af4d4ca6b3fb83b48d33597c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06faba8423b14991adb9510c28458bcd",
              "IPY_MODEL_f97ff6d74a86487ab4320ec24aa1ab9f",
              "IPY_MODEL_4474bbf28a4a43fdb3cad7cf484a392b"
            ],
            "layout": "IPY_MODEL_6883b0dc8a9144f197ee818619fcfbe8"
          }
        },
        "06faba8423b14991adb9510c28458bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512ed2e97a7f4f819c2ac692727d807d",
            "placeholder": "​",
            "style": "IPY_MODEL_fe1927a9255a41e79db57e3659766c76",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-hy/resolve/v1.5.0/models/default.zip: 100%"
          }
        },
        "f97ff6d74a86487ab4320ec24aa1ab9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec2e04fb6f94be29319a2039932686f",
            "max": 483970364,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9856d3bd916480088de9d91ed3d9bb6",
            "value": 483970364
          }
        },
        "4474bbf28a4a43fdb3cad7cf484a392b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed810569047c48a3b88d6eb2a70ec41c",
            "placeholder": "​",
            "style": "IPY_MODEL_e47bc2f1e47444998e5c192595decf2c",
            "value": " 484M/484M [00:11&lt;00:00, 42.6MB/s]"
          }
        },
        "6883b0dc8a9144f197ee818619fcfbe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512ed2e97a7f4f819c2ac692727d807d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1927a9255a41e79db57e3659766c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec2e04fb6f94be29319a2039932686f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9856d3bd916480088de9d91ed3d9bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed810569047c48a3b88d6eb2a70ec41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e47bc2f1e47444998e5c192595decf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/S101lemHYstanzaOCRv02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Armenian lemmatization with Stanza\n",
        "https://github.com/iued-uni-heidelberg/corpustools/blob/main/S101lemHYstanzaOCRv01.ipynb\n"
      ],
      "metadata": {
        "id": "skix7t6sFaZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, re\n"
      ],
      "metadata": {
        "id": "aEQcXSC6gMwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## downloading evaluation sets\n",
        "- 420 words: test with about 420 words of Armenian text\n",
        "- Armenian \"Brown-type\" corpus b"
      ],
      "metadata": {
        "id": "fFBRX6lTFfcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "!wget https://heibox.uni-heidelberg.de/f/ce6096da570f47b99500/?dl=1\n",
        "### optional\n",
        "!mv index.html?dl=1 evaluation-set-v01.txt"
      ],
      "metadata": {
        "id": "m549clSLFHs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/a847a12bffd4491f9070/?dl=1\n",
        "!mv index.html?dl=1 TED2020-dehy-hy-aa"
      ],
      "metadata": {
        "id": "IWwqNLkxPMfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### downloading Armenian Wikipedia\n",
        "!wget https://heibox.uni-heidelberg.de/f/d1f866a61bd545318213/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles.txt.gz\n",
        "!gunzip hywiki-20221101-pages-articles.txt.gz"
      ],
      "metadata": {
        "id": "j_-b-YYGq8bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32057497-8043-4bc8-a559-883cab15d81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-20 08:45:40--  https://heibox.uni-heidelberg.de/f/d1f866a61bd545318213/?dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/12517929-9d0e-47db-a15e-844e700ac3db/hywiki-20221101-pages-articles.txt.gz [following]\n",
            "--2023-03-20 08:45:40--  https://heibox.uni-heidelberg.de/seafhttp/files/12517929-9d0e-47db-a15e-844e700ac3db/hywiki-20221101-pages-articles.txt.gz\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 193021637 (184M) [application/octet-stream]\n",
            "Saving to: ‘index.html?dl=1’\n",
            "\n",
            "index.html?dl=1     100%[===================>] 184.08M  14.9MB/s    in 12s     \n",
            "\n",
            "2023-03-20 08:45:52 (15.7 MB/s) - ‘index.html?dl=1’ saved [193021637/193021637]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-20221101-pages-articles.txt"
      ],
      "metadata": {
        "id": "SQMJimofsTMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7a22cd-0e1b-403f-c40f-2615785966e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  2446411  56341171 803098410 hywiki-20221101-pages-articles.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing stanza"
      ],
      "metadata": {
        "id": "i__aUXulFkw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdzVArLUF3cb"
      },
      "outputs": [],
      "source": [
        "!pip install spacy-stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "import spacy_stanza\n"
      ],
      "metadata": {
        "id": "-VN9g4N4GAR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f80b583-7116-4226-e440-991f7fadd106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing English stanza (optional)"
      ],
      "metadata": {
        "id": "w6Kfwj63FzYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optional\n",
        "# Download the stanza model if necessary\n",
        "stanza.download(\"en\")\n",
        "\n",
        "# Initialize the pipeline\n",
        "nlp = spacy_stanza.load_pipeline(\"en\")\n",
        "\n",
        "doc = nlp(\"Barack Obama was born in Hawaii. He was elected president in 2008.\")\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
        "print(doc.ents)"
      ],
      "metadata": {
        "id": "dEA7KJdZPrWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### downloading and testing Armenian stanza"
      ],
      "metadata": {
        "id": "HGyKxEJNGG8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"hy\")\n"
      ],
      "metadata": {
        "id": "xq53mDsUGumV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "293a04662db745b097d39f2d5ddbbf7a",
            "9f6a00c9caa74528a6c72cdcdf3126d6",
            "94cb3fbf256a400fb7837412ea8171a4",
            "bf16b75b3f5d4a99a50d5bfb4460e156",
            "f163c52abe5f4b34b3af97587c58c123",
            "b9453ba1a0b4473aa4e2d901da7c6a55",
            "60f191b4744d4e3ebd5aab6e9a7ea015",
            "42cb62b8a8e6453f94693fd87fc4f819",
            "aa502f52ecac447e996556ccfded5aa7",
            "746dbd670eba4b029a4fbc2737de74a8",
            "74b7f034caf5439b93e12b5cb65e0bc7",
            "c7605f38af4d4ca6b3fb83b48d33597c",
            "06faba8423b14991adb9510c28458bcd",
            "f97ff6d74a86487ab4320ec24aa1ab9f",
            "4474bbf28a4a43fdb3cad7cf484a392b",
            "6883b0dc8a9144f197ee818619fcfbe8",
            "512ed2e97a7f4f819c2ac692727d807d",
            "fe1927a9255a41e79db57e3659766c76",
            "3ec2e04fb6f94be29319a2039932686f",
            "b9856d3bd916480088de9d91ed3d9bb6",
            "ed810569047c48a3b88d6eb2a70ec41c",
            "e47bc2f1e47444998e5c192595decf2c"
          ]
        },
        "outputId": "728a78be-e164-4e0e-9756-9103a7ef0302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "293a04662db745b097d39f2d5ddbbf7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloading default packages for language: hy (Armenian) ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-hy/resolve/v1.5.0/models/default.zip:   0%|          | 0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7605f38af4d4ca6b3fb83b48d33597c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_hy = spacy_stanza.load_pipeline(\"hy\")"
      ],
      "metadata": {
        "id": "KZKOs0aVG8Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "doc = nlp_hy(\"ՄԱՐԴՈՒ ԻՐԱՎՈՒՆՔՆԵՐԻ ՀԱՄԸՆԴՀԱՆՈՒՐ ՀՌՉԱԿԱԳԻՐ. ՆԵՐԱԾԱԿԱՆ. Քանզի մարդկային ընտանիքի բոլոր անդամներին ներհատուկ արժանապատվությունըև հավասար ու անօտարելի իրավունքները աշխարհի ազատության, արդարության ու խաղաղության հիմքն են.\")"
      ],
      "metadata": {
        "id": "m022wp2JHvOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n"
      ],
      "metadata": {
        "id": "LPhSOX15ICmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### full analysis of the file (optional)\n",
        "- includes dependency parsing"
      ],
      "metadata": {
        "id": "NVyvpuMDQXYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### optional\n",
        "with open('/content/TED2020-dehy-hy-aa', 'r', encoding='utf-8') as infile, open('/content/TED2020-dehy-hy-aa-ANALYSIS-full-v01.txt', 'w') as outfile:\n",
        "    # read sample.txt an and write its content into sample2.txt\n",
        "    outfile.write(\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{LAncestors}\\n\")\n",
        "    for line in infile:\n",
        "        line = line.strip()\n",
        "        doc = nlp_hy(line)\n",
        "        # outfile.write(line + '\\n')\n",
        "        for token in doc:\n",
        "            LAncestors = list(token.ancestors)\n",
        "            print(str(LAncestors))\n",
        "            try:\n",
        "                SLAncestors = str(list(token.ancestors))\n",
        "                parent = LAncestors[0]\n",
        "                parentLem = parent.lemma_\n",
        "            except:\n",
        "                parentLem = \"NONE\"\n",
        "            outfile.write(f\"{token.text}\\t{token.lemma_}\\t{token.pos_}\\t{token.dep_}\\t{parentLem}\\t{SLAncestors}\\n\")\n",
        " \n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "HJdW66EmJI2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### optional : check output \n",
        "!head -n 50 TED2020-dehy-hy-aa-ANALYSIS-full-v01.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqQteJEKwmd9",
        "outputId": "a9b85102-2a65-4663-d6ac-85f18721b2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open 'TED2020-dehy-hy-aa-ANALYSIS-full-v01.txt' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### function for lemmatization"
      ],
      "metadata": {
        "id": "_w7MrFvNQqxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parseFile(iFileName, oFileName, nlp_model = nlp_hy):\n",
        "    with open(iFileName, 'r', encoding='utf-8') as infile, open(oFileName, 'w') as outfile:\n",
        "        # read sample.txt an and write its content into sample2.txt\n",
        "        outfile.write(\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        "        c = 0\n",
        "        for line in infile:\n",
        "            c+=1\n",
        "            if c%10 == 0: print(str(c))\n",
        "            line = line.strip()\n",
        "            doc = nlp_model(line)\n",
        "            # outfile.write(line + '\\n')\n",
        "            for token in doc:\n",
        "                LAncestors = list(token.ancestors)\n",
        "                # print(str(LAncestors))\n",
        "                try:\n",
        "                    SLAncestors = str(list(token.ancestors))\n",
        "                    parent = LAncestors[0]\n",
        "                    parentLem = parent.lemma_\n",
        "                except:\n",
        "                    parentLem = \"NONE\"\n",
        "                outfile.write(f\"{token.text}\\t{token.pos_}\\t{token.lemma_}\\n\")\n",
        "        outfile.flush()\n",
        "    return\n"
      ],
      "metadata": {
        "id": "QT0tpHwjY4O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### command to lemmatize the file"
      ],
      "metadata": {
        "id": "FJoxNaZ7vfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000 lines, runs in 2 minutes...\n",
        "parseFile('/content/TED2020-dehy-hy-aa', '/content/TED2020-dehy-hy-aa--lemmatization-v01.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "rgdb1fl3a6F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes a lot of time, do not run it, just use as a template, split the file first and run several processes...\n",
        "parseFile('hywiki-20221101-pages-articles.txt', 'hywiki-20221101-pages-articles.vert', nlp_hy)"
      ],
      "metadata": {
        "id": "lrSvU_NbsZ9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking OCR errors\n",
        "### wikipedia lemmatized --> frequency dictionary "
      ],
      "metadata": {
        "id": "Disi8bxMhOD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/5b3213f991f84ca496ba/?dl=1\n",
        "!mv index.html?dl=1 hywiki-20221101-pages-articles-v03.vert"
      ],
      "metadata": {
        "id": "lhs5GwRihMxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-20221101-pages-articles-v03.vert"
      ],
      "metadata": {
        "id": "xJlX-J5ij72h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4041be25-eebf-4da5-fb67-c02d8ff1c3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2735467  8206467 75483279 hywiki-20221101-pages-articles-v03.vert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/350790e66ca24efdab1a/?dl=1\n",
        "!mv index.html?dl=1 hy-texts-vert.tgz \n",
        "!tar xvzf hy-texts-vert.tgz"
      ],
      "metadata": {
        "id": "dtxtpTo_mTSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/d601ceb0af5a4671a8e7/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Arm_ABBY.txt"
      ],
      "metadata": {
        "id": "2LPlwmpYsSt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Arm_ABBY.txt"
      ],
      "metadata": {
        "id": "i4AFw5r9zD4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parseFile('Parfum_Arm_ABBY.txt', 'Parfum_Arm_ABBY.vert.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "ZnrYlLB_uRsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Arm_ABBY.vert.txt"
      ],
      "metadata": {
        "id": "kyjvWWMuy-e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031bce48-8303-443b-fa3d-edd6289b15b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  83890  251594 2098541 Parfum_Arm_ABBY.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/743a1a57a37c42d8b585/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian_uncorrected.txt\n"
      ],
      "metadata": {
        "id": "D-Qu1FP8mbO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian_uncorrected.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xUHdJzezYry",
        "outputId": "efa1b1e3-36e4-4ded-8f9d-3cdc0c467393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13592  72207 854251 Parfum_Armenian_uncorrected.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dealing with Armenian OCR output with line breaks (is it correct?)\n",
        "\n",
        "FName = 'Parfum_Armenian_uncorrected.txt'\n",
        "FNameOut = 'Parfum_Armenian.txt'\n",
        "\n",
        "FIn = open(FName, 'r')\n",
        "FOut = open(FNameOut, 'w')\n",
        "\n",
        "for SLine in FIn:\n",
        "    SLine = SLine.strip()\n",
        "    if SLine == '': \n",
        "        FOut.write('\\n\\n')\n",
        "        continue\n",
        "    if SLine[-1] == '-':\n",
        "        SLine2write = SLine[:-1]\n",
        "        FOut.write(SLine2write)\n",
        "        continue\n",
        "\n",
        "    FOut.write(SLine + ' ')\n",
        "FOut.flush()\n",
        "\n"
      ],
      "metadata": {
        "id": "tstyqM_cph11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRgXoAx_zOka",
        "outputId": "de6acfcb-822a-429f-d644-ea0762943d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6126  69006 849250 Parfum_Armenian.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# runs for approximately 10 minutes, 6126 lines, 83828 words\n",
        "parseFile('Parfum_Armenian.txt', 'Parfum_Armenian.vert.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "Gf-OW1n_rbue",
        "outputId": "a9aef72b-2277-40df-bf59-014335d0445f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Due to multiword token expansion or an alignment issue, the original text has been replaced by space-separated expanded tokens.\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: [\"'\", 'Շարցնում', 'են', \"'\", 'ինչ', '՞', 'է', 'եղել', 'նրա', 'հետ', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'ինչ', '՛', 'էնա', 'անում', 'դանակով', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Նրա', 'համար', 'վնասակար', 'չի', 'լինի', ',', '-', 'շշպռեց', 'Ժաննան', ',', '-', 'իսկ', 'ինձ', 'համար', 'կլինի', ':', 'Ես', 'նիհարել', 'եմ', 'տասը', 'ֆունտ', ',', 'չնայած', 'կերել', 'եմ', 'երեք', 'հոգու', 'փոխարեն', ':', 'Իսկ', 'հանուն', 'ինչի', ':', 'Հանուն', 'շաբաթական', 'երեք', '<UNK>րանկի', '՛']\n",
            "Entities: [('Ժաննան', 'PERSON', 38, 44), ('տասը', 'CARDINAL', 82, 86), ('երեք', 'CARDINAL', 110, 114), ('երեք', 'CARDINAL', 164, 168)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'մյուս', 'կողմից', ',', 'լավ', 'չէ', 'երեխային', 'դես', 'ու', 'դեն', 'նետել', ':', 'Ով', '՛', 'գիտի', ',', 'օգտակար', 'կլինի', '՝', 'նրան', 'արդյոք', 'այդ', 'կաթը', ':', 'Մանկիկը', ',', 'հասկանում', 'ես', ',', 'սովորել', 'է', 'քո', 'կրծքի', 'հոտին', 'ու', 'քո', 'սրտի', 'բաբախյունին', ':']\n",
            "Entities: [('Մանկիկը', 'PERSON', 102, 109)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130\n",
            "140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ապա', 'որքան', '՞', 'ես', 'պահանջում', ',', '-', '-', 'գոռաց', 'Տերյեն', ':', '-', 'Հինգ', 'ֆրանկը', 'նման', 'չնչին', 'գործի', 'դիմաց', ',', 'ինչպիսին', 'նորածնին', 'կերակրելն', 'է', ',', 'մի', 'կույտ', 'փող', 'է', ':']\n",
            "Entities: [('Տերյեն', 'PERSON', 35, 41), ('Հինգ', 'CARDINAL', 44, 48)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բայց', 'ինչու', '՛', ',', 'սիրելիս', ',', '-', 'ասաց', 'Տերյեն', 'ն', 'կրկին', 'մատով', 'շուռումուռ', 'տվեց', 'զամբյուղի', 'պարունակությունը', ':', 'չէ', '՞', 'որ', 'սա', 'հիասքանչ', 'մանկիկ', 'է', ':', 'Այնքան', 'վարդագույն', 'է', ',', 'լաց', 'չի', 'լինում', ',', 'հանգիստ', 'է', 'քնում', ',', 'ն', 'կնքված', 'էլ', 'է', ':']\n",
            "Entities: [('Տերյեն', 'PERSON', 30, 36)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խամարդ', ',', 'ն', 'դեռնս', 'չի', 'տնօրինում', 'ամբողջապես', 'ճնավորված', 'հոգուն', ':', 'Հետնաբար', ',', 'սատանայի', 'համար', 'այն', '`', 'հետաքրքրություն', 'չի', 'ներկայացնում', ':', 'Միգուցենա', 'արդեն', 'խոսում', '՛', 'է', ':', 'Միգուցե', 'նրա', 'մոտ', 'ջղաճգութու', '՞', 'է', ':', 'Միգուցե']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '-', 'Դետեսնում', 'ես', ':', 'Ահա', 'այն', 'նախանշանը', ':', 'Եթենա', '՞', 'դիվահար', 'լիներ', ',', 'ապա', 'նրանից', 'գարշահոտ', 'կփչեր', ':']\n",
            "Entities: [('Դետեսնում', 'GPE', 3, 12)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "170\n",
            "180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Որովհետն', 'նա', 'առողջ', 'է', ',', '-', 'գոռաց', 'Տերյեն', ',', '-', 'նա', 'առողջ', 'է', ',', 'այդ', 'պատճառով', 'էլ', 'հոտ', 'չունի', ':', 'Հոտ', 'ունեն', '`', 'միայն', 'հիվանդ', 'երեխաները', ',', 'դա', 'բոլորին', 'է', 'հայտնի', ':', 'Օրինակ', ',', 'եթե', 'երեխան', 'ջրծաղիկ', 'ունի', ',', 'նրանից', 'ձիու', 'թրիքի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'եթե', 'քութեշ', ',', 'ապա', 'հին', 'խնձորի', ',', 'իսկ', 'թոքախտավոր', 'երեխայից', 'սոխի', 'հոտ', 'է', 'գալիս', ':', 'Սա', 'առողջ', 'է', '.', 'ահա', 'ն', 'բոլորը', ':', 'Այդ', 'դեպքում', 'ինչու', '՛', 'պետք', 'է']\n",
            "Entities: [('Որովհետն', 'PERSON', 2, 10), ('Տերյեն', 'PERSON', 30, 36)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['նրանից', 'գարշահոտ', 'գա', ':', 'Միթե', '՛', 'քո', 'սեփական', 'երեխաներից', 'գարշահոտ', 'է', 'գալիս', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ն', '-', 'Ահա', ',', '-', 'ասաց', 'բավարարված', 'Տերյեն', 'ու', 'ձեռքերը', 'կրկին', 'ծալեց', 'թիկունքում', ':', 'Կնշանակի', '՝', 'սատանայի', 'հետ', 'կապված', 'խոսքը', 'մենք', 'ետ', 'ենք', 'վերցնում', ':', 'Լավ', ':', 'Իսկ', 'հիմա', 'բարի', 'եղիր', 'ինձ', 'բացատրել', 'ինչ', '՞', 'հոտ', 'է', 'գալիս', 'կրծքի', 'նորածիններից', ',', 'եթե', 'նրանցից', 'գալիս', 'է', 'այնպիսի', 'հոտ', ',', 'որ', '`', 'պիսին', ',', 'քո', 'կարծիքով', ',', 'պետք', 'է', 'գա', ':', 'Դե', ':']\n",
            "Entities: [('Տերյեն', 'PERSON', 26, 32)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ՍՏ', '-', 'Ինչ', 'է', 'նշանակում', '«', 'լավ', '»', ',', '-', 'ողջ', 'ուժով', 'գոռաց', 'նրա', '`', 'վրա', 'Տերյեն', '-', '-', 'Միթե', '՛', 'քիչ', 'են', 'այնպիսի', 'բաները', ',', 'որոնք', 'լավ', '`', 'հոտ', 'ունեն', ':', 'Փնջով', 'նարդո', 'լավ', 'հոտ', 'ունի', ':', 'Ապուրի', 'միսը', 'լավ', 'հոտ', 'ունի', ':', 'Արաբական', 'այգիները', 'լավ', 'հոտ', 'ունեն', ':', 'Ես']\n",
            "Entities: [('Տերյեն', 'PERSON', 55, 61), ('Արաբական', 'NORP', 168, 176)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ցանկանում', 'եմ', 'իմանալ', 'ինչ', '՞', 'հոտ', 'ունեն', 'նորածինները', ':', 'Ծծմայրը', 'դանդաղում', 'էր', 'պատասխանել', ':', 'Նա', ',', 'իհարկե', ',', 'գիտեր', ',', 'թե', 'ինչ', 'հոտ', 'է', 'գալիս', 'կրծքի', 'նորածիններից', ',', 'գիտեր', 'բացարձակ', 'ճշտությամբ', ',', 'նրա', 'ձեռքի', 'սկով', 'տասնյակ', 'մանկիկներ', 'էին', 'անցել', ',', 'նա', 'նրանց', 'կերակրել', 'էր', ',', 'խնամել', ',', 'օրորել', ',', 'համբուրել', '...', 'Նա', 'կարող', 'էր', 'գիշերը', 'նրանց', 'ճանաչել', 'հոտով', ',', 'նույնիսկ', 'այսօր', 'նա', 'քթով', 'պարզորոշ', 'հիշում', 'էր', 'այդ', 'մանկական', 'հոտը', ':']\n",
            "Entities: [('տասնյակ', 'CARDINAL', 181, 188), ('գիշերը', 'TIME', 273, 279), ('այսօր', 'DATE', 310, 315)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "220\n",
            "230\n",
            "240\n",
            "250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ինչպես', 'կարամել', '՛', ',', '-', 'հարցրեց', 'նա', '՝', 'ձգտելով', 'կրկին', 'վերադառնալ', 'խիստ', 'խոսելաոճին', ':', '-', 'Կարամել', ':', 'Ինչ', '՞', 'ես', 'հասկանում', 'կարամելից', ':', 'Գոնե', 'մի', 'անգամ', 'կերել', '՛', 'ես', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['մինչդեռ', 'սեփական', 'բանականությունից', 'օգտվելու', 'համար', 'մարդուն', 'անհրաժեշտ', 'է', 'ինքնավստահություն', 'ու', 'հանգիստ', ':', 'Սակայն', 'նա', 'ամենավճռական', 'ձնով', 'պայքարում', 'էր', 'հասարակ', 'ժողովրդի', 'սնահավատության', 'դեմ', ':', 'Կախարդանքն', 'ու', 'խաղաթղթով', 'գուշակությունը', ',', 'հմայիխերի', 'կրումը', ',', 'չար', 'աչքից', 'ազատվելը', ',', 'ոգիների', 'կախարդանթները', ',', 'լիալուսնի', 'պահին', 'աճպարարությունները', '...', 'Ինչով', '՛', 'ասես', 'չէին', 'զբաղվում', 'այդ', 'մարդիկ', ':', 'Նրան', 'խորապես', 'հուսահատեգնում', 'էր', ',', 'որ', 'նմանատիպ', 'հեթանոսական', 'ավանդույթները', 'քրիստոնեական', 'կրոնի', 'առավել', 'քան', 'հազարամյա', 'գոյությունից', 'հետո', 'դեռնս', 'արմատախիլ', 'չէին', 'արվել', ':', 'Միաժամանակ', ',', 'այսպես', 'կոչված', ',', 'դիվահարության', 'ու', 'սատանայի', 'հետ', 'կապերի', 'դեպքերի', 'մեծ', 'մասը', 'էլ', 'ավելի', 'մոտիկից', 'ուսումնասիրման', 'ժամանակ', 'ներկայանում', 'էին', 'որպես', 'սնոտիապաշտական', 'ներկայացումներ', ':', 'Ճիշտ', 'է', ',', 'մերժել', 'բուն', 'սատանայի', 'գոյությունը', ',', 'կասկածել', 'նրա', 'իշխանության', 'մեջ', 'այդքան', 'հեռու', 'հայր', 'Տերյեն', 'չէր', 'գնա', '.', 'նմանատիպ', 'խնդիրների', 'լուծումը', ',', 'որոնք', 'առնչվում', 'էին', 'աստվածաբանության', 'հիմքերին', ',', 'համեստ', 'ու', 'հասարակ', 'վանականի', 'գործը', 'չէր', ',', 'դրա', 'համար', 'գոյություն', 'ունեն', 'այլ', 'ատյաններ', ':', 'Մյուս', 'կողմից', 'օրվա', 'պես', 'պարզ', 'էր', ',', 'որ', ',', 'եթե', 'նման', 'կարճամիտ', 'անձնավորությունը', ',', 'ինչպիսին', 'այդ', 'ծծմայրն', 'էր', ',', 'պնդում', 'է', ',', 'որ', 'ինքն', 'ինչ', '-', 'որ', 'դիվայնություն', 'Է', 'հայտնաբերել', ',', 'նշանակում', 'է', '՝', 'սատանան', 'ոչ', 'մի', 'դեպքում', 'չէր', 'կարող', 'կապված', 'լինել', 'այդ', 'գործի', 'հետ', ':', 'Հատկապես', 'այն', 'պատճառով', ',', 'որնրան', 'թվում', 'է', ',', 'թե', 'իբր', 'ինքը', 'դա', 'հայտնաբերել', 'է', ':', 'չէ', '՞', 'որ', 'դա', 'ճշմարիտ', 'ապացույցն', 'է', 'նրա', ',', 'որ', 'ոչ', 'մի', 'դիվայնություն', 'էլ', 'իրականում', 'չկար', '.', 'սատանան', 'այն', 'աստիճան', 'հիմար', 'չէ', ',', 'որ', 'թույլ', 'տա', 'ծծմայր', 'Ժաննա', 'Բյուսիին', 'իրեն', 'բացահայտել', ':', 'Եվ', 'այն', 'էլ', 'հոտառությամբ', ':', 'Ջգազմունքներից', 'ամենապարզունակի', ',', 'ամենանվաստի', 'օգնությամբ', ':', 'Կարծես', 'թե', 'դժոխքից', 'ծծմբի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'դրախտից', 'խունկի', 'ու', 'զմուռսի', ':', 'Դա', ',', 'իրոք', ',', 'ամենամութ']\n",
            "Entities: [('քրիստոնեական', 'NORP', 423, 435), ('Տերյեն', 'PERSON', 772, 778), ('Ժաննա Բյուսիին', 'PERSON', 1360, 1374)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'մնահավատությոն', 'է', ',', 'որն', 'արժանի', 'է', 'վայրի', 'հեթանոսա', '`', 'կան', 'ժամանակներին', ',', 'երբ', 'մարդիկ', 'ապրում', 'էին', 'կենդանիների', 'պես', ',', 'երբ', 'նրանց', 'տեսողությունն', 'այնքան', 'թույլ', 'էր', ',', \"'\", 'որ', 'չէին', 'տարբերում', 'գույները', ',', 'բայց', 'գտնում', 'էին', ',', 'որ', 'լսում', 'են', 'արյան', 'հոտը', ',', 'որ', 'կարող', 'են', 'հոտի', 'օգնությամբ', 'տարբերել', 'սուն', 'բարեկամից', ',', 'որ', 'իրենց', 'հոտն', 'առնում', 'են', 'հսկա', '՛մարդակերներն', 'ու', 'դարճորյակ', 'գայլերը', ',', 'որ', 'իրենց', 'որսով', 'են', 'զբաղված', 'վրիժառության', 'աստվածուհիները', ',', 'ն', '.', 'այդ', '`', 'խսկպատճառով', 'իրենց', 'նողկալի', 'աստվածներին', 'խարույկՄ', 'ների', 'վրա', 'այրված', 'գարշահոտ', 'մարդկային', 'զոհեր', 'էին', 'մա', '\"', '`', 'տուցում', ':', 'Սարսափելի', 'է', ':', '«', 'Հիմարը', 'քթով', 'է', 'տեսնում', 'ավելի', 'սն', 'աչքերով', '»', ',', 'ն', 'հավանաբար', ',', 'աստվածատուր', 'բաՄ', '.', 'նականռթյան', 'լույսը', 'հազար', 'տարի', 'նս', 'պետք', 'է', 'լուսավորի', ',', '|', 'նչն', 'որ', 'նախնադարյան', 'հավատալիքների', 'վերջին', 'մնացորդներն', 'անհետանան', ',', 'ինչպես', 'ուրվականները', ':', '-', 'Ախ', 'ն', 'այս', 'դժբախտ', 'փոքրիկ', 'մանկիկը', ':', 'Այս', 'անմեղ', 'արարածը', ':', 'Պառկած', 'է', 'իր', 'զամբյուղում', 'ու', 'քաղցր', 'քնել', 'է', '՝', 'անտեղյակ', 'այն', 'ստոր', 'կասկածանքներին', ',', 'որոնք', 'առաջ', 'են', 'քաշվել', 'նրա', 'դեմ', ':', 'Իսկ', 'այդ', 'անպատկառ', 'անձր', 'համարճակվում', 'է', 'պնդել', ',', 'որ', 'դու', ',', 'իբր', ',', 'հու', 'չունես', ',', 'ինչպիսին', 'պետք', 'է', 'ունենան', 'մարդկային', 'մանուկները', ':', 'Եվ', 'ինչ', '՞', '|', 'ասենք', 'մենք', 'դրա', 'վերաբերյալ', ':', '<UNK>ո', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ':', 'Եվ', 'նա', 'զգուշորեն', 'օրորում', 'էր', 'ծնկների', 'վրա', 'դրված', 'զամբյուղը', ',', 'մատով', 'շոյում', 'նորածնի', 'գլուխն', 'ու', 'մի', 'քանի', 'անգամ', 'կրկնում', 'ղու', '՛', '-', 'ղող<UNK>ղո', '՛', ',', 'քանզի', 'կարծում', 'էր', ',', 'որ', 'այդ', 'Ի', '\"', 'Ցո', 'վանչությունը', 'հանգստացուցիչ', 'ու', 'բարերար', 'ազդեցություն', 'է', 'թողնում', 'փոքրիկների', 'վրա', \"'\", 'Մ', 'Շ', 'Կարամելի', 'հոտ', 'պետք', 'է', 'ունենաս', ',', 'այ', 'քեզ', 'հիմարություն', ',', 'ղո', '՛', '-', 'ղու', '՛', '-', 'ղո', '՛', ':', '2', 'Որոշ', 'ժամանակ', 'նա', 'տատանվում', 'էր', ',', 'այնուհետն', 'ետ', 'ՐՊ', 'արդյոք', 'որնէ', 'մեկը', 'չի', '՞', 'հետնում', 'իրեն', ',', 'զամբյուղը', 'Գետնից', 'բարձրացրեց', 'ու', 'դրա', 'մեջ', 'խցկեց', 'իր', 'հաստ', 'քիթր', ',']\n",
            "Entities: [('հազար տարի', 'DATE', 609, 619), ('Ախ ն', 'ORGANIZATION', 728, 732), ('Ղո՛-ղո՛ւ-ղո՛ւ', 'ORGANIZATION', 1036, 1049), ('Ցո', 'PERSON', 1202, 1204), ('2', 'CARDINAL', 1350, 1351)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280\n",
            "290\n",
            "300\n",
            "310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['խցկեց', 'շատ', 'խոր', ',', 'այնպես', 'որ', ',', 'նորածնի', 'բարակ', 'շիկահեր', 'մազիկները', 'խուտուտ', 'տվեցին', 'նրա', 'ռունգերը', ',', 'հոտոտեց', 'երեխայի', 'գլուխը', 'հուսալով', 'ինչ', '-', 'որ', 'հոտ', 'ներշնչել', ':', 'Նա', 'այնքան', 'էլ', 'լավ', 'չէր', 'պատկերացնում', ',', 'թե', 'ինչպիսի', 'հոտ', 'պետք', 'է', 'ունենան', 'նորածինների', 'գլուխները', ':', 'Բնականաբար', ',', 'ոչ', 'կարամելի', 'հոտ', ',', 'այդ', 'մեկը', 'պարզից', 'պարզ', 'էր', '.', 'չէ', \"'\", 'որ', 'կարամեխ', 'այրված', 'շաքար', 'է', ',', 'ն', 'ինչպես', 'կարող', 'է', 'նորածինը', ',', 'որը', 'մինչ', 'այժմ', 'միայն', 'կաթ', 'էր', 'խմում', ',', 'այրված', 'շաքարի', 'հոտ', 'ունենալ', ':', 'Նրանից', 'կարող', 'էր', 'կաթի', 'հոտ', 'գալ', 'ծծմոր', 'կաթի', ':', 'Բայց', 'նրանից', 'կաթի', 'հոտ', 'չէր', 'գալիս', ':', 'Նրանից', 'կարող', 'էր', 'մազերի', 'հոտ', 'գալ', ',', 'մաշկի', 'ու', 'մազերի', ',', 'ն', ',', 'միգուցե', ',', 'մի', 'քիչ', 'մանկան', 'քրտնքի', 'հոտ', ':', 'Տերյեն', 'հոտոտեց', 'ն', 'այնուհետն', 'համոզեց', 'իրեն', ',', 'որ', 'զգում', 'Է', 'մաշկի', ',', 'մազերի', 'ու', ',', 'միգուցե', ',', 'մանկան', 'քրտնքի', 'թույլ', 'հոտը', ':', 'Բայց', 'նա', 'ոչինչ', 'չէր', 'զգում', ':', 'Որքան', 'էլ', 'ճգնում', 'էր', ':', '«', 'Հավանաբար', ',', 'մանուկները', 'հոտ', 'չունեն', '»', ',', '-', 'մտածում', 'էր', 'նա', ':', 'Հավանաբար', ',', 'դա', 'է', 'հարցը', ':', 'Հարցն', 'այն', 'է', ',', 'որ', 'նորածինը', ',', 'եթե', 'նրան', 'պահեն', 'մաքրության', 'մեջ', ',', 'ընդհանրապես', 'չի', 'կարող', 'հոտ', 'ունենալ', ',', 'ինչպես', 'չի', 'կարող', 'խոսել', ',', 'վազել', 'կամ', 'գրել', ':', 'Այս', 'հատկանիշները', 'գալիս', 'են', 'միայն', 'տարիքի', 'հետ', ':', 'Ճշգրիտ', 'ասած', '՝', 'մարդը', 'միայն', 'սեռական', 'հասունացման', 'շրջանում', 'է', 'սկսում', 'սուր', 'հոտ', 'արձակել', ':', 'Այո', ',', 'հենց', 'այդպես', 'էլ', 'կա', ':', 'Այդպես', ',', 'այլ', 'ոչ', 'այլ', 'կերպ', ':', 'Միթե', '՛', 'իր', 'Ժամանակին', 'Հորացիոսը', 'չէր', 'գրում', '.', '«', 'Պատանուց', 'այծիկի', 'հոտ', 'է', 'գալիս', ',', 'իսկ', 'աղջիկը', 'բուրում', 'է', ',', 'ինչպես', 'ծաղիկը', 'սպիտակ', 'նարգիզի', '»', ':', 'Ով-ով', ',', 'բայց', 'հռոմեացիները', 'դրա', 'մասին', 'պատկերացում', 'ունեին', ':', 'Մարդկային', 'հոտը', 'մշտապես', 'մարմնի', 'հոտն', 'է', ',', 'հետնաբար', 'մեղքի', 'հոտը', ':', 'Այդ', 'դեպքում', 'ինչ', '՞', 'հոտ', 'պետք', 'է', 'ունենա', 'նորածինը', ',', 'որը', 'դեռնս', 'ոչ', 'երազով', ',', 'ոչ', 'հոգով', 'մեղավոր', 'չէ', 'մարմնական', 'մեղքի', 'մեջ', ':', 'Ինչ', '՞', 'հոտ', 'պետք', 'է', 'նա', 'ունենա', ':', 'Ղո՛.', '-', 'ղու', '՛', '-', 'ղու', '՛', ':', 'Ոչ', 'մի', ':']\n",
            "Entities: [('Հորացիոսը', 'PERSON', 1109, 1118)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ճեռքը', 'փոքրիկ', 'ն', 'գեղեցիկ', ',', 'դուրս', 'էր', 'ցցվել', 'կափարիչի', 'տակից', 'ու', 'ցնցվում', 'էր', 'այտի', 'ուղղությամբ', ':', 'Տերյեն', 'գորովալից', 'ժպտաց', 'ու', 'հանկարծ', 'իրեն', 'շատ', 'հարմարավետ', 'զգաց', ':', 'Ինչ', '-', 'որ', 'մի', 'պահ', 'նա', 'նույնիսկ', 'իրեն', 'թույլ', 'տվեց', 'մի', 'ֆանտաստիկ', 'միտք', ',', 'որ', 'կարծես', 'թե', 'ինքը', 'այդ', 'երեխայի', 'հայրն', 'էր', ':', 'Կարծես', 'թե', 'ինքը', 'դարձել', 'է', 'ոչ', 'թե', 'վանական', ',', 'այլ', 'նորմալ', 'քաղքենի', ',', 'միգուցե', 'ազնիվ', 'արհեստավոր', ',', 'իրեն', 'կին', 'է', 'գտել', 'մի', 'այնպիսի', 'տաքուկ', 'կին', ',', 'որից', 'բրդի', 'ու', 'կաթի', 'հոտ', 'է', 'գալիս', ',', 'ն', 'նրանք', 'ծնել', 'են', 'որդի', ',', 'ն', 'ահա', 'ինքը', 'նրան', '`', 'օրորում', 'է', 'իր', 'սեփական', 'ծնկների', 'վրա', 'իր', 'սեփական', 'երեխային', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', '.', 'այդ', 'միտքը', 'հաճույք', 'էր', 'պատճառում', ':', 'Նրանում', 'ինչ', '-', 'որ', 'սփոփիչ', 'ներշնչանք', 'կար', ':', 'Հայրը', 'ծնկների', '`', 'վրա', 'օրորում', 'է', 'իր', 'սեփական', 'որդուն', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ',', 'պատկերը', 'հին', 'էր', 'ինչպես', 'աշխարհը', ',', 'ն', 'հավերժ', 'նոր', 'ու', 'ճիշտ', 'այն', 'ժամանակից', ',', 'ինչ', 'աշխարհր', 'լուսավոր', 'է', ',', 'հենց', 'այդպես', ':', 'Տերյեի', 'սիրտը', 'ջերմացավ', ',', 'նա', 'հուզվեց', ':']\n",
            "Entities: [('Տերյեն', 'PERSON', 86, 92)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'այդ', 'պահին', 'նորածինը', 'սկսեց', 'ճչալ', ':', 'Նա', 'կկոցեց', 'աչքերը', ',', 'լայն', 'բացեց', 'իր', 'կարմիր', 'բուկը', 'ն', 'այնքան', 'զզվելի', 'ու', 'ականջ', 'ծակող', 'ձայնով', 'ծղրտաց', ',', 'որ', 'Տերյեի', 'արյունը', 'երակներում', 'սառեց', ':', 'Նա', 'առաջ', 'պարզած', 'ձեռքով', 'ցնցում', 'էր', 'զամբյուղն', 'ու', 'գոռում', '՝', 'ղու', '՛', '-', 'ղու', '՛', '-', 'ղու', '՛', ',', 'որպեսզի', 'երեխային', 'ստիպի', 'լռել', ',', 'բայց', 'վերջինս', 'ավելի', 'բարճր', 'էր', 'ոռնում', '.', 'նրա', 'դեմքը', 'կապտել', 'էր', ',', 'ն', 'նա', 'կարծես', 'պատրաստ', 'էր', 'ոռնոցից', 'պայթել', ':']\n",
            "Entities: [('Տերյեի', 'PERSON', 128, 134)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "340\n",
            "350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Տիկին', 'Գայարը', ',', 'չնայած', 'դեռ', 'երեսուն', 'տարեկան', 'էլ', 'չկար', ',', 'արդեն', 'ապրել', 'էր', 'իր', 'կյանքը', ':', 'Նրա', 'արտաքինը', 'համապատասխանում', 'էր', 'տարիքին', ',', 'բայց', 'միաժամանակ', 'նա', 'իր', 'տարիքից', 'երկու', ',', 'երեք', ',', 'հարյուրապատիկ', 'անգամ', 'ավելի', 'մեծ', 'տեսք', 'ուներ', ',', 'նման', 'էր', 'աղջկա', 'մումիայի', ',', 'բայց', 'ներքուստ', 'արդեն', 'վաղուց', 'մեռած', 'էր', '.', 'փոքր', 'հասակում', 'հայրը', 'վառարանի', 'կրակխառնիչով', 'հարվածել', 'էր', 'նրա', 'ճակատին', '՝', 'ուղիղ', 'քթարմատից', 'վերն', ',', 'ն', 'այդ', 'Ժամանակվանից', 'նա', 'կորցրել', 'էր', 'հոտառությունը', ',', 'ինչպես', 'նան', 'մարդկային', 'ջերմության', 'ու', 'սառնության', 'ցանկացած', 'զգացում', 'ն', ',', 'ընդհանրապես', ',', 'ցանկացած', 'ուժեղ', 'զգացում', ':', 'Այդ', 'մեկ', 'հարվածով', 'նրա', 'մեջ', 'սպանվել', 'էին', 'ն', 'քնքշությունը', ',', 'ն', 'զզվանքը', ',', 'ն', 'ուրախությունը', ',', 'ն', '.', 'հուսահատությունը', ':', 'Ավելի', 'ուշ', ',', 'համատեղ', 'ապրելով', 'ամուսնու', 'հետ', 'ու', 'ծնելով', 'իր']\n",
            "Entities: [('Գայարը', 'PERSON', 6, 12), ('երեսուն տարեկան', 'DATE', 25, 40), ('երկու', 'CARDINAL', 147, 152), ('երեք', 'CARDINAL', 154, 158), ('մեկ', 'CARDINAL', 507, 510)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n",
            "500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'հիշեցնել', 'իր', 'պարտքի', 'մասին', ':', '«', 'Քաղաքավարության', 'համար', 'նա', 'մեկ', 'շաբաթ', 'սպասեց', ',', 'ու', 'երբ', 'պակասող', 'փո', '`', 'ղերը', 'այդպես', 'էլ', 'չփոխանցվեցին', ',', 'նա', 'բռնեց', 'տղայի', 'ձեռ|', '2', 'ունրա', 'հետ', 'գնաց', 'քաղաք', ':', 'Տ', ':', '`', 'Գետից', 'ոչ', 'հեռու', 'Մորտելյերի', 'փողոցի', 'վրա', ',', 'ապրում', 'էր', 'րա', 'ծանոթը', 'Գրիմալ', 'ազգանունով', 'կաշեգործը', ',', 'որին', 'աշՆ', '1', 'խատանքի', 'համար', 'մշտապես', 'պետք', 'էին', 'լինում', 'տղաներ', '2', 'Հ', 'ոչ', 'թե', 'որպես', 'աշ', 'սկերտներ', 'կամ', 'ենթավարպետներ', ',', 'այլ', 'որՏՅ', ':', 'պես', 'իխե', 'աշխատուժ', ':', 'չէ', '՞', 'որ', 'այդ', 'արհեստի', 'մեջ', 'հարկ', 'էր', '`', 'լինում', 'կատարել', 'կյանքի', 'համար', 'այն', 'աստիճան', 'վտանգավոր', 'գործողություններ', 'մորթափառից', 'մաքրել', 'նեխող', 'գազանների', 'մորթիները', ',', 'միմյանց', 'խառնել', 'դաբաղման', 'թուն', '.', 'ՐԵ', ':', 'ներկանյութերի', 'լուծույթները', ',', 'թափել', 'կսկծոր', 'գործված', 'քիմիական', 'Նյութերը', ',', 'որ', 'կարգին', 'վարպետը', ',', 'Աաաա', 'խնայելով', 'իր', 'ուսուցառած', 'օգնականներին', ',', 'վարձում', 'էր', 'գործազուրկ', 'ու', 'անտուն', 'խառնամբոխին', 'կամ', 'խնամազուրկ', 'երեխաներին', ',', 'որոնց', 'ճակատագրով', 'դժբախտության', 'դեպքում', 'ոչ', 'ոք', 'չի', 'հետաքրքրվի', ':', 'Հասկանալի', 'է', ',', 'որ', 'տիկին', 'Գայարը', 'գիտեր', ',', 'որ', 'Փրիմալի', 'դաբաղանոցում', 'Գրենույը', 'մարդկային', 'չափանիշներով', 'կենդանի', 'մնալու', 'շանս', 'չուներ', ':', 'Բայց', 'նա', 'այնպիսի', 'կին', 'չէր', ',', 'որ', 'մտահոգվեր', 'նման', 'հարցերի', 'շուրջ', ':', 'Չէ', '\"', 'որ', 'խնա', 'կատարել', 'էր', 'իր', 'պարտքը', ':', 'Խնամակալությունն', 'ավարտվել', 'է', ':', 'Ինչ', 'էլ', 'որ', 'տեղի', 'ունենար', 'խնամառուի', 'հետ', 'ապագայում', ',', 'դա', 'նրան', 'չէր', 'վերաբերում', ':', 'Ողջ', 'կմնա', '՝', 'լավ', 'է', ',', 'կմեռնի', 'նույնպես', 'լավ', 'է', ',', 'կարնորն', 'այն', 'է', ',', 'որ', 'ամեն', 'ինչ', 'լինի', 'օրենքով', ':', 'Այդ', 'իսկ', 'պատճառով', 'նա', 'պարոն', 'Գրիմալին', 'խնդրեց', 'գրությամբ', 'հաստատել', 'երեխայի', 'փոխանցումը', ',', 'իր', 'հերթին', 'ստացական', 'տվեց', 'տասնհինգ', 'ֆրանկ', 'միջնորդադրամ', 'ստանալու', 'վերաբերյալ', 'ն', 'ուղղվեց', 'տուն', '՝', 'Շարոն', 'փողոց', ':', 'Նա', 'նույնիսկ', 'փոքրագույն', 'խղճի', 'խայթ', 'չէր', 'զգում', ':', 'Շակառակը', ',', 'գտնում', 'էր', ',', 'որ', 'ոչ', 'միայն', 'օրենքով', 'է', 'գործել', ',', 'այլն']\n",
            "Entities: [('մեկ շաբաթ', 'DATE', 54, 63), ('2', 'CARDINAL', 140, 141), ('Մորտելյերի փողոցի', 'FACILITY', 184, 201), ('Գրիմալ', 'PERSON', 227, 233), ('1', 'CARDINAL', 265, 266), ('2', 'CARDINAL', 312, 313), ('Աաաա', 'GPE', 653, 657), ('Գայարը', 'PERSON', 847, 853), ('Փրիմալի', 'GPE', 864, 871), ('Գրենույը', 'PERSON', 885, 893), ('Գրիմալին', 'PERSON', 1244, 1252), ('տասնհինգ ֆրանկ', 'MONEY', 1323, 1337), ('Շարոն փողոց', 'FACILITY', 1387, 1398), ('Շակառակը', 'PERSON', 1444, 1452)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Գրգռվածությունից', 'նա', 'քիչ', 'էր', 'մնում', 'վատանար', ':', 'Նա', 'դեռնս', 'նույնիսկ', 'չէր', 'էլ', 'պարզել', 'որտեղից', 'է', 'ընդհանրապես', 'գալիս', 'այդ', 'բուրմունքը', ':', 'Երբեմն', 'թեթն', 'քամիների', 'միջն', 'ընդմիջումները', 'տնում', 'էին', 'րոպեներ', ',', 'ն', 'ամեն', 'անգամմնա', '՛', 'վրա', 'հարձակվում', 'էր', 'սահմռկեցուցիչ', 'սարսափը', ',', 'որ', 'ինքը', 'հավերժորեն', 'կորցրեց', 'այն', ':', 'Ի', 'վերջո', ',', 'նա', 'հանգեց', 'այն', 'փրկարար', 'հետնությանը', ',', 'որ', 'քամին', 'իրեն', 'է', 'հասնում', 'գետի', 'մյուս', 'ափից', '՝', 'հարավարնելյան', 'ուղղությամբ', 'ինչ', '-', 'որ', 'տեղից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այն', 'հանգամանքը', ',', 'որ', 'այս', 'հոյակապության', 'սկզբում', 'կանգնած', 'էր', 'սպանությունը', ',', 'նա', ',', 'եթե', 'ընդհանրապես', 'գիտակցում', 'էր', 'դա', ',', 'ընդունում', 'էր', 'խոր', 'անտարբերությամբ', ':', 'Մարե', 'փողոցի', 'աղջկա', 'արտաքինը', 'նրա', 'դեմքը', ',', 'նրա', 'մարմինը', ',', 'Գրենույն', 'արդեն', 'չէր', 'կարողանում', 'վերհիշել', ':', 'չէ', '՞', 'որ', 'պահպանել', 'էր', 'լավագույնը', ',', 'ինչը', 'նա', 'խլեց', 'ու', 'սեփականացրեց', '.', 'նրա', 'բուրմունքի', 'էությունը', ':']\n",
            "Entities: [('Մարե փողոցի', 'FACILITY', 141, 152), ('Գրենույն', 'PERSON', 192, 200)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1010\n",
            "1020\n",
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['10', '-', 'Շենյե', ',', '-', 'կանչեց', 'Բալդինին', 'իր', 'փոքրիկ', 'գրասենյակից', ',', 'որտեղ', 'նա', ',', 'աչքերը', 'փակ', 'դռանը', 'հառած', ',', 'մի', 'քանի', 'ժամ', 'քարացած', 'կանգնած', 'էր', ',', '-', 'հագեք', 'ճեր', 'կեղծամը', ':', 'Ուճիթապտղի', 'յուղի', 'տակառիկների', 'ն', 'կախված', 'բայոնյան', 'ապխտած', 'ազդրերի', 'միջն', 'հայտնվեց', 'Շենյեն', '՝', 'Բալդինիի', 'ենթավարպետը', 'նույնպես', 'արդեն', 'մի', 'ծեր', 'մարդ', ',', 'չնայած', 'տիրոջից', 'ավելի', 'երիտասարդ', ',', 'ու', 'քայլեց', 'առաջ', 'դեպի', 'առավել', 'նրբաճաշակ', 'կահավորված', 'կրպակի', 'շինությունը', ':', 'Նա', 'սերթուկի', 'գրպանից', 'դուրս', 'բերեց', 'իր', 'կեղծամը', 'ն', 'քաշեց', 'գլուխը', ':', \"'\", '-', 'Պարոն', 'Բալդինի', ',', 'դուք', 'դոււս', '՛', 'եք', 'գնում', ':', '`', 'ԾՈջ', '-', 'ասաց', 'Բալդինին', ',', '-', 'ես', 'մի', 'երկու', 'ժամով', 'առանձնանում', 'եմ', 'իմ', 'աշխատասենյակում', 'ու', 'ցանկանում', 'եմ', ',', 'որ', 'ինճ', 'բացարճակապես', 'ոչ', 'ոք', 'չանհանգստացնի', ':', 'ա', 'ՄԶ', 'հասկանում', 'եմ', ':', 'Դուք', 'նոր', 'օծանելիքներ', 'եք', 'հայտնագործում', ':', '`', '`', 'Բալդինի', 'Հենց', 'այդպես', ':', 'Կոմս', 'Վերամոնի', 'պատվե|', 'րով', 'ուզում', 'եմ', 'բուրումնավետ', 'դարձնել', 'իսպանական', 'կաշվի', 'մի', 'կտոր', ':', 'Նա', 'պահանջում', 'է', 'բացարճակապես', 'ինչ', '-', 'որ', 'նոր', 'հոտ', ':', 'Պահանջում', 'է', 'ինչ', '-', 'որ', 'մի', '...', 'մի', '...', 'կարծեմ', 'դա', 'կոչվում', 'էր', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '՝']\n",
            "Entities: [('10 -', 'DATE', 0, 4), ('Շենյե', 'PERSON', 5, 10), ('Բալդինին', 'PERSON', 20, 28), ('մի քանի ժամ', 'TIME', 86, 97), ('Շենյեն', 'PERSON', 214, 220), ('Բալդինիի', 'PERSON', 222, 230), ('Բալդինի', 'PERSON', 439, 446), ('ԾՈջ', 'ORGANIZATION', 472, 475), ('Բալդինին', 'PERSON', 482, 490), ('մի երկու ժամով', 'TIME', 496, 510), ('Բալդինի', 'PERSON', 664, 671), ('Վերամոնի', 'PERSON', 690, 698), ('իսպանական', 'NORP', 741, 750), ('«Ամուրն ու Պսիքեն»', 'ORGANIZATION', 862, 880)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['այն', ',', 'ինչը', 'նա', 'պահանջում', 'է', ',', 'իսկ', 'պատրաստված', 'է', 'Սեն', '-', 'Անդրե', '-', 'դեզ', '-', 'Ար', 'փողոցի', 'այն', 'բթամիտի', 'կողմից', '...', 'ինչպես', '՛', 'էր', 'անունը', '...']\n",
            "Entities: [('Սեն-Անդրե-դեզ-Ար փողոցի', 'FACILITY', 43, 66)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Այո', ',', 'Պելիսյե', ':', 'Ճիշտ', 'է', ':', 'Այդպես', 'են', 'նրան', '՝', 'այդ', 'բթամիտին', 'անվանում', ':', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', 'Պելիսյեից', '։', 'Դուք', 'գիտեք', '՛', 'այդ', 'օծանելիքը', ':']\n",
            "Entities: [('Բալդինի', 'PERSON', 0, 7), ('Պելիսյե', 'PERSON', 13, 20), ('«Ամուրն ու Պսիքեն» Պելիսյեից', 'ORGANIZATION', 69, 97)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Գռեհիկկ', '՞', ':']\n",
            "Entities: [('Բալդինի Գռեհի՞կ', 'PERSON', 0, 15)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բալդինի', 'Իրոք', '՛', ':', 'Իսկ', 'էլ', 'ինչ', '՞', 'կա', 'այնտեղ', ':']\n",
            "Entities: [('Բալդինի', 'PERSON', 0, 7)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ալքիմիկոս', 'է', ',', 'ասում', 'են', 'մարդիկ', '.', 'լավ', 'է', ',', 'թող', 'այդպես', 'էլ', 'մտածեն', ':', 'Այն', 'մասին', ',', 'որ', 'իր', 'արվեստն', 'արհեստ', 'է', ',', 'ինչպես', 'ն', 'ցանկացած', 'ուրիշը', ',', 'գիտեր', 'միայն', 'ինքը', ',', 'Ա', 'դրանում', 'էր', 'նրա', 'հպարտությունը', ':', 'Նա', 'չէր', 'էլ', 'ցանկանում', 'գյուտարար', 'լինել', ':', 'Գյուտարարությունը', 'բավական', 'կասկածելի', 'է', ',', 'գտնում', 'էր', 'Բալդինին', ',', 'քանի', 'որ', 'այն', 'մշտապես', 'նշանակում', 'է', 'կանոնների', 'խախտում', ':', 'Նա', 'ամեննին', 'էլ', 'չէր', 'պատրաստվում', 'կոմս', 'Վերամոնի', 'համար', 'նոր', 'օծանելիք', 'հնարել', ':', 'Համենայնդեպս', ',', 'Շենյեն', 'հարկադրված', 'չի', 'լինի', 'իրեն', 'համոզել', 'Պելիսյեից', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', 'ձեռք', 'բերել', ':', 'Նա', 'արդեն', 'ձեռք', 'էր', 'բերել', 'այդ', 'օծանելիքները', ':', 'Ահա', 'դրանք', ',', 'պատուհանի', 'մոտի', 'գրասեղանի', 'վրա', '՝', 'հղկած', 'խցանով', 'փոքրիկ', 'ապակե', 'սրվակների', 'մեջ', ':', 'Նա', 'դրանք', 'գնել', 'էր', 'մի', 'քանի', 'օր', 'առաջ', ':', 'Բնականաբար', ',', 'անձամբ', 'չէր', 'գնել', ':', 'Չէ', '՝', 'որ', 'նա', 'չէր', 'կարող', 'օծանելիքի', 'համար', 'անձամբ', 'մտնել', 'Պելիսյեի', 'մոտ', ':', 'Նա', 'գործել', 'էր', 'միջնորդի', 'միջոցով', ',', 'իսկ', 'վերջինս', 'էլ', 'իր', 'հերթին', 'մեկ', 'այլ', 'միջնորդի', 'օգնությամբ', ':', 'Ջգուշությունը', 'երբեք', 'չի', 'խանգարի', ':', 'Քանզի', 'Բալդինին', 'պատրաստվում', 'էր', 'այդ', 'օծանելիքն', 'օգտագործել', 'ոչ', 'միայն', 'իսպանական', 'կաշին', 'բուրումնավետ', 'դարճնելու', 'համար', '.', 'դրա', 'համար', 'մեկ', 'սրվակը', 'չէր', 'բավականացնի', ':', 'Նա', 'էլ', '՛', 'ավելի', 'վատ', 'մտադրություն', 'ուներ', '.', 'պատճենել', 'այն', ':']\n",
            "Entities: [('Գյուտարարությունը', 'GPE', 207, 224), ('Բալդինին', 'PERSON', 256, 264), ('Վերամոնի', 'PERSON', 352, 360), ('Շենյեն', 'PERSON', 402, 408), ('Պելիսյեից', 'GPE', 441, 450), ('«Ամուրն ու Պսիքեն»', 'ORGANIZATION', 451, 469), ('մի քանի օր առաջ', 'DATE', 622, 637), ('Պելիսյեի', 'PERSON', 717, 725), ('Ջգուշությունը', 'PERSON', 816, 829), ('Բալդինին', 'PERSON', 854, 862), ('իսպանական', 'NORP', 912, 921), ('մեկ', 'CARDINAL', 968, 971)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Ախ', '՛', ',', 'որքան', 'վատ', 'է', ',', 'որ', 'ազնիվ', 'մարդը', 'ստիպված', 'Է', 'հնարամտություն', 'գործածել', ':', 'Որքան', 'ծանր', 'է', 'զոհաբերել', 'այ', 'ամենաթանկարժեքը', ',', 'որ', 'ունես', '՝', 'նման', 'խղճուկ', 'ձնով', 'վարկաբեկելով', 'սեփական', 'պատիվը', ':', 'Բայց', 'ինչ', '՞']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['«', 'Խոնջանքով', '»', ',', 'մշկային', 'գերհագեցած', 'բուրմունքով', ':', 'Բոլորին', 'հանկարծ', 'տիրում', 'էր', 'մուշկի', 'հոտով', 'բուրելու', 'գազանային', 'ցանկությունը', ',', 'ն', 'Բալդինիին', 'ոչինչ', 'չէր', 'մնում', ',', 'քան', 'իր', 'հազրեվարդը', 'վերամշակել', 'գլուխը', 'լվանալու', 'համար', 'ջրի', 'ու', 'նարդոսը', 'կարել', 'բույրաբարձիկի', 'մեջ', ':', 'Դրա', 'փոխարեն', ',', 'երբ', 'հաջորդ', 'տարի', 'նա', 'պատվիրեց', 'համապատասխան', 'քանակությամբ', 'մուշկ', ',', 'մշկահոտ', 'ցիբետին', 'ու', 'կողբենու', 'շիթ', ',', 'Պելիսյեի', 'խելքին', 'փչեց', 'հորինել', '«', 'Անտառային', 'ծաղիկ', '»', 'անվանումով', 'օծանելիք', ',', 'ն', 'այն', 'անմիջապես', 'հաջողություն', 'նվաճեց', ':', 'Գիշերային', 'երկարատն', 'փորձերի', 'գնով', 'կամ', 'խելագար', 'գումարներով', 'լրտեսներին', 'կաշառելով', '՝', 'Բալդինին', 'ի', 'վերջո', 'պարզեց', ',', 'թե', 'ինչից', 'է', 'բաղկացած', '«', 'Անտառային', 'ծաղիկները', '»', ',', 'իսկ', 'Պելիսյեն', 'արդեն', 'կրկին', 'աչքի', 'ընկավ', 'այս', 'անգամ', '«', 'Թուրքական', 'գիշերներով', '»', 'կամ', '«', 'Լիսաբոնյան', 'բուրմունքով', '»', ',', '«', 'Թագավորական', 'պալատի', 'ծաղկեփնջով', '»', 'կամ', ',', 'սատանան', 'գիտի', ',', 'թե', 'էլ', 'ինչով', ':', 'Համենայնդեպս', ',', 'այդ', 'մարդն', 'իր', 'անսանձելի', 'նորարարական', 'կրքով', 'վտանգ', 'էր', 'ներկայացնում', 'ողջ', 'արհեստի', 'համար', ':', 'Ինչ', 'լավ', 'կլիներ', ',', 'եթե', 'դաժան', 'ժամանակների', 'արտադրամասային', 'իրավունքը', 'նորից', 'ետ', 'գար', ':', 'Նման', 'լկտի', 'դուրսպրծուկի', ',', 'նման', 'գռփողի', 'հանդեպ', ',', 'որը', 'հարստանում', 'էր', 'հոտերի', 'արժեզրկման', 'հաշվին', ',', 'կարելի', 'էր', 'կիրառել', 'ամենահրեշային', 'միջոցները', ':', '`', '՝', 'Նրանից', 'խլել', 'արտոնագիրը', ',', 'արգելել', 'օծանագործային', 'գործի', 'մեջ', 'խցկվել', '...', 'ն', 'ընդհանրապես', ',', 'խարդախը', 'նախնառաջ', 'թող', 'ինչ', '-', 'որ', 'բան', 'սովորի', ':', 'չէ', '՞', 'որ', 'նա', '՝', 'այդ', 'Պելիսյեն', ',', 'ուսուցառած', 'օծանագործ', 'ու', 'ճեռնոցագործ', 'չէր', ':', '`', 'Նրա', 'հայրն', 'ընդամենը', 'քացախ', 'քամող', 'էր', ',', 'Ա', 'Պելիսյեն', 'նս', 'քացախ', 'քամող', 'էր', ',', 'ոչ', 'այլ', 'ինչ', ':', 'Եվ', 'միայն', 'այն', 'պատճառով', ',', 'որ', 'նա', '՝', 'որպես', 'քացախ', 'քամող', ',', 'սպիրտային', 'արտադրության', 'մեջ', 'մուտքի', 'իրավունք', 'ուներ', ',', 'նրան', 'հաջողվեց', 'ներթափանցել', 'իրական', 'օծանագործների', 'շրջան', ',', 'ն', 'այժմ', 'նա', 'անօրինականություններ', 'է']\n",
            "Entities: [('«Խոնջանքով»', 'ORGANIZATION', 0, 11), ('Բալդինիին', 'PERSON', 119, 128), ('հաջորդ տարի', 'DATE', 254, 265), ('Պելիսյեի', 'PERSON', 344, 352), ('«Անտառային ծաղիկ»', 'WORK OF ART', 373, 390), ('Բալդինին', 'PERSON', 527, 535), ('Պելիսյեն', 'PERSON', 599, 607), ('Թուրքական', 'NORP', 642, 651), ('Լիսաբոնյան', 'ORGANIZATION', 669, 679), ('«Թագավորական պալատի', 'ORGANIZATION', 694, 713), ('Պելիսյեն', 'PERSON', 1200, 1208), ('Ա Պելիսյեն', 'PERSON', 1286, 1296)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'կատարում', 'այնտեղ', ',', 'ինչպես', 'գարշահոտ', 'Ժանտաքիսը', ':', '`', 'Ինչի', '՛', 'համար', 'էր', 'պետք', 'ամեն', 'սեզոն', 'մոդայի', 'մեջ', 'ներմու', '`', 'ծել', 'նոր', 'օծանելիք', ':', 'Ինչ', '՞', 'անհրաժեշտություն', 'կար', 'դա', 'անել', ':', 'Նախկինում', 'հանրությունը', 'լիովին', 'բավարարվում', 'էր', 'մանուշակի', 'ջրով', 'ու', 'պարզունակ', 'ծաղկային', 'խառնուրդներով', ',', 'որոնք', 'տասը', 'տարին', 'մեկ', 'ընդամենը', 'թեթնակի', 'փոփոխության', 'էին', 'ենթարկվում', ':', 'Հազարամյակներով', 'մարդիկ', 'բավարարվում', 'էին', 'խունկով', 'ու', 'զմուռսով', ',', 'մի', 'քանի', 'բալզամներով', ',', 'յուղերով', 'ու', 'չորացրած', 'խոտերով', ':', 'Եվ', 'նույնիսկ', 'այն', 'բանից', 'հետո', ',', 'երբ', 'նրանք', 'սովորեցին', 'փորձանոթների', '`', 'ու', 'թորման', 'կաթսաների', 'օգնությամբ', 'թորած', 'ջուր', 'ստանալ', ',', 'ջրային', 'գոլորշու', 'օգնությամբ', 'խոտերից', ',', 'ծաղիկնե', '`', 'րից', 'ու', 'տարբեր', 'տեսակի', 'փայտանյութերից', 'եթերային', 'յուղերի', 'տեսքով', 'խլել', 'նրանց', 'բուրումնավետությունը', ',', '`', 'կաղնուց', 'պատրաստված', 'ճզմիչների', 'օգնությամբ', 'քամել', 'այն', 'սերմերից', 'ու', 'կորիզներից', 'ն', 'մրգերի', 'կեղններից', 'կամ', 'խնամքով', 'ֆիլտրված', 'ճարպերի', 'օգնությամբ', 'այն', 'դուրս', 'բերել', 'ծաղկաթերթիկներից', ',', 'հոտերի', 'քանակը', ',', 'այնուամենայնիվ', ',', 'դեռնս', 'սահմանափակ', 'էր', ':', 'Այն', 'ժամանակներում', '`', 'այնպիսի', 'կերպար', ',', 'որպիսին', 'Պելիսյեն', 'է', ',', 'ընդհանրապես', 'չէր', 'կարող', 'լինել', '.', 'չէ', '՞', 'որ', 'այն', 'ժամանակներում', 'նույնիսկ', 'հասարակ', 'շրթներկի', 'պատրաստման', 'համար', 'պահանջվում', 'էին', 'ունակություններ', ',', 'որոնց', 'մասին', 'այդ', 'քացախագործը', 'չէր', 'էլ', 'կարող', 'երազել', ':', 'Պետք', 'էր', 'ոչ', 'միայն', 'կարողանալ', 'թորել', ',', 'պետք', 'էր', 'լինել', 'քսուքներ', 'պատրաստող', 'ու', 'դեղագործ', ',', 'ալքիմիկոս', 'ու', 'արհեստավոր', ',', 'միաժամանակ', 'առնտրական', ',', 'հումանիստ', 'ու', 'այգեպան', ':', 'Պետք', 'էր', 'կարողանալ', 'ոչխարի', 'երիկամների', 'ճարպը', 'տարբերել', 'հորթի', 'ճարպից', ',', 'իսկ', '«', 'Վիկտորիա', '»', 'տեսակի', 'մանուշակը', 'Պարմի', 'մանուշակից', ':', 'Անհրաժեշտ', 'էր', 'տիրապետել', 'լատիներենին', ':', 'Պետք', 'էր', 'գիտենալ', ',', 'թե', 'երբ', 'ես', 'տերւապատվում', \"խամ'\", 'բարները', ',', 'ն', 'երբ', 'է', 'ծաղկում', 'խորդենին', ',', 'ն', 'որ', 'արնածագի']\n",
            "Entities: [('Ժանտաքիսը', 'PERSON', 35, 44), ('տասը տարին', 'DATE', 254, 264), ('մեկ', 'CARDINAL', 265, 268), ('Պելիսյեն', 'PERSON', 940, 948), ('«Վիկտորիա»', 'FACILITY', 1348, 1358), ('Պարմի մանուշակից', 'FACILITY', 1376, 1392), ('լատիներենին', 'LANGUAGE', 1417, 1428)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Եվ', 'կամ', 'վերցնենք', 'խանգարվածությունը', 'արագության', 'վրա', ':', 'Ինչու', '՛', 'անհրաժեշտ', 'եղավ', 'այդքան', 'շատ', 'նոր', 'ճանապարհներ', 'անցկացնել', ':', 'Ինչի', '՞', 'համար', 'են', 'այդ', 'նոր', 'կամուրջները', ':', 'Ինչի', 'համար', ':', 'Որպեսզի', 'մեկ', 'շաբաթում', 'Լիոն', '՞', 'հասնեն', ':', 'Իսկ', 'ինչ', '՞', 'օգուտ', 'կա', 'դրանից', ':', 'Ում', 'համար', 'Է', 'դա', 'օգտավետ', ':', 'Ում', '՞', 'է', 'պետք', 'գլուխը', 'կոտրելով', 'սլանալ', 'Ատլանտյան', 'օվկիանոսով', ':', 'Մեկ', 'ամիս', 'անց', 'Ամերիկայում', 'հայտնվելու', 'համար', '՛', ':', 'Բայց', 'չէ', '՞', 'որ', 'մարդիկ', 'հազարամյակներ', 'շարունակ', 'հրաշալիորեն', 'բավարարվում', 'էին', 'առանց', 'այդ', 'աշխարհամասի', ':', 'Ինչ', '՞', 'է', 'կորցրել', 'նախնադարյան', 'անտառում', 'հնդկացիների', 'կամ', 'սնամորթների', 'մոտ', 'քաղաքակիրթ', 'մարդը', ':', 'Անգամ', 'Հյուսիս', 'նրանք', 'հասան', '՝', 'Լապլանդիա', ',', 'որտեղ', 'հավերժական', 'սառույց', 'է', ',', 'Ա', 'որտեղ', 'ապրում', 'են', 'վայրի', 'մարդիկ', ',', 'ովքեր', 'հում', 'ձուկ', 'են', 'խժռում', ':', 'Դա', 'դեռ', 'քիչ', 'էր', ',', 'ցանկացան', 'նս', 'մի', 'աշխարհամաս', 'հայտնաբերել', ',', 'ասում', 'են', ',', 'ինչ', '-', 'որ', 'տեղ', 'հարավային', 'ծովերում', ':', 'Իսկ', 'մեր', 'ինչին', '՞', 'է', 'պետք', 'այդ', 'խելագարությունը', ':', 'Միայն', 'այն', 'պատճառով', ',', 'որ', 'ուրիշներն', 'էլ', 'են', 'այդպես', 'անում', '՝', 'իսպանացիները', ',', 'անիծյալ', 'անգլիացիները', ',', 'անպատկառ', 'հոլանդացիները', ',', '.', 'որոնց', 'հետ', 'հետագայում', 'ստիպված', 'էինք', 'մարտ', 'մղել', ',', 'ինչն', 'ընդհանրապես', 'մեզ', 'չէինք', 'կարող', 'թույլ', 'տալ', ':', 'Երեք', 'հարյուր', 'հազար', 'լիվր', 'կանխիկ', 'գումար', '՝', 'ահա', 'թե', 'որքան', 'արժի', 'մեկ', 'ռազմանավը', ',', 'իսկ', 'հետո', 'նա', 'մեկ', 'թնդանոթային', 'կրակոցից', 'հինգ', 'րոպեի', 'ընթացքում', 'խորտակվում', 'է', ',', 'ն', 'մնաք', 'բարով', 'հավերժ', ',', 'հարկատուների', 'փողեր', ':', 'Այժմ', 'ֆինանսների', 'պարոն', 'նախարարը', 'պահանջում', 'է', 'իրեն', 'փոխանցել', 'բոլոր', 'եկամուտների', 'տասներորդ', 'մասը', ',', 'ն', 'դա', 'կործանարար', 'է', '։']\n",
            "Entities: [('Լիո՞ն', 'GPE', 179, 184), ('Ատլանտյան օվկիանոսով', 'LOCATION', 278, 298), ('Մեկ ամիս անց', 'DATE', 300, 312), ('Ամերիկայում', 'LOCATION', 313, 324), ('հնդկացիների', 'NORP', 473, 484), ('Լապլանդիա', 'GPE', 550, 559), ('Երեք հարյուր հազար լիվր', 'MONEY', 990, 1013), ('մեկ', 'CARDINAL', 1047, 1050), ('մեկ', 'CARDINAL', 1074, 1077), ('հինգ րոպեի', 'TIME', 1099, 1109), ('տասներորդ', 'ORDINAL', 1250, 1259)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1220\n",
            "1230\n",
            "1240\n",
            "1250\n",
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n",
            "1350\n",
            "1360\n",
            "1370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Հրաշալի', 'է', ',', 'հրաշալի', '...', '-', 'մրթմրթաց', 'նա', '՝', 'ագահաբար', 'հոտոտելով', ':', '-', '\"', 'Նրանում', '.', 'ուրախություն', 'կա', ',', 'նա', 'չքնաղ', 'է', '՝', 'ինչպես', 'մեղեդին', ',', 'նա', 'ուղղակի', 'ստեղծում', 'է', 'լավ', 'տրամադրություն', '...', 'Ինչ', '՞', 'անհեթեթություն', 'է', '՝', 'լավ']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['<UNK>իծաղեի', '՛', 'է', 'նման', 'ճարտասանությունը', '.', '«', 'Մեղեդի', 'է', ':', 'Ուրախություն', 'է', ':', 'Չքնաղ', 'է', ':', 'Բարձրացնում', 'է', 'տրամադրությունը', '»', ':', 'Հիմարություն', ':', 'Մանկական', 'հիմարություն', ':', 'Րոպեական', 'տպավորություն', ':', 'Շին', 'սխալ', ':', 'Խառնվածքի', 'հարց', ':', 'Ամենայն', 'հավանականությամբ', '՝', 'իտալական', 'ժա']\n",
            "Entities: [('իտալական', 'NORP', 216, 224)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '`', 'վորությամբ', ':', 'չէ', '՞', 'որ', 'դա', 'ոսկե', 'կանոն', 'է', ',', 'Բալդինի', ',', 'այ', 'դու', '՝', 'ծեր', 'ոչխարի', 'գլուխ', ':', 'Երբ', 'հոտ', 'ես', 'քաշում', '՝', 'հոտ', 'քաշիր', ',', 'իսկ', 'դատիր', 'հետո', ':', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ը', 'շարքային', 'օծաելիք', 'չէ', ':', 'Բավական', 'հաջող', 'արտադրանք', 'է', ':', 'Ճարպկորեն', 'թխված', 'անշնորհք', 'ապրանք', ':', 'Եթե', 'չասենք', 'կեղծիք', ':', 'Իսկ', 'կեղծիքից', 'բացի', ',', 'ուրիշ', 'էլ', 'ինչ', '՞', 'կարելի', 'Է', 'սպասել', 'Պելիսյեի', 'նման', 'մարդուց', ':', 'Բնականաբար', ',', 'այնպիսի', 'տիպը', ',', 'որպիսին', 'Պելիսյեն', 'է', ',', 'հասարակ', 'օծանելիք', 'չի', 'արտադրի', ':', 'Կեղծարարը', 'կարողանում', 'է', 'թոզ', 'փչել', 'մարդկանց', 'աչքերին', ',', 'հոտառությունը', 'շարքից', 'հանել', 'հոտի', 'կատարյալ', 'ներդաշնակությամբ', ':', 'Այդ', 'մարդը', 'հոտառական', 'արվեստի', 'գայլ', 'էր', 'գառան', 'մորթիով', ',', 'ահա', 'թե', 'ով', 'է', 'այդ', 'ճարպիկ', 'խաբեբան', '.', 'մի', 'խոսքով', '՝', 'տաղանդավոր', 'հրեշ', ':', 'Իսկ', 'դա', 'ավելի', 'վատ', 'է', ',', 'քան', 'ինչ', '-', 'որ', 'մի', 'անտաղանդ', 'ապաշնորհ', ',', 'որը', 'չի', 'գիտակցում', 'իր', 'տգիտությունը', ':', '52', 'Բայց', 'դու', ',', 'Բալդինի', ',', 'թույլ', 'չես', 'տա', 'քեզ', 'հիմարացնեն', ':', 'հու', '`', 'միայն', 'առաջին', 'րոպեին', 'փոքր', '-', 'ինչ', 'կորցրիր', 'գլուխդ', 'կեղծ', '`', 'տպավորությամբ', ':', 'Բայց', 'միթե', '՛', 'հայտնի', 'է', ',', 'թե', 'ինչ', 'տեղի', 'կու|', 'նենա', 'այդ', 'հոտի', 'հետ', 'մեկ', 'ժամ', 'անց', ',', 'երբ', 'եթերային', \"փոխա'րինումնե\", 'ը', 'գոլորշանան', ',', 'ու', 'բացահայտվի', 'նրա', 'միջուկը', ':', '222', 'ՅՆԱ', 'այսօր', 'երեկոյան', ',', 'երբ', 'բուրմունք', 'կարձակեն', 'միա', 'ա', '.', '`', 'ան', 'ծանր', ',', 'մութ', 'բաղադրիչները', ',', 'որոնք', 'այժմ', 'թաքնվում']\n",
            "Entities: [('Բալդինի', 'PERSON', 39, 46), ('«Ամուրն ու Պսիքեն»-ը', 'ORGANIZATION', 121, 141), ('Պելիսյեի', 'PERSON', 291, 299), ('Պելիսյեն', 'PERSON', 348, 356), ('52', 'CARDINAL', 696, 698), ('Բալդինի', 'PERSON', 709, 716), ('առաջին', 'ORDINAL', 759, 765), ('րոպեին', 'TIME', 766, 772), ('մեկ ժամ անց', 'TIME', 875, 886), ('222 ՅՆԱ', 'TIME', 956, 963), ('այսօր երեկոյան', 'TIME', 964, 978)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1390\n",
            "1400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Երկրորդ', 'կանոնն', 'ասում', 'է', '.', 'օծանելիքն', 'ապրում', 'է', 'Ժամանակի', 'մեջ', ',', 'նա', 'ունի', 'իր', 'երիտասարդությունը', ',', 'իր', 'հասունությունն', 'ու', 'ծերությունը', ':', 'Եվ', 'եթե', 'միայն', 'այդ', 'բոլոր', 'երեք', 'տարիքներում', 'միատեսակ', 'հաճելի', 'բուրմունք', 'Է', 'արճակում', ',', 'այն', 'կարելի', 'է', 'համարել', 'հաջողված', ':', 'չէ', '՞', 'որ', 'արդեն', 'քանիցս', 'եղել', 'է', 'այնպես', ',', 'որ', 'մեր', 'կողմից', 'պատրաստված', 'խառնուրդն', 'առաջին', 'փորձի', 'Ժամանակ', 'բուրում', 'էր', 'հրաշալի', 'թարմությամբ', ',', 'կարճ', 'ժամանակ', 'անց', 'նեխած', 'մրգահոտերով', ',', 'ն', 'ի', 'վերջո', '՝', 'արդեն', 'չափից', 'դուրս', 'զզվելի', 'մաքուր', 'մուշկի', 'հոտով', ',', 'քանի', 'որ', 'մենք', 'անցել', 'էինք', 'նրա', 'չափաբաժնի', 'նորմից', ':', 'Ընդհանուր', 'առմամբ', 'մուշկի', 'հետ', 'պետք', 'Է', 'զգուշությամբ', 'վարվել', ':', 'Մեն', '-', 'միակ', 'կաթիլը', 'կարող', 'է', 'հասցնել', 'աղետալի', 'հետնանքների', ':', 'Հնուց', 'եկող', 'սխալ', ':', 'Ով', 'գիտի', ',', 'միգուցե', 'Պելիսյեն', 'չափից', 'դոււս', '՛', 'է', 'մուշկ', 'խառնել', ':', 'Միգուցե', 'երեկոյան', 'կողմ', 'նրա', 'գոռոզամիտ', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ից', 'միմիայն', 'կատվի', 'մեզի', 'հոտ', '՛', 'մնա', ':', 'Կապրենք', 'կտեսնենք', ':']\n",
            "Entities: [('Երկրորդ', 'ORDINAL', 0, 7), ('երեք', 'CARDINAL', 144, 148), ('առաջին', 'ORDINAL', 300, 306), ('Պելիսյեն', 'PERSON', 635, 643), ('երեկոյան', 'TIME', 681, 689), ('«Ամուրն ու Պսիքեն»-ից', 'ORGANIZATION', 709, 730)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1410\n",
            "1420\n",
            "1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Բայց', 'նրա', 'ճեռքը', 'մեխանիկորեն', 'շարունակում', 'էր', 'հազար', 'անգամ', 'փորձված', 'նրբագեղ', 'շարժումով', 'Ժանյակավոր', 'թաշկինակը', 'թրջել', 'օծանելիքով', ',', 'այն', 'թափ', 'տալ', 'ու', 'արագ', 'անցկացնել', 'դեմքի', 'կողքով', ',', 'ն', 'ամեն', 'անգամ', 'մեխանիկորեն', 'իր', 'մեջ', 'էր', 'ներշնչում', 'բուրմունքով', 'ներթափանցված', 'օդի', 'չափաբաժինը', ',', 'որպեսզի', 'արվեստի', 'բոլոր', 'կանոններով', 'շունչը', 'պահելով', 'կատարի', 'երկարատն', 'արտաշնչում', ':', 'Ի', 'վերջո', ',', 'քիթն', 'ազատեց', 'նրան', 'այդ', 'տանջանքից', '.', 'ալերգիկ', 'ձնով', 'ներսից', 'ուռչելով', '՝', 'կարծես', 'խցանվեց', 'մեղրամոմե', 'խցանով', ':', 'Այժմ', 'արդեն', 'ընդհանրապես', 'չէր', 'կարող', 'որնէ', 'հոտ', 'զգալ', 'ու', 'հազիվ', 'էր', 'կարողանում', 'շնչել', ':', 'Քիթը', 'լցված', 'էր', ',', 'ինչպես', 'ծանր', 'հարբուխի', 'Ժամանակ', ',', 'իսկ', 'աչքերի', 'անկյուններում', 'արտասուքի', 'կաթիլներ', 'էին', 'հայտնվել', ':', 'Փառք', 'Աստծու', ':', 'Այժմ', 'կարելի', 'է', 'հանգիստ', 'խղճով', 'աշխատանքը', 'դադարեցնել', ':', 'Այժմ', 'նա', 'կատարեց', 'իր', 'պարտքը', ',', 'արեց', 'այն', 'ամենը', ',', 'ինչ', 'կարող', 'էր', 'արվեստի', 'բոլոր', 'կանոնների', 'համաձան', ',', 'ու', 'ինչպես', 'մեկ', 'անգամ', 'չէ', ',', 'որ', 'տեղի', 'էր', 'ունենում', ',', 'պարտվեց', ':', 'Սիռ', '՛', 'քօտտ6', 'ոօ', 'օԵկցճեսր', ':', ':']\n",
            "Entities: [('հազար', 'CARDINAL', 42, 47), ('մեկ', 'CARDINAL', 771, 774)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n",
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Նա', 'ետ', 'քաշեց', 'սողնակը', ',', 'բացեց', 'ծանր', 'դուռը', 'ու', 'ոչինչ', 'չտեսավ', ':', 'Մթությունն', 'ամբողջությամբ', 'կլանեց', 'մոմի', 'լույսը', ':', 'Հետոնա', '՞', 'աստիճանաբար', 'նշմարեց', 'երեխայի', 'կամ', 'տղայի', 'փոքրիկ', 'կերպար', 'ձեռքին', 'ինչ', '-', 'որ', 'առարկա', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Քեզ', 'ինչ', '՞', 'է', 'պետք', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n",
            "1590\n",
            "1600\n",
            "1610\n",
            "1620\n",
            "1630\n",
            "1640\n",
            "1650\n",
            "1660\n",
            "1670\n",
            "1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'ուզում', 'եք', 'այծի', 'մորթիները', 'բուրումնեա', '՛', 'դարձնել', ',', 'վարպետ', 'Բալդինի', ':', 'Այս', 'մորթիները', ',', 'որոնք', 'ես', 'եմ', 'ճեզ', 'բերել', ',', 'դուք', 'դրանց', '՞', 'եք', 'ցանկանում', 'բուրմունք', 'հաղորդել', ',', '-', 'շշնջաց', 'Գրենույը', 'կարծես', 'ի', 'գիտություն', 'չընդունելով', 'Բալդինիի', 'պատասխանը', ':']\n",
            "Entities: [('Բալդինի', 'PERSON', 62, 69), ('Գրենույը', 'PERSON', 162, 170), ('Բալդինիի', 'PERSON', 203, 211)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Պելիսյեի', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ով', '՛', ',', '-', 'հարցրեց', 'Գրենույն', 'ու', 'ավելի', 'շատ', 'խոնարհվեց', ':']\n",
            "Entities: [('Պելիսյեի', 'PERSON', 2, 10), ('Պսիքեն', 'PERSON', 22, 28), ('Գրենույն', 'PERSON', 44, 52)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['Այդ', 'պահին', 'Բալդինիի', 'մարմնով', 'սարսափի', 'թեթն', 'ջղաձգություն', 'անցավ', ':', 'Ոչ', 'այն', 'պատճառով', ',', 'որ', 'ինքը', 'հարգրեց', 'իրեն', '՝', 'որտեղից', '՛', 'է', 'այս', 'տղային', 'ամեն', 'ինչ', 'այդպիսի', 'ճշտությամբ', 'հայտնի', ',', 'այլ', 'ուղղակի', 'այն', 'պատճառով', ',', 'որ', 'ատելի', 'օծանելիքի', 'անունը', ',', 'որի', 'բաղադրությունը', 'այսօր', 'նա', ',', 'ի', 'խայտառակություն', 'իրեն', ',', 'չկարողացավ', 'պարզել', ',', 'բարձրաձայն', 'հնչեցվեց', ':']\n",
            "Entities: [('Բալդինիի', 'PERSON', 10, 18)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'ինչպես', '՛', 'քո', 'գլխում', 'նման', 'աբսուրդային', 'գաղափար', 'ծագեց', ',', 'որ', 'ես', 'ուրիշների', 'օծանելիքն', 'եմ', 'օգտագործում', ',', 'որպեսզի', '...']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այդպես', ',', '-', 'ասաց', 'Բալդինին', ',', 'որը', 'բացարձակապես', 'գնցված', 'էր', 'խոսակցության', '՝', 'դեպի', 'ճշգրիտի', 'ոլորտ', 'նման', 'շրջադարձով', ':', '-', 'էլ', '՛', 'ինչ', ':']\n",
            "Entities: [('Բալդինին', 'PERSON', 16, 24)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Բուրավետ', 'բալասանի', 'յուղը', '՛', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['աներ', 'սարսափելի', 'աշխատանք', ',', 'թերնս', 'ավելի', 'վատ', ',', 'քան', 'մասերի', 'պարզունակ', 'նույնականացումը', '.', 'չէ', '՞', 'որ', 'պետք', 'էր', 'չափել', ',', 'ու', 'կշռել', ',', 'ու', 'գրառել', ',', 'ն', 'ընդ', 'որում', '՝', 'լինել', 'չափազանց', 'ուշադիր', ',', 'քանզի', 'նվազագույն', 'անզգուշությունը', 'կաթոցիչի', 'դողդողոցը', ',', 'սխալը', 'կաթիխերը', 'հաշվելիս', ',', 'կարող', 'էր', 'ամեն', 'ինչ', 'կործանել', ':', 'Իսկ', 'յուրաքանչյուր', 'չհաջողված', 'փորճ', 'սարսափելի', 'թանկ', 'էր', 'նստում', ':', 'Յուրաքանչյուր', 'փչացված', 'խառնուրդ', 'արժեր', 'մի', 'փոքրիկ', 'ունեցվածք', '...', 'Նրա', 'մոտ', 'ցանկություն', 'առաջացավ', 'փորձել', 'այս', 'փոքրիկ', 'մարդուն', ',', 'ցանկություն', 'առաջացավ', 'նրան', 'հարցնել', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', 'ճշգրիտ', 'բանաճնի', 'մասին', ':', 'Եթե', 'նա', 'գիտի', 'այն', 'մեկ', 'գրամի', 'ու', 'մեկ', 'կաթիլի', 'ճշգրտությամբ', ',', 'կնշանակի', 'ակնհայտորեն', 'խաբեբա', 'է', ',', 'որն', 'ինչ', '-', 'որ', 'ձնով', 'կարողացել', 'է', 'հայթայթել', 'Պելիսյեի', 'բանաձնը', ',', 'որպեսզի', 'վստահություն', 'ներշնչի', 'ու', 'Բալդինիի', 'մոտ', 'տեղ', 'ստանա', ':', 'Բայց', 'եթենա', '՞', 'բացահայտի', 'մոտավորապես', ',', 'նշանակում', 'է', '՝', 'նա', 'հոտառության', 'հանճար', 'է', 'ն', ',', 'որպես', 'այդպիսին', ',', 'արժանի', 'Է', 'Բալդինիի', 'պրոֆեսիոնալ', 'հետաքրքրությանը', ':', 'Չի', 'կարելի', 'ասել', ',', 'որ', 'Բալդինին', 'կասկածի', 'տակ', 'դրեց', 'գործերից', 'հեռանալու', '՝', 'իր', 'կողմից', 'ընդունված', 'որոշումը', ':', 'Նույնիսկ', 'եթե', 'այս', 'պատանին', 'լիտրերով', 'այդ', 'օծանելիքից', 'հայթայթի', ',', 'Բալդինին', 'չի', 'ցանկանա', 'դրանով', 'բուրումնավետ', 'դարձնել', 'կոմս', 'Վերամոնի', 'կաշին', ',', 'բայց', '...', 'Բայց', 'չէ', '՞', 'որ', 'մարդը', 'նրա', 'համար', 'չի', 'ողջ', 'կյանքում', 'եղել', 'օծանագործ', 'ն', 'ողջ', 'կյանքում', 'զբաղվել', 'հոտերի', 'կազմումով', ',', 'որպեսզի', 'մի', 'ակնթարթում', 'կորցնի', 'իր', 'ողջ', 'պրոֆեսիոնալ', 'կիրքը', ':', 'Այժմ', 'նրան', 'հետաքրքրում', 'էր', 'անիծյալ', 'օծանելիքի', 'բանաձճնը', ',', 'ավելին', '՝', 'նա', 'ցանկանում', 'էր', 'ուսումնասիրել', 'տարօրինակ', 'տղայի', 'տաղանդը', ',', 'որն', 'ընթերցեց', 'իր', 'ճակատի', 'հոտը', ':', 'Նա', 'ցանկանում', 'էր', 'իմանալ', ',', 'թե', 'ինչ', 'է', 'թաքնված', 'դրա', 'ետնում', ':', 'Նրա', 'մոտ', 'առաջացավ', 'հասարակ', 'հետաքրքրասիրություն', ':']\n",
            "Entities: [('«Ամուրն ու Պսիքեն»-ի', 'ORGANIZATION', 475, 495), ('մեկ գրամի', 'QUANTITY', 534, 543), ('մեկ', 'CARDINAL', 547, 550), ('Պելիսյեի', 'PERSON', 641, 649), ('Բալդինիի', 'PERSON', 691, 699), ('Բալդինիի', 'PERSON', 815, 823), ('Բալդինին', 'PERSON', 872, 880), ('Բալդինին', 'PERSON', 1007, 1015), ('Վերամոնի', 'PERSON', 1060, 1068)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1720\n",
            "1730\n",
            "1740\n",
            "1750\n",
            "1760\n",
            "1770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['բուրավետ', 'բալասանից', ',', 'վարդի', 'յուղից', 'ու', 'մեխակից', ',', 'ինչպես', 'նան', 'բերգամոտից', 'ու', 'հազրեվարդի', 'լուծամզվածքից', 'ն', 'այխ', ':', 'Դա', 'պարզելու', 'համար', 'պետք', 'է', ',', 'ինչպես', 'ասում', 'են', ',', 'ունենալ', 'բավականին', 'նուրբ', 'հոտառություն', ',', 'ու', 'լիովին', 'հնարավոր', 'է', ',', 'որ', 'Աստված', 'քեզ', 'բավականին', 'նուրբ', 'հոտառություն', 'Է', 'տվել', ',', 'ինչպես', 'ն', 'շատ', 'ուրիշ', 'մարդկանց', '՝', 'հատկապես', 'քո', 'տարիքում', ':', 'Սակայն', 'օծանագործի', 'համար', ',', '-', 'ն', 'այստեղ', 'նա', 'վեր', 'պարզեց', 'մատն', 'ու', 'դուրս', 'ցցեց', 'կուրծքը', ',', 'սակայն', 'օծանագործի', 'համար', 'քիչ', 'է', 'ուղղակի', 'նուրբ', 'հոտառություն', 'ունենալը', ':', 'Նրան', 'անհրաժեշտ', 'Է', 'տասնամյակների', 'ընթացքում', 'վարժեցված', ',', 'անկաշառ', 'աշխատող', 'հոտառական', 'օրգան', ',', 'որը', 'թույլ', 'կտա', 'վստահորեն', 'կռահել', 'նույնիսկ', 'ամենաբարդ', 'հոտերը', ',', 'դրանց', 'բաղադրությունն', 'ու', 'համաչափությունները', ',', 'ինչպես', 'նան', 'ստեղծել', 'նոր', 'բուրմունքների', 'անհայտ', 'խառնուրդներ', ':', 'Նման', 'քիթը', ',', 'ն', 'նա', 'մատով', 'թխկթխկացրեց', 'իրենը', ',', '-', 'այդքան', 'հեշտ', 'չի', 'տրվում', ',', 'երիտասարդ', ':', 'Նման', 'քիթը', 'վաստակում', 'են', 'ջանասիրությամբ', 'ու', 'համբերությամբ', ':', 'թե', '՞', 'դու', 'կկարողանայիր', 'ուղղակի', 'այնպես', '՝', 'ձեռքի', 'հետ', 'անվանել', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', 'ճշգրիտ', 'բանաձնը', ':', 'Դե՛', '՞', 'Կկարոաանայի', '՛', ':']\n",
            "Entities: [('«Ամուրն ու Պսիքեն»-ի', 'ORGANIZATION', 880, 900)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Միգուցե', 'դու', 'ինճ', 'գոնե', 'մոտավոարպս', '՛', 'կասես', ',', 'ասաց', 'Բալդինին', 'ու', 'թեթնակի', 'թեքվեց', 'առաջ', ',', 'որպեսզի', 'ավելի', 'լավ', 'ուսումնասիրի', 'դռան', 'մեջ', 'թաքնված', 'դոդոշին', 'Գոնե', 'մոտավորապես', ',', 'ընդհանուր', 'տեսքով', ':', 'Դե', 'Խոսիր', ',', 'չէ', '՞', 'որ', 'դու', 'Փարիզի', 'լավագույն', 'քիթն', 'ես', ':']\n",
            "Entities: [('Բալդինին', 'PERSON', 47, 55), ('Փարիզի', 'GPE', 193, 199)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դե', ',', 'տեսնում', '՛', 'ես', ',', '-', 'փնթփնթաց', 'Բալդինին', '՝', 'միաժամանակ', 'բավարարված', 'ու', 'հիասթափված', ':', '-', 'Չես', 'կարող', ':', 'Իհարկե', 'ոչ', ':', 'Ոնց', 'կարող', 'ես', 'իմանալ', ':', 'Դու', 'նրանցից', 'ես', ',', 'ով', 'ժաշ', 'ուտելիս', 'որոշում', 'է', '՝', 'արդյոք', 'ապուրի', 'մեջ', 'մաղադանոս', '՛', 'է', ',', 'թե', '՞', 'կերբելուկ', ':', 'Դե', 'ինչ', ',', 'դա', 'էլ', 'արդեն', 'քիչ', 'չէ', ':', 'Իայց']\n",
            "Entities: [('Բալդինին', 'PERSON', 29, 37), ('Իայց', 'GPE', 237, 241)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1780\n",
            "1790\n",
            "1800\n",
            "1810\n",
            "1820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'ղատոմսն', 'իմ', 'քթի', 'մեջ', 'է', ':', '<UNK>առնեմ', '՞', 'դրանք', 'ձեզ', 'համար', ',', 'Հ', ':', 'մետր', ',', 'խառնեմ', ':', 'Ն', '`', '-', 'Այսինքն', '՝', 'ինչպես', '՛', ',', '-', 'բացականչեց', 'Բալդինին', 'ավելի', 'Բարեր', ',', 'քան', 'պատշաճ', 'էր', 'նրան', ',', 'ն', 'մոմը', 'մոտեցրեց', 'թզուկի', 'դեմքին', '-', '-', 'Այսինքն', '՝', 'ինչպես', '՛', 'խառնել', ':', 'Գրենույն', 'առաջին', 'անգամ', 'ետ', 'չընկրկեց', ':', 'Զ', '-', 'Ախր', 'դրանք', 'բոլորն', 'այստեղ', 'են', '՝', 'այդ', 'հոտերը', ',', 'որոնք', '18', 'պեոտլ', 'են', ',', 'դրանք', 'բոլորը', 'կան', 'այս', 'սենյակում', ',', 'ասաց', 'նա', '`', 'Ակրկին', 'մատն', 'ուղղեց', 'դեպի', 'մթությունը', ':', 'Վարդի', 'յուղն', '`', '.', 'ահա', 'անտեղ', 'է', ':', 'Իսկ', 'այնտեղ', 'նարնջի', 'գույնը', ':', 'Իսկ', 'այն', '`', 'տեղ', 'մեխակը', ':', 'Իսկ', 'այնտեղ', '՝', 'հազրեվարդը', '...']\n",
            "Entities: [('Բալդինին', 'PERSON', 101, 109), ('առաջին', 'ORDINAL', 209, 215), ('18', 'CARDINAL', 285, 287), ('Ակրկին', 'PERSON', 340, 346)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1830\n",
            "1840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դու', 'կարծում', 'ես', ',', 'որ', 'ես', 'քեզ', 'թույլ', 'կտամ', 'տնօրինել', 'իմ', 'արհեստանոցը', ':', 'Բնահյութերը', ',', 'որոնք', 'մի', 'ողջ', 'ունեցվածք', 'ար<UNK>են', '՞', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', '-', '<UNK>ահ', '՛', ':', '-', 'Բալդինին', 'կտրուկ', 'դուրս', 'փչեց', 'իր', 'մեջ', 'եղած', 'շունչը', ':', 'Այնուհետն', 'թոքերը', 'լցրեց', 'օդով', ',', 'երկար', 'նայեց', 'սարդանման', 'Գրենույին', 'ն', 'մտորեց', ':', '«', 'Ըստ', 'էության', '՝', 'միթե', '՛', '`', 'միննույն', 'չէ', ',', '-', 'մտածեց', 'նա', ',', '-', 'այսպես', 'թե', 'այնպես', 'վաղն', 'ամեն', 'ինչ', 'ավարտվելու', 'է', ':', 'Ես', ',', 'իհարկե', ',', 'գիտեմ', ',', 'որ', 'նա', 'չի', 'կարող', 'անել', 'այն', ',', 'ինչը', 'խոստանում', 'է', ',', 'դա', 'բացառվում', 'է', ',', 'այլապես', 'նա', 'ավելի', 'մեծ', 'համբավ', 'կունենար', ',', 'քան', 'մեծն', 'Ֆրանժիպանին', ':', 'Բայց', 'ինչու', 'սեփական', 'աչքերով', 'չհամոզվեմ', 'նրանում', ',', 'ինչը', 'գիտեմ', ':', 'Միգուցե', 'հանկարծ', 'մի', 'գե', '`', 'ղեցիկ', 'օր', 'Մեսինայում', 'իմ', 'գլուխը', 'մի', 'միտք', 'գա', ',', 'ծեր', 'մարդ', '`', 'կանց', 'մոտ', 'երբեմն', 'լինում', 'են', 'տարօրինակություններ', 'ու', 'խենթ', 'մտքեր', ',', 'որ', 'ես', 'չճանաչեցի', 'մի', 'հանճարի', ',', 'հրաշամանուկի', ',', 'արարածի', ',', 'ով', 'Աստծու', 'ողորմությամբ', 'շռայլորեն', 'տված', 'էր', '...', 'Դա', 'ամբողջապես', 'բացառվում', 'է', ':', 'Ելնելով', 'մենից', ',', 'ինչ', 'ինճ', 'հուշում', 'է', 'բանականությունս', ',', 'դա', 'ացառվ/', 'ճի', '.', 'Բայց', 'չէ', '՞', 'որ', 'լինում', 'են', 'հրաշքներ', ':', 'Անկաս', '`', '`', 'կած', ':', 'Եվ', 'ահա', ',', 'երբ', 'Մեսինայում', 'մոտենա', 'իմ', 'մեռնելու', 'ժա', '.', 'մահվան', 'մահճում', 'ինճ', 'կայցելի', 'մի', 'միտք', '.', 'այն', 'երեկո', 'Փա', 'Ա', 'ւմ', 'քեզ', 'ներկայացավ', 'հրաշքը', ',', 'իսկ', 'դու', 'փակեցիր', 'դ', '...', 'Դա', ',', 'բնականաբար', ',', 'այնքան', 'էլ', 'հաճելի', 'չէր', 'լինի', ',', 'Բալդինի', ':', 'Ավելի', 'լավ', 'Է', 'այս', 'հիմարը', 'սեղանի', 'վրա', 'մի', '`', 'երկու', 'կաթիլ', 'վարդի', 'յուղ', 'ու', 'մուշկի', 'թուրմ', 'թափի', ',', 'դու', 'նս', '|', 'անք', 'կթափեիր', ',', 'եթե', 'քեզ', 'դեռնս', 'իրոք', 'շարունակեր', 'հեՏ', 'սքրքրել', 'Պելիսյեի', 'օծանելիքը', ':', 'Եվ', 'ինչ', '՞', 'նշանակություն', 'Սուր', 'մի', 'քանի', 'կաթիլը', ',', 'այո', ',', 'թանկարժեք', ',', 'բավականին', ',', '`', 'բավականին', 'թանկարժեք', ',', 'եթե', 'համեմատես', 'դա', 'գիտեոուսալիության', 'ու', 'հանգիստ', 'ծերության', 'հետ', '»', ':', '-', 'ասաց', 'նա', 'միտումնավոր', 'խիստ', 'տոնով', ':', '-', 'Լսիր', ':', 'ԳԵ', 'ՅՔ', 'պ', ',', 'ինչպես', '՛', 'է', 'քո', 'անունը', ':', '2', 'ո', 'Պրենույ', ',', '-', 'ասաց', 'Գրենույը', ':', '-', 'Ժան', '-', 'Բատիստ', 'Գրենույ', ':', 'Ե', 'Ե', 'Սհա', ',', '-', 'ասաց', 'Բալդինին', '-', 'Դե', 'ուրեմն', 'լսիր', ',', '`', 'Ժան', '-', 'Իատ', 'Գրենույ', ':', 'Ես', 'միտքս', 'փոխեցի', ':', 'Դու']\n",
            "Entities: [('Բալդինին', 'PERSON', 11, 19), ('Այնուհետն', 'PERSON', 58, 67), ('Գրենույին', 'PERSON', 109, 118), ('Ֆրանժիպանին', 'PERSON', 347, 358), ('Մեսինայում', 'GPE', 450, 460), ('ճի.', 'PERSON', 736, 739), ('Մեսինայում', 'GPE', 797, 807), ('Բալդինի', 'PERSON', 972, 979), ('երկու', 'CARDINAL', 1020, 1025), ('Պելիսյեի', 'PERSON', 1129, 1137), ('ԳԵ ՅՔ', 'ORGANIZATION', 1344, 1349), ('2 ո', 'ORDINAL', 1374, 1377), ('Պրենույ', 'PERSON', 1379, 1386), ('Գրենույը', 'PERSON', 1394, 1402), ('Ժան', 'PERSON', 1405, 1408), ('Բատիստ Գրենույ', 'PERSON', 1409, 1423), ('Ե Ե  Սհա', 'PERSON', 1425, 1433), ('Բալդինին', 'PERSON', 1441, 1449), ('Ժան', 'PERSON', 1469, 1472), ('Իատ Գրենույ', 'PERSON', 1473, 1484)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1850\n",
            "1860\n",
            "1870\n",
            "1880\n",
            "1890\n",
            "1900\n",
            "1910\n",
            "1920\n",
            "1930\n",
            "1940\n",
            "1950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ձեզ', 'համար', 'որքան', '՞', 'պատրաստեմ', ',', 'մետր', ',', '-', 'հարցրեց', 'Գրենույը', ':']\n",
            "Entities: [('Գրենույը', 'PERSON', 45, 53)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'որքան', '՞', ',', 'ինչը', '՞', ',', '-', 'հարցրեց', 'Բալդինին', ',', 'ով', 'դեռ', 'չէր', 'ավարտել', 'իր', 'խոսքը', ':']\n",
            "Entities: [('Բալդինին', 'PERSON', 26, 34)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Այս', 'օծանելիքից', '՝', 'որքան', '՞', ',', '-', '-', 'խռպոտ', 'հարցրեց', 'Գրենույը', ':', '-', 'որքան', '՞', 'է', 'ձեզ', 'պետք', 'դրանից', ':', 'Կուզեք', '՛', 'մինչն', 'եզրը', 'լցնեմ', 'այ', 'այն', 'մեծ', 'ամանը', ':', '-', 'Եվ', 'նա', 'մատնացույց', 'արեց', 'երեք', 'լիտրից', 'ոչ', 'պակաս', 'տարողությամբ', 'խառնամանը', ':']\n",
            "Entities: [('Գրենույը', 'PERSON', 42, 50), ('երեք լիտրից', 'QUANTITY', 145, 156)]\n",
            "  doc = self._ensure_doc(text)\n",
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Ոչ', ',', 'պետք', 'չի', ',', '-', 'սարսափած', 'բացականչեց', 'Բալդինին', '.', 'նրա', 'այդ', 'գոռոցի', 'մեջ', 'կար', 'վախ', '՝', 'որչափ', 'խոր', 'արմատացած', ',', 'նույնչափ', 'էլ', 'տարերային', 'վախ', 'շռայլության', 'հանդեպ', ',', 'վախ', 'իր', 'սեփականության', 'համար', ':', 'Բայց', ',', 'կարծես', 'ամաչելով', 'այդ', 'ինքնամերկացնող', 'գոռոցից', ',', 'նա', 'անմիջապես', 'էլ', 'մռնչաց', ',', '-', 'չհամարձակվես', 'ինձ', 'ընդհատել', ':', '-', 'Այնուհետն', 'մի', 'քիչ', 'հանգստացավ', 'ն', 'շարունակեց', 'թեթնակի', 'հեգնական', 'ձայնով', ':', '-', 'Մեր', 'ինչին', '՞', 'է', 'պետք', 'երեք', 'լիտր', 'օծանելիքը', ',', 'որը', 'երկուսս', 'էլ', 'չենք', 'գնահատում', ':', 'Ըստ', 'էության', '՝', 'սրվակի']\n",
            "Entities: [('Բալդինին', 'PERSON', 36, 44), ('Այնուհետն', 'PERSON', 272, 281), ('երեք լիտր', 'QUANTITY', 357, 366)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1970\n",
            "1980\n",
            "1990\n",
            "2000\n",
            "2010\n",
            "2020\n",
            "2030\n",
            "2040\n",
            "2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['`', 'քո', 'պարզունակ', 'բթամտությունը', 'ցույց', 'են', 'տալիս', ',', 'որ', 'դու', '`', 'ոչինչ', 'չես', 'հասկանում', ',', 'դու', 'բարբարոս', 'ես', 'ու', 'անտաշ', ',', 'դրա', '`', 'հետ', 'էլ', 'գոնջոտ', ',', 'լկտի', ',', 'փսլնքոտ', ':', 'Դու', 'ի', 'վիճակի', 'չես', 'լիմոնադ', 'խառնել', ',', 'քեզ', 'չի', 'կարելի', 'սովորական', 'մատուտակի', '`', 'ջրի', 'վաճառք', 'վստահել', ',', 'իսկ', 'դու', 'խցկվում', 'ես', 'օծանագործի', '`', 'գործի', 'մեջ', ':', 'Գոհ', 'եղիր', ',', 'ուրախացիր', 'ու', 'շնորհակալ', 'եղիր', ',', '`', 'որ', 'քո', 'տերը', 'քեզ', 'դեռ', 'մոտ', 'է', 'թողնում', 'դաբաղման', 'լուծույլ', 'բիչեվ', 'չհամարձակվես', ',', 'լսում', '՛', 'ես', ',', 'երբեք', 'չհամարճակվես', '`', 'օծանագործի', 'դռան', 'շեմն', 'անցնել', ':', 'լ', '`', 'Այդպես', 'էր', 'խոսում', 'Բալդինին', ':', 'Եվ', 'մինչ', 'նա', 'խոսում', 'էր', ',', ':', 'ակա', 'տարածությունը', 'լցվեց', '«', 'Ամուրն', 'ու', 'Պսիքեն', '»', '-', 'ի', '`', 'բուրմունքով', ':', 'Բուրմունքի', 'մեջ', 'կա', 'համոզչություն', ',', 'որն', '5', 'արեւ', 'ուժեղ', 'է', 'բառերից', ',', 'ակնհայտությունից', ',', 'զգացմունքից', 'ու', 'կամքից', ':', 'Բուրմունքի', 'համոզչությունն', 'ան', ':', 'ժխտելի', 'է', ',', 'անհաղթահարելի', ',', 'այն', 'մեր', 'մեջ', 'Է', 'մտնում', ',', '`', 'ինչպես', 'օդն', 'է', 'մտնում', 'մեր', 'թոքերի', 'մեջ', ',', 'որը', 'շնչում', 'ենք', ',', '\"ան', 'լեփ', '-', 'լեցուն', ',', 'մինչն', 'վերջ', 'լցվում', 'է', 'մեր', 'մեջ', ':', 'Եվ', 'դրա', 'դեմ', 'դկան', 'միջոցներ', ':', 'Գրենույը', 'մի', 'կողմ', 'դրեց', 'շիշը', ',', 'օծանելիքից', 'թրջված', 'ճեռ6', '.', 'քրհեռացրեց', 'շշի', 'վզիկից', 'ն', 'չորացրեց', 'այ', 'քսելով', 'իր', 'բաճաաա', 'ԱՉ', 'Ց', 'փեշին', ':', 'Մեկ', ',', 'երկու', 'քայլ', 'ետ', ',', 'ողջ', 'մարմնով', 'անճոռնի', 'խոնարհումը', 'Բալդինիի', 'խրատների', 'կարկուտի', 'ներքո', 'բասկանաչափ', 'տատանեցին', 'օդը', ',', 'որպեսզի', 'տարածեն', 'հենց', '|', 'տեղծված', 'բուրումնահոտությունը', ':', 'Չնայած', 'Բալդինին']\n",
            "Entities: [('Բալդինին', 'PERSON', 463, 471), ('«Ամուրն ու Պսիքեն»-ի', 'ORGANIZATION', 521, 541), ('5', 'CARDINAL', 594, 595), ('Գրենույը', 'PERSON', 861, 869), ('ԱՉ Ց փեշին', 'PERSON', 966, 976), ('Մեկ', 'CARDINAL', 978, 981), ('երկու', 'CARDINAL', 983, 988), ('Բալդինիի', 'PERSON', 1029, 1037), ('Բալդինին', 'PERSON', 1148, 1156)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2060\n",
            "2070\n",
            "2080\n",
            "2090\n",
            "2100\n",
            "2110\n",
            "2120\n",
            "2130\n",
            "2140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['ակելով', 'թաշկինակը', 'սեղմել', 'քթին', ',', 'կարծես', 'ուզում', 'էր', 'ով', 'պաշտպանվել', 'իր', 'հոգու', 'վրաանո', '՛', 'հարձակումից', ':']\n",
            "Entities: []\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/spacy/language.py:999: UserWarning: Can't set named entities because of multi-word token expansion or because the character offsets don't map to valid tokens produced by the Stanza tokenizer:\n",
            "Words: ['-', 'Դուք', 'չեք', '՛', 'ցանկանում', 'փորձանմուշ', 'վերցնել', ',', '-', '-', 'կրկին', 'կարկաչող', 'ճայնով', 'ասաց', 'Գրենույը', ',', '-', 'միթե', '՛', 'չեք', 'ուզում', ',', 'վարպետ', ':', 'Միթե', '՛', 'չեք', 'փորձի', ':']\n",
            "Entities: [('Գրենույը', 'PERSON', 71, 79)]\n",
            "  doc = self._ensure_doc(text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2160\n",
            "2170\n",
            "2180\n",
            "2190\n",
            "2200\n",
            "2210\n",
            "2220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian.vert.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpr4kEppuIj_",
        "outputId": "7ce6ca21-c24b-4c8c-ac54-fae7df47bde3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  83828  251460 2055080 Parfum_Armenian.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading full Armenian corpus"
      ],
      "metadata": {
        "id": "xaX5H9ej21t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/c977e87cf2b244e6801b/?dl=1\n",
        "!mv index.html?dl=1 KorpusARM.tgz"
      ],
      "metadata": {
        "id": "OsQXUICO26Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf KorpusARM.tgz"
      ],
      "metadata": {
        "id": "ddJf6m-p3DEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir KorpusARM1"
      ],
      "metadata": {
        "id": "mdc3wgvv3kDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir KorpusARM1/stage01"
      ],
      "metadata": {
        "id": "fkZ8hFCA4H-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenating files\n",
        "!cat korpusARM/hyFiktion/* >KorpusARM1/stage01/hyFiktion.txt\n",
        "!cat korpusARM/hyNatur/* >KorpusARM1/stage01/hyNatur.txt\n",
        "!cat korpusARM/hyRecht/* >KorpusARM1/stage01/hyRecht.txt"
      ],
      "metadata": {
        "id": "ERWhoFyb3PE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir KorpusARM1/stage02"
      ],
      "metadata": {
        "id": "rNGX_hTh46NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for Armenian line breaks:\n",
        "\n",
        "def correctLineBreaksHY(FName, FNameOut):\n",
        "    FIn = open(FName, 'r')\n",
        "    FOut = open(FNameOut, 'w')\n",
        "    countHyphens = 0\n",
        "    for SLine in FIn:\n",
        "        SLine = SLine.strip()\n",
        "        if SLine == '': \n",
        "            FOut.write('\\n\\n')\n",
        "            continue\n",
        "        if SLine[-1] == '-':\n",
        "            SLine2write = SLine[:-1]\n",
        "            FOut.write(SLine2write)\n",
        "            countHyphens +=1\n",
        "            continue\n",
        "        FOut.write(SLine + ' ')\n",
        "    FOut.flush()\n",
        "    print(str(countHyphens) + ' hyphens corrected')\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "ga2FEpuM5LGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correctLineBreaksHY('KorpusARM1/stage01/hyFiktion.txt', 'KorpusARM1/stage02/hyFiktion.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyNatur.txt', 'KorpusARM1/stage02/hyNatur.txt')\n",
        "correctLineBreaksHY('KorpusARM1/stage01/hyRecht.txt', 'KorpusARM1/stage02/hyRecht.txt')"
      ],
      "metadata": {
        "id": "tDpxejA75wvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc KorpusARM1/stage02/hyFiktion.txt\n",
        "!wc KorpusARM1/stage02/hyNatur.txt\n",
        "!wc KorpusARM1/stage02/hyRecht.txt"
      ],
      "metadata": {
        "id": "qAUyLQOp8BUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir KorpusARM1/stage03"
      ],
      "metadata": {
        "id": "BbS0SBh983GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runs for about 47 minutes; alternatively, excecute one of the following cells to download parsed archived corpus\n",
        "parseFile('KorpusARM1/stage02/hyFiktion.txt', 'KorpusARM1/stage03/hyFiktion.vert.txt', nlp_hy)\n",
        "parseFile('KorpusARM1/stage02/hyNatur.txt', 'KorpusARM1/stage03/hyNatur.vert.txt', nlp_hy)\n",
        "parseFile('KorpusARM1/stage02/hyRecht.txt', 'KorpusARM1/stage03/hyRecht.vert.txt', nlp_hy)"
      ],
      "metadata": {
        "id": "n-FibDWT8NuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar cvzf KorpusARM1_stage03.tgz KorpusARM1/stage03/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iODGwbWoJ-qC",
        "outputId": "70b0568b-6a10-4fd6-957b-8eca122d1b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KorpusARM1/stage03/\n",
            "KorpusARM1/stage03/hyNatur.vert.txt\n",
            "KorpusARM1/stage03/hyRecht.vert.txt\n",
            "KorpusARM1/stage03/hyFiktion.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# alternative: download Lemmatized corpus\n",
        "!wget https://heibox.uni-heidelberg.de/f/095d2385bad74f2b8ffd/?dl=1\n",
        "!mv index.html?dl=1 KorpusARM1_stage03.tgz\n",
        "!tar xvzf KorpusARM1_stage03.tgz"
      ],
      "metadata": {
        "id": "JtE2W_f8Kz-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc /content/KorpusARM1/stage03/hyFiktion.vert.txt\n",
        "!wc /content/KorpusARM1/stage03/hyNatur.vert.txt\n",
        "!wc /content/KorpusARM1/stage03/hyRecht.vert.txt\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv7S99QGGg10",
        "outputId": "7a608bc5-8fde-4467-d0dd-9e0233fdabb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 115616  346846 2690663 /content/KorpusARM1/stage03/hyFiktion.vert.txt\n",
            "  83271  249801 2110874 /content/KorpusARM1/stage03/hyNatur.vert.txt\n",
            " 102399  307197 2970463 /content/KorpusARM1/stage03/hyRecht.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/KorpusARM1/stage03/* >/content/KorpusARM1/stage03all.vert.txt"
      ],
      "metadata": {
        "id": "4cVxtrERLep6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc /content/KorpusARM1/stage03all.vert.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCrZyRohLnIC",
        "outputId": "79e5ae31-7299-45b5-bb59-13e92e648367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 301286  903844 7772000 /content/KorpusARM1/stage03all.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dictionaries from parsed files"
      ],
      "metadata": {
        "id": "91nnXhNB2uIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DWiki = {}\n",
        "with open(\"hywiki-20221101-pages-articles-v03.vert\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DWiki[line] +=1\n",
        "        except:\n",
        "            DWiki[line] = 1\n"
      ],
      "metadata": {
        "id": "5TJS8qstj_5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DText = {}\n",
        "with open(\"Parfum_Armenian.vert.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DText[line] +=1\n",
        "        except:\n",
        "            DText[line] = 1\n"
      ],
      "metadata": {
        "id": "exBjjf9rkMxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for comparing texts with Wiki corpus"
      ],
      "metadata": {
        "id": "fmnrESykItMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lines2dict(SFIn):\n",
        "    DText = {}\n",
        "    with open(SFIn, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.rstrip()\n",
        "            try:\n",
        "                DText[line] +=1\n",
        "            except:\n",
        "                DText[line] = 1\n",
        "    print(len(DText))\n",
        "    return DText"
      ],
      "metadata": {
        "id": "tPHwN_60G2Y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compareDicts(DText, DWiki, lenText, lenWiki):\n",
        "    DFreqDiff = {} # dictionary of frequency differences\n",
        "    # lenWiki = 2735468\n",
        "    # lenText = 83829\n",
        "    c = 0\n",
        "    for key, val in sorted(DText.items(), key=lambda item: item[1], reverse=True):\n",
        "        c+=1\n",
        "        valText = val + 1\n",
        "        relText = valText / lenText\n",
        "        try:\n",
        "            valWiki = DWiki[key] + 1\n",
        "        except:\n",
        "            valWiki = 1\n",
        "        relWiki = valWiki / lenWiki\n",
        "\n",
        "        diffValue = relText / relWiki\n",
        "        DFreqDiff[key] = diffValue\n",
        "    \n",
        "    print(len(DFreqDiff))\n",
        "    return DFreqDiff"
      ],
      "metadata": {
        "id": "pw5PHpHJIFTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printCompareDict(DFreqDiff, DText, DWiki, SFOut):\n",
        "    fOut = open(SFOut, 'w')\n",
        "    countEntries = 0\n",
        "    for key, val in sorted(DFreqDiff.items(), key=lambda item: item[1], reverse=True):\n",
        "        countEntries += 1\n",
        "        try:\n",
        "            frqText = DText[key] + 1\n",
        "        except:\n",
        "            frqText = 1\n",
        "\n",
        "        try:\n",
        "            frqWiki = DWiki[key] + 1\n",
        "        except:\n",
        "            frqWiki = 1\n",
        "        fOut.write(f'{key}\\t{val}\\t{frqText}\\t{frqWiki}\\n')\n",
        "    fOut.flush()\n",
        "    print(countEntries)\n",
        "    return\n"
      ],
      "metadata": {
        "id": "dbuUkpU8He04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DWikiX = lines2dict('/content/hywiki-20221101-pages-articles-v03.vert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuf3Q498JEpd",
        "outputId": "31af3613-cf3e-4d0d-aab1-861af6a4dbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "227720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DhyFiktion = lines2dict('/content/KorpusARM1/stage03/hyFiktion.vert.txt')\n",
        "DhyNatur = lines2dict('/content/KorpusARM1/stage03/hyNatur.vert.txt')\n",
        "DhyRecht = lines2dict('/content/KorpusARM1/stage03/hyRecht.vert.txt')\n",
        "DhyAll = lines2dict('/content/KorpusARM1/stage03all.vert.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx54vc-YJiNV",
        "outputId": "be406c1c-6513-47a4-9687-33f1965cb7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20969\n",
            "21806\n",
            "11064\n",
            "43675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DFreqDiffWikiFiktion = compareDicts(DhyFiktion, DWikiX, 115616, 2735468)\n",
        "DFreqDiffWikiNatur = compareDicts(DhyNatur, DWikiX, 83271, 2735468)\n",
        "DFreqDiffWikiRecht = compareDicts(DhyRecht, DWikiX, 102399, 2735468)\n",
        "DFreqDiffWikiAll = compareDicts(DhyAll, DWikiX, 301286, 2735468)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-qp5OppL7pi",
        "outputId": "46c5421e-a097-4e97-be0c-31d032f7e19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20969\n",
            "21806\n",
            "11064\n",
            "43675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir KorpusARM1/stage04"
      ],
      "metadata": {
        "id": "-ArMjxLHNHwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printCompareDict(DFreqDiffWikiFiktion, DhyFiktion, DWikiX, '/content/KorpusARM1/stage04/hyFiktion.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiNatur, DhyNatur, DWikiX, '/content/KorpusARM1/stage04/hyNatur.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiRecht, DhyRecht, DWikiX, '/content/KorpusARM1/stage04/hyRecht.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiAll, DhyAll, DWikiX, '/content/KorpusARM1/stage04all.tsv.txt')"
      ],
      "metadata": {
        "id": "cgx1MPviM8Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "!wget https://heibox.uni-heidelberg.de/f/14706c04a4024b2f937d/?dl=1\n",
        "!mv index.html?dl=1 Pilot-Corrections-all.tsv\n",
        "!wc Pilot-Corrections-all.tsv\n"
      ],
      "metadata": {
        "id": "usd9A_y_RSk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrections(colNumberOri, colNumberCorrect, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect"
      ],
      "metadata": {
        "id": "VlBmzm25qlbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readCorrectionsFrq(colNumberOri, colNumberCorrect, colNumberFrq, SFIn, SFOut = None):\n",
        "    LTWrongCorrect = []\n",
        "    DWrongCorrect = {}\n",
        "    FOut = open(SFOut, 'w')\n",
        "    with open(SFIn, 'r') as FIn:\n",
        "        count = 0\n",
        "        for SLine in FIn:\n",
        "            count += 1\n",
        "            if count == 1: continue\n",
        "            SLine = SLine.strip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            SWrong = LLine[colNumberOri]\n",
        "            SCorrect = LLine[colNumberCorrect]\n",
        "            SFrq = LLine[colNumberFrq]\n",
        "            if SWrong != '' and SCorrect != '' and SWrong != SCorrect:\n",
        "                TWrongCorrect = (f'[{SWrong}]', f'[{SCorrect}]', f'{SFrq}')\n",
        "                LTWrongCorrect.append(TWrongCorrect)\n",
        "                if SWrong in DWrongCorrect.keys():\n",
        "                    SCorrect1 = DWrongCorrect[SWrong]\n",
        "                    if SCorrect1 != SCorrect:\n",
        "                        print(SWrong + '\\t' + SCorrect1 + '\\t' + SCorrect)\n",
        "                DWrongCorrect[SWrong] = SCorrect\n",
        "    if SFOut:\n",
        "        for SWrong, SCorrect, SFrq in LTWrongCorrect:\n",
        "            FOut.write(f'{SWrong}\\t{SCorrect}\\t{SFrq}\\n')    \n",
        "        FOut.flush()\n",
        "    print(len(DWrongCorrect))\n",
        "\n",
        "    return LTWrongCorrect, DWrongCorrect"
      ],
      "metadata": {
        "id": "rTU8YEX4Nkcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LTWrongCorrectWord, DWrongCorrectWord = readCorrections(1, 4, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-WordForm.tsv')\n",
        "LTWrongCorrectLemma, DWrongCorrectLemma = readCorrections(3, 6, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-Lemma.tsv')\n"
      ],
      "metadata": {
        "id": "780DBoamRmlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LTWrongCorrectWord)\n",
        "print(LTWrongCorrectLemma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjWbaA_2Sq0R",
        "outputId": "04f11065-0b7f-4b26-ed35-766e22218dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[մերճակա]', '[մերձակա]'), ('[առջն]', '[առջև]'), ('[թեթնություն]', '[թեթևություն]'), ('[Եթենա]', '[եթե նա]'), ('[ննա]', '[նա]'), ('[ճեռքերն]', '[ձեռքից]'), ('[ճայն]', '[ձայն]'), ('[ճեռքով]', '[ձեռքով]'), ('[այլնս]', '[այլևս]'), ('[ետնի]', '[ետևի]'), ('[կեղնները]', '[կեղևները]'), ('[ճկան]', '[ձկան]'), ('[ննա]', '[նա]'), ('[բանաձնի]', '[բանաձևի]'), ('[ճեր]', '[ձեր]'), ('[առնտրական]', '[առևտրական]'), ('[արնելյան]', '[արևելյան]'), ('[կուղնորվի]', '[կուղևորվի]'), ('[նս]', '[ևս]'), ('[հետնեց]', '[հետևել]'), ('[նուխիսկ]', '[նույնիսկ]'), ('[երնույթ]', '[երևույթ]'), ('[քրտնքով]', '[քրտինքով]'), ('[արվարճանում]', '[արվարձանում]'), ('[անճամբ]', '[անձամբ]'), ('[ճայնը]', '[ձայնը]'), ('[ճգվում]', '[ձգվում]'), ('[ճիու]', '[ձիու]'), ('[դարճնում]', '[դարձնում]'), ('[ուղնորվում]', '[ուղևորվում ]'), ('[իջնանատան]', '[իջևանատան]'), ('[ճգտում]', '[ձգտում]'), ('[դրսնորում]', '[դրսևորում]'), ('[արվարճանի]', '[արվարձանի]'), ('[ետնում]', '[ետևում]'), ('[ճնավորված]', '[ձևավորված]'), ('[Հետնաբար]', '[հետևաբար]'), ('[այլնս]', '[այլևս]'), ('[Շավանաբար]', '[հավանաբար]'), ('[սկզբիցնեթ]', '[սկզբիցևեթ]'), ('[միջն]', '[միջև]'), ('[համաճայնության]', '[համաձայնություն]'), ('[Թերնս]', '[թերևս]'), ('[տերնի]', '[տերև]'), ('[թնատակերի]', '[թևատակ]'), ('[դոււս]', '[դուրս]'), ('[բարճրացավ]', '[բարձրանալ]'), ('[երկարատն]', '[երկարատև]'), ('[նախնառաջ]', '[նախևառաջ]'), ('[ներքնից]', '[ներքև]'), ('[առջնից]', '[առջև]'), ('[ճեռնոցագործական]', '[ձեռնոցագործական]'), ('[հարնան]', '[գարնան]'), ('[ճգտումը]', '[ձգտումը]'), ('[առջնում]', '[առջևում]'), ('[ճմռանը]', '[ձմռանը]'), ('[սնահեր]', '[սևահեր]'), ('[ծանրութեթն]', '[ծանրութեթև]'), ('[ճագի]', '[ձագի]'), ('[Այլնս]', '[այլևս]'), ('[ինճ]', '[ինձ]'), ('[ճեռքն]', '[ձեռքն]'), ('[արճագանք]', '[արձագանք]'), ('[ճմեռ]', '[ձմեռ]'), ('[պառկածէրգերեզմանատանվրա]', '[պառկած էր գերեզմանատան վրա]'), ('[ճմերուկների]', '[ձմերուկների]'), ('[ունողկալի]', '[ու նողկալի]'), ('[գլխապտույտնե]', '[գլխապտույտներ]'), ('[ճայնի]', '[ձայնի]'), ('[ճկների]', '[ձկների]'), ('[այլնայլ]', '[այլևայլ]'), ('[ճնականություններից]', '[ձևականություններից]'), ('[չուննորներին]', '[չունևորներին]'), ('[արճակվող]', '[արձակվել]'), ('[խամարդ]', '[տղամարդ]'), ('[Միգուցենա]', '[միգուցե նա]'), ('[ջղաճգութու]', '[Ջղաձգություն]'), ('[Դետեսնում]', '[դե տեսնում ]'), ('[բարճրաց]', '[բարձրացնել]'), ('[ինճ]', '[ինձ]'), ('[Որովհետն]', '[որովհետև]'), ('[ննույնիսկ]', '[նույնիսկ]'), ('[հուսահատեգնում]', '[հեւսահատեցնել]'), ('[որնրան]', '[որ նրան]'), ('[Ջգազմունքներից]', '[Զգացմունք]'), ('[մնահավատությոն]', '[սնահավատություն]'), ('[հեթանոսա]', '[հեթանոսացում]'), ('[խարույկՄ]', '[խարույկ]'), ('[տուցում]', '[մատուցում]'), ('[նականռթյան]', '[բանականություն]'), ('[անձր]', '[անձ, անձրև]'), ('[տարօրի]', '[տարօրինակ]'), ('[թնիկները]', '[թևիկ]'), ('[աստվածավախու]', '[աստվածավախություն]'), ('[բարճր]', '[բարձր]'), ('[լավէ]', '[լավ է]'), ('[Թռենել]', '[թռնել]'), ('[հանճնեց]', '[հանձնել]'), ('[Դհյոյում]', '[Դյո]'), ('[տակիզ]', '[տակից]'), ('[առջն]', '[առջև]'), ('[ետնից]', '[ետևից]'), ('[միջն]', '[միջև]'), ('[այնուհետն]', '[այնուհետև]'), ('[բացարճակապես]', '[բացարձակապես]'), ('[որնէ]', '[որևէ]'), ('[այլնս]', '[այլևս]'), ('[թեթն]', '[թեթև]'), ('[թեթնակի]', '[թեթևակի]'), ('[որնէ]', '[որևէ]'), ('[ետնում]', '[ետևում]'), ('[արնի]', '[արևի]'), ('[միննույն]', '[միևնույն]'), ('[վերնում]', '[վերևում]'), ('[ինճ]', '[ինչ]'), ('[արճակում]', '[արձակում]'), ('[թերնս]', '[թերևս]'), ('[երբնիցե]', '[երբևիցե]'), ('[ճեռքը]', '[ձեռքը]'), ('[երնակայության]', '[երևակայության]'), ('[արնմուտք]', '[արևմուտք]'), ('[ճեռք]', '[ձեռք]'), ('[ճեռքի]', '[ձեռքի]'), ('[ճայնով]', '[ձայնով]'), ('[նան]', '[նաև]'), ('[դեռնս]', '[դեռևս]'), ('[ճեռքերը]', '[ձեռքերը]'), ('[հետնում]', '[հետևում]'), ('[արճակող]', '[արձակող]'), ('[որնիցե]', '[որևիցե]'), ('[դեռնս]', '[դեռևս]'), ('[այլնս]', '[այլևս]'), ('[ճեռքին]', '[ձեռքին]'), ('[արնմտյան]', '[արևմտյան]'), ('[այլես]', '[այլևս]'), ('[Նախնառաջ]', '[նախևառաջ]'), ('[հոգնոր]', '[հոգևոր]'), ('[ճեռքերով]', '[ձեռքերով]'), ('[ներքնում]', '[ներքևում]'), ('[համարճակվում]', '[համարձակվում]'), ('[արնելք]', '[արևելք]'), ('[առանճին]', '[առանձին]'), ('[արնմուտքից]', '[արևմուտքից]'), ('[երնակայական]', '[երևակայական]'), ('[թնածում]', '[թևածում]'), ('[բանաճնի]', '[բանաձևի]'), ('[դարճավ]', '[դարձավ]'), ('[բանաճնը]', '[բանաձևը]'), ('[թեթնացած]', '[թեթևացած]'), ('[հետնելով]', '[հետևելով]'), ('[հետնել]', '[հետևել]'), ('[կարնոր]', '[կարևոր]'), ('[ճիու]', '[ձիու]'), ('[հեղճուցիչ]', '[հեղձուցիչ]'), ('[անճնական]', '[անձնական]'), ('[առջնից]', '[առջևից]'), ('[երնում]', '[երևում]'), ('[ինճ]', '[ինձ]'), ('[փորճ]', '[փորձ]'), ('[բանաձնը]', '[բանաձևը]'), ('[եթենա]', '[եթե]'), ('[ինճ]', '[ինձ]'), ('[փորճն]', '[փորձն]'), ('[բանաձն]', '[բանաձևն]'), ('[բանաճն]', '[բանաձևն]'), ('[բարճրացնել]', '[բարձրացնել]'), ('[Այլնս]', '[այլևս]'), ('[սնահեր]', '[սևահեր]'), ('[բացարճակ]', '[բացարձակ]'), ('[ճգտելով]', '[ձգտելով]'), ('[բանաճներ]', '[բանաձևեր]'), ('[թեն]', '[թեև]'), ('[տերնները]', '[տերևերը]'), ('[բարճունքներում]', '[բարձունքներում]'), ('[առնտուրը]', '[առևտուրը]'), ('[անճամբ]', '[անձամբ]'), ('[օթնան]', '[օթևան]'), ('[բանաճներով]', '[բանաձներով]'), ('[արճակել]', '[արձակել]'), ('[բնեռը]', '[բևեռը]'), ('[օճեր]', '[օձեր]'), ('[ոջ]', '[ոչ]'), ('[անձրնը]', '[անձրևը]'), ('[թեթն]', '[թեթև]'), ('[ճգում]', '[ձգում]'), ('[տաքագնում]', '[տաքացնում]'), ('[Հնայած]', '[Չնայած]'), ('[ճեռքերի]', '[Ձեռքերի]'), ('[այխքան]', '[այդքան]'), ('[ճնացրեց]', '[ձևացրեց]'), ('[երնակայությունների]', '[երևակայությունների]'), ('[առջն]', '[առջև]'), ('[բարճր]', '[բարձր]')]\n",
            "[('[գաղտագող]', '[գաղտագողի]'), ('[լաուրա]', '[Լաուրա]'), ('[տաններոն]', '[Տաններոն]'), ('[մերճակա]', '[մերձակա]'), ('[ռանալել]', '[կռանալ]'), ('[Տերն]', '[Տեր]'), ('[ճեռք]', '[ձեռք]'), ('[կարագից]', '[կարագ]'), ('[ճայն]', '[ձայն]'), ('[ճեռք]', '[ձեռք]'), ('[այլնս]', '[այլևս]'), ('[ետուն]', '[ետև]'), ('[կեղն]', '[կեղև]'), ('[լուսաբացի]', '[լուսաբաց]'), ('[շուրջբոլոր]', '[շուրջբոլորը]'), ('[ճիկ]', '[ձուկ]'), ('[դիմափոշու]', '[դիմափոշի]'), ('[ննա]', '[նա]'), ('[բանաձին]', '[բանաձև]'), ('[ճեր]', '[դուք]'), ('[առնտրական]', '[առևտրական]'), ('[արնելյան]', '[արևելյան]'), ('[կուղնոր]', '[ուղևորվել]'), ('[փափկենալ]', '[փափկել]'), ('[իս]', '[ևս]'), ('[հետնել]', '[հետևել]'), ('[փնթփնթել]', '[փնթփնթալ]'), ('[մեսինա]', '[Մեսինա]'), ('[նուխիսկ]', '[նույնիսկ]'), ('[քացնել]', '[չքանալ]'), ('[երնույթ]', '[երևույթ]'), ('[քրտնք]', '[քրտինք]'), ('[արվարճան]', '[արվարձան]'), ('[անճամբ]', '[անձամբ]'), ('[ճայն]', '[ձայն]'), ('[ճգվել]', '[ձգվել]'), ('[թունելի]', '[թունել]'), ('[բատիստ]', '[Բատիստ]'), ('[ճիու]', '[ձի]'), ('[դարճնել]', '[դարձնել]'), ('[ուղնորվել]', '[ուղևորվել]'), ('[ռահել]', '[կռահել]'), ('[Ռիշին]', '[Ռիշի]'), ('[լաուրային]', '[Լաուրա]'), ('[իջնանատան]', '[իջևանատուն]'), ('[Գրասյան]', '[գրասյուն]'), ('[ճգտել]', '[ձգտել]'), ('[դրսնոր]', '[դրսևորել]'), ('[արվարճան]', '[արվարձան]'), ('[նվիրակար]', '[ամենագարշահոտ]'), ('[ետնել]', '[ետև]'), ('[ծծմոր]', '[ծծմայր]'), ('[ծծմոր]', '[ծծմայր]'), ('[ճնավորվել]', '[ձևավորվել]'), ('[հետնաբար]', '[հետևաբար]'), ('[ծծմոր]', '[ծծմայր]'), ('[կարամելի]', '[կարամել]'), ('[ակար]', '[ամենատանջալի]'), ('[ռալ]', '[չռել]'), ('[կոցել]', '[կկոցել]'), ('[ոռնել]', '[ոռնալ]'), ('[ոռնանալ]', '[ոռնացող]'), ('[որպիսիք]', '[որպիսին]'), ('[միակին]', '[միակ]'), ('[վերապրի]', '[վերապրել]'), ('[գոլորշին]', '[գոլորշի]'), ('[կարճ]', '[ամենաբարակ]'), ('[սանդալի]', '[սանդալ]'), ('[վերոն]', '[վերև]'), ('[ազդիր]', '[ազդր]'), ('[մաշկան]', '[մաշկ]'), ('[գիտել]', '[գիտենալ]'), ('[ավականանալ]', '[բավականացնել]'), ('[ծաղկեփին]', '[ծազկեփունջ]'), ('[հագել]', '[հագնել]'), ('[հարնան]', '[գարուն]'), ('[ճգտում]', '[ձգտում]'), ('[առջին]', '[առջև]'), ('[ճմիռ]', '[ձմեռ]'), ('[սնահ]', '[սևահեր]'), ('[սեփականանալ]', '[սեփականացնել]'), ('[նկուղի]', '[նկուղ]'), ('[ծանրութեթ]', '[ծանրութեթև]'), ('[արկիղ]', '[արկղ]'), ('[շրթ]', '[շրթներկ]'), ('[ճագ]', '[ձագ]'), ('[դողանալ]', '[դողալ]'), ('[պատկերանալ]', '[պատկերացնել]'), ('[այլնս]', '[այլևս]'), ('[վախել]', '[վախեցնել]'), ('[լինել]', '[ես]'), ('[կառափնատեղ]', '[կառափնատեղի]'), ('[կառափնատեղիղ]', '[կառափնատեղի]'), ('[ճեռք]', '[ձեռք]'), ('[արճագանք]', '[արձագանք]'), ('[ըյուսքին]', '[Ջյուսքինդ]'), ('[նվիրական]', '[ամենահանճարեղ]'), ('[ակտիր]', '[ամենագարշելի]'), ('[չօդափոխել]', '[օդափոխել]'), ('[չլվացնել]', '[լվանա]'), ('[ճմեռ]', '[ձմեռ]'), ('[ճմերուկ]', '[ձմերուկ]'), ('[ուշաթափեցնել]', '[ուշաթափել]'), ('[լվացնել]', '[լվանալ]'), ('[ճայն]', '[ձայն]'), ('[ճիկ]', '[ձուկ]'), ('[ծծումոր]', '[ծծմայր]'), ('[քրծեն]', '[քրծենի]'), ('[արկիղ]', '[արկղ]'), ('[այլնայլ]', '[այլևայլ]'), ('[ճնականություն]', '[ձևականություն]'), ('[չուննոր]', '[չունևոր]'), ('[կխնդրել]', '[խնդրել]'), ('[երակրել]', '[կերակրել]'), ('[պիս]', '[պես]'), ('[փինջ]', '[փունջ]'), ('[խկացնել]', '[չխկացնել]'), ('[խեցամաննե]', '[խեցաման]'), ('[գանգրան]', '[գանգրանալ]'), ('[օտարին]', '[օտար]'), ('[կարամելից]', '[կարամել]'), ('[նվիրար]', '[ամենապարզունակ]'), ('[ունեմ]', '[ունենալ]'), ('[քիթր]', '[քիթ]'), ('[աշխարհր]', '[աշխարհ]'), ('[ոստրամոխրագույնի]', '[ոստրամոխրագույն]'), ('[անկշտել]', '[անկշտում]'), ('[ոռինոց]', '[ոռնոց]'), ('[ճղճիղան]', '[ճղճղան]'), ('[դյո]', '[Դյո]'), ('[ժանտախտիգ]', '[ժանտախտից]'), ('[առուն]', '[առջև]'), ('[ետ]', '[ետև]'), ('[միջն]', '[միջև]'), ('[այնուհետ]', '[այնուհետև]'), ('[բացարճակապես]', '[բացարձակապես]'), ('[որ]', '[որևէ]'), ('[այլնս]', '[այլևս]'), ('[թեթ]', '[թեթև]'), ('[թեթնակ]', '[թեթևակի]'), ('[որ]', '[որևէ]'), ('[ետին]', '[ետև]'), ('[արն]', '[արև]'), ('[միննույն]', '[միևնույն]'), ('[վերն]', '[վերև]'), ('[ինճ]', '[ինչ]'), ('[արճակ]', '[արձակել]'), ('[թերուն]', '[թերևս]'), ('[մուշկի]', '[մուշկ]'), ('[երբնիցե]', '[երբևիցե]'), ('[ճեռք]', '[ձեռք]'), ('[տեզ]', '[տիզ]'), ('[երնակայություն]', '[երևակայություն]'), ('[արնմուտք]', '[արևմուտք]'), ('[ճեռք]', '[ձեռք]'), ('[ճեռք]', '[ձեռք]'), ('[ճայն]', '[ձայն]'), ('[նան]', '[նաև]'), ('[դեռին]', '[դեռևս]'), ('[ճեռք]', '[ձեռք]'), ('[հետնել]', '[հետևել]'), ('[արճակել]', '[արձակել]'), ('[որնիցե]', '[որևիցե]'), ('[դեռնս]', '[դեռևս]'), ('[այլնս]', '[այլևս]'), ('[շրթ]', '[շրթներկ]'), ('[ճեռք]', '[ձեռք]'), ('[արնմտյան]', '[արևմտյան]'), ('[այլես]', '[այլևս]'), ('[Նախնառաջ]', '[նախևառաջ]'), ('[հոգնոր]', '[հոգևոր]'), ('[խունկի]', '[խունկ]'), ('[ճեռք]', '[ձեռք]'), ('[ներք]', '[ներքև]'), ('[կաշին]', '[կաշի]'), ('[ազդիր]', '[ազդր]'), ('[դահճ]', '[դահիճ]'), ('[համարճակվել]', '[համարձակվել]'), ('[արնելք]', '[արևելք]'), ('[լցրել]', '[լցնել]'), ('[առանճ]', '[առանձին]'), ('[արնմուտք]', '[արևմուտք]'), ('[երնակայական]', '[երևակայական]'), ('[թնածել]', '[թևածել]'), ('[բանաճին]', '[բանաձև]'), ('[բանաճին]', '[բանաձև]'), ('[թեթնանալ]', '[թեթևանալ]'), ('[հետնել]', '[հետևել]'), ('[հետնել]', '[հետևել]'), ('[կարնոր]', '[կարևոր]'), ('[ճի]', '[ձի]'), ('[հեղճուցիչ]', '[հեղձուցիչ]'), ('[անճնական]', '[անձնական]'), ('[անորսալ]', '[անորսալի]'), ('[գաղտագող]', '[գաղտագողի]'), ('[առուջ]', '[առջև]'), ('[երնել]', '[երևալ]'), ('[ինճ]', '[ես]'), ('[փնթփնթաց]', '[փնթփնթալ]'), ('[փորճ]', '[փորձ]'), ('[բանաձին]', '[բանաձև]'), ('[եթենա]', '[եթե]'), ('[ինճ]', '[ես]'), ('[փորճ]', '[փորձ]'), ('[ալուֆ]', '[ալֆա]'), ('[բանաձ]', '[բանաձև]'), ('[բանաճ]', '[բանաձև]'), ('[թքած]', '[թքել]'), ('[բարճրանալ]', '[բարձրացնել]'), ('[Այլիս]', '[այլևս]'), ('[կավինավեհ]', '[ամենավեհ]'), ('[սնահեր]', '[սևահեր]'), ('[պոռթում]', '[պոռթկում]'), ('[բացարճակ]', '[բացարձակ]'), ('[բանաճ]', '[բանաձև]'), ('[թեն]', '[թեև]'), ('[տերն]', '[տերև]'), ('[շրթ]', '[շրթներկ]'), ('[բարճունք]', '[բարձունք]'), ('[ջրալ]', '[ջրալի]'), ('[թորվել]', '[թորել]'), ('[խլթխլթել]', '[խլթխլթալ]'), ('[առնտուր]', '[առևտուր]'), ('[անճամ]', '[անձամբ]'), ('[օթին]', '[օթևան]'), ('[բանաճ]', '[բանաձև]'), ('[արճակել]', '[արձակել]'), ('[բնեռ]', '[բևեռ]'), ('[օճ]', '[օձ]'), ('[ոջ]', '[ոչ]'), ('[անձր]', '[անձրև]'), ('[թեթն]', '[թեթև]'), ('[ճգալ]', '[ձգել]'), ('[լերել]', '[ուտել]'), ('[տաքագնել]', '[տաքացնել]'), ('[Հնայած]', '[Չնայած]'), ('[ճեռք]', '[ձեռք]'), ('[շրթ]', '[շրթներկ]'), ('[այխքան]', '[այդքան]'), ('[նարնջենու]', '[նարնջենի]'), ('[թաքչել]', '[թաքցնել]'), ('[ճնալ]', '[ձևացնել]'), ('[զնգզնգել]', '[զնգզնգալ]'), ('[գիտել]', '[իմանալ]'), ('[բարճր]', '[բարձր]')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LTWrongCorrectWordF, DWrongCorrectWordF = readCorrectionsFrq(1, 4, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-WordForm.tsv')\n",
        "LTWrongCorrectLemmaF, DWrongCorrectLemmaF = readCorrectionsFrq(3, 6, 9, '/content/Pilot-Corrections-all.tsv', SFOut = 'Pilot-Corrections-all-Lemma.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGYJhWPEO_yl",
        "outputId": "f9b3a5ec-2a40-4b38-cea1-134cc25652f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ինճ\tինձ\tինչ\n",
            "առջնից\tառջև\tառջևից\n",
            "ինճ\tինչ\tինձ\n",
            "172\n",
            "ինճ\tինչ\tես\n",
            "գիտել\tգիտենալ\tիմանալ\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LTWrongCorrectWordF)\n",
        "print(LTWrongCorrectLemmaF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If9vlUT_QQdh",
        "outputId": "153199b8-0d1f-49b4-f85d-6b4ccf83f1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[մերճակա]', '[մերձակա]', '4'), ('[առջն]', '[առջև]', '4'), ('[թեթնություն]', '[թեթևություն]', '4'), ('[Եթենա]', '[եթե նա]', '4'), ('[ննա]', '[նա]', '4'), ('[ճեռքերն]', '[ձեռքից]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճեռքով]', '[ձեռքով]', '4'), ('[այլնս]', '[այլևս]', '4'), ('[ետնի]', '[ետևի]', '4'), ('[կեղնները]', '[կեղևները]', '4'), ('[ճկան]', '[ձկան]', '4'), ('[ննա]', '[նա]', '4'), ('[բանաձնի]', '[բանաձևի]', '4'), ('[ճեր]', '[ձեր]', '4'), ('[առնտրական]', '[առևտրական]', '4'), ('[արնելյան]', '[արևելյան]', '4'), ('[կուղնորվի]', '[կուղևորվի]', '4'), ('[նս]', '[ևս]', '4'), ('[հետնեց]', '[հետևել]', '4'), ('[նուխիսկ]', '[նույնիսկ]', '4'), ('[երնույթ]', '[երևույթ]', '4'), ('[քրտնքով]', '[քրտինքով]', '4'), ('[արվարճանում]', '[արվարձանում]', '4'), ('[անճամբ]', '[անձամբ]', '4'), ('[ճայնը]', '[ձայնը]', '4'), ('[ճգվում]', '[ձգվում]', '4'), ('[ճիու]', '[ձիու]', '4'), ('[դարճնում]', '[դարձնում]', '4'), ('[ուղնորվում]', '[ուղևորվում ]', '4'), ('[իջնանատան]', '[իջևանատան]', '4'), ('[ճգտում]', '[ձգտում]', '4'), ('[դրսնորում]', '[դրսևորում]', '3'), ('[արվարճանի]', '[արվարձանի]', '3'), ('[ետնում]', '[ետևում]', '3'), ('[ճնավորված]', '[ձևավորված]', '3'), ('[Հետնաբար]', '[հետևաբար]', '3'), ('[այլնս]', '[այլևս]', '3'), ('[Շավանաբար]', '[հավանաբար]', '3'), ('[սկզբիցնեթ]', '[սկզբիցևեթ]', '3'), ('[միջն]', '[միջև]', '3'), ('[համաճայնության]', '[համաձայնություն]', '3'), ('[Թերնս]', '[թերևս]', '3'), ('[տերնի]', '[տերև]', '3'), ('[թնատակերի]', '[թևատակ]', '3'), ('[դոււս]', '[դուրս]', '3'), ('[բարճրացավ]', '[բարձրանալ]', '3'), ('[երկարատն]', '[երկարատև]', '3'), ('[նախնառաջ]', '[նախևառաջ]', '3'), ('[ներքնից]', '[ներքև]', '3'), ('[առջնից]', '[առջև]', '3'), ('[ճեռնոցագործական]', '[ձեռնոցագործական]', '3'), ('[հարնան]', '[գարնան]', '3'), ('[ճգտումը]', '[ձգտումը]', '3'), ('[առջնում]', '[առջևում]', '3'), ('[ճմռանը]', '[ձմռանը]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[ծանրութեթն]', '[ծանրութեթև]', '3'), ('[ճագի]', '[ձագի]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[ճեռքն]', '[ձեռքն]', '3'), ('[արճագանք]', '[արձագանք]', '3'), ('[ճմեռ]', '[ձմեռ]', '2'), ('[պառկածէրգերեզմանատանվրա]', '[պառկած էր գերեզմանատան վրա]', '2'), ('[ճմերուկների]', '[ձմերուկների]', '2'), ('[ունողկալի]', '[ու նողկալի]', '2'), ('[գլխապտույտնե]', '[գլխապտույտներ]', '2'), ('[ճայնի]', '[ձայնի]', '2'), ('[ճկների]', '[ձկների]', '2'), ('[այլնայլ]', '[այլևայլ]', '2'), ('[ճնականություններից]', '[ձևականություններից]', '2'), ('[չուննորներին]', '[չունևորներին]', '2'), ('[արճակվող]', '[արձակվել]', '2'), ('[խամարդ]', '[տղամարդ]', '2'), ('[Միգուցենա]', '[միգուցե նա]', '2'), ('[ջղաճգութու]', '[Ջղաձգություն]', '2'), ('[Դետեսնում]', '[դե տեսնում ]', '2'), ('[բարճրաց]', '[բարձրացնել]', '2'), ('[ինճ]', '[ինձ]', '2'), ('[Որովհետն]', '[որովհետև]', '2'), ('[ննույնիսկ]', '[նույնիսկ]', '2'), ('[հուսահատեգնում]', '[հեւսահատեցնել]', '2'), ('[որնրան]', '[որ նրան]', '2'), ('[Ջգազմունքներից]', '[Զգացմունք]', '2'), ('[մնահավատությոն]', '[սնահավատություն]', '2'), ('[հեթանոսա]', '[հեթանոսացում]', '2'), ('[խարույկՄ]', '[խարույկ]', '2'), ('[տուցում]', '[մատուցում]', '2'), ('[նականռթյան]', '[բանականություն]', '2'), ('[անձր]', '[անձ, անձրև]', '2'), ('[տարօրի]', '[տարօրինակ]', '2'), ('[թնիկները]', '[թևիկ]', '2'), ('[աստվածավախու]', '[աստվածավախություն]', '2'), ('[բարճր]', '[բարձր]', '2'), ('[լավէ]', '[լավ է]', '2'), ('[Թռենել]', '[թռնել]', '2'), ('[հանճնեց]', '[հանձնել]', '2'), ('[Դհյոյում]', '[Դյո]', '2'), ('[տակիզ]', '[տակից]', '2'), ('[առջն]', '[առջև]', '36'), ('[ետնից]', '[ետևից]', '30'), ('[միջն]', '[միջև]', '22'), ('[այնուհետն]', '[այնուհետև]', '22'), ('[բացարճակապես]', '[բացարձակապես]', '21'), ('[որնէ]', '[որևէ]', '20'), ('[այլնս]', '[այլևս]', '19'), ('[թեթն]', '[թեթև]', '18'), ('[թեթնակի]', '[թեթևակի]', '17'), ('[որնէ]', '[որևէ]', '16'), ('[ետնում]', '[ետևում]', '16'), ('[արնի]', '[արևի]', '14'), ('[միննույն]', '[միևնույն]', '13'), ('[վերնում]', '[վերևում]', '13'), ('[ինճ]', '[ինչ]', '13'), ('[արճակում]', '[արձակում]', '12'), ('[թերնս]', '[թերևս]', '12'), ('[երբնիցե]', '[երբևիցե]', '11'), ('[ճեռքը]', '[ձեռքը]', '10'), ('[երնակայության]', '[երևակայության]', '10'), ('[արնմուտք]', '[արևմուտք]', '10'), ('[ճեռք]', '[ձեռք]', '10'), ('[ճեռքի]', '[ձեռքի]', '9'), ('[ճայնով]', '[ձայնով]', '9'), ('[նան]', '[նաև]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[ճեռքերը]', '[ձեռքերը]', '8'), ('[հետնում]', '[հետևում]', '8'), ('[արճակող]', '[արձակող]', '8'), ('[որնիցե]', '[որևիցե]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[այլնս]', '[այլևս]', '8'), ('[ճեռքին]', '[ձեռքին]', '7'), ('[արնմտյան]', '[արևմտյան]', '7'), ('[այլես]', '[այլևս]', '7'), ('[Նախնառաջ]', '[նախևառաջ]', '7'), ('[հոգնոր]', '[հոգևոր]', '6'), ('[ճեռքերով]', '[ձեռքերով]', '6'), ('[ներքնում]', '[ներքևում]', '6'), ('[համարճակվում]', '[համարձակվում]', '5'), ('[արնելք]', '[արևելք]', '5'), ('[առանճին]', '[առանձին]', '5'), ('[արնմուտքից]', '[արևմուտքից]', '5'), ('[երնակայական]', '[երևակայական]', '5'), ('[թնածում]', '[թևածում]', '5'), ('[բանաճնի]', '[բանաձևի]', '5'), ('[դարճավ]', '[դարձավ]', '5'), ('[բանաճնը]', '[բանաձևը]', '5'), ('[թեթնացած]', '[թեթևացած]', '5'), ('[հետնելով]', '[հետևելով]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[կարնոր]', '[կարևոր]', '5'), ('[ճիու]', '[ձիու]', '5'), ('[հեղճուցիչ]', '[հեղձուցիչ]', '5'), ('[անճնական]', '[անձնական]', '5'), ('[առջնից]', '[առջևից]', '3'), ('[երնում]', '[երևում]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[բանաձնը]', '[բանաձևը]', '3'), ('[եթենա]', '[եթե]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճն]', '[փորձն]', '3'), ('[բանաձն]', '[բանաձևն]', '3'), ('[բանաճն]', '[բանաձևն]', '3'), ('[բարճրացնել]', '[բարձրացնել]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[բացարճակ]', '[բացարձակ]', '3'), ('[ճգտելով]', '[ձգտելով]', '3'), ('[բանաճներ]', '[բանաձևեր]', '3'), ('[թեն]', '[թեև]', '3'), ('[տերնները]', '[տերևերը]', '3'), ('[բարճունքներում]', '[բարձունքներում]', '3'), ('[առնտուրը]', '[առևտուրը]', '3'), ('[անճամբ]', '[անձամբ]', '3'), ('[օթնան]', '[օթևան]', '3'), ('[բանաճներով]', '[բանաձներով]', '3'), ('[արճակել]', '[արձակել]', '3'), ('[բնեռը]', '[բևեռը]', '3'), ('[օճեր]', '[օձեր]', '3'), ('[ոջ]', '[ոչ]', '3'), ('[անձրնը]', '[անձրևը]', '3'), ('[թեթն]', '[թեթև]', '3'), ('[ճգում]', '[ձգում]', '3'), ('[տաքագնում]', '[տաքացնում]', '3'), ('[Հնայած]', '[Չնայած]', '3'), ('[ճեռքերի]', '[Ձեռքերի]', '3'), ('[այխքան]', '[այդքան]', '3'), ('[ճնացրեց]', '[ձևացրեց]', '3'), ('[երնակայությունների]', '[երևակայությունների]', '3'), ('[առջն]', '[առջև]', '3'), ('[բարճր]', '[բարձր]', '3')]\n",
            "[('[գաղտագող]', '[գաղտագողի]', '5'), ('[լաուրա]', '[Լաուրա]', '5'), ('[տաններոն]', '[Տաններոն]', '5'), ('[մերճակա]', '[մերձակա]', '4'), ('[ռանալել]', '[կռանալ]', '4'), ('[Տերն]', '[Տեր]', '4'), ('[ճեռք]', '[ձեռք]', '4'), ('[կարագից]', '[կարագ]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճեռք]', '[ձեռք]', '4'), ('[այլնս]', '[այլևս]', '4'), ('[ետուն]', '[ետև]', '4'), ('[կեղն]', '[կեղև]', '4'), ('[լուսաբացի]', '[լուսաբաց]', '4'), ('[շուրջբոլոր]', '[շուրջբոլորը]', '4'), ('[ճիկ]', '[ձուկ]', '4'), ('[դիմափոշու]', '[դիմափոշի]', '4'), ('[ննա]', '[նա]', '4'), ('[բանաձին]', '[բանաձև]', '4'), ('[ճեր]', '[դուք]', '4'), ('[առնտրական]', '[առևտրական]', '4'), ('[արնելյան]', '[արևելյան]', '4'), ('[կուղնոր]', '[ուղևորվել]', '4'), ('[փափկենալ]', '[փափկել]', '4'), ('[իս]', '[ևս]', '4'), ('[հետնել]', '[հետևել]', '4'), ('[փնթփնթել]', '[փնթփնթալ]', '4'), ('[մեսինա]', '[Մեսինա]', '4'), ('[նուխիսկ]', '[նույնիսկ]', '4'), ('[քացնել]', '[չքանալ]', '4'), ('[երնույթ]', '[երևույթ]', '4'), ('[քրտնք]', '[քրտինք]', '4'), ('[արվարճան]', '[արվարձան]', '4'), ('[անճամբ]', '[անձամբ]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճգվել]', '[ձգվել]', '4'), ('[թունելի]', '[թունել]', '4'), ('[բատիստ]', '[Բատիստ]', '4'), ('[ճիու]', '[ձի]', '4'), ('[դարճնել]', '[դարձնել]', '4'), ('[ուղնորվել]', '[ուղևորվել]', '4'), ('[ռահել]', '[կռահել]', '4'), ('[Ռիշին]', '[Ռիշի]', '4'), ('[լաուրային]', '[Լաուրա]', '4'), ('[իջնանատան]', '[իջևանատուն]', '4'), ('[Գրասյան]', '[գրասյուն]', '4'), ('[ճգտել]', '[ձգտել]', '4'), ('[դրսնոր]', '[դրսևորել]', '3'), ('[արվարճան]', '[արվարձան]', '3'), ('[նվիրակար]', '[ամենագարշահոտ]', '3'), ('[ետնել]', '[ետև]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[ճնավորվել]', '[ձևավորվել]', '3'), ('[հետնաբար]', '[հետևաբար]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[կարամելի]', '[կարամել]', '3'), ('[ակար]', '[ամենատանջալի]', '3'), ('[ռալ]', '[չռել]', '3'), ('[կոցել]', '[կկոցել]', '3'), ('[ոռնել]', '[ոռնալ]', '3'), ('[ոռնանալ]', '[ոռնացող]', '3'), ('[որպիսիք]', '[որպիսին]', '3'), ('[միակին]', '[միակ]', '3'), ('[վերապրի]', '[վերապրել]', '3'), ('[գոլորշին]', '[գոլորշի]', '3'), ('[կարճ]', '[ամենաբարակ]', '3'), ('[սանդալի]', '[սանդալ]', '3'), ('[վերոն]', '[վերև]', '3'), ('[ազդիր]', '[ազդր]', '3'), ('[մաշկան]', '[մաշկ]', '3'), ('[գիտել]', '[գիտենալ]', '3'), ('[ավականանալ]', '[բավականացնել]', '3'), ('[ծաղկեփին]', '[ծազկեփունջ]', '3'), ('[հագել]', '[հագնել]', '3'), ('[հարնան]', '[գարուն]', '3'), ('[ճգտում]', '[ձգտում]', '3'), ('[առջին]', '[առջև]', '3'), ('[ճմիռ]', '[ձմեռ]', '3'), ('[սնահ]', '[սևահեր]', '3'), ('[սեփականանալ]', '[սեփականացնել]', '3'), ('[նկուղի]', '[նկուղ]', '3'), ('[ծանրութեթ]', '[ծանրութեթև]', '3'), ('[արկիղ]', '[արկղ]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[ճագ]', '[ձագ]', '3'), ('[դողանալ]', '[դողալ]', '3'), ('[պատկերանալ]', '[պատկերացնել]', '3'), ('[այլնս]', '[այլևս]', '3'), ('[վախել]', '[վախեցնել]', '3'), ('[լինել]', '[ես]', '3'), ('[կառափնատեղ]', '[կառափնատեղի]', '3'), ('[կառափնատեղիղ]', '[կառափնատեղի]', '3'), ('[ճեռք]', '[ձեռք]', '3'), ('[արճագանք]', '[արձագանք]', '3'), ('[ըյուսքին]', '[Ջյուսքինդ]', '2'), ('[նվիրական]', '[ամենահանճարեղ]', '2'), ('[ակտիր]', '[ամենագարշելի]', '2'), ('[չօդափոխել]', '[օդափոխել]', '2'), ('[չլվացնել]', '[լվանա]', '2'), ('[ճմեռ]', '[ձմեռ]', '2'), ('[ճմերուկ]', '[ձմերուկ]', '2'), ('[ուշաթափեցնել]', '[ուշաթափել]', '2'), ('[լվացնել]', '[լվանալ]', '2'), ('[ճայն]', '[ձայն]', '2'), ('[ճիկ]', '[ձուկ]', '2'), ('[ծծումոր]', '[ծծմայր]', '2'), ('[քրծեն]', '[քրծենի]', '2'), ('[արկիղ]', '[արկղ]', '2'), ('[այլնայլ]', '[այլևայլ]', '2'), ('[ճնականություն]', '[ձևականություն]', '2'), ('[չուննոր]', '[չունևոր]', '2'), ('[կխնդրել]', '[խնդրել]', '2'), ('[երակրել]', '[կերակրել]', '2'), ('[պիս]', '[պես]', '2'), ('[փինջ]', '[փունջ]', '2'), ('[խկացնել]', '[չխկացնել]', '2'), ('[խեցամաննե]', '[խեցաման]', '2'), ('[գանգրան]', '[գանգրանալ]', '2'), ('[օտարին]', '[օտար]', '2'), ('[կարամելից]', '[կարամել]', '2'), ('[նվիրար]', '[ամենապարզունակ]', '2'), ('[ունեմ]', '[ունենալ]', '2'), ('[քիթր]', '[քիթ]', '2'), ('[աշխարհր]', '[աշխարհ]', '2'), ('[ոստրամոխրագույնի]', '[ոստրամոխրագույն]', '2'), ('[անկշտել]', '[անկշտում]', '2'), ('[ոռինոց]', '[ոռնոց]', '2'), ('[ճղճիղան]', '[ճղճղան]', '2'), ('[դյո]', '[Դյո]', '2'), ('[ժանտախտիգ]', '[ժանտախտից]', '2'), ('[առուն]', '[առջև]', '36'), ('[ետ]', '[ետև]', '30'), ('[միջն]', '[միջև]', '22'), ('[այնուհետ]', '[այնուհետև]', '22'), ('[բացարճակապես]', '[բացարձակապես]', '21'), ('[որ]', '[որևէ]', '20'), ('[այլնս]', '[այլևս]', '19'), ('[թեթ]', '[թեթև]', '18'), ('[թեթնակ]', '[թեթևակի]', '17'), ('[որ]', '[որևէ]', '16'), ('[ետին]', '[ետև]', '16'), ('[արն]', '[արև]', '14'), ('[միննույն]', '[միևնույն]', '13'), ('[վերն]', '[վերև]', '13'), ('[ինճ]', '[ինչ]', '13'), ('[արճակ]', '[արձակել]', '12'), ('[թերուն]', '[թերևս]', '12'), ('[մուշկի]', '[մուշկ]', '12'), ('[երբնիցե]', '[երբևիցե]', '11'), ('[ճեռք]', '[ձեռք]', '10'), ('[տեզ]', '[տիզ]', '10'), ('[երնակայություն]', '[երևակայություն]', '10'), ('[արնմուտք]', '[արևմուտք]', '10'), ('[ճեռք]', '[ձեռք]', '10'), ('[ճեռք]', '[ձեռք]', '9'), ('[ճայն]', '[ձայն]', '9'), ('[նան]', '[նաև]', '8'), ('[դեռին]', '[դեռևս]', '8'), ('[ճեռք]', '[ձեռք]', '8'), ('[հետնել]', '[հետևել]', '8'), ('[արճակել]', '[արձակել]', '8'), ('[որնիցե]', '[որևիցե]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[այլնս]', '[այլևս]', '8'), ('[շրթ]', '[շրթներկ]', '8'), ('[ճեռք]', '[ձեռք]', '7'), ('[արնմտյան]', '[արևմտյան]', '7'), ('[այլես]', '[այլևս]', '7'), ('[Նախնառաջ]', '[նախևառաջ]', '7'), ('[հոգնոր]', '[հոգևոր]', '6'), ('[խունկի]', '[խունկ]', '6'), ('[ճեռք]', '[ձեռք]', '6'), ('[ներք]', '[ներքև]', '6'), ('[կաշին]', '[կաշի]', '6'), ('[ազդիր]', '[ազդր]', '6'), ('[դահճ]', '[դահիճ]', '6'), ('[համարճակվել]', '[համարձակվել]', '5'), ('[արնելք]', '[արևելք]', '5'), ('[լցրել]', '[լցնել]', '5'), ('[առանճ]', '[առանձին]', '5'), ('[արնմուտք]', '[արևմուտք]', '5'), ('[երնակայական]', '[երևակայական]', '5'), ('[թնածել]', '[թևածել]', '5'), ('[բանաճին]', '[բանաձև]', '5'), ('[բանաճին]', '[բանաձև]', '5'), ('[թեթնանալ]', '[թեթևանալ]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[կարնոր]', '[կարևոր]', '5'), ('[ճի]', '[ձի]', '5'), ('[հեղճուցիչ]', '[հեղձուցիչ]', '5'), ('[անճնական]', '[անձնական]', '5'), ('[անորսալ]', '[անորսալի]', '5'), ('[գաղտագող]', '[գաղտագողի]', '5'), ('[առուջ]', '[առջև]', '3'), ('[երնել]', '[երևալ]', '3'), ('[ինճ]', '[ես]', '3'), ('[փնթփնթաց]', '[փնթփնթալ]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[բանաձին]', '[բանաձև]', '3'), ('[եթենա]', '[եթե]', '3'), ('[ինճ]', '[ես]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[ալուֆ]', '[ալֆա]', '3'), ('[բանաձ]', '[բանաձև]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[թքած]', '[թքել]', '3'), ('[բարճրանալ]', '[բարձրացնել]', '3'), ('[Այլիս]', '[այլևս]', '3'), ('[կավինավեհ]', '[ամենավեհ]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[պոռթում]', '[պոռթկում]', '3'), ('[բացարճակ]', '[բացարձակ]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[թեն]', '[թեև]', '3'), ('[տերն]', '[տերև]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[բարճունք]', '[բարձունք]', '3'), ('[ջրալ]', '[ջրալի]', '3'), ('[թորվել]', '[թորել]', '3'), ('[խլթխլթել]', '[խլթխլթալ]', '3'), ('[առնտուր]', '[առևտուր]', '3'), ('[անճամ]', '[անձամբ]', '3'), ('[օթին]', '[օթևան]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[արճակել]', '[արձակել]', '3'), ('[բնեռ]', '[բևեռ]', '3'), ('[օճ]', '[օձ]', '3'), ('[ոջ]', '[ոչ]', '3'), ('[անձր]', '[անձրև]', '3'), ('[թեթն]', '[թեթև]', '3'), ('[ճգալ]', '[ձգել]', '3'), ('[լերել]', '[ուտել]', '3'), ('[տաքագնել]', '[տաքացնել]', '3'), ('[Հնայած]', '[Չնայած]', '3'), ('[ճեռք]', '[ձեռք]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[այխքան]', '[այդքան]', '3'), ('[նարնջենու]', '[նարնջենի]', '3'), ('[թաքչել]', '[թաքցնել]', '3'), ('[ճնալ]', '[ձևացնել]', '3'), ('[զնգզնգել]', '[զնգզնգալ]', '3'), ('[գիտել]', '[իմանալ]', '3'), ('[բարճր]', '[բարձր]', '3')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "printCompareDict(DFreqDiffWikiFiktion, DhyFiktion, DWikiX, '/content/KorpusARM1/stage04/hyFiktion.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiNatur, DhyNatur, DWikiX, '/content/KorpusARM1/stage04/hyNatur.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiRecht, DhyRecht, DWikiX, '/content/KorpusARM1/stage04/hyRecht.tsv.txt')\n",
        "printCompareDict(DFreqDiffWikiAll, DhyAll, DWikiX, '/content/KorpusARM1/stage04all.tsv.txt')"
      ],
      "metadata": {
        "id": "MzRUl4EiWPy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebdfd58-eac0-476b-eaad-657c9c8ef07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20969\n",
            "21806\n",
            "11064\n",
            "43675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/KorpusARM1/stage05"
      ],
      "metadata": {
        "id": "9h6OCvyEZZ-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printCompareDictWCorrections(DFreqDiff, DText, DWiki, DWrongCorrectWord, DWrongCorrectLemma, SFOut):\n",
        "    fOut = open(SFOut, 'w')\n",
        "    countEntries = 0\n",
        "    countCorrLem = 0\n",
        "    countCorrWord = 0\n",
        "    for key, val in sorted(DFreqDiff.items(), key=lambda item: item[1], reverse=True):\n",
        "        countEntries += 1\n",
        "        try:\n",
        "            frqText = DText[key] + 1\n",
        "        except:\n",
        "            frqText = 1\n",
        "\n",
        "        try:\n",
        "            frqWiki = DWiki[key] + 1\n",
        "        except:\n",
        "            frqWiki = 1\n",
        "        \n",
        "        SWordCorr = ''\n",
        "        SLemCorr = ''\n",
        "        SPoSCorr = ''\n",
        "        try:\n",
        "            LFieldsKey = key.split('\\t')\n",
        "            if len(LFieldsKey) == 3:\n",
        "                SWord = LFieldsKey[0]\n",
        "                SLem = LFieldsKey[2]\n",
        "                if SWord in DWrongCorrectWord.keys():\n",
        "                    SWordCorr = DWrongCorrectWord[SWord]\n",
        "                    countCorrWord +=1\n",
        "\n",
        "                if SLem in DWrongCorrectLemma.keys():\n",
        "                    SLemCorr = DWrongCorrectLemma[SLem]\n",
        "                    countCorrLem +=1\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        fOut.write(f'{key}\\t{val}\\t{SWordCorr}\\t{SPoSCorr}\\t{SLemCorr}\\t{frqText}\\t{frqWiki}\\n')\n",
        "    fOut.flush()\n",
        "    print(countEntries, countCorrWord, countCorrLem)\n",
        "    return\n"
      ],
      "metadata": {
        "id": "lhaLbxBgV9pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "printCompareDictWCorrections(DFreqDiffWikiFiktion, DhyFiktion, DWikiX, DWrongCorrectWord, DWrongCorrectLemma, '/content/KorpusARM1/stage05/hyFiktion.tsv.txt')\n",
        "printCompareDictWCorrections(DFreqDiffWikiNatur, DhyNatur, DWikiX, DWrongCorrectWord, DWrongCorrectLemma, '/content/KorpusARM1/stage05/hyNatur.tsv.txt')\n",
        "printCompareDictWCorrections(DFreqDiffWikiRecht, DhyRecht, DWikiX, DWrongCorrectWord, DWrongCorrectLemma, '/content/KorpusARM1/stage05/hyRecht.tsv.txt')\n",
        "printCompareDictWCorrections(DFreqDiffWikiAll, DhyAll, DWikiX, DWrongCorrectWord, DWrongCorrectLemma, '/content/KorpusARM1/stage05all.tsv.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Mvq66qZirp",
        "outputId": "717e89ec-9827-4f68-ce95-1fcb77755d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20969 145 440\n",
            "21806 94 292\n",
            "11064 50 117\n",
            "43675 181 550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## files to annotate:\n",
        "https://heibox.uni-heidelberg.de/d/8e44baf95ccb4c728a63/\n"
      ],
      "metadata": {
        "id": "DCWFsG4Lf8T2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITX8CWlaf6KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### checking if there is a frequency difference for an entry"
      ],
      "metadata": {
        "id": "lNz9tWIKuy0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DFreqDiff = {} # dictionary of frequency differences\n",
        "lenWiki = 2735468\n",
        "lenText = 83829\n",
        "c = 0\n",
        "for key, val in sorted(DText.items(), key=lambda item: item[1], reverse=True):\n",
        "    c+=1\n",
        "    valText = val + 1\n",
        "    relText = valText / lenText\n",
        "    try:\n",
        "        valWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        valWiki = 1\n",
        "    relWiki = valWiki / lenWiki\n",
        "\n",
        "    diffValue = relText / relWiki\n",
        "    DFreqDiff[key] = diffValue\n"
      ],
      "metadata": {
        "id": "ewfn2ngSu6sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fOut = open('Parfum_Armenian-freq-diff.txt', 'w')\n",
        "for key, val in sorted(DFreqDiff.items(), key=lambda item: item[1], reverse=True):\n",
        "    try:\n",
        "        frqText = DText[key] + 1\n",
        "    except:\n",
        "        frqText = 1\n",
        "\n",
        "    try:\n",
        "        frqWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        frqWiki = 1\n",
        "    fOut.write(f'{key}\\t{val}\\t{frqText}\\t{frqWiki}\\n')\n",
        "fOut.flush()"
      ],
      "metadata": {
        "id": "v3TNjk49xxPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat texts-vert/* >text-vert-all.vert.txt"
      ],
      "metadata": {
        "id": "rBODLGvH0_Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc text-vert-all.vert.txt"
      ],
      "metadata": {
        "id": "vGRyIth63pks",
        "outputId": "9aa3980a-440a-4ca1-b920-9040d7f8a406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 112723  338169 3062358 text-vert-all.vert.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DText2 = {}\n",
        "with open(\"text-vert-all.vert.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.rstrip()\n",
        "        try:\n",
        "            DText2[line] +=1\n",
        "        except:\n",
        "            DText2[line] = 1"
      ],
      "metadata": {
        "id": "mxkmuk223eEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DFreqDiff2 = {} # dictionary of frequency differences\n",
        "lenWiki = 2735468\n",
        "lenText = 112723\n",
        "c = 0\n",
        "for key, val in sorted(DText2.items(), key=lambda item: item[1], reverse=True):\n",
        "    c+=1\n",
        "    valText = val + 1\n",
        "    relText = valText / lenText\n",
        "    try:\n",
        "        valWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        valWiki = 1\n",
        "    relWiki = valWiki / lenWiki\n",
        "\n",
        "    diffValue = relText / relWiki\n",
        "    DFreqDiff2[key] = diffValue\n"
      ],
      "metadata": {
        "id": "4XnwSDmF3j-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fOut = open('text-vert-all-freq-diff.txt', 'w')\n",
        "for key, val in sorted(DFreqDiff2.items(), key=lambda item: item[1], reverse=True):\n",
        "    try:\n",
        "        frqText = DText2[key] + 1\n",
        "    except:\n",
        "        frqText = 1\n",
        "\n",
        "    try:\n",
        "        frqWiki = DWiki[key] + 1\n",
        "    except:\n",
        "        frqWiki = 1\n",
        "    fOut.write(f'{key}\\t{val}\\t{frqText}\\t{frqWiki}\\n')\n",
        "fOut.flush()"
      ],
      "metadata": {
        "id": "6gKv0TaC39NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading corrected file and discovering rewrite rules\n",
        "- common prefix; common suffix\n",
        "- remaining string to rewrite\n"
      ],
      "metadata": {
        "id": "Qak75Zf9hl0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "!wget https://heibox.uni-heidelberg.de/f/82b78c77a7bd4eff955d/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "LkJFnc3yh3PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 40 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "foqpXiQ-4VRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "za80HLZ0LzxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Parfum_Armenian-freq-diff-all.tsv Parfum_Armenian-freq-diff-all-v01.tsv"
      ],
      "metadata": {
        "id": "O9zVIsQOL4HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dowloading the file with corrections\n",
        "!wget https://heibox.uni-heidelberg.de/f/14706c04a4024b2f937d/?dl=1\n",
        "!mv index.html?dl=1 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "D291v87sL_yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "vWwzIBruMGBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2527650-6790-481c-b5fb-ca2b11402475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  325  2864 26793 Parfum_Armenian-freq-diff-all.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 40 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "zA4RQMrVMEzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 40 Parfum_Armenian-freq-diff-all.tsv"
      ],
      "metadata": {
        "id": "cL-jkZdJMlqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LTWrongCorrectW, DWrongCorrectW = readCorrections(1, 4, '/content/Parfum_Armenian-freq-diff-all.tsv', SFOut = 'Parfum_Armenian-freq-diff-WrCoWForm.tsv')\n",
        "LTWrongCorrectL, DWrongCorrectL = readCorrections(3, 6, '/content/Parfum_Armenian-freq-diff-all.tsv', SFOut = 'Parfum_Armenian-freq-diff-WrCoLems.tsv')\n",
        "LTWrongCorrectWf, DWrongCorrectWf = readCorrectionsFrq(1, 4, 9, '/content/Parfum_Armenian-freq-diff-all.tsv', SFOut = 'Parfum_Armenian-freq-diff-WrCoWFormF.tsv')\n",
        "LTWrongCorrectLf, DWrongCorrectLf = readCorrectionsFrq(3, 6, 9, '/content/Parfum_Armenian-freq-diff-all.tsv', SFOut = 'Parfum_Armenian-freq-diff-WrCoLemsF.tsv')"
      ],
      "metadata": {
        "id": "WWBdvnSIueGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bfc1fe-8041-402e-87f8-44f01bf31f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ինճ\tինձ\tինչ\n",
            "առջնից\tառջև\tառջևից\n",
            "ինճ\tինչ\tինձ\n",
            "172\n",
            "ինճ\tինչ\tես\n",
            "գիտել\tգիտենալ\tիմանալ\n",
            "206\n",
            "ինճ\tինձ\tինչ\n",
            "առջնից\tառջև\tառջևից\n",
            "ինճ\tինչ\tինձ\n",
            "172\n",
            "ինճ\tինչ\tես\n",
            "գիտել\tգիտենալ\tիմանալ\n",
            "206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LTWrongCorrectW)\n",
        "print(LTWrongCorrectL)\n",
        "print(LTWrongCorrectWf)\n",
        "print(LTWrongCorrectLf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbV1WbRkQ4FB",
        "outputId": "e3170176-a87a-497c-cf1c-5f6cdc5d77b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[մերճակա]', '[մերձակա]'), ('[առջն]', '[առջև]'), ('[թեթնություն]', '[թեթևություն]'), ('[Եթենա]', '[եթե նա]'), ('[ննա]', '[նա]'), ('[ճեռքերն]', '[ձեռքից]'), ('[ճայն]', '[ձայն]'), ('[ճեռքով]', '[ձեռքով]'), ('[այլնս]', '[այլևս]'), ('[ետնի]', '[ետևի]'), ('[կեղնները]', '[կեղևները]'), ('[ճկան]', '[ձկան]'), ('[ննա]', '[նա]'), ('[բանաձնի]', '[բանաձևի]'), ('[ճեր]', '[ձեր]'), ('[առնտրական]', '[առևտրական]'), ('[արնելյան]', '[արևելյան]'), ('[կուղնորվի]', '[կուղևորվի]'), ('[նս]', '[ևս]'), ('[հետնեց]', '[հետևել]'), ('[նուխիսկ]', '[նույնիսկ]'), ('[երնույթ]', '[երևույթ]'), ('[քրտնքով]', '[քրտինքով]'), ('[արվարճանում]', '[արվարձանում]'), ('[անճամբ]', '[անձամբ]'), ('[ճայնը]', '[ձայնը]'), ('[ճգվում]', '[ձգվում]'), ('[ճիու]', '[ձիու]'), ('[դարճնում]', '[դարձնում]'), ('[ուղնորվում]', '[ուղևորվում ]'), ('[իջնանատան]', '[իջևանատան]'), ('[ճգտում]', '[ձգտում]'), ('[դրսնորում]', '[դրսևորում]'), ('[արվարճանի]', '[արվարձանի]'), ('[ետնում]', '[ետևում]'), ('[ճնավորված]', '[ձևավորված]'), ('[Հետնաբար]', '[հետևաբար]'), ('[այլնս]', '[այլևս]'), ('[Շավանաբար]', '[հավանաբար]'), ('[սկզբիցնեթ]', '[սկզբիցևեթ]'), ('[միջն]', '[միջև]'), ('[համաճայնության]', '[համաձայնություն]'), ('[Թերնս]', '[թերևս]'), ('[տերնի]', '[տերև]'), ('[թնատակերի]', '[թևատակ]'), ('[դոււս]', '[դուրս]'), ('[բարճրացավ]', '[բարձրանալ]'), ('[երկարատն]', '[երկարատև]'), ('[նախնառաջ]', '[նախևառաջ]'), ('[ներքնից]', '[ներքև]'), ('[առջնից]', '[առջև]'), ('[ճեռնոցագործական]', '[ձեռնոցագործական]'), ('[հարնան]', '[գարնան]'), ('[ճգտումը]', '[ձգտումը]'), ('[առջնում]', '[առջևում]'), ('[ճմռանը]', '[ձմռանը]'), ('[սնահեր]', '[սևահեր]'), ('[ծանրութեթն]', '[ծանրութեթև]'), ('[ճագի]', '[ձագի]'), ('[Այլնս]', '[այլևս]'), ('[ինճ]', '[ինձ]'), ('[ճեռքն]', '[ձեռքն]'), ('[արճագանք]', '[արձագանք]'), ('[ճմեռ]', '[ձմեռ]'), ('[պառկածէրգերեզմանատանվրա]', '[պառկած էր գերեզմանատան վրա]'), ('[ճմերուկների]', '[ձմերուկների]'), ('[ունողկալի]', '[ու նողկալի]'), ('[գլխապտույտնե]', '[գլխապտույտներ]'), ('[ճայնի]', '[ձայնի]'), ('[ճկների]', '[ձկների]'), ('[այլնայլ]', '[այլևայլ]'), ('[ճնականություններից]', '[ձևականություններից]'), ('[չուննորներին]', '[չունևորներին]'), ('[արճակվող]', '[արձակվել]'), ('[խամարդ]', '[տղամարդ]'), ('[Միգուցենա]', '[միգուցե նա]'), ('[ջղաճգութու]', '[Ջղաձգություն]'), ('[Դետեսնում]', '[դե տեսնում ]'), ('[բարճրաց]', '[բարձրացնել]'), ('[ինճ]', '[ինձ]'), ('[Որովհետն]', '[որովհետև]'), ('[ննույնիսկ]', '[նույնիսկ]'), ('[հուսահատեգնում]', '[հեւսահատեցնել]'), ('[որնրան]', '[որ նրան]'), ('[Ջգազմունքներից]', '[Զգացմունք]'), ('[մնահավատությոն]', '[սնահավատություն]'), ('[հեթանոսա]', '[հեթանոսացում]'), ('[խարույկՄ]', '[խարույկ]'), ('[տուցում]', '[մատուցում]'), ('[նականռթյան]', '[բանականություն]'), ('[անձր]', '[անձ, անձրև]'), ('[տարօրի]', '[տարօրինակ]'), ('[թնիկները]', '[թևիկ]'), ('[աստվածավախու]', '[աստվածավախություն]'), ('[բարճր]', '[բարձր]'), ('[լավէ]', '[լավ է]'), ('[Թռենել]', '[թռնել]'), ('[հանճնեց]', '[հանձնել]'), ('[Դհյոյում]', '[Դյո]'), ('[տակիզ]', '[տակից]'), ('[առջն]', '[առջև]'), ('[ետնից]', '[ետևից]'), ('[միջն]', '[միջև]'), ('[այնուհետն]', '[այնուհետև]'), ('[բացարճակապես]', '[բացարձակապես]'), ('[որնէ]', '[որևէ]'), ('[այլնս]', '[այլևս]'), ('[թեթն]', '[թեթև]'), ('[թեթնակի]', '[թեթևակի]'), ('[որնէ]', '[որևէ]'), ('[ետնում]', '[ետևում]'), ('[արնի]', '[արևի]'), ('[միննույն]', '[միևնույն]'), ('[վերնում]', '[վերևում]'), ('[ինճ]', '[ինչ]'), ('[արճակում]', '[արձակում]'), ('[թերնս]', '[թերևս]'), ('[երբնիցե]', '[երբևիցե]'), ('[ճեռքը]', '[ձեռքը]'), ('[երնակայության]', '[երևակայության]'), ('[արնմուտք]', '[արևմուտք]'), ('[ճեռք]', '[ձեռք]'), ('[ճեռքի]', '[ձեռքի]'), ('[ճայնով]', '[ձայնով]'), ('[նան]', '[նաև]'), ('[դեռնս]', '[դեռևս]'), ('[ճեռքերը]', '[ձեռքերը]'), ('[հետնում]', '[հետևում]'), ('[արճակող]', '[արձակող]'), ('[որնիցե]', '[որևիցե]'), ('[դեռնս]', '[դեռևս]'), ('[այլնս]', '[այլևս]'), ('[ճեռքին]', '[ձեռքին]'), ('[արնմտյան]', '[արևմտյան]'), ('[այլես]', '[այլևս]'), ('[Նախնառաջ]', '[նախևառաջ]'), ('[հոգնոր]', '[հոգևոր]'), ('[ճեռքերով]', '[ձեռքերով]'), ('[ներքնում]', '[ներքևում]'), ('[համարճակվում]', '[համարձակվում]'), ('[արնելք]', '[արևելք]'), ('[առանճին]', '[առանձին]'), ('[արնմուտքից]', '[արևմուտքից]'), ('[երնակայական]', '[երևակայական]'), ('[թնածում]', '[թևածում]'), ('[բանաճնի]', '[բանաձևի]'), ('[դարճավ]', '[դարձավ]'), ('[բանաճնը]', '[բանաձևը]'), ('[թեթնացած]', '[թեթևացած]'), ('[հետնելով]', '[հետևելով]'), ('[հետնել]', '[հետևել]'), ('[կարնոր]', '[կարևոր]'), ('[ճիու]', '[ձիու]'), ('[հեղճուցիչ]', '[հեղձուցիչ]'), ('[անճնական]', '[անձնական]'), ('[առջնից]', '[առջևից]'), ('[երնում]', '[երևում]'), ('[ինճ]', '[ինձ]'), ('[փորճ]', '[փորձ]'), ('[բանաձնը]', '[բանաձևը]'), ('[եթենա]', '[եթե]'), ('[ինճ]', '[ինձ]'), ('[փորճն]', '[փորձն]'), ('[բանաձն]', '[բանաձևն]'), ('[բանաճն]', '[բանաձևն]'), ('[բարճրացնել]', '[բարձրացնել]'), ('[Այլնս]', '[այլևս]'), ('[սնահեր]', '[սևահեր]'), ('[բացարճակ]', '[բացարձակ]'), ('[ճգտելով]', '[ձգտելով]'), ('[բանաճներ]', '[բանաձևեր]'), ('[թեն]', '[թեև]'), ('[տերնները]', '[տերևերը]'), ('[բարճունքներում]', '[բարձունքներում]'), ('[առնտուրը]', '[առևտուրը]'), ('[անճամբ]', '[անձամբ]'), ('[օթնան]', '[օթևան]'), ('[բանաճներով]', '[բանաձներով]'), ('[արճակել]', '[արձակել]'), ('[բնեռը]', '[բևեռը]'), ('[օճեր]', '[օձեր]'), ('[ոջ]', '[ոչ]'), ('[անձրնը]', '[անձրևը]'), ('[թեթն]', '[թեթև]'), ('[ճգում]', '[ձգում]'), ('[տաքագնում]', '[տաքացնում]'), ('[Հնայած]', '[Չնայած]'), ('[ճեռքերի]', '[Ձեռքերի]'), ('[այխքան]', '[այդքան]'), ('[ճնացրեց]', '[ձևացրեց]'), ('[երնակայությունների]', '[երևակայությունների]'), ('[առջն]', '[առջև]'), ('[բարճր]', '[բարձր]')]\n",
            "[('[գաղտագող]', '[գաղտագողի]'), ('[լաուրա]', '[Լաուրա]'), ('[տաններոն]', '[Տաններոն]'), ('[մերճակա]', '[մերձակա]'), ('[ռանալել]', '[կռանալ]'), ('[Տերն]', '[Տեր]'), ('[ճեռք]', '[ձեռք]'), ('[կարագից]', '[կարագ]'), ('[ճայն]', '[ձայն]'), ('[ճեռք]', '[ձեռք]'), ('[այլնս]', '[այլևս]'), ('[ետուն]', '[ետև]'), ('[կեղն]', '[կեղև]'), ('[լուսաբացի]', '[լուսաբաց]'), ('[շուրջբոլոր]', '[շուրջբոլորը]'), ('[ճիկ]', '[ձուկ]'), ('[դիմափոշու]', '[դիմափոշի]'), ('[ննա]', '[նա]'), ('[բանաձին]', '[բանաձև]'), ('[ճեր]', '[դուք]'), ('[առնտրական]', '[առևտրական]'), ('[արնելյան]', '[արևելյան]'), ('[կուղնոր]', '[ուղևորվել]'), ('[փափկենալ]', '[փափկել]'), ('[իս]', '[ևս]'), ('[հետնել]', '[հետևել]'), ('[փնթփնթել]', '[փնթփնթալ]'), ('[մեսինա]', '[Մեսինա]'), ('[նուխիսկ]', '[նույնիսկ]'), ('[քացնել]', '[չքանալ]'), ('[երնույթ]', '[երևույթ]'), ('[քրտնք]', '[քրտինք]'), ('[արվարճան]', '[արվարձան]'), ('[անճամբ]', '[անձամբ]'), ('[ճայն]', '[ձայն]'), ('[ճգվել]', '[ձգվել]'), ('[թունելի]', '[թունել]'), ('[բատիստ]', '[Բատիստ]'), ('[ճիու]', '[ձի]'), ('[դարճնել]', '[դարձնել]'), ('[ուղնորվել]', '[ուղևորվել]'), ('[ռահել]', '[կռահել]'), ('[Ռիշին]', '[Ռիշի]'), ('[լաուրային]', '[Լաուրա]'), ('[իջնանատան]', '[իջևանատուն]'), ('[Գրասյան]', '[գրասյուն]'), ('[ճգտել]', '[ձգտել]'), ('[դրսնոր]', '[դրսևորել]'), ('[արվարճան]', '[արվարձան]'), ('[նվիրակար]', '[ամենագարշահոտ]'), ('[ետնել]', '[ետև]'), ('[ծծմոր]', '[ծծմայր]'), ('[ծծմոր]', '[ծծմայր]'), ('[ճնավորվել]', '[ձևավորվել]'), ('[հետնաբար]', '[հետևաբար]'), ('[ծծմոր]', '[ծծմայր]'), ('[կարամելի]', '[կարամել]'), ('[ակար]', '[ամենատանջալի]'), ('[ռալ]', '[չռել]'), ('[կոցել]', '[կկոցել]'), ('[ոռնել]', '[ոռնալ]'), ('[ոռնանալ]', '[ոռնացող]'), ('[որպիսիք]', '[որպիսին]'), ('[միակին]', '[միակ]'), ('[վերապրի]', '[վերապրել]'), ('[գոլորշին]', '[գոլորշի]'), ('[կարճ]', '[ամենաբարակ]'), ('[սանդալի]', '[սանդալ]'), ('[վերոն]', '[վերև]'), ('[ազդիր]', '[ազդր]'), ('[մաշկան]', '[մաշկ]'), ('[գիտել]', '[գիտենալ]'), ('[ավականանալ]', '[բավականացնել]'), ('[ծաղկեփին]', '[ծազկեփունջ]'), ('[հագել]', '[հագնել]'), ('[հարնան]', '[գարուն]'), ('[ճգտում]', '[ձգտում]'), ('[առջին]', '[առջև]'), ('[ճմիռ]', '[ձմեռ]'), ('[սնահ]', '[սևահեր]'), ('[սեփականանալ]', '[սեփականացնել]'), ('[նկուղի]', '[նկուղ]'), ('[ծանրութեթ]', '[ծանրութեթև]'), ('[արկիղ]', '[արկղ]'), ('[շրթ]', '[շրթներկ]'), ('[ճագ]', '[ձագ]'), ('[դողանալ]', '[դողալ]'), ('[պատկերանալ]', '[պատկերացնել]'), ('[այլնս]', '[այլևս]'), ('[վախել]', '[վախեցնել]'), ('[լինել]', '[ես]'), ('[կառափնատեղ]', '[կառափնատեղի]'), ('[կառափնատեղիղ]', '[կառափնատեղի]'), ('[ճեռք]', '[ձեռք]'), ('[արճագանք]', '[արձագանք]'), ('[ըյուսքին]', '[Ջյուսքինդ]'), ('[նվիրական]', '[ամենահանճարեղ]'), ('[ակտիր]', '[ամենագարշելի]'), ('[չօդափոխել]', '[օդափոխել]'), ('[չլվացնել]', '[լվանա]'), ('[ճմեռ]', '[ձմեռ]'), ('[ճմերուկ]', '[ձմերուկ]'), ('[ուշաթափեցնել]', '[ուշաթափել]'), ('[լվացնել]', '[լվանալ]'), ('[ճայն]', '[ձայն]'), ('[ճիկ]', '[ձուկ]'), ('[ծծումոր]', '[ծծմայր]'), ('[քրծեն]', '[քրծենի]'), ('[արկիղ]', '[արկղ]'), ('[այլնայլ]', '[այլևայլ]'), ('[ճնականություն]', '[ձևականություն]'), ('[չուննոր]', '[չունևոր]'), ('[կխնդրել]', '[խնդրել]'), ('[երակրել]', '[կերակրել]'), ('[պիս]', '[պես]'), ('[փինջ]', '[փունջ]'), ('[խկացնել]', '[չխկացնել]'), ('[խեցամաննե]', '[խեցաման]'), ('[գանգրան]', '[գանգրանալ]'), ('[օտարին]', '[օտար]'), ('[կարամելից]', '[կարամել]'), ('[նվիրար]', '[ամենապարզունակ]'), ('[ունեմ]', '[ունենալ]'), ('[քիթր]', '[քիթ]'), ('[աշխարհր]', '[աշխարհ]'), ('[ոստրամոխրագույնի]', '[ոստրամոխրագույն]'), ('[անկշտել]', '[անկշտում]'), ('[ոռինոց]', '[ոռնոց]'), ('[ճղճիղան]', '[ճղճղան]'), ('[դյո]', '[Դյո]'), ('[ժանտախտիգ]', '[ժանտախտից]'), ('[առուն]', '[առջև]'), ('[ետ]', '[ետև]'), ('[միջն]', '[միջև]'), ('[այնուհետ]', '[այնուհետև]'), ('[բացարճակապես]', '[բացարձակապես]'), ('[որ]', '[որևէ]'), ('[այլնս]', '[այլևս]'), ('[թեթ]', '[թեթև]'), ('[թեթնակ]', '[թեթևակի]'), ('[որ]', '[որևէ]'), ('[ետին]', '[ետև]'), ('[արն]', '[արև]'), ('[միննույն]', '[միևնույն]'), ('[վերն]', '[վերև]'), ('[ինճ]', '[ինչ]'), ('[արճակ]', '[արձակել]'), ('[թերուն]', '[թերևս]'), ('[մուշկի]', '[մուշկ]'), ('[երբնիցե]', '[երբևիցե]'), ('[ճեռք]', '[ձեռք]'), ('[տեզ]', '[տիզ]'), ('[երնակայություն]', '[երևակայություն]'), ('[արնմուտք]', '[արևմուտք]'), ('[ճեռք]', '[ձեռք]'), ('[ճեռք]', '[ձեռք]'), ('[ճայն]', '[ձայն]'), ('[նան]', '[նաև]'), ('[դեռին]', '[դեռևս]'), ('[ճեռք]', '[ձեռք]'), ('[հետնել]', '[հետևել]'), ('[արճակել]', '[արձակել]'), ('[որնիցե]', '[որևիցե]'), ('[դեռնս]', '[դեռևս]'), ('[այլնս]', '[այլևս]'), ('[շրթ]', '[շրթներկ]'), ('[ճեռք]', '[ձեռք]'), ('[արնմտյան]', '[արևմտյան]'), ('[այլես]', '[այլևս]'), ('[Նախնառաջ]', '[նախևառաջ]'), ('[հոգնոր]', '[հոգևոր]'), ('[խունկի]', '[խունկ]'), ('[ճեռք]', '[ձեռք]'), ('[ներք]', '[ներքև]'), ('[կաշին]', '[կաշի]'), ('[ազդիր]', '[ազդր]'), ('[դահճ]', '[դահիճ]'), ('[համարճակվել]', '[համարձակվել]'), ('[արնելք]', '[արևելք]'), ('[լցրել]', '[լցնել]'), ('[առանճ]', '[առանձին]'), ('[արնմուտք]', '[արևմուտք]'), ('[երնակայական]', '[երևակայական]'), ('[թնածել]', '[թևածել]'), ('[բանաճին]', '[բանաձև]'), ('[բանաճին]', '[բանաձև]'), ('[թեթնանալ]', '[թեթևանալ]'), ('[հետնել]', '[հետևել]'), ('[հետնել]', '[հետևել]'), ('[կարնոր]', '[կարևոր]'), ('[ճի]', '[ձի]'), ('[հեղճուցիչ]', '[հեղձուցիչ]'), ('[անճնական]', '[անձնական]'), ('[անորսալ]', '[անորսալի]'), ('[գաղտագող]', '[գաղտագողի]'), ('[առուջ]', '[առջև]'), ('[երնել]', '[երևալ]'), ('[ինճ]', '[ես]'), ('[փնթփնթաց]', '[փնթփնթալ]'), ('[փորճ]', '[փորձ]'), ('[բանաձին]', '[բանաձև]'), ('[եթենա]', '[եթե]'), ('[ինճ]', '[ես]'), ('[փորճ]', '[փորձ]'), ('[ալուֆ]', '[ալֆա]'), ('[բանաձ]', '[բանաձև]'), ('[բանաճ]', '[բանաձև]'), ('[թքած]', '[թքել]'), ('[բարճրանալ]', '[բարձրացնել]'), ('[Այլիս]', '[այլևս]'), ('[կավինավեհ]', '[ամենավեհ]'), ('[սնահեր]', '[սևահեր]'), ('[պոռթում]', '[պոռթկում]'), ('[բացարճակ]', '[բացարձակ]'), ('[բանաճ]', '[բանաձև]'), ('[թեն]', '[թեև]'), ('[տերն]', '[տերև]'), ('[շրթ]', '[շրթներկ]'), ('[բարճունք]', '[բարձունք]'), ('[ջրալ]', '[ջրալի]'), ('[թորվել]', '[թորել]'), ('[խլթխլթել]', '[խլթխլթալ]'), ('[առնտուր]', '[առևտուր]'), ('[անճամ]', '[անձամբ]'), ('[օթին]', '[օթևան]'), ('[բանաճ]', '[բանաձև]'), ('[արճակել]', '[արձակել]'), ('[բնեռ]', '[բևեռ]'), ('[օճ]', '[օձ]'), ('[ոջ]', '[ոչ]'), ('[անձր]', '[անձրև]'), ('[թեթն]', '[թեթև]'), ('[ճգալ]', '[ձգել]'), ('[լերել]', '[ուտել]'), ('[տաքագնել]', '[տաքացնել]'), ('[Հնայած]', '[Չնայած]'), ('[ճեռք]', '[ձեռք]'), ('[շրթ]', '[շրթներկ]'), ('[այխքան]', '[այդքան]'), ('[նարնջենու]', '[նարնջենի]'), ('[թաքչել]', '[թաքցնել]'), ('[ճնալ]', '[ձևացնել]'), ('[զնգզնգել]', '[զնգզնգալ]'), ('[գիտել]', '[իմանալ]'), ('[բարճր]', '[բարձր]')]\n",
            "[('[մերճակա]', '[մերձակա]', '4'), ('[առջն]', '[առջև]', '4'), ('[թեթնություն]', '[թեթևություն]', '4'), ('[Եթենա]', '[եթե նա]', '4'), ('[ննա]', '[նա]', '4'), ('[ճեռքերն]', '[ձեռքից]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճեռքով]', '[ձեռքով]', '4'), ('[այլնս]', '[այլևս]', '4'), ('[ետնի]', '[ետևի]', '4'), ('[կեղնները]', '[կեղևները]', '4'), ('[ճկան]', '[ձկան]', '4'), ('[ննա]', '[նա]', '4'), ('[բանաձնի]', '[բանաձևի]', '4'), ('[ճեր]', '[ձեր]', '4'), ('[առնտրական]', '[առևտրական]', '4'), ('[արնելյան]', '[արևելյան]', '4'), ('[կուղնորվի]', '[կուղևորվի]', '4'), ('[նս]', '[ևս]', '4'), ('[հետնեց]', '[հետևել]', '4'), ('[նուխիսկ]', '[նույնիսկ]', '4'), ('[երնույթ]', '[երևույթ]', '4'), ('[քրտնքով]', '[քրտինքով]', '4'), ('[արվարճանում]', '[արվարձանում]', '4'), ('[անճամբ]', '[անձամբ]', '4'), ('[ճայնը]', '[ձայնը]', '4'), ('[ճգվում]', '[ձգվում]', '4'), ('[ճիու]', '[ձիու]', '4'), ('[դարճնում]', '[դարձնում]', '4'), ('[ուղնորվում]', '[ուղևորվում ]', '4'), ('[իջնանատան]', '[իջևանատան]', '4'), ('[ճգտում]', '[ձգտում]', '4'), ('[դրսնորում]', '[դրսևորում]', '3'), ('[արվարճանի]', '[արվարձանի]', '3'), ('[ետնում]', '[ետևում]', '3'), ('[ճնավորված]', '[ձևավորված]', '3'), ('[Հետնաբար]', '[հետևաբար]', '3'), ('[այլնս]', '[այլևս]', '3'), ('[Շավանաբար]', '[հավանաբար]', '3'), ('[սկզբիցնեթ]', '[սկզբիցևեթ]', '3'), ('[միջն]', '[միջև]', '3'), ('[համաճայնության]', '[համաձայնություն]', '3'), ('[Թերնս]', '[թերևս]', '3'), ('[տերնի]', '[տերև]', '3'), ('[թնատակերի]', '[թևատակ]', '3'), ('[դոււս]', '[դուրս]', '3'), ('[բարճրացավ]', '[բարձրանալ]', '3'), ('[երկարատն]', '[երկարատև]', '3'), ('[նախնառաջ]', '[նախևառաջ]', '3'), ('[ներքնից]', '[ներքև]', '3'), ('[առջնից]', '[առջև]', '3'), ('[ճեռնոցագործական]', '[ձեռնոցագործական]', '3'), ('[հարնան]', '[գարնան]', '3'), ('[ճգտումը]', '[ձգտումը]', '3'), ('[առջնում]', '[առջևում]', '3'), ('[ճմռանը]', '[ձմռանը]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[ծանրութեթն]', '[ծանրութեթև]', '3'), ('[ճագի]', '[ձագի]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[ճեռքն]', '[ձեռքն]', '3'), ('[արճագանք]', '[արձագանք]', '3'), ('[ճմեռ]', '[ձմեռ]', '2'), ('[պառկածէրգերեզմանատանվրա]', '[պառկած էր գերեզմանատան վրա]', '2'), ('[ճմերուկների]', '[ձմերուկների]', '2'), ('[ունողկալի]', '[ու նողկալի]', '2'), ('[գլխապտույտնե]', '[գլխապտույտներ]', '2'), ('[ճայնի]', '[ձայնի]', '2'), ('[ճկների]', '[ձկների]', '2'), ('[այլնայլ]', '[այլևայլ]', '2'), ('[ճնականություններից]', '[ձևականություններից]', '2'), ('[չուննորներին]', '[չունևորներին]', '2'), ('[արճակվող]', '[արձակվել]', '2'), ('[խամարդ]', '[տղամարդ]', '2'), ('[Միգուցենա]', '[միգուցե նա]', '2'), ('[ջղաճգութու]', '[Ջղաձգություն]', '2'), ('[Դետեսնում]', '[դե տեսնում ]', '2'), ('[բարճրաց]', '[բարձրացնել]', '2'), ('[ինճ]', '[ինձ]', '2'), ('[Որովհետն]', '[որովհետև]', '2'), ('[ննույնիսկ]', '[նույնիսկ]', '2'), ('[հուսահատեգնում]', '[հեւսահատեցնել]', '2'), ('[որնրան]', '[որ նրան]', '2'), ('[Ջգազմունքներից]', '[Զգացմունք]', '2'), ('[մնահավատությոն]', '[սնահավատություն]', '2'), ('[հեթանոսա]', '[հեթանոսացում]', '2'), ('[խարույկՄ]', '[խարույկ]', '2'), ('[տուցում]', '[մատուցում]', '2'), ('[նականռթյան]', '[բանականություն]', '2'), ('[անձր]', '[անձ, անձրև]', '2'), ('[տարօրի]', '[տարօրինակ]', '2'), ('[թնիկները]', '[թևիկ]', '2'), ('[աստվածավախու]', '[աստվածավախություն]', '2'), ('[բարճր]', '[բարձր]', '2'), ('[լավէ]', '[լավ է]', '2'), ('[Թռենել]', '[թռնել]', '2'), ('[հանճնեց]', '[հանձնել]', '2'), ('[Դհյոյում]', '[Դյո]', '2'), ('[տակիզ]', '[տակից]', '2'), ('[առջն]', '[առջև]', '36'), ('[ետնից]', '[ետևից]', '30'), ('[միջն]', '[միջև]', '22'), ('[այնուհետն]', '[այնուհետև]', '22'), ('[բացարճակապես]', '[բացարձակապես]', '21'), ('[որնէ]', '[որևէ]', '20'), ('[այլնս]', '[այլևս]', '19'), ('[թեթն]', '[թեթև]', '18'), ('[թեթնակի]', '[թեթևակի]', '17'), ('[որնէ]', '[որևէ]', '16'), ('[ետնում]', '[ետևում]', '16'), ('[արնի]', '[արևի]', '14'), ('[միննույն]', '[միևնույն]', '13'), ('[վերնում]', '[վերևում]', '13'), ('[ինճ]', '[ինչ]', '13'), ('[արճակում]', '[արձակում]', '12'), ('[թերնս]', '[թերևս]', '12'), ('[երբնիցե]', '[երբևիցե]', '11'), ('[ճեռքը]', '[ձեռքը]', '10'), ('[երնակայության]', '[երևակայության]', '10'), ('[արնմուտք]', '[արևմուտք]', '10'), ('[ճեռք]', '[ձեռք]', '10'), ('[ճեռքի]', '[ձեռքի]', '9'), ('[ճայնով]', '[ձայնով]', '9'), ('[նան]', '[նաև]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[ճեռքերը]', '[ձեռքերը]', '8'), ('[հետնում]', '[հետևում]', '8'), ('[արճակող]', '[արձակող]', '8'), ('[որնիցե]', '[որևիցե]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[այլնս]', '[այլևս]', '8'), ('[ճեռքին]', '[ձեռքին]', '7'), ('[արնմտյան]', '[արևմտյան]', '7'), ('[այլես]', '[այլևս]', '7'), ('[Նախնառաջ]', '[նախևառաջ]', '7'), ('[հոգնոր]', '[հոգևոր]', '6'), ('[ճեռքերով]', '[ձեռքերով]', '6'), ('[ներքնում]', '[ներքևում]', '6'), ('[համարճակվում]', '[համարձակվում]', '5'), ('[արնելք]', '[արևելք]', '5'), ('[առանճին]', '[առանձին]', '5'), ('[արնմուտքից]', '[արևմուտքից]', '5'), ('[երնակայական]', '[երևակայական]', '5'), ('[թնածում]', '[թևածում]', '5'), ('[բանաճնի]', '[բանաձևի]', '5'), ('[դարճավ]', '[դարձավ]', '5'), ('[բանաճնը]', '[բանաձևը]', '5'), ('[թեթնացած]', '[թեթևացած]', '5'), ('[հետնելով]', '[հետևելով]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[կարնոր]', '[կարևոր]', '5'), ('[ճիու]', '[ձիու]', '5'), ('[հեղճուցիչ]', '[հեղձուցիչ]', '5'), ('[անճնական]', '[անձնական]', '5'), ('[առջնից]', '[առջևից]', '3'), ('[երնում]', '[երևում]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[բանաձնը]', '[բանաձևը]', '3'), ('[եթենա]', '[եթե]', '3'), ('[ինճ]', '[ինձ]', '3'), ('[փորճն]', '[փորձն]', '3'), ('[բանաձն]', '[բանաձևն]', '3'), ('[բանաճն]', '[բանաձևն]', '3'), ('[բարճրացնել]', '[բարձրացնել]', '3'), ('[Այլնս]', '[այլևս]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[բացարճակ]', '[բացարձակ]', '3'), ('[ճգտելով]', '[ձգտելով]', '3'), ('[բանաճներ]', '[բանաձևեր]', '3'), ('[թեն]', '[թեև]', '3'), ('[տերնները]', '[տերևերը]', '3'), ('[բարճունքներում]', '[բարձունքներում]', '3'), ('[առնտուրը]', '[առևտուրը]', '3'), ('[անճամբ]', '[անձամբ]', '3'), ('[օթնան]', '[օթևան]', '3'), ('[բանաճներով]', '[բանաձներով]', '3'), ('[արճակել]', '[արձակել]', '3'), ('[բնեռը]', '[բևեռը]', '3'), ('[օճեր]', '[օձեր]', '3'), ('[ոջ]', '[ոչ]', '3'), ('[անձրնը]', '[անձրևը]', '3'), ('[թեթն]', '[թեթև]', '3'), ('[ճգում]', '[ձգում]', '3'), ('[տաքագնում]', '[տաքացնում]', '3'), ('[Հնայած]', '[Չնայած]', '3'), ('[ճեռքերի]', '[Ձեռքերի]', '3'), ('[այխքան]', '[այդքան]', '3'), ('[ճնացրեց]', '[ձևացրեց]', '3'), ('[երնակայությունների]', '[երևակայությունների]', '3'), ('[առջն]', '[առջև]', '3'), ('[բարճր]', '[բարձր]', '3')]\n",
            "[('[գաղտագող]', '[գաղտագողի]', '5'), ('[լաուրա]', '[Լաուրա]', '5'), ('[տաններոն]', '[Տաններոն]', '5'), ('[մերճակա]', '[մերձակա]', '4'), ('[ռանալել]', '[կռանալ]', '4'), ('[Տերն]', '[Տեր]', '4'), ('[ճեռք]', '[ձեռք]', '4'), ('[կարագից]', '[կարագ]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճեռք]', '[ձեռք]', '4'), ('[այլնս]', '[այլևս]', '4'), ('[ետուն]', '[ետև]', '4'), ('[կեղն]', '[կեղև]', '4'), ('[լուսաբացի]', '[լուսաբաց]', '4'), ('[շուրջբոլոր]', '[շուրջբոլորը]', '4'), ('[ճիկ]', '[ձուկ]', '4'), ('[դիմափոշու]', '[դիմափոշի]', '4'), ('[ննա]', '[նա]', '4'), ('[բանաձին]', '[բանաձև]', '4'), ('[ճեր]', '[դուք]', '4'), ('[առնտրական]', '[առևտրական]', '4'), ('[արնելյան]', '[արևելյան]', '4'), ('[կուղնոր]', '[ուղևորվել]', '4'), ('[փափկենալ]', '[փափկել]', '4'), ('[իս]', '[ևս]', '4'), ('[հետնել]', '[հետևել]', '4'), ('[փնթփնթել]', '[փնթփնթալ]', '4'), ('[մեսինա]', '[Մեսինա]', '4'), ('[նուխիսկ]', '[նույնիսկ]', '4'), ('[քացնել]', '[չքանալ]', '4'), ('[երնույթ]', '[երևույթ]', '4'), ('[քրտնք]', '[քրտինք]', '4'), ('[արվարճան]', '[արվարձան]', '4'), ('[անճամբ]', '[անձամբ]', '4'), ('[ճայն]', '[ձայն]', '4'), ('[ճգվել]', '[ձգվել]', '4'), ('[թունելի]', '[թունել]', '4'), ('[բատիստ]', '[Բատիստ]', '4'), ('[ճիու]', '[ձի]', '4'), ('[դարճնել]', '[դարձնել]', '4'), ('[ուղնորվել]', '[ուղևորվել]', '4'), ('[ռահել]', '[կռահել]', '4'), ('[Ռիշին]', '[Ռիշի]', '4'), ('[լաուրային]', '[Լաուրա]', '4'), ('[իջնանատան]', '[իջևանատուն]', '4'), ('[Գրասյան]', '[գրասյուն]', '4'), ('[ճգտել]', '[ձգտել]', '4'), ('[դրսնոր]', '[դրսևորել]', '3'), ('[արվարճան]', '[արվարձան]', '3'), ('[նվիրակար]', '[ամենագարշահոտ]', '3'), ('[ետնել]', '[ետև]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[ճնավորվել]', '[ձևավորվել]', '3'), ('[հետնաբար]', '[հետևաբար]', '3'), ('[ծծմոր]', '[ծծմայր]', '3'), ('[կարամելի]', '[կարամել]', '3'), ('[ակար]', '[ամենատանջալի]', '3'), ('[ռալ]', '[չռել]', '3'), ('[կոցել]', '[կկոցել]', '3'), ('[ոռնել]', '[ոռնալ]', '3'), ('[ոռնանալ]', '[ոռնացող]', '3'), ('[որպիսիք]', '[որպիսին]', '3'), ('[միակին]', '[միակ]', '3'), ('[վերապրի]', '[վերապրել]', '3'), ('[գոլորշին]', '[գոլորշի]', '3'), ('[կարճ]', '[ամենաբարակ]', '3'), ('[սանդալի]', '[սանդալ]', '3'), ('[վերոն]', '[վերև]', '3'), ('[ազդիր]', '[ազդր]', '3'), ('[մաշկան]', '[մաշկ]', '3'), ('[գիտել]', '[գիտենալ]', '3'), ('[ավականանալ]', '[բավականացնել]', '3'), ('[ծաղկեփին]', '[ծազկեփունջ]', '3'), ('[հագել]', '[հագնել]', '3'), ('[հարնան]', '[գարուն]', '3'), ('[ճգտում]', '[ձգտում]', '3'), ('[առջին]', '[առջև]', '3'), ('[ճմիռ]', '[ձմեռ]', '3'), ('[սնահ]', '[սևահեր]', '3'), ('[սեփականանալ]', '[սեփականացնել]', '3'), ('[նկուղի]', '[նկուղ]', '3'), ('[ծանրութեթ]', '[ծանրութեթև]', '3'), ('[արկիղ]', '[արկղ]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[ճագ]', '[ձագ]', '3'), ('[դողանալ]', '[դողալ]', '3'), ('[պատկերանալ]', '[պատկերացնել]', '3'), ('[այլնս]', '[այլևս]', '3'), ('[վախել]', '[վախեցնել]', '3'), ('[լինել]', '[ես]', '3'), ('[կառափնատեղ]', '[կառափնատեղի]', '3'), ('[կառափնատեղիղ]', '[կառափնատեղի]', '3'), ('[ճեռք]', '[ձեռք]', '3'), ('[արճագանք]', '[արձագանք]', '3'), ('[ըյուսքին]', '[Ջյուսքինդ]', '2'), ('[նվիրական]', '[ամենահանճարեղ]', '2'), ('[ակտիր]', '[ամենագարշելի]', '2'), ('[չօդափոխել]', '[օդափոխել]', '2'), ('[չլվացնել]', '[լվանա]', '2'), ('[ճմեռ]', '[ձմեռ]', '2'), ('[ճմերուկ]', '[ձմերուկ]', '2'), ('[ուշաթափեցնել]', '[ուշաթափել]', '2'), ('[լվացնել]', '[լվանալ]', '2'), ('[ճայն]', '[ձայն]', '2'), ('[ճիկ]', '[ձուկ]', '2'), ('[ծծումոր]', '[ծծմայր]', '2'), ('[քրծեն]', '[քրծենի]', '2'), ('[արկիղ]', '[արկղ]', '2'), ('[այլնայլ]', '[այլևայլ]', '2'), ('[ճնականություն]', '[ձևականություն]', '2'), ('[չուննոր]', '[չունևոր]', '2'), ('[կխնդրել]', '[խնդրել]', '2'), ('[երակրել]', '[կերակրել]', '2'), ('[պիս]', '[պես]', '2'), ('[փինջ]', '[փունջ]', '2'), ('[խկացնել]', '[չխկացնել]', '2'), ('[խեցամաննե]', '[խեցաման]', '2'), ('[գանգրան]', '[գանգրանալ]', '2'), ('[օտարին]', '[օտար]', '2'), ('[կարամելից]', '[կարամել]', '2'), ('[նվիրար]', '[ամենապարզունակ]', '2'), ('[ունեմ]', '[ունենալ]', '2'), ('[քիթր]', '[քիթ]', '2'), ('[աշխարհր]', '[աշխարհ]', '2'), ('[ոստրամոխրագույնի]', '[ոստրամոխրագույն]', '2'), ('[անկշտել]', '[անկշտում]', '2'), ('[ոռինոց]', '[ոռնոց]', '2'), ('[ճղճիղան]', '[ճղճղան]', '2'), ('[դյո]', '[Դյո]', '2'), ('[ժանտախտիգ]', '[ժանտախտից]', '2'), ('[առուն]', '[առջև]', '36'), ('[ետ]', '[ետև]', '30'), ('[միջն]', '[միջև]', '22'), ('[այնուհետ]', '[այնուհետև]', '22'), ('[բացարճակապես]', '[բացարձակապես]', '21'), ('[որ]', '[որևէ]', '20'), ('[այլնս]', '[այլևս]', '19'), ('[թեթ]', '[թեթև]', '18'), ('[թեթնակ]', '[թեթևակի]', '17'), ('[որ]', '[որևէ]', '16'), ('[ետին]', '[ետև]', '16'), ('[արն]', '[արև]', '14'), ('[միննույն]', '[միևնույն]', '13'), ('[վերն]', '[վերև]', '13'), ('[ինճ]', '[ինչ]', '13'), ('[արճակ]', '[արձակել]', '12'), ('[թերուն]', '[թերևս]', '12'), ('[մուշկի]', '[մուշկ]', '12'), ('[երբնիցե]', '[երբևիցե]', '11'), ('[ճեռք]', '[ձեռք]', '10'), ('[տեզ]', '[տիզ]', '10'), ('[երնակայություն]', '[երևակայություն]', '10'), ('[արնմուտք]', '[արևմուտք]', '10'), ('[ճեռք]', '[ձեռք]', '10'), ('[ճեռք]', '[ձեռք]', '9'), ('[ճայն]', '[ձայն]', '9'), ('[նան]', '[նաև]', '8'), ('[դեռին]', '[դեռևս]', '8'), ('[ճեռք]', '[ձեռք]', '8'), ('[հետնել]', '[հետևել]', '8'), ('[արճակել]', '[արձակել]', '8'), ('[որնիցե]', '[որևիցե]', '8'), ('[դեռնս]', '[դեռևս]', '8'), ('[այլնս]', '[այլևս]', '8'), ('[շրթ]', '[շրթներկ]', '8'), ('[ճեռք]', '[ձեռք]', '7'), ('[արնմտյան]', '[արևմտյան]', '7'), ('[այլես]', '[այլևս]', '7'), ('[Նախնառաջ]', '[նախևառաջ]', '7'), ('[հոգնոր]', '[հոգևոր]', '6'), ('[խունկի]', '[խունկ]', '6'), ('[ճեռք]', '[ձեռք]', '6'), ('[ներք]', '[ներքև]', '6'), ('[կաշին]', '[կաշի]', '6'), ('[ազդիր]', '[ազդր]', '6'), ('[դահճ]', '[դահիճ]', '6'), ('[համարճակվել]', '[համարձակվել]', '5'), ('[արնելք]', '[արևելք]', '5'), ('[լցրել]', '[լցնել]', '5'), ('[առանճ]', '[առանձին]', '5'), ('[արնմուտք]', '[արևմուտք]', '5'), ('[երնակայական]', '[երևակայական]', '5'), ('[թնածել]', '[թևածել]', '5'), ('[բանաճին]', '[բանաձև]', '5'), ('[բանաճին]', '[բանաձև]', '5'), ('[թեթնանալ]', '[թեթևանալ]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[հետնել]', '[հետևել]', '5'), ('[կարնոր]', '[կարևոր]', '5'), ('[ճի]', '[ձի]', '5'), ('[հեղճուցիչ]', '[հեղձուցիչ]', '5'), ('[անճնական]', '[անձնական]', '5'), ('[անորսալ]', '[անորսալի]', '5'), ('[գաղտագող]', '[գաղտագողի]', '5'), ('[առուջ]', '[առջև]', '3'), ('[երնել]', '[երևալ]', '3'), ('[ինճ]', '[ես]', '3'), ('[փնթփնթաց]', '[փնթփնթալ]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[բանաձին]', '[բանաձև]', '3'), ('[եթենա]', '[եթե]', '3'), ('[ինճ]', '[ես]', '3'), ('[փորճ]', '[փորձ]', '3'), ('[ալուֆ]', '[ալֆա]', '3'), ('[բանաձ]', '[բանաձև]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[թքած]', '[թքել]', '3'), ('[բարճրանալ]', '[բարձրացնել]', '3'), ('[Այլիս]', '[այլևս]', '3'), ('[կավինավեհ]', '[ամենավեհ]', '3'), ('[սնահեր]', '[սևահեր]', '3'), ('[պոռթում]', '[պոռթկում]', '3'), ('[բացարճակ]', '[բացարձակ]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[թեն]', '[թեև]', '3'), ('[տերն]', '[տերև]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[բարճունք]', '[բարձունք]', '3'), ('[ջրալ]', '[ջրալի]', '3'), ('[թորվել]', '[թորել]', '3'), ('[խլթխլթել]', '[խլթխլթալ]', '3'), ('[առնտուր]', '[առևտուր]', '3'), ('[անճամ]', '[անձամբ]', '3'), ('[օթին]', '[օթևան]', '3'), ('[բանաճ]', '[բանաձև]', '3'), ('[արճակել]', '[արձակել]', '3'), ('[բնեռ]', '[բևեռ]', '3'), ('[օճ]', '[օձ]', '3'), ('[ոջ]', '[ոչ]', '3'), ('[անձր]', '[անձրև]', '3'), ('[թեթն]', '[թեթև]', '3'), ('[ճգալ]', '[ձգել]', '3'), ('[լերել]', '[ուտել]', '3'), ('[տաքագնել]', '[տաքացնել]', '3'), ('[Հնայած]', '[Չնայած]', '3'), ('[ճեռք]', '[ձեռք]', '3'), ('[շրթ]', '[շրթներկ]', '3'), ('[այխքան]', '[այդքան]', '3'), ('[նարնջենու]', '[նարնջենի]', '3'), ('[թաքչել]', '[թաքցնել]', '3'), ('[ճնալ]', '[ձևացնել]', '3'), ('[զնգզնգել]', '[զնգզնգալ]', '3'), ('[գիտել]', '[իմանալ]', '3'), ('[բարճր]', '[բարձր]', '3')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to compare two strings\n",
        "import os\n",
        "def getCmnPrefix(S1, S2):\n",
        "    common = os.path.commonprefix([S1, S2])\n",
        "    return common\n",
        "\n",
        "\n",
        "def getCmnSuffix(S1,S2):\n",
        "    S1r = S1[::-1]\n",
        "    S2r = S2[::-1]\n",
        "    commonR = getCmnPrefix(S1r, S2r)\n",
        "    common = commonR[::-1]\n",
        "    return common\n",
        "\n",
        "def getDifInfix(S1, S2, LContext = 0, RContext = 0):\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    diffInfix1 = S1[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    # print('S1', S1, IPLen-LContext, -1*(ISLen)+RContext)\n",
        "    diffInfix2 = S2[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    # print('S2', S2, IPLen-LContext, -1*(ISLen)+RContext)\n",
        "    return(diffInfix1, diffInfix2)\n",
        "\n",
        "def getDifSuffix(S1, S2, LContext = 0):\n",
        "    # used if common suffix == ''\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    if ISLen == 0:\n",
        "        diffSuffix1 = S1[IPLen-LContext:]\n",
        "        diffSuffix2 = S2[IPLen-LContext:]\n",
        "    else:\n",
        "        diffSuffix1 = ''\n",
        "        diffSuffix2 = ''\n",
        "    return(diffSuffix1, diffSuffix2)\n",
        "\n",
        "def getDifPrefix(S1, S2, RContext = 0):\n",
        "    # used if common suffix == ''\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "    if IPLen == 0:\n",
        "        diffPrefix1 = S1[:-1*(ISLen)+RContext]\n",
        "        diffPrefix2 = S2[:-1*(ISLen)+RContext]\n",
        "    else:\n",
        "        diffPrefix1 = ''\n",
        "        diffPrefix2 = ''\n",
        "       \n",
        "    return(diffPrefix1, diffPrefix2)\n",
        "\n",
        "def getDiff(S1, S2, LContext = 0, RContext = 0):\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    if IPLen and ISLen:\n",
        "        diff1 = S1[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "        diff2 = S2[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "    elif IPLen: # there is a common prefix, find different suffixes\n",
        "        diff1 = S1[IPLen-LContext:]\n",
        "        diff2 = S2[IPLen-LContext:]\n",
        "    elif ISLen: # there is a common suffix, find different prefixes\n",
        "        diff1 = S1[:-1*(ISLen)+RContext]\n",
        "        diff2 = S2[:-1*(ISLen)+RContext]\n",
        "    else:\n",
        "        diff1 = S1\n",
        "        diff2 = S2\n",
        "    return (diff1, diff2)\n",
        "\n"
      ],
      "metadata": {
        "id": "w3nwDAXc_wEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first attempt, not used...\n",
        "'''\n",
        "def getDifInfix2X(S1, S2, LContext = 0, RContext = 0):\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "\n",
        "    if LContext and RContext:\n",
        "        diffInfix1 = S1[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "        diffInfix2 = S2[IPLen-LContext:-1*(ISLen)+RContext]\n",
        "        print('both')\n",
        "    elif LContext:\n",
        "        diffInfix1 = S1[IPLen-LContext:-1*(ISLen)]\n",
        "        diffInfix2 = S2[IPLen-LContext:-1*(ISLen)]\n",
        "        print('left')\n",
        "    elif RContext:\n",
        "        diffInfix1 = S1[IPLen:-1*(ISLen+RContext)]\n",
        "        diffInfix2 = S2[IPLen:-1*(ISLen+RContext)]\n",
        "        print('right')\n",
        "    else:\n",
        "        diffInfix1 = S1[IPLen:-1*ISLen]\n",
        "        diffInfix2 = S2[IPLen:-1*ISLen]\n",
        "        print('no-context')\n",
        "\n",
        "    return(diffInfix1, diffInfix2)\n",
        "\n",
        "\n",
        "\n",
        "def getDifPrefix(S1, S2, RContext = 0):\n",
        "    # used if common prefix == ''\n",
        "    IPLen = len(getCmnPrefix(S1, S2))\n",
        "    # print('IPLen', IPLen)\n",
        "    ISLen = len(getCmnSuffix(S1, S2))\n",
        "    # print('ISLen', ISLen)\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "OiP4EPl2Eene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "P12 = getCmnPrefix('перепливи', 'перелови')\n",
        "S12 = getCmnSuffix('перепливи', 'перелови')\n",
        "# I1, I2 = getDifInfix('перепливи', 'перелови')\n",
        "# print(P12, S12)\n",
        "# print(I1, I2)\n",
        "\n",
        "I1, I2 = getDifInfix('перепливи', 'перелови', LContext = 0, RContext = 0)\n",
        "print(I1, I2)\n",
        "\n",
        "S1, S2 = getDifSuffix('розгубився', 'розгубивсь', LContext = 0)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDifSuffix('розгубився', 'розгубивс', LContext = 0)\n",
        "print(S1, S2)\n",
        "\n",
        "S1, S2 = getDifPrefix('вловив', 'зловив', RContext = 0)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDifPrefix('ловив', 'зловив', RContext = 0)\n",
        "print(S1, S2)\n",
        "\n",
        "print('new version....')\n",
        "I1, I2 = getDiff('перепливи', 'перелови', LContext = 1, RContext = 1)\n",
        "print(I1, I2)\n",
        "\n",
        "S1, S2 = getDiff('розгубився', 'розгубивсь', LContext = 1)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDiff('розгубився', 'розгубивс', LContext = 1)\n",
        "print(S1, S2)\n",
        "\n",
        "S1, S2 = getDiff('вловив', 'зловив', RContext = 1)\n",
        "print(S1, S2)\n",
        "S1, S2 = getDiff('ловив', 'зловив', RContext = 1)\n",
        "print(S1, S2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrcT9UPL_1G-",
        "outputId": "43c1e177-f1f8-4bb2-dc9e-97f62c1ee56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "пли ло\n",
            "я ь\n",
            "я \n",
            "в з\n",
            " з\n",
            "new version....\n",
            "еплив елов\n",
            "ся сь\n",
            "ся с\n",
            "вл зл\n",
            "л зл\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOut = open('Parfum_Armenian-freq-diff-Changes2.txt', 'w')\n",
        "\n",
        "DChanges = {}\n",
        "for SWrong, SRight in LTWrongCorrectW:\n",
        "    P12 = getCmnPrefix(SWrong, SRight)\n",
        "    S12 = getCmnSuffix(SWrong, SRight)\n",
        "    I1, I2 = getDiff(SWrong, SRight, LContext = 2, RContext =2)\n",
        "    try:\n",
        "        DChanges[(I1, I2)] += 1\n",
        "    except:\n",
        "        DChanges[(I1, I2)] = 1\n",
        "\n",
        "    print(SWrong, '(' , P12, '<', I1, '|', I2, '>', S12, ')', SRight)\n",
        "    FOut.write(f'{SWrong} ( {P12} < {I1} | {I2} > {S12} ) {SRight}\\n')\n",
        "\n",
        "for SWrong, SRight in LTWrongCorrectL:\n",
        "    P12 = getCmnPrefix(SWrong, SRight)\n",
        "    S12 = getCmnSuffix(SWrong, SRight)\n",
        "    I1, I2 = getDiff(SWrong, SRight, LContext = 2, RContext = 2)\n",
        "    try:\n",
        "        DChanges[(I1, I2)] += 1\n",
        "    except:\n",
        "        DChanges[(I1, I2)] = 1\n",
        "\n",
        "    print(SWrong, '(' , P12, '<', I1, '|', I2, '>', S12, ')', SRight)\n",
        "    FOut.write(f'{SWrong} ( {P12} < {I1} | {I2} > {S12} ) {SRight}\\n')\n",
        "FOut.flush()\n",
        "\n",
        "\n",
        "FOut = open('Parfum_Armenian-freq-diff-ChangeDict2.txt', 'w')\n",
        "for key, value in sorted(DChanges.items(), key=lambda item: item[1], reverse=True):\n",
        "    L, R = key\n",
        "    FOut.write(f'{L}\\t{R}\\t{value}\\n')\n",
        "\n",
        "FOut.flush()\n"
      ],
      "metadata": {
        "id": "WYvbFevMLh4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## the same with integration of frq information:\n",
        "FOut = open('ChangesF2.txt', 'w')\n",
        "\n",
        "DChanges = {}\n",
        "for SWrong, SRight, SFrq in LTWrongCorrectWf:\n",
        "    try:\n",
        "        IFrq = int(SFrq)\n",
        "    except:\n",
        "        IFrq = 1\n",
        "    P12 = getCmnPrefix(SWrong, SRight)\n",
        "    S12 = getCmnSuffix(SWrong, SRight)\n",
        "    I1, I2 = getDiff(SWrong, SRight, LContext = 2, RContext =2)\n",
        "    try:\n",
        "        DChanges[(I1, I2)] += IFrq\n",
        "    except:\n",
        "        DChanges[(I1, I2)] = IFrq\n",
        "\n",
        "    print(SWrong, '(' , P12, '<', I1, '|', I2, '>', S12, ')', SRight)\n",
        "    FOut.write(f'{SWrong} ( {P12} < {I1} | {I2} > {S12} ) {SRight}\\n')\n",
        "\n",
        "for SWrong, SRight, SFrq in LTWrongCorrectLf:\n",
        "    try:\n",
        "        IFrq = int(SFrq)\n",
        "    except:\n",
        "        IFrq = 1\n",
        "    P12 = getCmnPrefix(SWrong, SRight)\n",
        "    S12 = getCmnSuffix(SWrong, SRight)\n",
        "    I1, I2 = getDiff(SWrong, SRight, LContext = 2, RContext = 2)\n",
        "    try:\n",
        "        DChanges[(I1, I2)] += IFrq\n",
        "    except:\n",
        "        DChanges[(I1, I2)] = IFrq\n",
        "\n",
        "    print(SWrong, '(' , P12, '<', I1, '|', I2, '>', S12, ')', SRight)\n",
        "    FOut.write(f'{SWrong} ( {P12} < {I1} | {I2} > {S12} ) {SRight}\\n')\n",
        "FOut.flush()\n",
        "\n",
        "\n",
        "FOut = open('ChangeDictF2.txt', 'w')\n",
        "for key, value in sorted(DChanges.items(), key=lambda item: item[1], reverse=True):\n",
        "    L, R = key\n",
        "    if L != '' and R != '' and L != R:\n",
        "        FOut.write(f'{L}\\t{R}\\t{value}\\n')\n",
        "\n",
        "FOut.flush()"
      ],
      "metadata": {
        "id": "ysYJ0tNlgQWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cat /content/ChangeDictF1.txt | tail -n+2 >/content/ChangeDictF1a.txt\n",
        "# !cat /content/ChangeDictF2.txt | tail -n+2 >/content/ChangeDictF2a.txt\n"
      ],
      "metadata": {
        "id": "NAJj1pFbbYFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv /content/ChangeDictF1.txt /content/KorpusARM1/\n",
        "# !mv /content/ChangeDictF2.txt /content/KorpusARM1/\n"
      ],
      "metadata": {
        "id": "VWuQmKh0b6Pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ChangeDict* >ChangesDFAll.txt"
      ],
      "metadata": {
        "id": "2Emh_YkgcEPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all substrings of a string\n",
        "# https://www.geeksforgeeks.org/python-get-all-substrings-of-given-string/\n",
        "\n",
        "'''\n",
        "# Python3 code to demonstrate working of\n",
        "# Get all substrings of string\n",
        "# Using list comprehension + string slicing\n",
        " \n",
        "# initializing string\n",
        "test_str = \"Geeks\"\n",
        " \n",
        "# printing original string\n",
        "print(\"The original string is : \" + str(test_str))\n",
        " \n",
        "# Get all substrings of string\n",
        "# Using list comprehension + string slicing\n",
        "res = [test_str[i: j] for i in range(len(test_str))\n",
        "          for j in range(i + 1, len(test_str) + 1)]\n",
        " \n",
        "# printing result\n",
        "print(\"All substrings of string are : \" + str(res))\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "sxsNB2wpfMB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we read wikipedia file into a frq dictionary, and generate all substrings for each string, and create a frq dictionary of substrings\n",
        "\n",
        "def corp2tokLim2frqDict(SFIn):\n",
        "    DFrq = {}\n",
        "    with open(SFIn) as FIn:\n",
        "        for SLine in FIn:\n",
        "            SLine = SLine.rstrip()\n",
        "            # LLine = SLine.split('\\t')\n",
        "            LLine = re.split('[ ,:\\.;\\-\\(\\)\\?\\!\\[\\]]+', SLine)\n",
        "            for tok in LLine:\n",
        "                tokLim = f'[{tok}]'\n",
        "                try:\n",
        "                    DFrq[tokLim]+=1\n",
        "                except:\n",
        "                    DFrq[tokLim]=1\n",
        "    return DFrq\n",
        "\n",
        "def printFrqDict(DFrq, SFOut):\n",
        "    FOut = open(SFOut, 'w')\n",
        "    count = 0\n",
        "    for key, val in sorted(DFrq.items(), key=lambda item: item[1], reverse=True):\n",
        "        count+=1\n",
        "        FOut.write(f'{count}\\t{key}\\t{val}\\n')\n",
        "    FOut.flush()"
      ],
      "metadata": {
        "id": "6Da_G5V7fRyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runs 1 min\n",
        "DTokLimFrqWikipedia = corp2tokLim2frqDict('/content/hywiki-20221101-pages-articles.txt')\n",
        "printFrqDict(DTokLimFrqWikipedia, 'hywiki-20221101-frq-dict.txt')"
      ],
      "metadata": {
        "id": "KZylzND3hV3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc hywiki-20221101-frq-dict.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynPxdqAViRVW",
        "outputId": "dda63d17-a9cc-4aed-df0f-9bf33fd707f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 2586453  7759467 78654850 hywiki-20221101-frq-dict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 40 hywiki-20221101-frq-dict.txt"
      ],
      "metadata": {
        "id": "ptwD72KGhzz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readChangesLeft2dict(SFIn):\n",
        "    DFrq = {}\n",
        "    DRepl = {}\n",
        "    with open(SFIn) as FIn:\n",
        "        for SLine in FIn:\n",
        "            SLine = SLine.rstrip()\n",
        "            LLine = SLine.split('\\t')\n",
        "            try:\n",
        "                L = LLine[0]\n",
        "                R = LLine[1]\n",
        "                SFrq = LLine[2]\n",
        "                IFrq = int(SFrq)\n",
        "                DFrq[L]=IFrq\n",
        "                DRepl[L]= R\n",
        "\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return DFrq, DRepl\n"
      ],
      "metadata": {
        "id": "e4FRPx7civV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DFrqChangesL, DFrqChangesReplacements = readChangesLeft2dict('/content/ChangesDFAll.txt')\n",
        "printFrqDict(DFrqChangesL, 'ChangesDFLeftAll.txt')"
      ],
      "metadata": {
        "id": "myYLG3iSjnXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing string\n",
        "test_str = \"Geeks\"\n",
        " \n",
        "# printing original string\n",
        "print(\"The original string is : \" + str(test_str))\n",
        " \n",
        "# Get all substrings of string\n",
        "# Using list comprehension + string slicing\n",
        "res = [test_str[i: j] for i in range(len(test_str))\n",
        "          for j in range(i + 1, len(test_str) + 1)]\n",
        " \n",
        "# printing result\n",
        "print(\"All substrings of string are : \" + str(res))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxOfk2V0k7Ug",
        "outputId": "5749082b-a141-43f2-d911-297a3ac3febd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The original string is : Geeks\n",
            "All substrings of string are : ['G', 'Ge', 'Gee', 'Geek', 'Geeks', 'e', 'ee', 'eek', 'eeks', 'e', 'ek', 'eks', 'k', 'ks', 's']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frqDict2substrDict(DFrq,FrqThreshold=0):\n",
        "    DFrqSubStr = {}\n",
        "    for test_str, frq in DFrq.items():\n",
        "        if frq <= FrqThreshold: continue\n",
        "        LSubStr = [test_str[i: j] for i in range(len(test_str)) for j in range(i + 1, len(test_str) + 1)]\n",
        "        for el in LSubStr:\n",
        "            try:\n",
        "                DFrqSubStr[el] += frq\n",
        "            except:\n",
        "                DFrqSubStr[el] = frq\n",
        "    return DFrqSubStr"
      ],
      "metadata": {
        "id": "nigd8Hclkfu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# runs approx 1.5 min\n",
        "DFrqSubstringsWiki = frqDict2substrDict(DTokLimFrqWikipedia, FrqThreshold = 1)\n",
        "printFrqDict(DFrqSubstringsWiki, '/content/hywiki-20221101-frq-dict-substrings.txt')"
      ],
      "metadata": {
        "id": "T2DlSaRclum9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc /content/hywiki-20221101-frq-dict-substrings.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me5_C5MCmlbf",
        "outputId": "ad44ac54-d123-4ce0-914b-808e27c1bbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 12755762  38267464 361186819 /content/hywiki-20221101-frq-dict-substrings.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 40 /content/hywiki-20221101-frq-dict-substrings.txt"
      ],
      "metadata": {
        "id": "SE5dGJf8mptq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOutLeft = open('ChangesDLeftNinWiki.txt', 'w')\n",
        "for L, frqL in sorted(DFrqChangesL.items(), key=lambda item: item[1], reverse=True):\n",
        "    if L not in DFrqSubstringsWiki.keys():\n",
        "        try:\n",
        "            R = DFrqChangesReplacements[L]\n",
        "        except:\n",
        "            R = 'NONE'\n",
        "        FOutLeft.write(f'{L}\\t{R}\\t{str(frqL)}\\n')\n",
        "\n",
        "FOutLeft.flush()"
      ],
      "metadata": {
        "id": "Aqw1YVcrm2ii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}