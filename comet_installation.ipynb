{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iued-uni-heidelberg/corpustools/blob/main/comet_installation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snDEkpImrK0C"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install unbabel-comet"
      ],
      "metadata": {
        "id": "kLwwHrB5rQu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Unbabel/COMET"
      ],
      "metadata": {
        "id": "cMqOrTXorXEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install poetry"
      ],
      "metadata": {
        "id": "sXisbFDArm6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ./COMET/\n",
        "!pwd\n",
        "!poetry install"
      ],
      "metadata": {
        "id": "9HxCAg72r_-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7MyerCOrw6n",
        "outputId": "dad7b8a7-2edd-4299-89bb-212674694d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod a+rwx /content/COMET/comet/cli/score.py"
      ],
      "metadata": {
        "id": "VVa96dPks6tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFhISPuwtkLa",
        "outputId": "2e85f574-c77b-453d-b4c1-21d31bae5af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=\"$/env/python:./comet/cli/score.py\"\n",
        "# !PYTHONPATH=. ./comet/cli/score.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBSTZLrnsp9B",
        "outputId": "9fce7b49-4f19-4234-f17b-13e053d98934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\"$/env/python:./comet/cli/score.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js1u83GWt2_3",
        "outputId": "74fb6b4a-dd75-402f-d2e8-69afec9b97e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python:./comet/cli/score.py\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo -e \"Dem Feuer konnte Einhalt geboten werden\\nSchulen und Kindergärten wurden eröffnet.\" >> src.de\n",
        "!echo -e \"The fire could be stopped\\nSchools and kindergartens were open\" >> hyp1.en\n",
        "!echo -e \"The fire could have been stopped\\nSchools and pre-school were open\" >> hyp2.en\n",
        "!echo -e \"They were able to control the fire.\\nSchools and kindergartens opened\" >> ref.en"
      ],
      "metadata": {
        "id": "m8-mpjhjtMQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp1.en -r ref.en --gpus 0 >results.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT3FjFRSuP22",
        "outputId": "e10b697f-cbc4-4ec6-916c-46dc85afba8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "Predicting DataLoader 0: 100% 1/1 [00:01<00:00,  1.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp1.en -r ref.en >>results.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN8xWy5aVfA2",
        "outputId": "0c2919e0-a325-49bf-8ea1-7c51ead3193e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Predicting DataLoader 0: 100% 1/1 [00:03<00:00,  3.55s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp2.en -r ref.en >>results.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tx5ch2XVjce",
        "outputId": "f6b938b5-36ef-4d42-94ad-2bde12375390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Predicting DataLoader 0: 100% 1/1 [00:03<00:00,  3.47s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s src.de -t hyp2.en -r ref.en --gpus 0 >>results.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0np0nGXuo8H",
        "outputId": "a2ec2203-d318-4bee-ca23-1b8be77f9def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1814: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "Predicting DataLoader 0: 100% 1/1 [00:01<00:00,  1.40s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/84df50ae57cf4851b4ba/?dl=1"
      ],
      "metadata": {
        "id": "TRCKtpXr-TLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 exArticles.zip"
      ],
      "metadata": {
        "id": "J-VzSNox-Z94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip exArticles.zip"
      ],
      "metadata": {
        "id": "KCREoJFRYzok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading articles..."
      ],
      "metadata": {
        "id": "X2t6JXQW_ey5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8YDOE0pYen2",
        "outputId": "ea23e8e2-2752-4b94-dcdf-c1e48b2e8032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COMET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s /content/article-aerzteblatt-2023-01-101-de.txt"
      ],
      "metadata": {
        "id": "VIOCrdHxYUb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s /content/article-aerzteblatt-2023-01-101-de.txt -t /content/article-aerzteblatt-2023-01-101-en-googlemt.txt -r /content/article-aerzteblatt-2023-01-101-en.txt >results2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s27T5PQfFCj2",
        "outputId": "6e1c4a6d-c811-4d35-9424-f6fe7b8b9e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Predicting DataLoader 0: 100% 13/13 [00:05<00:00,  2.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!comet-score -s /content/article-aerzteblatt-2023-01-101-de.txt -t /content/article-aerzteblatt-2023-01-101-en-deeplmt.txt -r /content/article-aerzteblatt-2023-01-101-en.txt >>results2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cklNdfudGaDF",
        "outputId": "111c3d77-7171-4f32-de98-bd9bdb9f7ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 12\n",
            "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Predicting DataLoader 0: 100% 13/13 [00:05<00:00,  2.20it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOJVvpLVe_X6",
        "outputId": "a5de6d42-f2fb-4b29-b741-cb6298151b7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-26 14:29:49--  https://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223646468 (213M) [application/x-gzip]\n",
            "Saving to: ‘meteor-1.5.tar.gz’\n",
            "\n",
            "meteor-1.5.tar.gz   100%[===================>] 213.29M  4.59MB/s    in 50s     \n",
            "\n",
            "2023-01-26 14:30:40 (4.23 MB/s) - ‘meteor-1.5.tar.gz’ saved [223646468/223646468]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf meteor-1.5.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHrNYpmBfEgZ",
        "outputId": "91bc1fa0-0a66-46f3-82ff-ed9be3630cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meteor-1.5/\n",
            "meteor-1.5/data/\n",
            "meteor-1.5/data/paraphrase-es.gz\n",
            "meteor-1.5/data/paraphrase-cz.gz\n",
            "meteor-1.5/data/paraphrase-fr.gz\n",
            "meteor-1.5/data/paraphrase-en.gz\n",
            "meteor-1.5/data/paraphrase-de.gz\n",
            "meteor-1.5/data/paraphrase-ru.gz\n",
            "meteor-1.5/xray/\n",
            "meteor-1.5/xray/visualize_alignments.py\n",
            "meteor-1.5/xray/template/\n",
            "meteor-1.5/xray/template/score.tex\n",
            "meteor-1.5/xray/xray.py\n",
            "meteor-1.5/xray/MeteorAlignment.py\n",
            "meteor-1.5/xray/Generation.py\n",
            "meteor-1.5/scripts/\n",
            "meteor-1.5/scripts/sgmlize.py\n",
            "meteor-1.5/scripts/meteor_shower.py\n",
            "meteor-1.5/scripts/unroll_wmt_ranks.py\n",
            "meteor-1.5/scripts/meteorToMosesAlign.py\n",
            "meteor-1.5/scripts/delete_stray_matches.py\n",
            "meteor-1.5/scripts/bleu.py\n",
            "meteor-1.5/scripts/wmt_bleu.py\n",
            "meteor-1.5/scripts/tc_train_set.py\n",
            "meteor-1.5/scripts/wmt_ter.py\n",
            "meteor-1.5/scripts/freq.py\n",
            "meteor-1.5/scripts/filter_merge_rank_set.py\n",
            "meteor-1.5/scripts/wmt-eval.sh\n",
            "meteor-1.5/scripts/new_language.py\n",
            "meteor-1.5/scripts/tercom-0.8.0.jar\n",
            "meteor-1.5/scripts/ter.py\n",
            "meteor-1.5/scripts/agg.py\n",
            "meteor-1.5/scripts/build_wordnet_files.py\n",
            "meteor-1.5/scripts/combine_segcor_trainset.py\n",
            "meteor-1.5/scripts/rankconsist.py\n",
            "meteor-1.5/scripts/wmt_fmt.py\n",
            "meteor-1.5/scripts/mteval-v13m.pl\n",
            "meteor-1.5/README.html\n",
            "meteor-1.5/INSTALL\n",
            "meteor-1.5/resources/\n",
            "meteor-1.5/resources/stem/\n",
            "meteor-1.5/resources/stem/arabic-buckwalter-reduced.gz\n",
            "meteor-1.5/resources/nonbreaking/\n",
            "meteor-1.5/resources/nonbreaking/english.prefixes\n",
            "meteor-1.5/resources/nonbreaking/french.prefixes\n",
            "meteor-1.5/resources/nonbreaking/russian.prefixes\n",
            "meteor-1.5/resources/nonbreaking/german.prefixes\n",
            "meteor-1.5/resources/nonbreaking/spanish.prefixes\n",
            "meteor-1.5/resources/nonbreaking/czech.prefixes\n",
            "meteor-1.5/resources/synonym/\n",
            "meteor-1.5/resources/synonym/COPYING.WORDNET\n",
            "meteor-1.5/resources/synonym/english.synsets\n",
            "meteor-1.5/resources/synonym/english.exceptions\n",
            "meteor-1.5/resources/synonym/english.relations\n",
            "meteor-1.5/resources/function/\n",
            "meteor-1.5/resources/function/french.words\n",
            "meteor-1.5/resources/function/russian.words\n",
            "meteor-1.5/resources/function/romanian.words\n",
            "meteor-1.5/resources/function/dutch.words\n",
            "meteor-1.5/resources/function/arabic-buckwalter-reduced.words\n",
            "meteor-1.5/resources/function/portuguese.words\n",
            "meteor-1.5/resources/function/turkish.words\n",
            "meteor-1.5/resources/function/norwegian.words\n",
            "meteor-1.5/resources/function/danish.words\n",
            "meteor-1.5/resources/function/swedish.words\n",
            "meteor-1.5/resources/function/other.words\n",
            "meteor-1.5/resources/function/italian.words\n",
            "meteor-1.5/resources/function/english.words\n",
            "meteor-1.5/resources/function/spanish.words\n",
            "meteor-1.5/resources/function/czech.words\n",
            "meteor-1.5/resources/function/hungarian.words\n",
            "meteor-1.5/resources/function/german.words\n",
            "meteor-1.5/resources/function/finnish.words\n",
            "meteor-1.5/COPYING\n",
            "meteor-1.5/mt-diff/\n",
            "meteor-1.5/mt-diff/mt-diff.py\n",
            "meteor-1.5/mt-diff/files/\n",
            "meteor-1.5/mt-diff/files/mteval-v13m.pl\n",
            "meteor-1.5/example/\n",
            "meteor-1.5/example/xray/\n",
            "meteor-1.5/example/xray/reference\n",
            "meteor-1.5/example/xray/system1.hyp\n",
            "meteor-1.5/example/xray/system2.hyp\n",
            "meteor-1.5/example/tune/\n",
            "meteor-1.5/example/tune/example.score.in\n",
            "meteor-1.5/example/tune/example.eval.in\n",
            "meteor-1.5/example/tune/example.score.out\n",
            "meteor-1.5/example/tune/example.eval.out\n",
            "meteor-1.5/example/meteor-seg.scr\n",
            "meteor-1.5/example/meteor-sys.scr\n",
            "meteor-1.5/example/train/\n",
            "meteor-1.5/example/train/fr-en.sys2\n",
            "meteor-1.5/example/train/fr-en.sys1\n",
            "meteor-1.5/example/train/fr-en.ref\n",
            "meteor-1.5/example/train/fr-en.rank\n",
            "meteor-1.5/example/ref.sgm\n",
            "meteor-1.5/example/test.sgm\n",
            "meteor-1.5/example/meteor-doc.scr\n",
            "meteor-1.5/build.xml\n",
            "meteor-1.5/src/\n",
            "meteor-1.5/src/Trainer.java\n",
            "meteor-1.5/src/FilterParaphrase.java\n",
            "meteor-1.5/src/Meteor.java\n",
            "meteor-1.5/src/SGMtoPlaintext.java\n",
            "meteor-1.5/src/org/\n",
            "meteor-1.5/src/org/tartarus/\n",
            "meteor-1.5/src/org/tartarus/snowball/\n",
            "meteor-1.5/src/org/tartarus/snowball/Among.java\n",
            "meteor-1.5/src/org/tartarus/snowball/SnowballStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/germanStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/russianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/swedishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/hungarianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/turkishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/romanianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/dutchStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/danishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/portugueseStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/englishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/finnishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/porterStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/italianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/norwegianStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/spanishStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/ext/frenchStemmer.java\n",
            "meteor-1.5/src/org/tartarus/snowball/SnowballProgram.java\n",
            "meteor-1.5/src/Parex.java\n",
            "meteor-1.5/src/edu/\n",
            "meteor-1.5/src/edu/cmu/\n",
            "meteor-1.5/src/edu/cmu/meteor/\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorScorer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorStats.java\n",
            "meteor-1.5/src/edu/cmu/meteor/scorer/MeteorConfiguration.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ParaphraseTransducer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SynonymDictionary.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ExactMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/ParaphraseMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Alignment.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Match.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/LookupTableStemmer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Stage.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SnowballStemmerWrapper.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/StemMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Aligner.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/PartialAlignment.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/Stemmer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/aligner/SynonymMatcher.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/\n",
            "meteor-1.5/src/edu/cmu/meteor/util/Constants.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/Normalizer.java\n",
            "meteor-1.5/src/edu/cmu/meteor/util/SGMData.java\n",
            "meteor-1.5/src/edu/cmu/parex/\n",
            "meteor-1.5/src/edu/cmu/parex/PhraseTable.java\n",
            "meteor-1.5/src/edu/cmu/parex/ParaphraseExtractor.java\n",
            "meteor-1.5/src/edu/cmu/parex/Paraphrase.java\n",
            "meteor-1.5/src/Matcher.java\n",
            "meteor-1.5/src/Stemmer.java\n",
            "meteor-1.5/meteor-1.5.jar\n"
          ]
        }
      ]
    }
  ]
}